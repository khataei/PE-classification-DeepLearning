{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ahUZuAfz8Jje"
   },
   "source": [
    "# Sklearn Tuner for CNN Activity Classifier - V2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Re0ecmVI8Jjk"
   },
   "source": [
    "In this notebook, we use SKlearn  to tune a CNN neural net to classify PE activity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ixsGb9tY8Jjm"
   },
   "source": [
    "#### Load dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5At1PKQp8Jjp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 5830697819915717075\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 14026761192917927219\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 4022219571\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 9042929706644495121\n",
      "physical_device_desc: \"device: 0, name: Quadro P2000, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 3859967937030855165\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      "]\n",
      "# GPUs Available:  1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.3.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os  \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "import tensorflow\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, Conv1D, GlobalMaxPooling1D\n",
    "from tensorflow.keras.layers import AveragePooling1D, LeakyReLU , MaxPool1D, GlobalAveragePooling1D\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint \n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, roc_curve \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "print(device_lib.list_local_devices())\n",
    "import tensorflow as tf\n",
    "print(\"# GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "tensorflow.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hg5wX2Dd8Jjz"
   },
   "source": [
    "#### Set hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lYLOM99-8Jj2"
   },
   "outputs": [],
   "source": [
    "# output directory name:\n",
    "output_dir = 'model_output/tunecnn-sklearn-2'\n",
    "input_dir =  'Z:/Research/dfuller/Walkabilly/studies/smarphone_accel/data/Ethica_Jaeger_Merged/pocket/'\n",
    "input_file_name = 'pocket-NN-data.npz'\n",
    "\n",
    "# from the data preparation section we have:\n",
    "window_size_second = 3\n",
    "frequency = 30\n",
    "lenght_of_each_seq = window_size_second * frequency\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn hyperparams\n",
    "params = {\n",
    "    'n_conv_1':[512, 768], # filters, a.k.a. kernels\n",
    "    'k_conv_1':[2, 3], # kernel length\n",
    "    'n_conv_2':[256, 512], # filters, a.k.a. kernels\n",
    "    'k_conv_2':[2, 3], # kernel length\n",
    "    'n_conv_3':[256, 512], # filters, a.k.a. kernels\n",
    "    'k_conv_3':[2, 3], # kernel length\n",
    "    'maxpooling_pool_size':[3],\n",
    "    'avepooling_pool_size':[3],\n",
    "    'n_dense_1':[256, 512],\n",
    "    'dropout_1':[0.2, 0.3],\n",
    "    'n_dense_2':[256, 512],\n",
    "    'dropout_2':[0.25],\n",
    "    'activation_conv':['elu', 'relu', LeakyReLU()],\n",
    "    'activation_dense':['elu', 'relu', LeakyReLU()]\n",
    "}\n",
    "\n",
    "# training:\n",
    "n_tune_iter = 30\n",
    "cv = 3\n",
    "epochs = 60\n",
    "batch_size = 256\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DaLx4yZ48Jj9"
   },
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CD9X0yJg8Jj_"
   },
   "source": [
    "##### For this notebook we use the acceleration data gathered from the pocket location. It was prepared in the DataPrep-Deep notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6r44JKj-8JkA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acceleration_data\n",
      "metadata\n",
      "labels\n"
     ]
    }
   ],
   "source": [
    "# read the raw file and get the keys:\n",
    "raw_data = np.load(file=input_dir+input_file_name,allow_pickle=True)\n",
    "for k in raw_data.keys():\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the data\n",
    "\n",
    "accel_array = raw_data['acceleration_data']\n",
    "meta_array = raw_data['metadata']\n",
    "labels_array = raw_data['labels']\n",
    "input_shape = list(accel_array.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WWq3ipbu8JlG"
   },
   "source": [
    "#### Preprocess data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert the  labels to integer.\n",
    "In the raw data format of the labels is String and there are 6 classes. 'Lying', 'Sitting', 'Self Pace walk', 'Running 3 METs',\n",
    "       'Running 5 METs', 'Running 7 METs' <br>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LyReiequ8Jln"
   },
   "outputs": [],
   "source": [
    "n_class = len(np.unique(labels_array))\n",
    "class_list, labels_array_int = np.unique(labels_array,return_inverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = to_categorical(labels_array_int, num_classes=n_class)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "40x3s0KY8Jlv",
    "outputId": "d3ac3e31-3c47-4b01-c2f9-ada0684b31b7"
   },
   "source": [
    "### Splitting and shuffeling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f5grc2H78Jlz",
    "outputId": "3f7eeb55-f851-4796-de4e-0c68eb9df88d"
   },
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "     accel_array, y, test_size=0.1, random_state=65)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "GscSnCpk8Jlm"
   },
   "source": [
    "\n",
    "#### Design neural network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_conv_1': [512, 768],\n",
       " 'k_conv_1': [2, 3],\n",
       " 'n_conv_2': [256, 512],\n",
       " 'k_conv_2': [2, 3],\n",
       " 'n_conv_3': [256, 512],\n",
       " 'k_conv_3': [2, 3],\n",
       " 'maxpooling_pool_size': [3],\n",
       " 'avepooling_pool_size': [3],\n",
       " 'n_dense_1': [256, 512],\n",
       " 'dropout_1': [0.2, 0.3],\n",
       " 'n_dense_2': [256, 512],\n",
       " 'dropout_2': [0.25],\n",
       " 'activation_conv': ['elu',\n",
       "  'relu',\n",
       "  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU at 0x1fab9652c88>],\n",
       " 'activation_dense': ['elu',\n",
       "  'relu',\n",
       "  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU at 0x1fab97d27c8>]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(n_conv_1=256, k_conv_1=3, n_conv_2=256, k_conv_2=3, n_conv_3=256, k_conv_3=3,\n",
    "                 maxpooling_pool_size = 2, avepooling_pool_size = 2, n_dense_1=256, dropout_1=0.2,\n",
    "                 n_dense_2=256, dropout_2=0.2, activation_conv= 'relu', activation_dense= 'elu'\n",
    "                ):\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(n_conv_1, k_conv_1, activation=activation_conv, input_shape=input_shape[1:]))\n",
    "    model.add(MaxPool1D(pool_size = maxpooling_pool_size))\n",
    "    model.add(Conv1D(n_conv_2, k_conv_2, activation=activation_conv))\n",
    "    model.add(AveragePooling1D(pool_size = avepooling_pool_size))\n",
    "    model.add(Conv1D(n_conv_3, k_conv_3, activation=activation_conv))\n",
    "    # model.add(GlobalMaxPooling1D())\n",
    "    model.add(GlobalAveragePooling1D())\n",
    "    model.add(Dense(n_dense_1, activation=activation_dense))\n",
    "    model.add(Dropout(dropout_1))\n",
    "    model.add(Dense(n_dense_2, activation=activation_dense))\n",
    "    model.add(Dropout(dropout_2))\n",
    "    model.add(Dense(n_class, activation='softmax'))\n",
    "#     model.summary()\n",
    "    print(f\"\"\"n_conv_1 = {n_conv_1}, k_conv_1 = {k_conv_1},  n_conv_2 = {n_conv_2}, k_conv_2 = {k_conv_2}, \n",
    "          n_conv_3 = {n_conv_3},  k_conv_3 = {k_conv_3},  maxpooling_pool_size = {maxpooling_pool_size},\n",
    "          avepooling_pool_size = {avepooling_pool_size},  n_dense_1 = {n_dense_1}, dropout_1 = {dropout_1},\n",
    "          n_dense_2 = {n_dense_2}, dropout_2 = {dropout_2}, activation_conv=  {activation_conv},\n",
    "          activation_dense=  {activation_dense}\"\"\")\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_conv_1 = 256, k_conv_1 = 3,  n_conv_2 = 256, k_conv_2 = 3, \n",
      "          n_conv_3 = 256,  k_conv_3 = 3,  maxpooling_pool_size = 2,\n",
      "          avepooling_pool_size = 2,  n_dense_1 = 256, dropout_1 = 0.2,\n",
      "          n_dense_2 = 256, dropout_2 = 0.2, activation_conv=  relu,\n",
      "          activation_dense=  elu\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 88, 256)           2560      \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 44, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 42, 256)           196864    \n",
      "_________________________________________________________________\n",
      "average_pooling1d (AveragePo (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 19, 256)           196864    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 1542      \n",
      "=================================================================\n",
      "Total params: 529,414\n",
      "Trainable params: 529,414\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_default = create_model()\n",
    "model_default.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasClassifier(build_fn=create_model, epochs=epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_conv_1 = 768, k_conv_1 = 2,  n_conv_2 = 256, k_conv_2 = 3, \n",
      "          n_conv_3 = 512,  k_conv_3 = 3,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 512, dropout_1 = 0.3,\n",
      "          n_dense_2 = 256, dropout_2 = 0.25, activation_conv=  elu,\n",
      "          activation_dense=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001FAC0EED048>\n",
      "Epoch 1/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 1.1788 - accuracy: 0.5048\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 1.0486 - accuracy: 0.5526\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.9630 - accuracy: 0.5897\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.8955 - accuracy: 0.6246\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.8301 - accuracy: 0.6529\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.7811 - accuracy: 0.6744\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.7419 - accuracy: 0.6928\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.7131 - accuracy: 0.7046\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.6746 - accuracy: 0.7223\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.6436 - accuracy: 0.7398\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.6152 - accuracy: 0.7479\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.5987 - accuracy: 0.7568\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.5709 - accuracy: 0.7706\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.5419 - accuracy: 0.7827\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.5287 - accuracy: 0.7892\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.5081 - accuracy: 0.8012\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.5002 - accuracy: 0.8045\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.4970 - accuracy: 0.8033\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.4776 - accuracy: 0.8149\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.4692 - accuracy: 0.8183\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.4553 - accuracy: 0.8242\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.4450 - accuracy: 0.8258\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.4382 - accuracy: 0.8315\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.4276 - accuracy: 0.8346\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.4223 - accuracy: 0.8365\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.4120 - accuracy: 0.8392\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.4106 - accuracy: 0.8420\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.4072 - accuracy: 0.8429\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.3962 - accuracy: 0.8474\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3881 - accuracy: 0.8488\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.3793 - accuracy: 0.8532\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3827 - accuracy: 0.8523\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3846 - accuracy: 0.8508\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.3696 - accuracy: 0.8568\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3593 - accuracy: 0.8599\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3588 - accuracy: 0.8612\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3561 - accuracy: 0.8605\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3450 - accuracy: 0.8657\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3398 - accuracy: 0.8666\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3350 - accuracy: 0.8668\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3338 - accuracy: 0.8703\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3298 - accuracy: 0.8703\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3234 - accuracy: 0.8732\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3181 - accuracy: 0.8734\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3159 - accuracy: 0.8742\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3150 - accuracy: 0.8767\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3065 - accuracy: 0.8787\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3091 - accuracy: 0.8783\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2969 - accuracy: 0.8815\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3026 - accuracy: 0.8791\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2956 - accuracy: 0.8822\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2950 - accuracy: 0.8823\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2829 - accuracy: 0.8875\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2920 - accuracy: 0.8837\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2814 - accuracy: 0.8873\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2780 - accuracy: 0.8889\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2769 - accuracy: 0.8909\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2776 - accuracy: 0.8905\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2629 - accuracy: 0.8946\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2669 - accuracy: 0.8924\n",
      "76/76 [==============================] - 1s 17ms/step - loss: 0.3082 - accuracy: 0.8898\n",
      "n_conv_1 = 768, k_conv_1 = 2,  n_conv_2 = 256, k_conv_2 = 3, \n",
      "          n_conv_3 = 512,  k_conv_3 = 3,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 512, dropout_1 = 0.3,\n",
      "          n_dense_2 = 256, dropout_2 = 0.25, activation_conv=  elu,\n",
      "          activation_dense=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001FAC0DCEE08>\n",
      "Epoch 1/60\n",
      "  1/152 [..............................] - ETA: 3s - loss: 1.7971 - accuracy: 0.1523WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0150s vs `on_train_batch_end` time: 0.0249s). Check your callbacks.\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 1.1742 - accuracy: 0.5030\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 1.0465 - accuracy: 0.5537\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.9648 - accuracy: 0.5923\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.9064 - accuracy: 0.6163\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.8440 - accuracy: 0.6503\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.8074 - accuracy: 0.6649\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.7428 - accuracy: 0.6928\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.7140 - accuracy: 0.7071\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.6635 - accuracy: 0.7325\n",
      "Epoch 10/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 6s 39ms/step - loss: 0.6271 - accuracy: 0.7445\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.6193 - accuracy: 0.7503\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.5677 - accuracy: 0.7741\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.5533 - accuracy: 0.7795\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.5263 - accuracy: 0.7882\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.5086 - accuracy: 0.7976\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.4990 - accuracy: 0.8006\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.4848 - accuracy: 0.8096\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.4683 - accuracy: 0.8171\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.4643 - accuracy: 0.8181\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.4579 - accuracy: 0.8175\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.4459 - accuracy: 0.8251\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.4291 - accuracy: 0.8321\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.4240 - accuracy: 0.8318\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.4174 - accuracy: 0.8376\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.4170 - accuracy: 0.8378\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.4045 - accuracy: 0.8414\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.4010 - accuracy: 0.8437\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.3951 - accuracy: 0.8429\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.3858 - accuracy: 0.8472\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3818 - accuracy: 0.8500\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.3739 - accuracy: 0.8524\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3759 - accuracy: 0.8525\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3588 - accuracy: 0.8598\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3639 - accuracy: 0.8566\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.3636 - accuracy: 0.8582\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.3452 - accuracy: 0.8648\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.3460 - accuracy: 0.8640\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3406 - accuracy: 0.8652\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.3362 - accuracy: 0.8676\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3369 - accuracy: 0.8688\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3292 - accuracy: 0.8706\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.3250 - accuracy: 0.8716\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3203 - accuracy: 0.8738\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.3152 - accuracy: 0.8758\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.3164 - accuracy: 0.8733\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3066 - accuracy: 0.8777\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.3005 - accuracy: 0.8819\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.2964 - accuracy: 0.8863\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.2988 - accuracy: 0.8817\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.2853 - accuracy: 0.8866\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.2879 - accuracy: 0.8858\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2784 - accuracy: 0.8899\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.2814 - accuracy: 0.8876\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.2730 - accuracy: 0.8918\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2647 - accuracy: 0.8966\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.2739 - accuracy: 0.8913\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2643 - accuracy: 0.8964\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2721 - accuracy: 0.8933\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2618 - accuracy: 0.8959\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2569 - accuracy: 0.8981\n",
      "76/76 [==============================] - 1s 14ms/step - loss: 0.3311 - accuracy: 0.8900\n",
      "n_conv_1 = 768, k_conv_1 = 2,  n_conv_2 = 256, k_conv_2 = 3, \n",
      "          n_conv_3 = 512,  k_conv_3 = 3,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 512, dropout_1 = 0.3,\n",
      "          n_dense_2 = 256, dropout_2 = 0.25, activation_conv=  elu,\n",
      "          activation_dense=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001FAC95EC8C8>\n",
      "Epoch 1/60\n",
      "  1/152 [..............................] - ETA: 3s - loss: 1.8022 - accuracy: 0.1719WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0150s vs `on_train_batch_end` time: 0.0230s). Check your callbacks.\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 1.1665 - accuracy: 0.5038\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 1.0602 - accuracy: 0.5543\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.9851 - accuracy: 0.5832\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.9185 - accuracy: 0.6140\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.8670 - accuracy: 0.6370\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.7835 - accuracy: 0.6788\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.7422 - accuracy: 0.6961\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.7078 - accuracy: 0.7115\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.6616 - accuracy: 0.7302\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.6420 - accuracy: 0.7399\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.6213 - accuracy: 0.7504\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.5884 - accuracy: 0.7620\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.5654 - accuracy: 0.7729\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.5436 - accuracy: 0.7824\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.5382 - accuracy: 0.7860\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.5095 - accuracy: 0.7974\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.5093 - accuracy: 0.7961\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.4838 - accuracy: 0.8070\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.4856 - accuracy: 0.8079\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.4742 - accuracy: 0.8143\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.4510 - accuracy: 0.8218\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.4530 - accuracy: 0.8230\n",
      "Epoch 23/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 6s 40ms/step - loss: 0.4376 - accuracy: 0.8290\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.4247 - accuracy: 0.8332\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.4270 - accuracy: 0.8311\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.4198 - accuracy: 0.8361\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.4111 - accuracy: 0.8393\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.4040 - accuracy: 0.8433\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3947 - accuracy: 0.8456\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3836 - accuracy: 0.8494\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3838 - accuracy: 0.8490\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3796 - accuracy: 0.8514\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3708 - accuracy: 0.8541\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3605 - accuracy: 0.8596\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3616 - accuracy: 0.8601\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3637 - accuracy: 0.8581\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3560 - accuracy: 0.8626\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3466 - accuracy: 0.8638\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3414 - accuracy: 0.8658\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3441 - accuracy: 0.8653\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3364 - accuracy: 0.8674\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3357 - accuracy: 0.8666\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3232 - accuracy: 0.8730\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3199 - accuracy: 0.8722\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3190 - accuracy: 0.8744\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3088 - accuracy: 0.8780\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3041 - accuracy: 0.8797\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.3098 - accuracy: 0.8772\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.3021 - accuracy: 0.8808\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2942 - accuracy: 0.8809\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.2861 - accuracy: 0.8871\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2899 - accuracy: 0.8826\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2890 - accuracy: 0.8846\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2741 - accuracy: 0.8889\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.2808 - accuracy: 0.8871\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.2860 - accuracy: 0.8863\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2649 - accuracy: 0.8924\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2634 - accuracy: 0.8924\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2635 - accuracy: 0.8946\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2549 - accuracy: 0.8958\n",
      "76/76 [==============================] - 1s 14ms/step - loss: 0.3076 - accuracy: 0.8892\n",
      "n_conv_1 = 768, k_conv_1 = 2,  n_conv_2 = 256, k_conv_2 = 3, \n",
      "          n_conv_3 = 512,  k_conv_3 = 2,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 256, dropout_1 = 0.3,\n",
      "          n_dense_2 = 256, dropout_2 = 0.25, activation_conv=  relu,\n",
      "          activation_dense=  relu\n",
      "Epoch 1/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 1.0932 - accuracy: 0.5385\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.7641 - accuracy: 0.6812\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.6351 - accuracy: 0.7414\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.5174 - accuracy: 0.7988\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.4453 - accuracy: 0.8316\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.4056 - accuracy: 0.8480\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.3656 - accuracy: 0.8647\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.3478 - accuracy: 0.8719\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.3333 - accuracy: 0.8733\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.3050 - accuracy: 0.8871\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.3050 - accuracy: 0.8857\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.2804 - accuracy: 0.8966\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.2813 - accuracy: 0.8965\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.2630 - accuracy: 0.9019\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.2593 - accuracy: 0.9046\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.2502 - accuracy: 0.9070\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.2430 - accuracy: 0.9102\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.2372 - accuracy: 0.9131\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.2239 - accuracy: 0.9171\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.2270 - accuracy: 0.9156\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.2137 - accuracy: 0.9213\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.2115 - accuracy: 0.9224\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.2107 - accuracy: 0.9222\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.2003 - accuracy: 0.9245\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.1977 - accuracy: 0.9257\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.1917 - accuracy: 0.9269\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.1844 - accuracy: 0.9307\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.1876 - accuracy: 0.9293\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.1795 - accuracy: 0.9343\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.1768 - accuracy: 0.9336\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.1776 - accuracy: 0.9349\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.1659 - accuracy: 0.9378\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.1659 - accuracy: 0.9373\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.1617 - accuracy: 0.9392\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.1583 - accuracy: 0.9408\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.1600 - accuracy: 0.9402\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.1553 - accuracy: 0.9423\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.1565 - accuracy: 0.9412\n",
      "Epoch 39/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 6s 37ms/step - loss: 0.1552 - accuracy: 0.9424\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.1468 - accuracy: 0.9438\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.1438 - accuracy: 0.9442\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.1369 - accuracy: 0.9484\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.1380 - accuracy: 0.9483\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.1386 - accuracy: 0.9471\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.1369 - accuracy: 0.9466\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.1324 - accuracy: 0.9505\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.1248 - accuracy: 0.9523\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.1307 - accuracy: 0.9498\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.1259 - accuracy: 0.9525\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.1246 - accuracy: 0.9528\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.1246 - accuracy: 0.9529\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.1214 - accuracy: 0.9544\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.1159 - accuracy: 0.9565\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.1166 - accuracy: 0.9561\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.1175 - accuracy: 0.9550\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.1151 - accuracy: 0.9563\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.1095 - accuracy: 0.9582\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.1144 - accuracy: 0.9562\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.1108 - accuracy: 0.9564\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.1066 - accuracy: 0.9576\n",
      "76/76 [==============================] - 1s 14ms/step - loss: 0.2182 - accuracy: 0.9357\n",
      "n_conv_1 = 768, k_conv_1 = 2,  n_conv_2 = 256, k_conv_2 = 3, \n",
      "          n_conv_3 = 512,  k_conv_3 = 2,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 256, dropout_1 = 0.3,\n",
      "          n_dense_2 = 256, dropout_2 = 0.25, activation_conv=  relu,\n",
      "          activation_dense=  relu\n",
      "Epoch 1/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 1.1084 - accuracy: 0.5323\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.7816 - accuracy: 0.6810\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.6492 - accuracy: 0.7339\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.5475 - accuracy: 0.7804\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.4586 - accuracy: 0.8217\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.4127 - accuracy: 0.8433\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3777 - accuracy: 0.8538\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3531 - accuracy: 0.8628\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.3471 - accuracy: 0.8667\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.3145 - accuracy: 0.8783\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2949 - accuracy: 0.8855\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2962 - accuracy: 0.8882\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.2802 - accuracy: 0.8920\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.2647 - accuracy: 0.9006\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2625 - accuracy: 0.8995\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.2556 - accuracy: 0.9046\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.2433 - accuracy: 0.9071\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2355 - accuracy: 0.9116\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.2376 - accuracy: 0.9092\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.2247 - accuracy: 0.9147\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.2173 - accuracy: 0.9179\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.2151 - accuracy: 0.9193\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.2151 - accuracy: 0.9189\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.2110 - accuracy: 0.9216\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.1962 - accuracy: 0.9258\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.1966 - accuracy: 0.9250\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.1923 - accuracy: 0.9293\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.1851 - accuracy: 0.9296\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.1861 - accuracy: 0.9294\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.1880 - accuracy: 0.9299\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.1754 - accuracy: 0.9357\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.1683 - accuracy: 0.9369\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.1687 - accuracy: 0.9359\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.1687 - accuracy: 0.9378\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.1720 - accuracy: 0.9358\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.1603 - accuracy: 0.9405\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.1593 - accuracy: 0.9399\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.1575 - accuracy: 0.9407\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.1497 - accuracy: 0.9441\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.1533 - accuracy: 0.9427\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.1441 - accuracy: 0.9453\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.1389 - accuracy: 0.9477\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.1439 - accuracy: 0.9450\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.1366 - accuracy: 0.9482\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.1382 - accuracy: 0.9469\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.1373 - accuracy: 0.9483\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.1381 - accuracy: 0.9456\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.1304 - accuracy: 0.9505\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.1234 - accuracy: 0.9528\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.1297 - accuracy: 0.9520\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.1251 - accuracy: 0.9529\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.1351 - accuracy: 0.9506\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.1293 - accuracy: 0.9513\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.1190 - accuracy: 0.9546\n",
      "Epoch 55/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 6s 36ms/step - loss: 0.1183 - accuracy: 0.9546\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.1226 - accuracy: 0.9534\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.1199 - accuracy: 0.9545\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.1098 - accuracy: 0.9592\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.1092 - accuracy: 0.9587\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.1147 - accuracy: 0.9556\n",
      "76/76 [==============================] - 1s 14ms/step - loss: 0.2345 - accuracy: 0.9363\n",
      "n_conv_1 = 768, k_conv_1 = 2,  n_conv_2 = 256, k_conv_2 = 3, \n",
      "          n_conv_3 = 512,  k_conv_3 = 2,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 256, dropout_1 = 0.3,\n",
      "          n_dense_2 = 256, dropout_2 = 0.25, activation_conv=  relu,\n",
      "          activation_dense=  relu\n",
      "Epoch 1/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 1.1071 - accuracy: 0.5342\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.7651 - accuracy: 0.6828\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.6236 - accuracy: 0.7444\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.5217 - accuracy: 0.7931\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.4407 - accuracy: 0.8323\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.4048 - accuracy: 0.8448\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.3745 - accuracy: 0.8596\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.3430 - accuracy: 0.8689\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.3358 - accuracy: 0.8742\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.3081 - accuracy: 0.8852\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.2956 - accuracy: 0.8884\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.2855 - accuracy: 0.8935\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.2760 - accuracy: 0.8959\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.2693 - accuracy: 0.9010\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.2548 - accuracy: 0.9054\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.2470 - accuracy: 0.9080\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.2408 - accuracy: 0.9122\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.2280 - accuracy: 0.9160\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.2265 - accuracy: 0.9161\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.2282 - accuracy: 0.9166\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.2110 - accuracy: 0.9208\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.2059 - accuracy: 0.9235\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.2109 - accuracy: 0.9212\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.2000 - accuracy: 0.9255\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.2006 - accuracy: 0.9258\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.1964 - accuracy: 0.9271\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.1857 - accuracy: 0.9318\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.1823 - accuracy: 0.9325\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.1876 - accuracy: 0.9331\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.1756 - accuracy: 0.9347\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.1732 - accuracy: 0.9369\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.1702 - accuracy: 0.9377\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.1673 - accuracy: 0.9385\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.1693 - accuracy: 0.9366\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.1586 - accuracy: 0.9412\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.1656 - accuracy: 0.9387\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.1505 - accuracy: 0.9425\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.1579 - accuracy: 0.9422\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.1473 - accuracy: 0.9440\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.1462 - accuracy: 0.9457\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.1464 - accuracy: 0.9459\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.1394 - accuracy: 0.9468\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.1357 - accuracy: 0.9497\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.1347 - accuracy: 0.9500\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.1317 - accuracy: 0.9508\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.1469 - accuracy: 0.9472\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.1300 - accuracy: 0.9496\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.1295 - accuracy: 0.9518\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.1251 - accuracy: 0.9538\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.1255 - accuracy: 0.9522\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.1173 - accuracy: 0.9562\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.1259 - accuracy: 0.9516\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.1166 - accuracy: 0.9563\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.1148 - accuracy: 0.9574\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.1236 - accuracy: 0.9533\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.1134 - accuracy: 0.9564\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.1100 - accuracy: 0.9586\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.1133 - accuracy: 0.9561\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.1116 - accuracy: 0.9581\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.1224 - accuracy: 0.9538\n",
      "76/76 [==============================] - 1s 14ms/step - loss: 0.2453 - accuracy: 0.9356\n",
      "n_conv_1 = 512, k_conv_1 = 2,  n_conv_2 = 256, k_conv_2 = 3, \n",
      "          n_conv_3 = 256,  k_conv_3 = 2,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 256, dropout_1 = 0.2,\n",
      "          n_dense_2 = 256, dropout_2 = 0.25, activation_conv=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001FAC93D7588>,\n",
      "          activation_dense=  relu\n",
      "Epoch 1/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 1.1328 - accuracy: 0.5229\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.9008 - accuracy: 0.6195\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.7860 - accuracy: 0.6644\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.7069 - accuracy: 0.7004\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.6515 - accuracy: 0.7325\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.6020 - accuracy: 0.7570\n",
      "Epoch 7/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 4s 26ms/step - loss: 0.5594 - accuracy: 0.7778\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.5140 - accuracy: 0.7992\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.4903 - accuracy: 0.8092\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.4599 - accuracy: 0.8203\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.4594 - accuracy: 0.8215\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.4519 - accuracy: 0.8242\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.4234 - accuracy: 0.8353\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.4099 - accuracy: 0.8405\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.4039 - accuracy: 0.8418\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3914 - accuracy: 0.8480\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3834 - accuracy: 0.8514\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3784 - accuracy: 0.8526\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3923 - accuracy: 0.8474\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3628 - accuracy: 0.8607\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3639 - accuracy: 0.8566\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3498 - accuracy: 0.8621\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3485 - accuracy: 0.8668\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3392 - accuracy: 0.8674\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3417 - accuracy: 0.8655\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3450 - accuracy: 0.8676\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3336 - accuracy: 0.8698\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3351 - accuracy: 0.8692\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3182 - accuracy: 0.8744\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3169 - accuracy: 0.8773\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3084 - accuracy: 0.8806\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3185 - accuracy: 0.8771\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3120 - accuracy: 0.8775\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3073 - accuracy: 0.8808\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3102 - accuracy: 0.8793\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3088 - accuracy: 0.8791\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3031 - accuracy: 0.8824\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2936 - accuracy: 0.8863\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2978 - accuracy: 0.8844\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2991 - accuracy: 0.8852\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2859 - accuracy: 0.8895\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2930 - accuracy: 0.8887\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2847 - accuracy: 0.8898\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2815 - accuracy: 0.8900\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2733 - accuracy: 0.8959\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2781 - accuracy: 0.8935\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2745 - accuracy: 0.8949\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2718 - accuracy: 0.8965\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2867 - accuracy: 0.8898\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2647 - accuracy: 0.8978\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2661 - accuracy: 0.8981\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2696 - accuracy: 0.8933\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2741 - accuracy: 0.8945\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2661 - accuracy: 0.8974\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2568 - accuracy: 0.9011\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2591 - accuracy: 0.8999\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2605 - accuracy: 0.8976\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2608 - accuracy: 0.8986\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2589 - accuracy: 0.9006\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2658 - accuracy: 0.8961\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 0.2609 - accuracy: 0.9028\n",
      "n_conv_1 = 512, k_conv_1 = 2,  n_conv_2 = 256, k_conv_2 = 3, \n",
      "          n_conv_3 = 256,  k_conv_3 = 2,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 256, dropout_1 = 0.2,\n",
      "          n_dense_2 = 256, dropout_2 = 0.25, activation_conv=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001FAC9B3A408>,\n",
      "          activation_dense=  relu\n",
      "Epoch 1/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 1.1258 - accuracy: 0.5210\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.8941 - accuracy: 0.6248\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.8028 - accuracy: 0.6593\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.7235 - accuracy: 0.6926\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.6737 - accuracy: 0.7199\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.6262 - accuracy: 0.7474\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.5670 - accuracy: 0.7725\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.5297 - accuracy: 0.7903\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.5082 - accuracy: 0.7980\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.4834 - accuracy: 0.8059\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.4571 - accuracy: 0.8224\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.4449 - accuracy: 0.8271\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.4279 - accuracy: 0.8336\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.4090 - accuracy: 0.8413\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.4013 - accuracy: 0.8450\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3910 - accuracy: 0.8504\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3780 - accuracy: 0.8556\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3768 - accuracy: 0.8541\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3647 - accuracy: 0.8594\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3582 - accuracy: 0.8624\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3509 - accuracy: 0.8639\n",
      "Epoch 22/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3546 - accuracy: 0.8633\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3631 - accuracy: 0.8573\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3437 - accuracy: 0.8661\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3328 - accuracy: 0.8705\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3276 - accuracy: 0.8723\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3306 - accuracy: 0.8705\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3223 - accuracy: 0.8729\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3248 - accuracy: 0.8718\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3237 - accuracy: 0.8734\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3181 - accuracy: 0.8760\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3089 - accuracy: 0.8791\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3104 - accuracy: 0.8791\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3045 - accuracy: 0.8806\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3150 - accuracy: 0.8768\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2967 - accuracy: 0.8826\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2982 - accuracy: 0.8841\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2974 - accuracy: 0.8821\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2846 - accuracy: 0.8885\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2869 - accuracy: 0.8899\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2871 - accuracy: 0.8898\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2932 - accuracy: 0.8846\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2835 - accuracy: 0.8881\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2838 - accuracy: 0.8885\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2821 - accuracy: 0.8905\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2794 - accuracy: 0.8900\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2778 - accuracy: 0.8915\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2769 - accuracy: 0.8917\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2769 - accuracy: 0.8943\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2705 - accuracy: 0.8947\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2723 - accuracy: 0.8939\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2682 - accuracy: 0.8977\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2561 - accuracy: 0.9026\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2594 - accuracy: 0.9005\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2601 - accuracy: 0.8987\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2711 - accuracy: 0.8966\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2623 - accuracy: 0.8993\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2615 - accuracy: 0.8997\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2566 - accuracy: 0.9006\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2588 - accuracy: 0.9008\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 0.2926 - accuracy: 0.8945\n",
      "n_conv_1 = 512, k_conv_1 = 2,  n_conv_2 = 256, k_conv_2 = 3, \n",
      "          n_conv_3 = 256,  k_conv_3 = 2,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 256, dropout_1 = 0.2,\n",
      "          n_dense_2 = 256, dropout_2 = 0.25, activation_conv=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001FAC82DEDC8>,\n",
      "          activation_dense=  relu\n",
      "Epoch 1/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 1.1234 - accuracy: 0.5215\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.8903 - accuracy: 0.6234\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.7958 - accuracy: 0.6621\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.7214 - accuracy: 0.6932\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.6702 - accuracy: 0.7209\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.6050 - accuracy: 0.7528\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.5825 - accuracy: 0.7635\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.5423 - accuracy: 0.7829\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.5093 - accuracy: 0.7974\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.4851 - accuracy: 0.8069\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.4607 - accuracy: 0.8196\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.4522 - accuracy: 0.8199\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.4226 - accuracy: 0.8348\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.4230 - accuracy: 0.8357\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.4107 - accuracy: 0.8372\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3969 - accuracy: 0.8446\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3950 - accuracy: 0.8459\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3746 - accuracy: 0.8544\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3769 - accuracy: 0.8533\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3758 - accuracy: 0.8532\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3599 - accuracy: 0.8600\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3625 - accuracy: 0.8571\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3540 - accuracy: 0.8617\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3427 - accuracy: 0.8649\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3395 - accuracy: 0.8662\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3426 - accuracy: 0.8650\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3409 - accuracy: 0.8675\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3334 - accuracy: 0.8687\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3255 - accuracy: 0.8726\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3264 - accuracy: 0.8726\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3168 - accuracy: 0.8766\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3208 - accuracy: 0.8730\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3082 - accuracy: 0.8794\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3098 - accuracy: 0.8797\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3072 - accuracy: 0.8806\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3058 - accuracy: 0.8816\n",
      "Epoch 37/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3079 - accuracy: 0.8796\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3003 - accuracy: 0.8828\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3071 - accuracy: 0.8792\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2910 - accuracy: 0.8876\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2979 - accuracy: 0.8857\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2961 - accuracy: 0.8850\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2839 - accuracy: 0.8896\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2829 - accuracy: 0.8901\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2909 - accuracy: 0.8878\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2719 - accuracy: 0.8946\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2874 - accuracy: 0.8894\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2844 - accuracy: 0.8874\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2794 - accuracy: 0.8914\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2805 - accuracy: 0.8904\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2766 - accuracy: 0.8939\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2682 - accuracy: 0.8955\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2740 - accuracy: 0.8939\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2711 - accuracy: 0.8952\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2619 - accuracy: 0.8985\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2690 - accuracy: 0.8960\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2691 - accuracy: 0.8971\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2694 - accuracy: 0.8944\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2489 - accuracy: 0.9041\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2655 - accuracy: 0.8963\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 0.2687 - accuracy: 0.9023\n",
      "n_conv_1 = 768, k_conv_1 = 2,  n_conv_2 = 512, k_conv_2 = 3, \n",
      "          n_conv_3 = 256,  k_conv_3 = 3,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 512, dropout_1 = 0.2,\n",
      "          n_dense_2 = 512, dropout_2 = 0.25, activation_conv=  elu,\n",
      "          activation_dense=  elu\n",
      "Epoch 1/60\n",
      "  2/152 [..............................] - ETA: 5s - loss: 1.7476 - accuracy: 0.2422WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0210s vs `on_train_batch_end` time: 0.0319s). Check your callbacks.\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 1.1973 - accuracy: 0.4865\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 1.0747 - accuracy: 0.5378\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 1.0151 - accuracy: 0.5683\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.9441 - accuracy: 0.5942\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.8637 - accuracy: 0.6312\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.7932 - accuracy: 0.6660\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.7116 - accuracy: 0.7043\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.6620 - accuracy: 0.7271\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.6230 - accuracy: 0.7432\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.5641 - accuracy: 0.7731\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.5346 - accuracy: 0.7873\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.4961 - accuracy: 0.8039\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.4655 - accuracy: 0.8185\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.4369 - accuracy: 0.8291\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.4172 - accuracy: 0.8362\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.4133 - accuracy: 0.8386\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.3956 - accuracy: 0.8458\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.3732 - accuracy: 0.8523\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.3672 - accuracy: 0.8565\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.3600 - accuracy: 0.8591\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.3441 - accuracy: 0.8658\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.3347 - accuracy: 0.8692\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.3330 - accuracy: 0.8678\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.3168 - accuracy: 0.8758\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.3094 - accuracy: 0.8792\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.3035 - accuracy: 0.8818\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2960 - accuracy: 0.8862\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2979 - accuracy: 0.8828\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2925 - accuracy: 0.8872\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2769 - accuracy: 0.8900\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2641 - accuracy: 0.8965\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2695 - accuracy: 0.8938\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2733 - accuracy: 0.8926\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2596 - accuracy: 0.8962\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2517 - accuracy: 0.9011\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2508 - accuracy: 0.8993\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2545 - accuracy: 0.9003\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2419 - accuracy: 0.9050\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2488 - accuracy: 0.9017\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2440 - accuracy: 0.9052\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2299 - accuracy: 0.9098\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2237 - accuracy: 0.9123\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2248 - accuracy: 0.9131\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2151 - accuracy: 0.9149\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2176 - accuracy: 0.9164\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2151 - accuracy: 0.9166\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2135 - accuracy: 0.9163\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2039 - accuracy: 0.9200\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2016 - accuracy: 0.9206\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2034 - accuracy: 0.9205\n",
      "Epoch 51/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2018 - accuracy: 0.9208\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.1971 - accuracy: 0.9230 0s - loss: 0.1959 \n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.1942 - accuracy: 0.9247\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.1939 - accuracy: 0.9250\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.1891 - accuracy: 0.9250\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.1872 - accuracy: 0.9279\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.1874 - accuracy: 0.9274\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.1814 - accuracy: 0.9295\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.1701 - accuracy: 0.9352\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.1782 - accuracy: 0.9327\n",
      "76/76 [==============================] - 1s 19ms/step - loss: 0.2763 - accuracy: 0.9157\n",
      "n_conv_1 = 768, k_conv_1 = 2,  n_conv_2 = 512, k_conv_2 = 3, \n",
      "          n_conv_3 = 256,  k_conv_3 = 3,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 512, dropout_1 = 0.2,\n",
      "          n_dense_2 = 512, dropout_2 = 0.25, activation_conv=  elu,\n",
      "          activation_dense=  elu\n",
      "Epoch 1/60\n",
      "  1/152 [..............................] - ETA: 4s - loss: 1.7809 - accuracy: 0.2109WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0199s vs `on_train_batch_end` time: 0.0299s). Check your callbacks.\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 1.1914 - accuracy: 0.4874\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 1.0606 - accuracy: 0.5475\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 1.0022 - accuracy: 0.5781\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.9403 - accuracy: 0.6066\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.8574 - accuracy: 0.6434\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.7909 - accuracy: 0.6707\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.7219 - accuracy: 0.6987\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.6768 - accuracy: 0.7196\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.6185 - accuracy: 0.7483\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.5623 - accuracy: 0.7730\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.5381 - accuracy: 0.7826\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.5062 - accuracy: 0.7990\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.4768 - accuracy: 0.8111\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.4450 - accuracy: 0.8263\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.4386 - accuracy: 0.8292\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.4143 - accuracy: 0.8365\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.4019 - accuracy: 0.8445\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.3854 - accuracy: 0.8488\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.3767 - accuracy: 0.8520\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.3679 - accuracy: 0.8563\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.3703 - accuracy: 0.8533\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.3405 - accuracy: 0.8653\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.3417 - accuracy: 0.8661\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.3272 - accuracy: 0.8704\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.3273 - accuracy: 0.8704\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.3137 - accuracy: 0.8739\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.3113 - accuracy: 0.8769\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.3063 - accuracy: 0.8791\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2955 - accuracy: 0.8820\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2941 - accuracy: 0.8823\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2880 - accuracy: 0.8864\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2845 - accuracy: 0.8874\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2780 - accuracy: 0.8900\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2652 - accuracy: 0.8941\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2682 - accuracy: 0.8941\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2545 - accuracy: 0.8982\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2558 - accuracy: 0.8990\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2511 - accuracy: 0.9009\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2473 - accuracy: 0.9021\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2412 - accuracy: 0.9055\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2338 - accuracy: 0.9082\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2355 - accuracy: 0.9065\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2287 - accuracy: 0.9110\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2362 - accuracy: 0.9096\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2254 - accuracy: 0.9108\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2153 - accuracy: 0.9159\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2154 - accuracy: 0.9155\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2186 - accuracy: 0.9133\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2067 - accuracy: 0.9184\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.1986 - accuracy: 0.9228\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.1984 - accuracy: 0.9223\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2020 - accuracy: 0.9220\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.1985 - accuracy: 0.9236\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2036 - accuracy: 0.9215\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.1829 - accuracy: 0.9305\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.1928 - accuracy: 0.9270\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.1870 - accuracy: 0.9285\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.1810 - accuracy: 0.9317\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.1672 - accuracy: 0.9353\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.1839 - accuracy: 0.9289\n",
      "76/76 [==============================] - 1s 18ms/step - loss: 0.2874 - accuracy: 0.9200\n",
      "n_conv_1 = 768, k_conv_1 = 2,  n_conv_2 = 512, k_conv_2 = 3, \n",
      "          n_conv_3 = 256,  k_conv_3 = 3,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 512, dropout_1 = 0.2,\n",
      "          n_dense_2 = 512, dropout_2 = 0.25, activation_conv=  elu,\n",
      "          activation_dense=  elu\n",
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/152 [..............................] - ETA: 4s - loss: 1.8105 - accuracy: 0.1133WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0189s vs `on_train_batch_end` time: 0.0299s). Check your callbacks.\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 1.1924 - accuracy: 0.4902\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 1.0743 - accuracy: 0.5394\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 1.0111 - accuracy: 0.5753\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.9472 - accuracy: 0.6069\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.8716 - accuracy: 0.6341\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.8063 - accuracy: 0.6628\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.7384 - accuracy: 0.6936\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.6761 - accuracy: 0.7245\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.6225 - accuracy: 0.7453\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.5778 - accuracy: 0.7623\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.5350 - accuracy: 0.7839\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.5096 - accuracy: 0.7978\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.4814 - accuracy: 0.8116\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.4575 - accuracy: 0.8214\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.4248 - accuracy: 0.8349\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.4196 - accuracy: 0.8341\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.3987 - accuracy: 0.8436\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.3949 - accuracy: 0.8461\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.3749 - accuracy: 0.8506\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.3608 - accuracy: 0.8582\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.3545 - accuracy: 0.8614\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.3378 - accuracy: 0.8704\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.3257 - accuracy: 0.8743\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.3220 - accuracy: 0.8757\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.3170 - accuracy: 0.8781\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.3030 - accuracy: 0.8836\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2961 - accuracy: 0.8842\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.3003 - accuracy: 0.8832\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2989 - accuracy: 0.8838\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2800 - accuracy: 0.8897\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2782 - accuracy: 0.8925\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2735 - accuracy: 0.8959\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2701 - accuracy: 0.8951\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2639 - accuracy: 0.8964\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2622 - accuracy: 0.8961\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2626 - accuracy: 0.8963\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2506 - accuracy: 0.9037\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2439 - accuracy: 0.9039\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2521 - accuracy: 0.9019\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2396 - accuracy: 0.9064\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2401 - accuracy: 0.9079\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2324 - accuracy: 0.9100\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2282 - accuracy: 0.9111\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2211 - accuracy: 0.9121\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2281 - accuracy: 0.9113\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2248 - accuracy: 0.9117\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2094 - accuracy: 0.9186\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2152 - accuracy: 0.9165\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2095 - accuracy: 0.9187\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2177 - accuracy: 0.9162\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.1990 - accuracy: 0.9226\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2033 - accuracy: 0.9208\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.1896 - accuracy: 0.9266\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.1997 - accuracy: 0.9226\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.1872 - accuracy: 0.9266\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.1952 - accuracy: 0.9258\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.1940 - accuracy: 0.9239\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.1856 - accuracy: 0.9295\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.1825 - accuracy: 0.9306\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.1717 - accuracy: 0.9342\n",
      "76/76 [==============================] - 1s 18ms/step - loss: 0.2792 - accuracy: 0.9234\n",
      "n_conv_1 = 768, k_conv_1 = 2,  n_conv_2 = 512, k_conv_2 = 3, \n",
      "          n_conv_3 = 256,  k_conv_3 = 3,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 512, dropout_1 = 0.2,\n",
      "          n_dense_2 = 256, dropout_2 = 0.25, activation_conv=  relu,\n",
      "          activation_dense=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001FAC9CFA788>\n",
      "Epoch 1/60\n",
      "  1/152 [..............................] - ETA: 4s - loss: 1.7974 - accuracy: 0.1484WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0189s vs `on_train_batch_end` time: 0.0299s). Check your callbacks.\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 1.0761 - accuracy: 0.5463\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.7351 - accuracy: 0.6932\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.5705 - accuracy: 0.7727\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.4635 - accuracy: 0.8232\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.3917 - accuracy: 0.8529\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.3626 - accuracy: 0.8635\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.3305 - accuracy: 0.8762\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.3076 - accuracy: 0.8838\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2958 - accuracy: 0.8899\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2775 - accuracy: 0.8952\n",
      "Epoch 11/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2630 - accuracy: 0.9015\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2551 - accuracy: 0.9048\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2490 - accuracy: 0.9061\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2424 - accuracy: 0.9079\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2241 - accuracy: 0.9158\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2255 - accuracy: 0.9153\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2101 - accuracy: 0.9203\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2153 - accuracy: 0.9194\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2159 - accuracy: 0.9176\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1973 - accuracy: 0.9257\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1920 - accuracy: 0.9280\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1879 - accuracy: 0.9299\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1900 - accuracy: 0.9278\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1792 - accuracy: 0.9312\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1692 - accuracy: 0.9356\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1684 - accuracy: 0.9357\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1646 - accuracy: 0.9370\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1615 - accuracy: 0.9374\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1574 - accuracy: 0.9402\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1459 - accuracy: 0.9441\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1526 - accuracy: 0.9422\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1524 - accuracy: 0.9402\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1504 - accuracy: 0.9434\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1377 - accuracy: 0.9462\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1409 - accuracy: 0.9438\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1406 - accuracy: 0.9480\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1315 - accuracy: 0.9489\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1342 - accuracy: 0.9489\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1332 - accuracy: 0.9483\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1227 - accuracy: 0.9527\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1279 - accuracy: 0.9512\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1263 - accuracy: 0.9501\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1177 - accuracy: 0.9541\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1187 - accuracy: 0.9535\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1147 - accuracy: 0.9548\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1114 - accuracy: 0.9563\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1166 - accuracy: 0.9557\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1127 - accuracy: 0.9559\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1091 - accuracy: 0.9588\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1081 - accuracy: 0.9585\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1077 - accuracy: 0.9576\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1056 - accuracy: 0.9599\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1058 - accuracy: 0.9583 1s - loss: 0\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1029 - accuracy: 0.9601\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1045 - accuracy: 0.9607\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1011 - accuracy: 0.9616\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.0951 - accuracy: 0.9638\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1003 - accuracy: 0.9619\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.0928 - accuracy: 0.9642\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.0903 - accuracy: 0.9644\n",
      "76/76 [==============================] - 1s 18ms/step - loss: 0.2565 - accuracy: 0.9378\n",
      "n_conv_1 = 768, k_conv_1 = 2,  n_conv_2 = 512, k_conv_2 = 3, \n",
      "          n_conv_3 = 256,  k_conv_3 = 3,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 512, dropout_1 = 0.2,\n",
      "          n_dense_2 = 256, dropout_2 = 0.25, activation_conv=  relu,\n",
      "          activation_dense=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001FAC988F748>\n",
      "Epoch 1/60\n",
      "  1/152 [..............................] - ETA: 4s - loss: 1.7928 - accuracy: 0.1484WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0190s vs `on_train_batch_end` time: 0.0289s). Check your callbacks.\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 1.0713 - accuracy: 0.5464\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.7237 - accuracy: 0.7020\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.5547 - accuracy: 0.7836\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.4457 - accuracy: 0.8327\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.3767 - accuracy: 0.8582\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.3594 - accuracy: 0.8626\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.3317 - accuracy: 0.8732\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.3068 - accuracy: 0.8827\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2987 - accuracy: 0.8859\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2761 - accuracy: 0.8940\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2609 - accuracy: 0.8999\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2577 - accuracy: 0.9020\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2394 - accuracy: 0.9083 0s - loss: 0.2378 - accu\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2335 - accuracy: 0.9114 0s - loss: 0.2338 - accuracy\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2276 - accuracy: 0.9126\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2178 - accuracy: 0.9181\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2153 - accuracy: 0.9170\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2058 - accuracy: 0.9217\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1966 - accuracy: 0.9253\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2089 - accuracy: 0.9237\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1895 - accuracy: 0.9278\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1888 - accuracy: 0.9289\n",
      "Epoch 23/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1834 - accuracy: 0.9304\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1868 - accuracy: 0.9297\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1782 - accuracy: 0.9319\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1659 - accuracy: 0.9373\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1623 - accuracy: 0.9366\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1614 - accuracy: 0.9402\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1544 - accuracy: 0.9413\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1529 - accuracy: 0.9431\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1570 - accuracy: 0.9405\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1504 - accuracy: 0.9424\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1386 - accuracy: 0.9469\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1476 - accuracy: 0.9436\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1427 - accuracy: 0.9456\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1391 - accuracy: 0.9468\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1339 - accuracy: 0.9486\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1290 - accuracy: 0.9501\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1363 - accuracy: 0.9483\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1240 - accuracy: 0.9524\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1229 - accuracy: 0.9538\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1271 - accuracy: 0.9508\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1227 - accuracy: 0.9531\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1115 - accuracy: 0.9558\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1196 - accuracy: 0.9531\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1090 - accuracy: 0.9580\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1190 - accuracy: 0.9551\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1111 - accuracy: 0.9577\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1076 - accuracy: 0.9579\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1040 - accuracy: 0.9596\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1037 - accuracy: 0.9596\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1060 - accuracy: 0.9591\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.0999 - accuracy: 0.9611\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1190 - accuracy: 0.9555\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1007 - accuracy: 0.9607 0s - loss: 0.0996 - accu\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.0947 - accuracy: 0.9633\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.0998 - accuracy: 0.9621\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1002 - accuracy: 0.9631\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.0954 - accuracy: 0.9633\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.0950 - accuracy: 0.9642\n",
      "76/76 [==============================] - 1s 18ms/step - loss: 0.2825 - accuracy: 0.9286\n",
      "n_conv_1 = 768, k_conv_1 = 2,  n_conv_2 = 512, k_conv_2 = 3, \n",
      "          n_conv_3 = 256,  k_conv_3 = 3,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 512, dropout_1 = 0.2,\n",
      "          n_dense_2 = 256, dropout_2 = 0.25, activation_conv=  relu,\n",
      "          activation_dense=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001FAC9AC1B08>\n",
      "Epoch 1/60\n",
      "  1/152 [..............................] - ETA: 4s - loss: 1.7894 - accuracy: 0.1875WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0189s vs `on_train_batch_end` time: 0.0289s). Check your callbacks.\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 1.0541 - accuracy: 0.5596\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.7296 - accuracy: 0.6978\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.5653 - accuracy: 0.7753\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.4462 - accuracy: 0.8315\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.4005 - accuracy: 0.8465\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.3428 - accuracy: 0.8700\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.3296 - accuracy: 0.8759\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.3108 - accuracy: 0.8816\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2896 - accuracy: 0.8917\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2751 - accuracy: 0.8959\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2669 - accuracy: 0.8978\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2561 - accuracy: 0.9026\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2434 - accuracy: 0.9090\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2296 - accuracy: 0.9142\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2257 - accuracy: 0.9151\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2170 - accuracy: 0.9177\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2152 - accuracy: 0.9188\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2041 - accuracy: 0.9234\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2015 - accuracy: 0.9234\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1896 - accuracy: 0.9284\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1937 - accuracy: 0.9264\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1849 - accuracy: 0.9296\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1754 - accuracy: 0.9333\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1686 - accuracy: 0.9357\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1718 - accuracy: 0.9358\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1728 - accuracy: 0.9340\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1614 - accuracy: 0.9371\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1583 - accuracy: 0.9401\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1555 - accuracy: 0.9403\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1544 - accuracy: 0.9405\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1483 - accuracy: 0.9427\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1472 - accuracy: 0.9439\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1528 - accuracy: 0.9430\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1387 - accuracy: 0.9467\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1363 - accuracy: 0.9467\n",
      "Epoch 36/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1328 - accuracy: 0.9498\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1281 - accuracy: 0.9511\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1343 - accuracy: 0.9478\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1273 - accuracy: 0.9519\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1224 - accuracy: 0.9530\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1218 - accuracy: 0.9531\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1160 - accuracy: 0.9548\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1268 - accuracy: 0.9524\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1153 - accuracy: 0.9552\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1165 - accuracy: 0.9555\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1216 - accuracy: 0.9554\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1024 - accuracy: 0.9606\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1110 - accuracy: 0.9575\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1033 - accuracy: 0.9598\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1052 - accuracy: 0.9601\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1086 - accuracy: 0.9584\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1091 - accuracy: 0.9581\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1017 - accuracy: 0.9604\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.0971 - accuracy: 0.9626\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1017 - accuracy: 0.9612\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.0976 - accuracy: 0.9620\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.0995 - accuracy: 0.9621\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.0989 - accuracy: 0.9633\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.0892 - accuracy: 0.9651\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.0935 - accuracy: 0.9632\n",
      "76/76 [==============================] - 1s 18ms/step - loss: 0.2706 - accuracy: 0.9339\n",
      "n_conv_1 = 512, k_conv_1 = 3,  n_conv_2 = 512, k_conv_2 = 3, \n",
      "          n_conv_3 = 256,  k_conv_3 = 3,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 512, dropout_1 = 0.3,\n",
      "          n_dense_2 = 256, dropout_2 = 0.25, activation_conv=  elu,\n",
      "          activation_dense=  relu\n",
      "Epoch 1/60\n",
      "  1/152 [..............................] - ETA: 0s - loss: 1.8002 - accuracy: 0.1211WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0150s vs `on_train_batch_end` time: 0.0232s). Check your callbacks.\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 1.1296 - accuracy: 0.5219\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.9171 - accuracy: 0.6115\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.7738 - accuracy: 0.6849\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.6705 - accuracy: 0.7295\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.6234 - accuracy: 0.7479\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.5865 - accuracy: 0.7668\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.5552 - accuracy: 0.7802\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.5228 - accuracy: 0.7952\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.5258 - accuracy: 0.7979\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.4923 - accuracy: 0.8092\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.4868 - accuracy: 0.8101\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.4542 - accuracy: 0.8215\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.4466 - accuracy: 0.8258\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.4327 - accuracy: 0.8345\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.4253 - accuracy: 0.8346\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.4167 - accuracy: 0.8388\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.4007 - accuracy: 0.8454\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3890 - accuracy: 0.8524\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3703 - accuracy: 0.8542\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3668 - accuracy: 0.8580\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3643 - accuracy: 0.8584\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3590 - accuracy: 0.8597\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3515 - accuracy: 0.8644\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3477 - accuracy: 0.8646\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3398 - accuracy: 0.8676\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3401 - accuracy: 0.8674\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3336 - accuracy: 0.8716\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3263 - accuracy: 0.8761\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3158 - accuracy: 0.8777\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3308 - accuracy: 0.8713\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3112 - accuracy: 0.8802\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3129 - accuracy: 0.8781\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3041 - accuracy: 0.8814\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3007 - accuracy: 0.8831\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2975 - accuracy: 0.8861\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2944 - accuracy: 0.8874\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2907 - accuracy: 0.8881\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2880 - accuracy: 0.8882\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2850 - accuracy: 0.8908\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2893 - accuracy: 0.8887\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2867 - accuracy: 0.8901\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2855 - accuracy: 0.8904\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2798 - accuracy: 0.8934\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2818 - accuracy: 0.8910\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2826 - accuracy: 0.8919\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2617 - accuracy: 0.8981\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2713 - accuracy: 0.8965\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2633 - accuracy: 0.8976\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2675 - accuracy: 0.8959\n",
      "Epoch 50/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2649 - accuracy: 0.8966\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2601 - accuracy: 0.8992\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2561 - accuracy: 0.9013\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2539 - accuracy: 0.9036\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2573 - accuracy: 0.8988\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2482 - accuracy: 0.9043\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2473 - accuracy: 0.9044\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2451 - accuracy: 0.9045\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2481 - accuracy: 0.9048\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2372 - accuracy: 0.9083\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2304 - accuracy: 0.9101\n",
      "76/76 [==============================] - 1s 16ms/step - loss: 0.2616 - accuracy: 0.9139\n",
      "n_conv_1 = 512, k_conv_1 = 3,  n_conv_2 = 512, k_conv_2 = 3, \n",
      "          n_conv_3 = 256,  k_conv_3 = 3,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 512, dropout_1 = 0.3,\n",
      "          n_dense_2 = 256, dropout_2 = 0.25, activation_conv=  elu,\n",
      "          activation_dense=  relu\n",
      "Epoch 1/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 1.1187 - accuracy: 0.5304\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.9363 - accuracy: 0.6022\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.7829 - accuracy: 0.6839\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.6805 - accuracy: 0.7283\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.6292 - accuracy: 0.7498\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.5994 - accuracy: 0.7637\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.5626 - accuracy: 0.7814\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.5216 - accuracy: 0.7958\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.5041 - accuracy: 0.8079\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.4844 - accuracy: 0.8115\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.4655 - accuracy: 0.8210\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.4441 - accuracy: 0.8307\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.4374 - accuracy: 0.8310\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.4232 - accuracy: 0.8355\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.4057 - accuracy: 0.8446\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3968 - accuracy: 0.8503\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.4001 - accuracy: 0.8475\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3758 - accuracy: 0.8555\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3717 - accuracy: 0.8572\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3574 - accuracy: 0.8646\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3630 - accuracy: 0.8605\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3590 - accuracy: 0.8635\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3377 - accuracy: 0.8683\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3350 - accuracy: 0.8722\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3349 - accuracy: 0.8728\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3448 - accuracy: 0.8685\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3374 - accuracy: 0.8700\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3219 - accuracy: 0.8776\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3242 - accuracy: 0.8753\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3139 - accuracy: 0.8780\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3094 - accuracy: 0.8796\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3076 - accuracy: 0.8793\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3057 - accuracy: 0.8812\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3042 - accuracy: 0.8822\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3005 - accuracy: 0.8826\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2969 - accuracy: 0.8856\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2906 - accuracy: 0.8860\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2867 - accuracy: 0.8874\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2821 - accuracy: 0.8885\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2918 - accuracy: 0.8877\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2909 - accuracy: 0.8856\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2794 - accuracy: 0.8912\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2846 - accuracy: 0.8891\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2742 - accuracy: 0.8938\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2699 - accuracy: 0.8940\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2662 - accuracy: 0.8954\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2696 - accuracy: 0.8947\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2686 - accuracy: 0.8937\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2572 - accuracy: 0.8985\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2539 - accuracy: 0.8994\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2535 - accuracy: 0.8998\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2499 - accuracy: 0.9021\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2523 - accuracy: 0.9025\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2435 - accuracy: 0.9052\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2479 - accuracy: 0.9010\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2582 - accuracy: 0.8987\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2368 - accuracy: 0.9061\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2360 - accuracy: 0.9078\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2377 - accuracy: 0.9056\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2339 - accuracy: 0.9081\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 0.2881 - accuracy: 0.8934\n",
      "n_conv_1 = 512, k_conv_1 = 3,  n_conv_2 = 512, k_conv_2 = 3, \n",
      "          n_conv_3 = 256,  k_conv_3 = 3,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 512, dropout_1 = 0.3,\n",
      "          n_dense_2 = 256, dropout_2 = 0.25, activation_conv=  elu,\n",
      "          activation_dense=  relu\n",
      "Epoch 1/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 1.1260 - accuracy: 0.5234\n",
      "Epoch 2/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 5s 35ms/step - loss: 0.9253 - accuracy: 0.6052\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.7886 - accuracy: 0.6789\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.6867 - accuracy: 0.7211\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.6448 - accuracy: 0.7417\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.6008 - accuracy: 0.7593\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.5693 - accuracy: 0.7749\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.5377 - accuracy: 0.7882\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.5382 - accuracy: 0.7898\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.4912 - accuracy: 0.8096\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.4730 - accuracy: 0.8142\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.4619 - accuracy: 0.8219\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.4503 - accuracy: 0.8238\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.4297 - accuracy: 0.8312\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.4470 - accuracy: 0.8266\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.4015 - accuracy: 0.8418\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.4050 - accuracy: 0.8426\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3908 - accuracy: 0.8490\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3872 - accuracy: 0.8496\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3704 - accuracy: 0.8580\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3695 - accuracy: 0.8559\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3758 - accuracy: 0.8551\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3591 - accuracy: 0.8640\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3417 - accuracy: 0.8681\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3520 - accuracy: 0.8662\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3468 - accuracy: 0.8668\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3357 - accuracy: 0.8713\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3328 - accuracy: 0.8708\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3195 - accuracy: 0.8771\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3290 - accuracy: 0.8739\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3209 - accuracy: 0.8762\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3026 - accuracy: 0.8845\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3112 - accuracy: 0.8810\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3156 - accuracy: 0.8775\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3010 - accuracy: 0.8821\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3052 - accuracy: 0.8823\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2987 - accuracy: 0.8841\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2940 - accuracy: 0.8856\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2881 - accuracy: 0.8909\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2901 - accuracy: 0.8881\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2883 - accuracy: 0.8890\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2864 - accuracy: 0.8897\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2728 - accuracy: 0.8929\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2765 - accuracy: 0.8940\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2745 - accuracy: 0.8933\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2691 - accuracy: 0.8938\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2737 - accuracy: 0.8945\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2666 - accuracy: 0.8952\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2672 - accuracy: 0.8962\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2693 - accuracy: 0.8959\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2531 - accuracy: 0.9001\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2624 - accuracy: 0.8983\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2547 - accuracy: 0.9010\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2520 - accuracy: 0.9013\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2423 - accuracy: 0.9050\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2598 - accuracy: 0.8989\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2482 - accuracy: 0.9029\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2437 - accuracy: 0.9046\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2446 - accuracy: 0.9043\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2414 - accuracy: 0.9066\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 0.3089 - accuracy: 0.8965\n",
      "n_conv_1 = 768, k_conv_1 = 2,  n_conv_2 = 256, k_conv_2 = 3, \n",
      "          n_conv_3 = 512,  k_conv_3 = 3,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 512, dropout_1 = 0.2,\n",
      "          n_dense_2 = 512, dropout_2 = 0.25, activation_conv=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001FAC9372D48>,\n",
      "          activation_dense=  elu\n",
      "Epoch 1/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 1.0778 - accuracy: 0.5358\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.8425 - accuracy: 0.6349\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.7561 - accuracy: 0.6799\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.6862 - accuracy: 0.7178\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.6185 - accuracy: 0.7527\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.5712 - accuracy: 0.7766\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.5307 - accuracy: 0.7917\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.4935 - accuracy: 0.8111\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.4796 - accuracy: 0.8151\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.4658 - accuracy: 0.8221\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.4366 - accuracy: 0.8324\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.4351 - accuracy: 0.8323\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.4235 - accuracy: 0.8387\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.4183 - accuracy: 0.8403\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.4024 - accuracy: 0.8450\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3983 - accuracy: 0.8476\n",
      "Epoch 17/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 6s 39ms/step - loss: 0.3874 - accuracy: 0.8505\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3824 - accuracy: 0.8524\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3932 - accuracy: 0.8448\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3623 - accuracy: 0.8578\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3693 - accuracy: 0.8611\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3592 - accuracy: 0.8585\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3489 - accuracy: 0.8645\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3547 - accuracy: 0.8626\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3489 - accuracy: 0.8637\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3406 - accuracy: 0.8663\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3338 - accuracy: 0.8695\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3331 - accuracy: 0.8691\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3349 - accuracy: 0.8676\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3133 - accuracy: 0.8760\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3199 - accuracy: 0.8730\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3194 - accuracy: 0.8725\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3102 - accuracy: 0.8765\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3175 - accuracy: 0.8761\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3119 - accuracy: 0.8761\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3217 - accuracy: 0.8733\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3043 - accuracy: 0.8776\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3062 - accuracy: 0.8787\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2997 - accuracy: 0.8787\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2934 - accuracy: 0.8808\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2929 - accuracy: 0.8808\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2950 - accuracy: 0.8807\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2837 - accuracy: 0.8853\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2856 - accuracy: 0.8843\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2743 - accuracy: 0.8884\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2761 - accuracy: 0.8900\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2928 - accuracy: 0.8816\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2734 - accuracy: 0.8889\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2761 - accuracy: 0.8871\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2724 - accuracy: 0.8895\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2657 - accuracy: 0.8922\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2714 - accuracy: 0.8893\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2645 - accuracy: 0.8922\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2635 - accuracy: 0.8925\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2614 - accuracy: 0.8932\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2624 - accuracy: 0.8927\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2564 - accuracy: 0.8952\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2511 - accuracy: 0.8977\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2575 - accuracy: 0.8945\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2459 - accuracy: 0.9004\n",
      "76/76 [==============================] - 1s 15ms/step - loss: 0.3528 - accuracy: 0.8802\n",
      "n_conv_1 = 768, k_conv_1 = 2,  n_conv_2 = 256, k_conv_2 = 3, \n",
      "          n_conv_3 = 512,  k_conv_3 = 3,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 512, dropout_1 = 0.2,\n",
      "          n_dense_2 = 512, dropout_2 = 0.25, activation_conv=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001FAC9880D88>,\n",
      "          activation_dense=  elu\n",
      "Epoch 1/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 1.0853 - accuracy: 0.5326\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.8577 - accuracy: 0.6282\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.7711 - accuracy: 0.6718\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.6974 - accuracy: 0.7129\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.6554 - accuracy: 0.7343\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.5983 - accuracy: 0.7608\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.5341 - accuracy: 0.7900\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.5148 - accuracy: 0.7994\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.4911 - accuracy: 0.8089\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.4615 - accuracy: 0.8222\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.4563 - accuracy: 0.8243\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.4292 - accuracy: 0.8363\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.4264 - accuracy: 0.8336\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.4119 - accuracy: 0.8417\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.4159 - accuracy: 0.8419\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3891 - accuracy: 0.8494\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3888 - accuracy: 0.8498\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3756 - accuracy: 0.8548\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3740 - accuracy: 0.8540\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3797 - accuracy: 0.8514\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3608 - accuracy: 0.8601\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3584 - accuracy: 0.8626\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3500 - accuracy: 0.8635\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3531 - accuracy: 0.8620\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3432 - accuracy: 0.8658\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3371 - accuracy: 0.8679\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3484 - accuracy: 0.8635\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3335 - accuracy: 0.8704\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3297 - accuracy: 0.8689\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3222 - accuracy: 0.8725\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3217 - accuracy: 0.8743\n",
      "Epoch 32/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3165 - accuracy: 0.8751\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3129 - accuracy: 0.8757\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3098 - accuracy: 0.8766\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3074 - accuracy: 0.8762\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3093 - accuracy: 0.8770\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3040 - accuracy: 0.8791\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2980 - accuracy: 0.8793\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2938 - accuracy: 0.8814\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3035 - accuracy: 0.8799\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3301 - accuracy: 0.8707\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2889 - accuracy: 0.8827\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2838 - accuracy: 0.8848\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2760 - accuracy: 0.8891\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2752 - accuracy: 0.8884\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2881 - accuracy: 0.8834\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2689 - accuracy: 0.8900\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2684 - accuracy: 0.8924\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2622 - accuracy: 0.8944\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2789 - accuracy: 0.8865\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2588 - accuracy: 0.8944\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2711 - accuracy: 0.8893\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2658 - accuracy: 0.8934\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2611 - accuracy: 0.8922\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2542 - accuracy: 0.8963\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2521 - accuracy: 0.8979\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2513 - accuracy: 0.8984\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2507 - accuracy: 0.8990\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2445 - accuracy: 0.9006\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2390 - accuracy: 0.9026\n",
      "76/76 [==============================] - 1s 15ms/step - loss: 0.3532 - accuracy: 0.8839\n",
      "n_conv_1 = 768, k_conv_1 = 2,  n_conv_2 = 256, k_conv_2 = 3, \n",
      "          n_conv_3 = 512,  k_conv_3 = 3,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 512, dropout_1 = 0.2,\n",
      "          n_dense_2 = 512, dropout_2 = 0.25, activation_conv=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001FAC13B2548>,\n",
      "          activation_dense=  elu\n",
      "Epoch 1/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 1.0891 - accuracy: 0.5321\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.8688 - accuracy: 0.6246\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.7714 - accuracy: 0.6722\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.6938 - accuracy: 0.7128\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.6393 - accuracy: 0.7432\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.5788 - accuracy: 0.7734\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.5353 - accuracy: 0.7897\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.5116 - accuracy: 0.7976\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.4823 - accuracy: 0.8114\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.4711 - accuracy: 0.8167\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.4585 - accuracy: 0.8205\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.4299 - accuracy: 0.8328\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.4235 - accuracy: 0.8360\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.4103 - accuracy: 0.8414\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.4147 - accuracy: 0.8389\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3993 - accuracy: 0.8432\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3855 - accuracy: 0.8486\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3894 - accuracy: 0.8478\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3830 - accuracy: 0.8509\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3761 - accuracy: 0.8546\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3655 - accuracy: 0.8549\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3651 - accuracy: 0.8545\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3578 - accuracy: 0.8620\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3567 - accuracy: 0.8596\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3487 - accuracy: 0.8645\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3415 - accuracy: 0.8651\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3451 - accuracy: 0.8640\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3283 - accuracy: 0.8691\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3347 - accuracy: 0.8683\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3348 - accuracy: 0.8671\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3253 - accuracy: 0.8706\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3236 - accuracy: 0.8709\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3090 - accuracy: 0.8767\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3205 - accuracy: 0.8710\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3095 - accuracy: 0.8766\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3068 - accuracy: 0.8767\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3070 - accuracy: 0.8757\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2984 - accuracy: 0.8787\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2949 - accuracy: 0.8796\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3029 - accuracy: 0.8786\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2841 - accuracy: 0.8854\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2945 - accuracy: 0.8796\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2858 - accuracy: 0.8870\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2945 - accuracy: 0.8826\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2935 - accuracy: 0.8810\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2791 - accuracy: 0.8881\n",
      "Epoch 47/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2725 - accuracy: 0.8895\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2800 - accuracy: 0.8865\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2738 - accuracy: 0.8892\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.2629 - accuracy: 0.8924\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2697 - accuracy: 0.8902\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2734 - accuracy: 0.8896\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2602 - accuracy: 0.8950\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2576 - accuracy: 0.8950\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2573 - accuracy: 0.8943\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2686 - accuracy: 0.8909\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2520 - accuracy: 0.8954\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2686 - accuracy: 0.8928\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2489 - accuracy: 0.8978\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2440 - accuracy: 0.8996\n",
      "76/76 [==============================] - 1s 15ms/step - loss: 0.3380 - accuracy: 0.8811\n",
      "n_conv_1 = 512, k_conv_1 = 2,  n_conv_2 = 256, k_conv_2 = 3, \n",
      "          n_conv_3 = 512,  k_conv_3 = 3,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 512, dropout_1 = 0.3,\n",
      "          n_dense_2 = 256, dropout_2 = 0.25, activation_conv=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001FAC98F7F88>,\n",
      "          activation_dense=  relu\n",
      "Epoch 1/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 1.1258 - accuracy: 0.5216\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.8721 - accuracy: 0.6314\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.7722 - accuracy: 0.6720\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.7204 - accuracy: 0.6946\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.6472 - accuracy: 0.7285\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.6050 - accuracy: 0.7523\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.5470 - accuracy: 0.7806\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.5168 - accuracy: 0.7975\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.4802 - accuracy: 0.8115\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.4633 - accuracy: 0.8205\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.4564 - accuracy: 0.8199\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.4219 - accuracy: 0.8363\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.4070 - accuracy: 0.8424\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.4175 - accuracy: 0.8377\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3981 - accuracy: 0.8453\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3917 - accuracy: 0.8493\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3677 - accuracy: 0.8573\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3775 - accuracy: 0.8535\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3731 - accuracy: 0.8536\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3605 - accuracy: 0.8609\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3591 - accuracy: 0.8588\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3622 - accuracy: 0.8583\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3477 - accuracy: 0.8653\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3417 - accuracy: 0.8664\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3349 - accuracy: 0.8672\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3274 - accuracy: 0.8738\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3285 - accuracy: 0.8731\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3197 - accuracy: 0.8747\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3211 - accuracy: 0.8753\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3149 - accuracy: 0.8786\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3192 - accuracy: 0.8750\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3138 - accuracy: 0.8771\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3094 - accuracy: 0.8784\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2920 - accuracy: 0.8843\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2985 - accuracy: 0.8818\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3027 - accuracy: 0.8810\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2952 - accuracy: 0.8847\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2907 - accuracy: 0.8864\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2855 - accuracy: 0.8874\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2888 - accuracy: 0.8882\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2864 - accuracy: 0.8903\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2886 - accuracy: 0.8885\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2723 - accuracy: 0.8912\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2787 - accuracy: 0.8904\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2731 - accuracy: 0.8935\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2713 - accuracy: 0.8942\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2721 - accuracy: 0.8944\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2674 - accuracy: 0.8951\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2653 - accuracy: 0.8975\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2734 - accuracy: 0.8932\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2539 - accuracy: 0.9003\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2694 - accuracy: 0.8964\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2433 - accuracy: 0.9050\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2653 - accuracy: 0.8970\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2603 - accuracy: 0.9002\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2617 - accuracy: 0.8968\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2562 - accuracy: 0.9009\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2451 - accuracy: 0.9043\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2560 - accuracy: 0.9019\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2431 - accuracy: 0.9043\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 0.2780 - accuracy: 0.8995\n",
      "n_conv_1 = 512, k_conv_1 = 2,  n_conv_2 = 256, k_conv_2 = 3, \n",
      "          n_conv_3 = 512,  k_conv_3 = 3,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 512, dropout_1 = 0.3,\n",
      "          n_dense_2 = 256, dropout_2 = 0.25, activation_conv=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001FAC99E89C8>,\n",
      "          activation_dense=  relu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 1.1110 - accuracy: 0.5242\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.8844 - accuracy: 0.6229\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.7807 - accuracy: 0.6660\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.7048 - accuracy: 0.7047\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.6487 - accuracy: 0.7298\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.5779 - accuracy: 0.7662\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.5440 - accuracy: 0.7809\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.5128 - accuracy: 0.7950\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.4678 - accuracy: 0.8177\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.4506 - accuracy: 0.8237\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.4387 - accuracy: 0.8293\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.4161 - accuracy: 0.8392\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.4063 - accuracy: 0.8394\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3886 - accuracy: 0.8466\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3801 - accuracy: 0.8505\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3962 - accuracy: 0.8439\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3737 - accuracy: 0.8554\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3525 - accuracy: 0.8627\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3667 - accuracy: 0.8574\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3552 - accuracy: 0.8589\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3465 - accuracy: 0.8638\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3406 - accuracy: 0.8639\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3404 - accuracy: 0.8653\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3270 - accuracy: 0.8717\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3317 - accuracy: 0.8707\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3275 - accuracy: 0.8690\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3188 - accuracy: 0.8732\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3201 - accuracy: 0.8752\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3167 - accuracy: 0.8760\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3084 - accuracy: 0.8783\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2995 - accuracy: 0.8805\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2947 - accuracy: 0.8829\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3089 - accuracy: 0.8794\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3011 - accuracy: 0.8805\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3038 - accuracy: 0.8802\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2956 - accuracy: 0.8816\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2839 - accuracy: 0.8870\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2964 - accuracy: 0.8812\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2786 - accuracy: 0.8898\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2859 - accuracy: 0.8856\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2825 - accuracy: 0.8875\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2809 - accuracy: 0.8889\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2746 - accuracy: 0.8907\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2687 - accuracy: 0.8925\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2752 - accuracy: 0.8928\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2693 - accuracy: 0.8942\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2609 - accuracy: 0.8963\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2596 - accuracy: 0.8967\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2717 - accuracy: 0.8928\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2586 - accuracy: 0.8978\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2491 - accuracy: 0.9033\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2559 - accuracy: 0.8979\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2708 - accuracy: 0.8936\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2493 - accuracy: 0.9016\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2446 - accuracy: 0.9031\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2408 - accuracy: 0.9044\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2473 - accuracy: 0.9025\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2348 - accuracy: 0.9068\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2484 - accuracy: 0.9027\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2553 - accuracy: 0.8989\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 0.2877 - accuracy: 0.8940\n",
      "n_conv_1 = 512, k_conv_1 = 2,  n_conv_2 = 256, k_conv_2 = 3, \n",
      "          n_conv_3 = 512,  k_conv_3 = 3,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 512, dropout_1 = 0.3,\n",
      "          n_dense_2 = 256, dropout_2 = 0.25, activation_conv=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001FAC97A0B48>,\n",
      "          activation_dense=  relu\n",
      "Epoch 1/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 1.1172 - accuracy: 0.5284\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.8954 - accuracy: 0.6247\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.7892 - accuracy: 0.6632\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.7163 - accuracy: 0.6994\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.6691 - accuracy: 0.7188\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.5972 - accuracy: 0.7564\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.5521 - accuracy: 0.7763\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.5185 - accuracy: 0.7959\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.4817 - accuracy: 0.8102\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.4659 - accuracy: 0.8160\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.4451 - accuracy: 0.8252\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.4362 - accuracy: 0.8304\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.4187 - accuracy: 0.8346\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.4095 - accuracy: 0.8389\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.4004 - accuracy: 0.8454\n",
      "Epoch 16/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3803 - accuracy: 0.8524\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3971 - accuracy: 0.8446\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3647 - accuracy: 0.8570\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3683 - accuracy: 0.8570\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3511 - accuracy: 0.8619\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3576 - accuracy: 0.8609\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3559 - accuracy: 0.8610\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3401 - accuracy: 0.8660\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3342 - accuracy: 0.8682\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3332 - accuracy: 0.8700\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3351 - accuracy: 0.8685\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3286 - accuracy: 0.8696\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3130 - accuracy: 0.8753\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3155 - accuracy: 0.8769\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3227 - accuracy: 0.8718\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3068 - accuracy: 0.8756\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3190 - accuracy: 0.8749\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3079 - accuracy: 0.8786\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3021 - accuracy: 0.8790\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3041 - accuracy: 0.8797\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2932 - accuracy: 0.8834\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2970 - accuracy: 0.8835\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2846 - accuracy: 0.8874\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2930 - accuracy: 0.8827\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2870 - accuracy: 0.8874\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2899 - accuracy: 0.8860\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2722 - accuracy: 0.8935\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2776 - accuracy: 0.8908\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2754 - accuracy: 0.8910\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2754 - accuracy: 0.8928\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2591 - accuracy: 0.8965\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2683 - accuracy: 0.8947\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2651 - accuracy: 0.8972\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2724 - accuracy: 0.8926\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2612 - accuracy: 0.8963\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2520 - accuracy: 0.9005\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2570 - accuracy: 0.8994\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2453 - accuracy: 0.9035\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2537 - accuracy: 0.8990\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2545 - accuracy: 0.9017\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2498 - accuracy: 0.9013\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2551 - accuracy: 0.9002\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2412 - accuracy: 0.9030\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2424 - accuracy: 0.9068\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2428 - accuracy: 0.9050\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 0.2672 - accuracy: 0.9043\n",
      "n_conv_1 = 512, k_conv_1 = 3,  n_conv_2 = 512, k_conv_2 = 3, \n",
      "          n_conv_3 = 512,  k_conv_3 = 2,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 512, dropout_1 = 0.3,\n",
      "          n_dense_2 = 256, dropout_2 = 0.25, activation_conv=  relu,\n",
      "          activation_dense=  relu\n",
      "Epoch 1/60\n",
      "  1/152 [..............................] - ETA: 3s - loss: 1.7936 - accuracy: 0.1641WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0150s vs `on_train_batch_end` time: 0.0229s). Check your callbacks.\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 1.0975 - accuracy: 0.5379\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.7181 - accuracy: 0.7089\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.5244 - accuracy: 0.8001\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.4312 - accuracy: 0.8381\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3687 - accuracy: 0.8615\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3444 - accuracy: 0.8698\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3284 - accuracy: 0.8777\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.3130 - accuracy: 0.8801\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.2942 - accuracy: 0.8905\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2794 - accuracy: 0.8941\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.2682 - accuracy: 0.8990\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2610 - accuracy: 0.9033\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.2580 - accuracy: 0.9053\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2371 - accuracy: 0.9099\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2398 - accuracy: 0.9098\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2243 - accuracy: 0.9165\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2176 - accuracy: 0.9183\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2225 - accuracy: 0.9172\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2069 - accuracy: 0.9232\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2069 - accuracy: 0.9239\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2052 - accuracy: 0.9235\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.1883 - accuracy: 0.9305\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.1857 - accuracy: 0.9301\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.1835 - accuracy: 0.9318\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.1781 - accuracy: 0.9324\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.1788 - accuracy: 0.9338\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.1677 - accuracy: 0.9366\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.1700 - accuracy: 0.9358\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.1633 - accuracy: 0.9388\n",
      "Epoch 30/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 5s 35ms/step - loss: 0.1613 - accuracy: 0.9386\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.1567 - accuracy: 0.9414\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.1552 - accuracy: 0.9412\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.1531 - accuracy: 0.9420\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.1403 - accuracy: 0.9468\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.1430 - accuracy: 0.9457\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.1410 - accuracy: 0.9469\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.1449 - accuracy: 0.9466\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.1309 - accuracy: 0.9504\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.1347 - accuracy: 0.9493\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.1252 - accuracy: 0.9523\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.1231 - accuracy: 0.9533\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.1344 - accuracy: 0.9499\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.1280 - accuracy: 0.9515\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.1197 - accuracy: 0.9543\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.1216 - accuracy: 0.9549\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.1207 - accuracy: 0.9554\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.1081 - accuracy: 0.9593\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.1110 - accuracy: 0.9574\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.1201 - accuracy: 0.9550\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.1038 - accuracy: 0.9608\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.1075 - accuracy: 0.9594\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.1026 - accuracy: 0.9607\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.1049 - accuracy: 0.9608\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.1099 - accuracy: 0.9584\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.1045 - accuracy: 0.9606\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.0962 - accuracy: 0.9636\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.1004 - accuracy: 0.9612\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.0917 - accuracy: 0.9639\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.0936 - accuracy: 0.9642\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.0976 - accuracy: 0.9629\n",
      "76/76 [==============================] - 1s 14ms/step - loss: 0.2401 - accuracy: 0.9358\n",
      "n_conv_1 = 512, k_conv_1 = 3,  n_conv_2 = 512, k_conv_2 = 3, \n",
      "          n_conv_3 = 512,  k_conv_3 = 2,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 512, dropout_1 = 0.3,\n",
      "          n_dense_2 = 256, dropout_2 = 0.25, activation_conv=  relu,\n",
      "          activation_dense=  relu\n",
      "Epoch 1/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 1.0771 - accuracy: 0.5502\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.6956 - accuracy: 0.7244\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.5149 - accuracy: 0.8025\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.4245 - accuracy: 0.8396\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3810 - accuracy: 0.8541\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.3494 - accuracy: 0.8673\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3223 - accuracy: 0.8767\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.3048 - accuracy: 0.8846\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.2942 - accuracy: 0.8893\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2882 - accuracy: 0.8923\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2728 - accuracy: 0.8982\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2582 - accuracy: 0.9028\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2482 - accuracy: 0.9059\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2440 - accuracy: 0.9060\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2439 - accuracy: 0.9089\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2345 - accuracy: 0.9123\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2183 - accuracy: 0.9189\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2152 - accuracy: 0.9198\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2056 - accuracy: 0.9237\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.1993 - accuracy: 0.9263\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.1933 - accuracy: 0.9284\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.1937 - accuracy: 0.9281\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.1837 - accuracy: 0.9332\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.1742 - accuracy: 0.9344\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.1795 - accuracy: 0.9337\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.1719 - accuracy: 0.9368\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.1686 - accuracy: 0.9393\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.1602 - accuracy: 0.9400\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.1536 - accuracy: 0.9437\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.1580 - accuracy: 0.9431\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.1497 - accuracy: 0.9450\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.1468 - accuracy: 0.9455\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.1489 - accuracy: 0.9444\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.1495 - accuracy: 0.9434\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.1440 - accuracy: 0.9451\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.1331 - accuracy: 0.9496\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.1322 - accuracy: 0.9489\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.1283 - accuracy: 0.9525\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.1295 - accuracy: 0.9515\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.1323 - accuracy: 0.9509\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.1237 - accuracy: 0.9550\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.1241 - accuracy: 0.9536\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.1205 - accuracy: 0.9531\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.1109 - accuracy: 0.9571\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.1165 - accuracy: 0.9560\n",
      "Epoch 46/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 5s 35ms/step - loss: 0.1137 - accuracy: 0.9574\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.1035 - accuracy: 0.9603\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.1049 - accuracy: 0.9602\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.1053 - accuracy: 0.9605\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.1051 - accuracy: 0.9597\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.1083 - accuracy: 0.9587\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.0958 - accuracy: 0.9626\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.0996 - accuracy: 0.9620\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.0995 - accuracy: 0.9619\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.0932 - accuracy: 0.9648\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.0912 - accuracy: 0.9653\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.0960 - accuracy: 0.9637\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.0941 - accuracy: 0.9647\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.0901 - accuracy: 0.9668\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.0872 - accuracy: 0.9678\n",
      "76/76 [==============================] - 1s 14ms/step - loss: 0.2383 - accuracy: 0.9392\n",
      "n_conv_1 = 512, k_conv_1 = 3,  n_conv_2 = 512, k_conv_2 = 3, \n",
      "          n_conv_3 = 512,  k_conv_3 = 2,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 512, dropout_1 = 0.3,\n",
      "          n_dense_2 = 256, dropout_2 = 0.25, activation_conv=  relu,\n",
      "          activation_dense=  relu\n",
      "Epoch 1/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 1.0682 - accuracy: 0.5537\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.7029 - accuracy: 0.7219\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.5097 - accuracy: 0.8037\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.4442 - accuracy: 0.8345\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.3772 - accuracy: 0.8603\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.3441 - accuracy: 0.8710\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3305 - accuracy: 0.8745\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.3156 - accuracy: 0.8838\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2881 - accuracy: 0.8937\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2885 - accuracy: 0.8938\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2653 - accuracy: 0.9027\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2600 - accuracy: 0.9041\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2482 - accuracy: 0.9082\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2395 - accuracy: 0.9125\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2288 - accuracy: 0.9153\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2231 - accuracy: 0.9161\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2202 - accuracy: 0.9184\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2129 - accuracy: 0.9227\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2114 - accuracy: 0.9227\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2026 - accuracy: 0.9255\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.1933 - accuracy: 0.9298\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.1948 - accuracy: 0.9274\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.1863 - accuracy: 0.9321\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.1856 - accuracy: 0.9320\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.1803 - accuracy: 0.9337\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.1741 - accuracy: 0.9350\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.1642 - accuracy: 0.9389\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.1762 - accuracy: 0.9348\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.1607 - accuracy: 0.9404\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.1599 - accuracy: 0.9415\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.1573 - accuracy: 0.9422\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.1539 - accuracy: 0.9438\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.1474 - accuracy: 0.9445\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.1503 - accuracy: 0.9450\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.1506 - accuracy: 0.9441\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.1375 - accuracy: 0.9495\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.1462 - accuracy: 0.9463\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.1388 - accuracy: 0.9482\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.1334 - accuracy: 0.9501\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.1326 - accuracy: 0.9505\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.1227 - accuracy: 0.9541\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.1259 - accuracy: 0.9515\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.1199 - accuracy: 0.9557\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.1222 - accuracy: 0.9544\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.1172 - accuracy: 0.9555\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.1118 - accuracy: 0.9587\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.1199 - accuracy: 0.9555\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.1096 - accuracy: 0.9591\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.1122 - accuracy: 0.9583\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.1074 - accuracy: 0.9592\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.1004 - accuracy: 0.9618\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.1160 - accuracy: 0.9565\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.1005 - accuracy: 0.9620\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.1192 - accuracy: 0.9554\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.1084 - accuracy: 0.9596\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.0980 - accuracy: 0.9634\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.0958 - accuracy: 0.9639\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.1010 - accuracy: 0.9633\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.0887 - accuracy: 0.9662\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.0885 - accuracy: 0.9659\n",
      "76/76 [==============================] - 1s 14ms/step - loss: 0.2301 - accuracy: 0.9396\n",
      "n_conv_1 = 512, k_conv_1 = 3,  n_conv_2 = 256, k_conv_2 = 2, \n",
      "          n_conv_3 = 256,  k_conv_3 = 2,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 256, dropout_1 = 0.3,\n",
      "          n_dense_2 = 256, dropout_2 = 0.25, activation_conv=  elu,\n",
      "          activation_dense=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001FAC9460B48>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 1.1704 - accuracy: 0.5032\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.9527 - accuracy: 0.6054\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.8193 - accuracy: 0.6664\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.7746 - accuracy: 0.6855\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.7365 - accuracy: 0.7031\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.6953 - accuracy: 0.7199\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.6837 - accuracy: 0.7251\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.6533 - accuracy: 0.7376\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.6376 - accuracy: 0.7445\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.6178 - accuracy: 0.7532\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.6017 - accuracy: 0.7602\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.5941 - accuracy: 0.7611\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.5700 - accuracy: 0.7727\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.5548 - accuracy: 0.7791\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.5437 - accuracy: 0.7856\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.5385 - accuracy: 0.7865\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.5238 - accuracy: 0.7921\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.5239 - accuracy: 0.7941\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.4952 - accuracy: 0.8066\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.4905 - accuracy: 0.8092\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.4841 - accuracy: 0.8104\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.4734 - accuracy: 0.8157\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.4612 - accuracy: 0.8204\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.4633 - accuracy: 0.8195\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.4563 - accuracy: 0.8230\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.4476 - accuracy: 0.8258\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.4356 - accuracy: 0.8307\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.4291 - accuracy: 0.8340\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.4299 - accuracy: 0.8329\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.4182 - accuracy: 0.8393\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.4146 - accuracy: 0.8414\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.4023 - accuracy: 0.8461\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.4075 - accuracy: 0.8439\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3966 - accuracy: 0.8477\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3959 - accuracy: 0.8488\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3899 - accuracy: 0.8507\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.4045 - accuracy: 0.8451\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3781 - accuracy: 0.8561\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3749 - accuracy: 0.8577\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3694 - accuracy: 0.8608\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3648 - accuracy: 0.8612\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3674 - accuracy: 0.8597\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3616 - accuracy: 0.8614\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3628 - accuracy: 0.8623\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3523 - accuracy: 0.8666\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3484 - accuracy: 0.8656\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3432 - accuracy: 0.8681\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3516 - accuracy: 0.8647\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3358 - accuracy: 0.8716\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3434 - accuracy: 0.8689\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3339 - accuracy: 0.8717\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3304 - accuracy: 0.8749\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3331 - accuracy: 0.8715\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3255 - accuracy: 0.8756\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3185 - accuracy: 0.8770\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3158 - accuracy: 0.8783 0s - loss: 0.3156 - accuracy: 0.87\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3104 - accuracy: 0.8804\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3178 - accuracy: 0.8781\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3109 - accuracy: 0.8800\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3064 - accuracy: 0.8803\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 0.3049 - accuracy: 0.8766\n",
      "n_conv_1 = 512, k_conv_1 = 3,  n_conv_2 = 256, k_conv_2 = 2, \n",
      "          n_conv_3 = 256,  k_conv_3 = 2,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 256, dropout_1 = 0.3,\n",
      "          n_dense_2 = 256, dropout_2 = 0.25, activation_conv=  elu,\n",
      "          activation_dense=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001FBE8900C88>\n",
      "Epoch 1/60\n",
      "  1/152 [..............................] - ETA: 2s - loss: 1.7928 - accuracy: 0.1953WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0100s vs `on_train_batch_end` time: 0.0160s). Check your callbacks.\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 1.1637 - accuracy: 0.5047\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.9316 - accuracy: 0.6181\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.8206 - accuracy: 0.6695\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.7735 - accuracy: 0.6861\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.7350 - accuracy: 0.7029\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.7160 - accuracy: 0.7114\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.6716 - accuracy: 0.7283\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.6611 - accuracy: 0.7341\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.6433 - accuracy: 0.7428\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.6156 - accuracy: 0.7533\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.5931 - accuracy: 0.7637\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.5898 - accuracy: 0.7638\n",
      "Epoch 13/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 3s 23ms/step - loss: 0.5779 - accuracy: 0.7686\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.5693 - accuracy: 0.7734\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.5461 - accuracy: 0.7821\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.5336 - accuracy: 0.7881\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.5234 - accuracy: 0.7923\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.5099 - accuracy: 0.7996\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.5032 - accuracy: 0.8035\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.4891 - accuracy: 0.8080 0s - los\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.4825 - accuracy: 0.8105\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.4635 - accuracy: 0.8200\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.4639 - accuracy: 0.8202\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.4594 - accuracy: 0.8225\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.4429 - accuracy: 0.8277\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.4393 - accuracy: 0.8304\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.4271 - accuracy: 0.8362\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.4191 - accuracy: 0.8404\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.4280 - accuracy: 0.8376\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.4111 - accuracy: 0.8434\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.4109 - accuracy: 0.8456\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.4083 - accuracy: 0.8448\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3987 - accuracy: 0.8490\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3870 - accuracy: 0.8514\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3857 - accuracy: 0.8547\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3876 - accuracy: 0.8546\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3774 - accuracy: 0.8571\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3795 - accuracy: 0.8564\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3727 - accuracy: 0.8596\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3695 - accuracy: 0.8604\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3669 - accuracy: 0.8623\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3619 - accuracy: 0.8631\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3550 - accuracy: 0.8657\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3495 - accuracy: 0.8688\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3503 - accuracy: 0.8667\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3513 - accuracy: 0.8674\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3432 - accuracy: 0.8705\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3458 - accuracy: 0.8682\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3393 - accuracy: 0.8719\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3362 - accuracy: 0.8726\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3355 - accuracy: 0.8725\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3291 - accuracy: 0.8739\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3200 - accuracy: 0.8787\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3181 - accuracy: 0.8807\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3219 - accuracy: 0.8778\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3178 - accuracy: 0.8794\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3220 - accuracy: 0.8772\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3129 - accuracy: 0.8811\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3119 - accuracy: 0.8814\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3043 - accuracy: 0.8844\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.3726 - accuracy: 0.8700\n",
      "n_conv_1 = 512, k_conv_1 = 3,  n_conv_2 = 256, k_conv_2 = 2, \n",
      "          n_conv_3 = 256,  k_conv_3 = 2,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 256, dropout_1 = 0.3,\n",
      "          n_dense_2 = 256, dropout_2 = 0.25, activation_conv=  elu,\n",
      "          activation_dense=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001FBE9D96F88>\n",
      "Epoch 1/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 1.1538 - accuracy: 0.5117\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.9291 - accuracy: 0.6203\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.8123 - accuracy: 0.6735\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.7623 - accuracy: 0.6961\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.7398 - accuracy: 0.7019\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.7165 - accuracy: 0.7076\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.6842 - accuracy: 0.7221\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.6680 - accuracy: 0.7293\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.6423 - accuracy: 0.7385\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.6190 - accuracy: 0.7528\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.6123 - accuracy: 0.7515\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.6040 - accuracy: 0.7571\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.5697 - accuracy: 0.7750\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.5593 - accuracy: 0.7764\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.5496 - accuracy: 0.7799\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.5354 - accuracy: 0.7866\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.5197 - accuracy: 0.7933\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.5308 - accuracy: 0.7909\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.5158 - accuracy: 0.7945\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.4890 - accuracy: 0.8053\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.4820 - accuracy: 0.8112\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.4810 - accuracy: 0.8111\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.4652 - accuracy: 0.8155\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.4709 - accuracy: 0.8155\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.4535 - accuracy: 0.8226\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.4564 - accuracy: 0.8224\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.4498 - accuracy: 0.8243\n",
      "Epoch 28/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 3s 23ms/step - loss: 0.4322 - accuracy: 0.8320\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.4318 - accuracy: 0.8334\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.4225 - accuracy: 0.8364\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.4239 - accuracy: 0.8371\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.4110 - accuracy: 0.8418\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.4173 - accuracy: 0.8383\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3989 - accuracy: 0.8475\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3945 - accuracy: 0.8489\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3951 - accuracy: 0.8494\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3894 - accuracy: 0.8491\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3789 - accuracy: 0.8565\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3771 - accuracy: 0.8551\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3703 - accuracy: 0.8585\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3683 - accuracy: 0.8582\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3659 - accuracy: 0.8605\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3646 - accuracy: 0.8621\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3612 - accuracy: 0.8617\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3615 - accuracy: 0.8620\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3466 - accuracy: 0.8675\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3410 - accuracy: 0.8704\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.3431 - accuracy: 0.8702\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3387 - accuracy: 0.8717\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3343 - accuracy: 0.8737\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3270 - accuracy: 0.8755\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3306 - accuracy: 0.8757\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3237 - accuracy: 0.8783\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3211 - accuracy: 0.8807\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3183 - accuracy: 0.8801\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3165 - accuracy: 0.8792\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3126 - accuracy: 0.8810\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3092 - accuracy: 0.8840\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3091 - accuracy: 0.8846\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3024 - accuracy: 0.8872\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.2906 - accuracy: 0.8968\n",
      "n_conv_1 = 512, k_conv_1 = 3,  n_conv_2 = 512, k_conv_2 = 3, \n",
      "          n_conv_3 = 256,  k_conv_3 = 3,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 256, dropout_1 = 0.3,\n",
      "          n_dense_2 = 256, dropout_2 = 0.25, activation_conv=  relu,\n",
      "          activation_dense=  relu\n",
      "Epoch 1/60\n",
      "  1/152 [..............................] - ETA: 2s - loss: 1.7863 - accuracy: 0.2148WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0140s vs `on_train_batch_end` time: 0.0209s). Check your callbacks.\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 1.1093 - accuracy: 0.5324\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.7348 - accuracy: 0.7024\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.5541 - accuracy: 0.7852\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.4589 - accuracy: 0.8228\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3927 - accuracy: 0.8516\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3688 - accuracy: 0.8605\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3443 - accuracy: 0.8707\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3219 - accuracy: 0.8793\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3123 - accuracy: 0.8812\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3027 - accuracy: 0.8873\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2926 - accuracy: 0.8893\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2808 - accuracy: 0.8948\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2642 - accuracy: 0.9016\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2621 - accuracy: 0.9039\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2470 - accuracy: 0.9081\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2465 - accuracy: 0.9096\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2455 - accuracy: 0.9098\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2339 - accuracy: 0.9136\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2258 - accuracy: 0.9170\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2213 - accuracy: 0.9183\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2223 - accuracy: 0.9184\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2029 - accuracy: 0.9253\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2049 - accuracy: 0.9242\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2000 - accuracy: 0.9263\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.1978 - accuracy: 0.9264\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.1921 - accuracy: 0.9289\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.1904 - accuracy: 0.9284\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.1844 - accuracy: 0.9317\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.1842 - accuracy: 0.9307\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.1709 - accuracy: 0.9361\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.1835 - accuracy: 0.9328\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.1678 - accuracy: 0.9369\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.1569 - accuracy: 0.9394\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.1561 - accuracy: 0.9407\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.1624 - accuracy: 0.9385\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.1615 - accuracy: 0.9391\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.1558 - accuracy: 0.9418\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.1487 - accuracy: 0.9446\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.1438 - accuracy: 0.9466\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.1462 - accuracy: 0.9452\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.1454 - accuracy: 0.9447\n",
      "Epoch 42/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 5s 34ms/step - loss: 0.1376 - accuracy: 0.9482\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.1345 - accuracy: 0.9503\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.1302 - accuracy: 0.9510\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.1363 - accuracy: 0.9485\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.1272 - accuracy: 0.9514\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.1357 - accuracy: 0.9505\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.1206 - accuracy: 0.9541\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.1254 - accuracy: 0.9516\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.1192 - accuracy: 0.9550\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.1145 - accuracy: 0.9566\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.1165 - accuracy: 0.9566\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.1158 - accuracy: 0.9567\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.1190 - accuracy: 0.9553\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.1128 - accuracy: 0.9571\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.1080 - accuracy: 0.9597\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.1285 - accuracy: 0.9528\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.1036 - accuracy: 0.9606\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.1008 - accuracy: 0.9622\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.1034 - accuracy: 0.9609\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 0.2446 - accuracy: 0.9349\n",
      "n_conv_1 = 512, k_conv_1 = 3,  n_conv_2 = 512, k_conv_2 = 3, \n",
      "          n_conv_3 = 256,  k_conv_3 = 3,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 256, dropout_1 = 0.3,\n",
      "          n_dense_2 = 256, dropout_2 = 0.25, activation_conv=  relu,\n",
      "          activation_dense=  relu\n",
      "Epoch 1/60\n",
      "  1/152 [..............................] - ETA: 3s - loss: 1.7984 - accuracy: 0.1562WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0139s vs `on_train_batch_end` time: 0.0209s). Check your callbacks.\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 1.0943 - accuracy: 0.5388\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.7150 - accuracy: 0.7173\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.5446 - accuracy: 0.7931\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.4788 - accuracy: 0.8200\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3950 - accuracy: 0.8513\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3707 - accuracy: 0.8603\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3390 - accuracy: 0.8706\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3280 - accuracy: 0.8762\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3143 - accuracy: 0.8827\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3035 - accuracy: 0.8841\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2958 - accuracy: 0.8900\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2776 - accuracy: 0.8969\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2780 - accuracy: 0.8972\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2551 - accuracy: 0.9058\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2505 - accuracy: 0.9079\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2484 - accuracy: 0.9065\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2392 - accuracy: 0.9114\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2309 - accuracy: 0.9138\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2245 - accuracy: 0.9169\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2225 - accuracy: 0.9175\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2177 - accuracy: 0.9202\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2126 - accuracy: 0.9219\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2134 - accuracy: 0.9214\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2030 - accuracy: 0.9250\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.1955 - accuracy: 0.9267\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.1915 - accuracy: 0.9292\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.1843 - accuracy: 0.9314\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.1880 - accuracy: 0.9303\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.1808 - accuracy: 0.9332\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.1708 - accuracy: 0.9360\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.1788 - accuracy: 0.9353\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.1721 - accuracy: 0.9375\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.1619 - accuracy: 0.9385\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.1659 - accuracy: 0.9401\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.1566 - accuracy: 0.9418\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.1626 - accuracy: 0.9411\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.1499 - accuracy: 0.9435\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.1529 - accuracy: 0.9439\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.1538 - accuracy: 0.9433\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.1421 - accuracy: 0.9470\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.1504 - accuracy: 0.9448\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.1399 - accuracy: 0.9476\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.1470 - accuracy: 0.9451\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.1368 - accuracy: 0.9482\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.1328 - accuracy: 0.9511\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.1275 - accuracy: 0.9523\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.1345 - accuracy: 0.9500\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.1330 - accuracy: 0.9505\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.1227 - accuracy: 0.9546\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.1234 - accuracy: 0.9548\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.1223 - accuracy: 0.9552\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.1138 - accuracy: 0.9579\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.1262 - accuracy: 0.9531\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.1112 - accuracy: 0.9574\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.1184 - accuracy: 0.9555\n",
      "Epoch 56/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 5s 34ms/step - loss: 0.1147 - accuracy: 0.9575\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.1098 - accuracy: 0.9591\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.1099 - accuracy: 0.9583\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.1041 - accuracy: 0.9615\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.1043 - accuracy: 0.9614\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 0.2575 - accuracy: 0.9347\n",
      "n_conv_1 = 512, k_conv_1 = 3,  n_conv_2 = 512, k_conv_2 = 3, \n",
      "          n_conv_3 = 256,  k_conv_3 = 3,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 256, dropout_1 = 0.3,\n",
      "          n_dense_2 = 256, dropout_2 = 0.25, activation_conv=  relu,\n",
      "          activation_dense=  relu\n",
      "Epoch 1/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 1.0855 - accuracy: 0.5471\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.7296 - accuracy: 0.7112\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.5470 - accuracy: 0.7924\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.4375 - accuracy: 0.8352\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3925 - accuracy: 0.8524\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3618 - accuracy: 0.8655\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3455 - accuracy: 0.8720\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3189 - accuracy: 0.8809\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3118 - accuracy: 0.8842\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3005 - accuracy: 0.8879\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2862 - accuracy: 0.8949\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2734 - accuracy: 0.8980\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2630 - accuracy: 0.9019\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2561 - accuracy: 0.9042\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2624 - accuracy: 0.9012\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2361 - accuracy: 0.9106\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2270 - accuracy: 0.9138\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2296 - accuracy: 0.9135\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2244 - accuracy: 0.9151\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2287 - accuracy: 0.9140\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2195 - accuracy: 0.9165\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2080 - accuracy: 0.9214\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2081 - accuracy: 0.9210\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.1968 - accuracy: 0.9240\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2058 - accuracy: 0.9228\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.1916 - accuracy: 0.9271\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.1981 - accuracy: 0.9247\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.1808 - accuracy: 0.9322\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.1846 - accuracy: 0.9323\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.1814 - accuracy: 0.9317\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.1683 - accuracy: 0.9366\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.1686 - accuracy: 0.9359\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.1673 - accuracy: 0.9362\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.1687 - accuracy: 0.9367\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.1662 - accuracy: 0.9380\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.1671 - accuracy: 0.9376\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.1529 - accuracy: 0.9431\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.1570 - accuracy: 0.9407\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.1513 - accuracy: 0.9445\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.1451 - accuracy: 0.9453\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.1413 - accuracy: 0.9460\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.1351 - accuracy: 0.9489\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.1412 - accuracy: 0.9466\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.1402 - accuracy: 0.9476\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.1544 - accuracy: 0.9442\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.1283 - accuracy: 0.9515\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.1258 - accuracy: 0.9530\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.1279 - accuracy: 0.9520\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.1285 - accuracy: 0.9522\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.1234 - accuracy: 0.9537\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.1224 - accuracy: 0.9534\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.1144 - accuracy: 0.9565\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.1194 - accuracy: 0.9541\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.1202 - accuracy: 0.9558\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.1200 - accuracy: 0.9550\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.1105 - accuracy: 0.9593\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.1097 - accuracy: 0.9580\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.1189 - accuracy: 0.9556\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.1012 - accuracy: 0.9618\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.1122 - accuracy: 0.9580\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 0.2145 - accuracy: 0.9421\n",
      "n_conv_1 = 768, k_conv_1 = 2,  n_conv_2 = 256, k_conv_2 = 3, \n",
      "          n_conv_3 = 512,  k_conv_3 = 2,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 256, dropout_1 = 0.3,\n",
      "          n_dense_2 = 256, dropout_2 = 0.25, activation_conv=  relu,\n",
      "          activation_dense=  elu\n",
      "Epoch 1/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 1.0410 - accuracy: 0.5581\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.7259 - accuracy: 0.6965\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.5731 - accuracy: 0.7710\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.4614 - accuracy: 0.8268\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.4026 - accuracy: 0.8527\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.3568 - accuracy: 0.8686\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.3333 - accuracy: 0.8774\n",
      "Epoch 8/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 6s 37ms/step - loss: 0.3194 - accuracy: 0.8844\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.2907 - accuracy: 0.8945\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.2876 - accuracy: 0.8952\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.2651 - accuracy: 0.9015\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.2549 - accuracy: 0.9054\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.2446 - accuracy: 0.9088\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.2334 - accuracy: 0.9133\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.2311 - accuracy: 0.9152\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.2208 - accuracy: 0.9196\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.2093 - accuracy: 0.9225\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.2131 - accuracy: 0.9223\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.2013 - accuracy: 0.9246\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.1989 - accuracy: 0.9270\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.1829 - accuracy: 0.9325\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.1826 - accuracy: 0.9306\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.1871 - accuracy: 0.9307\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.1791 - accuracy: 0.9332\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.1767 - accuracy: 0.9352\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.1676 - accuracy: 0.9366\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.1677 - accuracy: 0.9376\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.1616 - accuracy: 0.9392\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.1576 - accuracy: 0.9406\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.1569 - accuracy: 0.9423\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.1499 - accuracy: 0.9442\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.1502 - accuracy: 0.9437\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.1482 - accuracy: 0.9441\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.1428 - accuracy: 0.9470\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.1342 - accuracy: 0.9491\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.1378 - accuracy: 0.9476\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.1337 - accuracy: 0.9493\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.1351 - accuracy: 0.9503\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.1284 - accuracy: 0.9519\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.1269 - accuracy: 0.9530\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.1244 - accuracy: 0.9520\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.1220 - accuracy: 0.9537\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.1163 - accuracy: 0.9550\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.1205 - accuracy: 0.9548\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.1138 - accuracy: 0.9565\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.1138 - accuracy: 0.9565\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.1120 - accuracy: 0.9590\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.1318 - accuracy: 0.9513\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.1053 - accuracy: 0.9595\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.1088 - accuracy: 0.9594\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.1082 - accuracy: 0.9600\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.1090 - accuracy: 0.9584\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.1047 - accuracy: 0.9595\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.0949 - accuracy: 0.9642\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.1009 - accuracy: 0.9612\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.1015 - accuracy: 0.9618\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.0992 - accuracy: 0.9632\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.0940 - accuracy: 0.9649\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.0962 - accuracy: 0.9643\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.0867 - accuracy: 0.9671\n",
      "76/76 [==============================] - 1s 14ms/step - loss: 0.2528 - accuracy: 0.9334\n",
      "n_conv_1 = 768, k_conv_1 = 2,  n_conv_2 = 256, k_conv_2 = 3, \n",
      "          n_conv_3 = 512,  k_conv_3 = 2,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 256, dropout_1 = 0.3,\n",
      "          n_dense_2 = 256, dropout_2 = 0.25, activation_conv=  relu,\n",
      "          activation_dense=  elu\n",
      "Epoch 1/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 1.0566 - accuracy: 0.5498\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.7160 - accuracy: 0.7035\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.5585 - accuracy: 0.7811\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.4494 - accuracy: 0.8297\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.3960 - accuracy: 0.8513\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.3638 - accuracy: 0.8621\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.3302 - accuracy: 0.8774\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.3135 - accuracy: 0.8827\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.2993 - accuracy: 0.8895\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.2858 - accuracy: 0.8944\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.2652 - accuracy: 0.9021\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.2599 - accuracy: 0.9043\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.2429 - accuracy: 0.9113\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.2265 - accuracy: 0.9168\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.2311 - accuracy: 0.9135\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.2271 - accuracy: 0.9178\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.2188 - accuracy: 0.9186\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.2064 - accuracy: 0.9234\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.2054 - accuracy: 0.9243\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.1993 - accuracy: 0.9259\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.2048 - accuracy: 0.9240\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.1897 - accuracy: 0.9302\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.1834 - accuracy: 0.9313\n",
      "Epoch 24/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 6s 37ms/step - loss: 0.1740 - accuracy: 0.9340\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.1823 - accuracy: 0.9324\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.1729 - accuracy: 0.9340\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.1691 - accuracy: 0.9378\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.1648 - accuracy: 0.9383\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.1620 - accuracy: 0.9392\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.1613 - accuracy: 0.9403\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.1525 - accuracy: 0.9433\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.1516 - accuracy: 0.9426\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.1454 - accuracy: 0.9439\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.1462 - accuracy: 0.9447\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.1337 - accuracy: 0.9507\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.1420 - accuracy: 0.9465\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.1358 - accuracy: 0.9487\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.1401 - accuracy: 0.9470\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.1307 - accuracy: 0.9510\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.1275 - accuracy: 0.9508\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.1239 - accuracy: 0.9530\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.1233 - accuracy: 0.9539\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.1259 - accuracy: 0.9514\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.1163 - accuracy: 0.9556\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.1196 - accuracy: 0.9545\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.1144 - accuracy: 0.9570\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.1137 - accuracy: 0.9569\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.1075 - accuracy: 0.9595\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.1147 - accuracy: 0.9573\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.1089 - accuracy: 0.9596\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.1062 - accuracy: 0.9598\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.1059 - accuracy: 0.9599\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.1004 - accuracy: 0.9630\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.0999 - accuracy: 0.9622\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.1012 - accuracy: 0.9601\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.0980 - accuracy: 0.9623\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.1098 - accuracy: 0.9594\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.0928 - accuracy: 0.9654\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.0971 - accuracy: 0.9640\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.1054 - accuracy: 0.9626\n",
      "76/76 [==============================] - 1s 14ms/step - loss: 0.2311 - accuracy: 0.9370\n",
      "n_conv_1 = 768, k_conv_1 = 2,  n_conv_2 = 256, k_conv_2 = 3, \n",
      "          n_conv_3 = 512,  k_conv_3 = 2,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 256, dropout_1 = 0.3,\n",
      "          n_dense_2 = 256, dropout_2 = 0.25, activation_conv=  relu,\n",
      "          activation_dense=  elu\n",
      "Epoch 1/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 1.0501 - accuracy: 0.5520\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.7289 - accuracy: 0.6942\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.5671 - accuracy: 0.7728\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.4773 - accuracy: 0.8170\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.3943 - accuracy: 0.8542\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.3699 - accuracy: 0.8625\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.3399 - accuracy: 0.8738\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.3139 - accuracy: 0.8840\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.2868 - accuracy: 0.8958\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.2752 - accuracy: 0.8996\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.2795 - accuracy: 0.8969\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.2546 - accuracy: 0.9066\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.2493 - accuracy: 0.9076\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.2390 - accuracy: 0.9105\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.2289 - accuracy: 0.9167\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.2204 - accuracy: 0.9180\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.2201 - accuracy: 0.9189\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.2117 - accuracy: 0.9225\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.2005 - accuracy: 0.9265\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.2026 - accuracy: 0.9246\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.2036 - accuracy: 0.9259\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.1856 - accuracy: 0.9311\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.1835 - accuracy: 0.9311\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.1784 - accuracy: 0.9345\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.1707 - accuracy: 0.9372\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.1726 - accuracy: 0.9366\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.1651 - accuracy: 0.9381\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.1672 - accuracy: 0.9386\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.1581 - accuracy: 0.9410\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.1530 - accuracy: 0.9414\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.1487 - accuracy: 0.9449\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.1495 - accuracy: 0.9431\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.1444 - accuracy: 0.9467\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.1507 - accuracy: 0.9439\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.1383 - accuracy: 0.9470\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.1360 - accuracy: 0.9498\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.1339 - accuracy: 0.9496\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.1408 - accuracy: 0.9474\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.1296 - accuracy: 0.9522\n",
      "Epoch 40/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 6s 36ms/step - loss: 0.1227 - accuracy: 0.9537\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.1289 - accuracy: 0.9517\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.1261 - accuracy: 0.9520\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.1238 - accuracy: 0.9535\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.1259 - accuracy: 0.9526\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.1206 - accuracy: 0.9553\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.1148 - accuracy: 0.9566\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.1120 - accuracy: 0.9585\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.1132 - accuracy: 0.9568\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.1070 - accuracy: 0.9594\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.1051 - accuracy: 0.9587\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.1153 - accuracy: 0.9561\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.1108 - accuracy: 0.9587\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.1024 - accuracy: 0.9612\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.1033 - accuracy: 0.9604\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.1024 - accuracy: 0.9613\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.1054 - accuracy: 0.9600\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.1132 - accuracy: 0.9575\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.0980 - accuracy: 0.9619\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.0958 - accuracy: 0.9635\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.0945 - accuracy: 0.9636\n",
      "76/76 [==============================] - 1s 14ms/step - loss: 0.2375 - accuracy: 0.9374\n",
      "n_conv_1 = 512, k_conv_1 = 2,  n_conv_2 = 256, k_conv_2 = 2, \n",
      "          n_conv_3 = 512,  k_conv_3 = 3,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 512, dropout_1 = 0.2,\n",
      "          n_dense_2 = 256, dropout_2 = 0.25, activation_conv=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001FBEC3D7208>,\n",
      "          activation_dense=  relu\n",
      "Epoch 1/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 1.1238 - accuracy: 0.5217\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.8982 - accuracy: 0.6153\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.7826 - accuracy: 0.6651\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.7142 - accuracy: 0.6985\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.6452 - accuracy: 0.7327\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.5939 - accuracy: 0.7603\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.5470 - accuracy: 0.7822\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.5096 - accuracy: 0.7961\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.4856 - accuracy: 0.8100\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.4653 - accuracy: 0.8192\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.4446 - accuracy: 0.8268\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.4209 - accuracy: 0.8354\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.4251 - accuracy: 0.8348\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3946 - accuracy: 0.8448\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3886 - accuracy: 0.8473\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3761 - accuracy: 0.8529\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3770 - accuracy: 0.8515\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3793 - accuracy: 0.8500\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3617 - accuracy: 0.8587\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3470 - accuracy: 0.8651\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3559 - accuracy: 0.8599\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3435 - accuracy: 0.8647\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3349 - accuracy: 0.8699\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3545 - accuracy: 0.8622\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3349 - accuracy: 0.8670\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3290 - accuracy: 0.8711\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3141 - accuracy: 0.8774\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3252 - accuracy: 0.8709\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3200 - accuracy: 0.8722\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3092 - accuracy: 0.8767\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3035 - accuracy: 0.8806\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3010 - accuracy: 0.8800\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3113 - accuracy: 0.8790\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3027 - accuracy: 0.8820\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2962 - accuracy: 0.8856\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.2911 - accuracy: 0.8850\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3009 - accuracy: 0.8830\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.2858 - accuracy: 0.8874\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.2760 - accuracy: 0.8910\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.2817 - accuracy: 0.8905\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.2774 - accuracy: 0.8920\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.2759 - accuracy: 0.8920\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.2764 - accuracy: 0.8910\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.2707 - accuracy: 0.8943\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2647 - accuracy: 0.8962\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.2579 - accuracy: 0.8994\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.2697 - accuracy: 0.8956\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.2699 - accuracy: 0.8931\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.2590 - accuracy: 0.8991\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.2614 - accuracy: 0.8976\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.2515 - accuracy: 0.9010\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.2610 - accuracy: 0.8995\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.2463 - accuracy: 0.9042\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.2421 - accuracy: 0.9040\n",
      "Epoch 55/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 4s 25ms/step - loss: 0.2507 - accuracy: 0.9015\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.2438 - accuracy: 0.9054\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.2459 - accuracy: 0.9038\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.2422 - accuracy: 0.9048\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.2431 - accuracy: 0.9037\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2353 - accuracy: 0.9099\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 0.3145 - accuracy: 0.8856\n",
      "n_conv_1 = 512, k_conv_1 = 2,  n_conv_2 = 256, k_conv_2 = 2, \n",
      "          n_conv_3 = 512,  k_conv_3 = 3,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 512, dropout_1 = 0.2,\n",
      "          n_dense_2 = 256, dropout_2 = 0.25, activation_conv=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001FAC93DE608>,\n",
      "          activation_dense=  relu\n",
      "Epoch 1/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 1.1232 - accuracy: 0.5213\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.8921 - accuracy: 0.6198\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.7737 - accuracy: 0.6717\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.7132 - accuracy: 0.7005\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.6450 - accuracy: 0.7328\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.5796 - accuracy: 0.7642\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.5300 - accuracy: 0.7903\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.5099 - accuracy: 0.7982\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.4836 - accuracy: 0.8093\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.4633 - accuracy: 0.8188\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.4416 - accuracy: 0.8299\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.4261 - accuracy: 0.8337\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.4122 - accuracy: 0.8386\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.4072 - accuracy: 0.8408\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3816 - accuracy: 0.8504\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3811 - accuracy: 0.8507\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3789 - accuracy: 0.8507\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3598 - accuracy: 0.8611\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3637 - accuracy: 0.8589\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3617 - accuracy: 0.8567\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3401 - accuracy: 0.8654\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3346 - accuracy: 0.8669\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3338 - accuracy: 0.8700\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3388 - accuracy: 0.8674\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3331 - accuracy: 0.8699\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3279 - accuracy: 0.8713\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3159 - accuracy: 0.8771\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3213 - accuracy: 0.8762\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3129 - accuracy: 0.8799\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3090 - accuracy: 0.8785\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3096 - accuracy: 0.8785\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.2966 - accuracy: 0.8842\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.2986 - accuracy: 0.8811\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.2942 - accuracy: 0.8843\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.2888 - accuracy: 0.8867\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.2952 - accuracy: 0.8823\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.2810 - accuracy: 0.8903\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.2862 - accuracy: 0.8869\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.2746 - accuracy: 0.8919\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.2788 - accuracy: 0.8926\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.2769 - accuracy: 0.8916\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.2795 - accuracy: 0.8901\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.2706 - accuracy: 0.8946\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.2752 - accuracy: 0.8909 0s - los\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2649 - accuracy: 0.8962\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.2642 - accuracy: 0.8986\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.2616 - accuracy: 0.8973\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.2567 - accuracy: 0.8983\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.2450 - accuracy: 0.9041\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.2614 - accuracy: 0.8953\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.2540 - accuracy: 0.9004\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.2526 - accuracy: 0.8997\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.2464 - accuracy: 0.9038\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.2630 - accuracy: 0.8985\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.2379 - accuracy: 0.9067\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.2421 - accuracy: 0.9058\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.2409 - accuracy: 0.9054\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.2431 - accuracy: 0.9060\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.2387 - accuracy: 0.9071\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.2339 - accuracy: 0.9099\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 0.2987 - accuracy: 0.8978\n",
      "n_conv_1 = 512, k_conv_1 = 2,  n_conv_2 = 256, k_conv_2 = 2, \n",
      "          n_conv_3 = 512,  k_conv_3 = 3,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 512, dropout_1 = 0.2,\n",
      "          n_dense_2 = 256, dropout_2 = 0.25, activation_conv=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001FAC98F21C8>,\n",
      "          activation_dense=  relu\n",
      "Epoch 1/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 1.1098 - accuracy: 0.5243\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.8830 - accuracy: 0.6208\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.7833 - accuracy: 0.6651\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.7043 - accuracy: 0.7020\n",
      "Epoch 5/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 4s 25ms/step - loss: 0.6487 - accuracy: 0.7296\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.5992 - accuracy: 0.7546\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.5620 - accuracy: 0.7755\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.5176 - accuracy: 0.7918\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.4773 - accuracy: 0.8118\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.4666 - accuracy: 0.8168\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.4617 - accuracy: 0.8182\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.4292 - accuracy: 0.8299\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.4132 - accuracy: 0.8394\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.4059 - accuracy: 0.8400\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3941 - accuracy: 0.8462\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3832 - accuracy: 0.8500\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3860 - accuracy: 0.8486\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3719 - accuracy: 0.8535\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3651 - accuracy: 0.8560\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3652 - accuracy: 0.8585\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3569 - accuracy: 0.8562\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3462 - accuracy: 0.8623\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3413 - accuracy: 0.8634\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3419 - accuracy: 0.8641\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3362 - accuracy: 0.8677\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3223 - accuracy: 0.8739\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3319 - accuracy: 0.8697\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3213 - accuracy: 0.8739\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3247 - accuracy: 0.8734\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3120 - accuracy: 0.8766\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3183 - accuracy: 0.8736\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3081 - accuracy: 0.8775\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3004 - accuracy: 0.8820\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3030 - accuracy: 0.8811\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.2954 - accuracy: 0.8821\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.2926 - accuracy: 0.8836\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2935 - accuracy: 0.8840\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.2905 - accuracy: 0.8864\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.2934 - accuracy: 0.8841\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.2813 - accuracy: 0.8901\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.2779 - accuracy: 0.8901\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.2782 - accuracy: 0.8894\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.2685 - accuracy: 0.8957\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.2818 - accuracy: 0.8907\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.2774 - accuracy: 0.8916\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.2643 - accuracy: 0.8953\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.2735 - accuracy: 0.8928\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.2692 - accuracy: 0.8958\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.2642 - accuracy: 0.8966\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2697 - accuracy: 0.8937\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.2601 - accuracy: 0.8985\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.2536 - accuracy: 0.9002\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.2446 - accuracy: 0.9052\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.2453 - accuracy: 0.9045\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.2573 - accuracy: 0.8999\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.2551 - accuracy: 0.9005\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.2399 - accuracy: 0.9082\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.2449 - accuracy: 0.9017\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.2510 - accuracy: 0.9037\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.2280 - accuracy: 0.9124\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 0.3094 - accuracy: 0.8953\n",
      "n_conv_1 = 512, k_conv_1 = 3,  n_conv_2 = 256, k_conv_2 = 2, \n",
      "          n_conv_3 = 256,  k_conv_3 = 3,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 256, dropout_1 = 0.3,\n",
      "          n_dense_2 = 256, dropout_2 = 0.25, activation_conv=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001FBEC37D148>,\n",
      "          activation_dense=  elu\n",
      "Epoch 1/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 1.1137 - accuracy: 0.5184\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.7936 - accuracy: 0.6701\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.6889 - accuracy: 0.7223\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.6189 - accuracy: 0.7543\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.5872 - accuracy: 0.7672\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.5492 - accuracy: 0.7850\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.5347 - accuracy: 0.7923\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.4953 - accuracy: 0.8076\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.4711 - accuracy: 0.8191\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.4631 - accuracy: 0.8195\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.4479 - accuracy: 0.8283\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.4350 - accuracy: 0.8354\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.4274 - accuracy: 0.8373\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.4073 - accuracy: 0.8457\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.4070 - accuracy: 0.8436\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.3950 - accuracy: 0.8502\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.3837 - accuracy: 0.8548\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.3676 - accuracy: 0.8604\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.3798 - accuracy: 0.8550\n",
      "Epoch 20/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 4s 23ms/step - loss: 0.3664 - accuracy: 0.8602\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.3718 - accuracy: 0.8556\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.3601 - accuracy: 0.8615\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.3567 - accuracy: 0.8652\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.3428 - accuracy: 0.8708\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.3469 - accuracy: 0.8660\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.3515 - accuracy: 0.8645\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.3415 - accuracy: 0.8690\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.3419 - accuracy: 0.8698\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.3422 - accuracy: 0.8688\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.3322 - accuracy: 0.8725\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.3309 - accuracy: 0.8745\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.3266 - accuracy: 0.8752\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.3297 - accuracy: 0.8722\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.3260 - accuracy: 0.8761\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.3178 - accuracy: 0.8787\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.3071 - accuracy: 0.8835\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.3156 - accuracy: 0.8788\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.3072 - accuracy: 0.8816\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.3080 - accuracy: 0.8825\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.3027 - accuracy: 0.8837\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.3107 - accuracy: 0.8801\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.2980 - accuracy: 0.8843\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.3144 - accuracy: 0.8787\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.2937 - accuracy: 0.8843\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.2957 - accuracy: 0.8852\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.2945 - accuracy: 0.8871\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.2874 - accuracy: 0.8866\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.2944 - accuracy: 0.8847\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.2845 - accuracy: 0.8886\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.2935 - accuracy: 0.8845\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.2795 - accuracy: 0.8898\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.2995 - accuracy: 0.8829\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.2813 - accuracy: 0.8878\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.2870 - accuracy: 0.8872\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.2816 - accuracy: 0.8899\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.2748 - accuracy: 0.8912\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.2798 - accuracy: 0.8886\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.2796 - accuracy: 0.8921\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.2743 - accuracy: 0.8937\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.2690 - accuracy: 0.8936\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 0.3022 - accuracy: 0.8847\n",
      "n_conv_1 = 512, k_conv_1 = 3,  n_conv_2 = 256, k_conv_2 = 2, \n",
      "          n_conv_3 = 256,  k_conv_3 = 3,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 256, dropout_1 = 0.3,\n",
      "          n_dense_2 = 256, dropout_2 = 0.25, activation_conv=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001FAE88A92C8>,\n",
      "          activation_dense=  elu\n",
      "Epoch 1/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 1.0814 - accuracy: 0.5379\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.7822 - accuracy: 0.6772\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.6687 - accuracy: 0.7293\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.6104 - accuracy: 0.7577\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.5906 - accuracy: 0.7654\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.5487 - accuracy: 0.7872\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.5112 - accuracy: 0.8031\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.5050 - accuracy: 0.8034\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.4758 - accuracy: 0.8191\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.4529 - accuracy: 0.8289\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.4430 - accuracy: 0.8333\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.4372 - accuracy: 0.8351\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.4257 - accuracy: 0.8387\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.4105 - accuracy: 0.8448\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.3954 - accuracy: 0.8515\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.3882 - accuracy: 0.8541\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.3853 - accuracy: 0.8551\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.3841 - accuracy: 0.8525\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.3851 - accuracy: 0.8529\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.3691 - accuracy: 0.8599\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.3649 - accuracy: 0.8621\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.3600 - accuracy: 0.8631\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.3599 - accuracy: 0.8626\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.3545 - accuracy: 0.8652\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.3504 - accuracy: 0.8660\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.3435 - accuracy: 0.8687\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.3462 - accuracy: 0.8680\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.3356 - accuracy: 0.8723\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.3333 - accuracy: 0.8735\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.3287 - accuracy: 0.8729\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.3374 - accuracy: 0.8712\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.3253 - accuracy: 0.8774\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.3196 - accuracy: 0.8760\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.3243 - accuracy: 0.8748\n",
      "Epoch 35/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 4s 23ms/step - loss: 0.3068 - accuracy: 0.8800\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.3254 - accuracy: 0.8747\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.3017 - accuracy: 0.8824\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.3084 - accuracy: 0.8808\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.3043 - accuracy: 0.8820\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.2922 - accuracy: 0.8869\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.3158 - accuracy: 0.8782\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.2901 - accuracy: 0.8865\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.3116 - accuracy: 0.8774\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.3000 - accuracy: 0.8828\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.2903 - accuracy: 0.8878\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.2881 - accuracy: 0.8870\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.2944 - accuracy: 0.8853\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.2830 - accuracy: 0.8886\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.2812 - accuracy: 0.8894\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.2808 - accuracy: 0.8896\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.2850 - accuracy: 0.8880\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.2825 - accuracy: 0.8898\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.2788 - accuracy: 0.8896\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.2768 - accuracy: 0.8888\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.2790 - accuracy: 0.8889\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.2751 - accuracy: 0.8924\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.2715 - accuracy: 0.8912\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.2746 - accuracy: 0.8899\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.2744 - accuracy: 0.8926\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.2726 - accuracy: 0.8930\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.2960 - accuracy: 0.8904\n",
      "n_conv_1 = 512, k_conv_1 = 3,  n_conv_2 = 256, k_conv_2 = 2, \n",
      "          n_conv_3 = 256,  k_conv_3 = 3,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 256, dropout_1 = 0.3,\n",
      "          n_dense_2 = 256, dropout_2 = 0.25, activation_conv=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001FBEE72B4C8>,\n",
      "          activation_dense=  elu\n",
      "Epoch 1/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 1.1093 - accuracy: 0.5284\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.8012 - accuracy: 0.6701\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.6779 - accuracy: 0.7273\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.6288 - accuracy: 0.7487\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.5902 - accuracy: 0.7659\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.5577 - accuracy: 0.7785\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.5417 - accuracy: 0.7881\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.5054 - accuracy: 0.8055\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.4900 - accuracy: 0.8125\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.4642 - accuracy: 0.8234\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.4500 - accuracy: 0.8280\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.4256 - accuracy: 0.8386\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.4329 - accuracy: 0.8363\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.4194 - accuracy: 0.8401\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.4116 - accuracy: 0.8458\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.4020 - accuracy: 0.8474\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.3912 - accuracy: 0.8507\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.3877 - accuracy: 0.8515\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.3837 - accuracy: 0.8535\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.3700 - accuracy: 0.8595\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.3679 - accuracy: 0.8602\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.3620 - accuracy: 0.8639\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.3572 - accuracy: 0.8638\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.3620 - accuracy: 0.8610\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.3611 - accuracy: 0.8610\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.3429 - accuracy: 0.8679\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.3396 - accuracy: 0.8687\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.3411 - accuracy: 0.8692\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.3396 - accuracy: 0.8711\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.3360 - accuracy: 0.8700\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.3367 - accuracy: 0.8702\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.3303 - accuracy: 0.8727\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.3246 - accuracy: 0.8763\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.3231 - accuracy: 0.8768\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.3374 - accuracy: 0.8696\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.3086 - accuracy: 0.8825\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.3213 - accuracy: 0.8748\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.3132 - accuracy: 0.8797\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.3143 - accuracy: 0.8768\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.3158 - accuracy: 0.8779\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.3033 - accuracy: 0.8841\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.2995 - accuracy: 0.8837\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.3051 - accuracy: 0.8815\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.3032 - accuracy: 0.8827\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.2975 - accuracy: 0.8848\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.2931 - accuracy: 0.8858\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.2950 - accuracy: 0.8854\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.2940 - accuracy: 0.8875\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.3020 - accuracy: 0.8851\n",
      "Epoch 50/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 4s 23ms/step - loss: 0.2904 - accuracy: 0.8860\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.2892 - accuracy: 0.8900\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.2874 - accuracy: 0.8871\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.2815 - accuracy: 0.8907\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.2835 - accuracy: 0.8913\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.2880 - accuracy: 0.8896\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.2823 - accuracy: 0.8913\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.2748 - accuracy: 0.8915\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.2770 - accuracy: 0.8904\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.2793 - accuracy: 0.8924\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.2699 - accuracy: 0.8945\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 0.3060 - accuracy: 0.8854\n",
      "n_conv_1 = 768, k_conv_1 = 3,  n_conv_2 = 512, k_conv_2 = 3, \n",
      "          n_conv_3 = 256,  k_conv_3 = 2,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 512, dropout_1 = 0.2,\n",
      "          n_dense_2 = 512, dropout_2 = 0.25, activation_conv=  elu,\n",
      "          activation_dense=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001FAD4D2E2C8>\n",
      "Epoch 1/60\n",
      "  1/152 [..............................] - ETA: 0s - loss: 1.7839 - accuracy: 0.1992WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0189s vs `on_train_batch_end` time: 0.0299s). Check your callbacks.\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 1.1284 - accuracy: 0.5196\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.8881 - accuracy: 0.6343\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.7746 - accuracy: 0.6817\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.7334 - accuracy: 0.7002\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.6788 - accuracy: 0.7253\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.6535 - accuracy: 0.7386\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.6220 - accuracy: 0.7515\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.5940 - accuracy: 0.7629\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.5537 - accuracy: 0.7803\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.5324 - accuracy: 0.7877\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.5216 - accuracy: 0.7935\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.5054 - accuracy: 0.7996\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.4917 - accuracy: 0.8062\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.4705 - accuracy: 0.8177\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.4538 - accuracy: 0.8251\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.4609 - accuracy: 0.8227\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.4467 - accuracy: 0.8271\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.4409 - accuracy: 0.8273\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.4259 - accuracy: 0.8358\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.4191 - accuracy: 0.8372\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.4154 - accuracy: 0.8408\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.4037 - accuracy: 0.8439\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.4052 - accuracy: 0.8457\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.4001 - accuracy: 0.8486\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.3949 - accuracy: 0.8487\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.3807 - accuracy: 0.8544\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.3706 - accuracy: 0.8580\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.3762 - accuracy: 0.8563\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.3648 - accuracy: 0.8627\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.3581 - accuracy: 0.8641\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.3579 - accuracy: 0.8625\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.3503 - accuracy: 0.8678\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.3510 - accuracy: 0.8665\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.3409 - accuracy: 0.8698\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.3493 - accuracy: 0.8666\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.3358 - accuracy: 0.8724\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.3354 - accuracy: 0.8717\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.3284 - accuracy: 0.8761\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.3254 - accuracy: 0.8762\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.3193 - accuracy: 0.8783\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.3175 - accuracy: 0.8783\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.3118 - accuracy: 0.8813\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.3020 - accuracy: 0.8824\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.3066 - accuracy: 0.8836\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.2985 - accuracy: 0.8874\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.2894 - accuracy: 0.8909\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.2923 - accuracy: 0.8887\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.2875 - accuracy: 0.8897\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.2762 - accuracy: 0.8967\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.2869 - accuracy: 0.8909\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.2898 - accuracy: 0.8916\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.2713 - accuracy: 0.8977\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.2636 - accuracy: 0.9002\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.2642 - accuracy: 0.8993\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.2630 - accuracy: 0.9005\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.2575 - accuracy: 0.9030\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.2557 - accuracy: 0.9022\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.2475 - accuracy: 0.9052\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2518 - accuracy: 0.9041\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.2503 - accuracy: 0.9044\n",
      "76/76 [==============================] - 1s 19ms/step - loss: 0.2641 - accuracy: 0.9087\n",
      "n_conv_1 = 768, k_conv_1 = 3,  n_conv_2 = 512, k_conv_2 = 3, \n",
      "          n_conv_3 = 256,  k_conv_3 = 2,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 512, dropout_1 = 0.2,\n",
      "          n_dense_2 = 512, dropout_2 = 0.25, activation_conv=  elu,\n",
      "          activation_dense=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001FAC9345F08>\n",
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 7s 48ms/step - loss: 1.1280 - accuracy: 0.5182\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.9059 - accuracy: 0.6261\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.7757 - accuracy: 0.6830\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.7266 - accuracy: 0.7049\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.6877 - accuracy: 0.7211\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.6381 - accuracy: 0.7412\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.6100 - accuracy: 0.7547\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.5715 - accuracy: 0.7724\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.5460 - accuracy: 0.7805\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.5180 - accuracy: 0.7947\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.5143 - accuracy: 0.7953\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.4916 - accuracy: 0.8087\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.4643 - accuracy: 0.8198\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.4503 - accuracy: 0.8245\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.4459 - accuracy: 0.8292\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.4406 - accuracy: 0.8315\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.4426 - accuracy: 0.8284\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.4294 - accuracy: 0.8369\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.4090 - accuracy: 0.8450\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.4160 - accuracy: 0.8418\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.3922 - accuracy: 0.8499\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.3898 - accuracy: 0.8543\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.3813 - accuracy: 0.8567\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.3750 - accuracy: 0.8581\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.3708 - accuracy: 0.8600\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.3739 - accuracy: 0.8597\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.3579 - accuracy: 0.8648\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.3580 - accuracy: 0.8646\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.3516 - accuracy: 0.8672\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.3462 - accuracy: 0.8684\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.3413 - accuracy: 0.8711\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.3351 - accuracy: 0.8725\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.3350 - accuracy: 0.8716\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.3327 - accuracy: 0.8741\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.3211 - accuracy: 0.8749\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.3197 - accuracy: 0.8793\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.3086 - accuracy: 0.8829\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.3042 - accuracy: 0.8818\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.3047 - accuracy: 0.8809\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.2981 - accuracy: 0.8844\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.2946 - accuracy: 0.8855\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.2900 - accuracy: 0.8884\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2916 - accuracy: 0.8889\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.2942 - accuracy: 0.8887\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.2786 - accuracy: 0.8945\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2781 - accuracy: 0.8941\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2761 - accuracy: 0.8950\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2700 - accuracy: 0.8951\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.2653 - accuracy: 0.8977\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.2520 - accuracy: 0.9026\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.2671 - accuracy: 0.8987\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.2594 - accuracy: 0.9007\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.2528 - accuracy: 0.9023\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2412 - accuracy: 0.9073\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.2420 - accuracy: 0.9052\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2498 - accuracy: 0.9051\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.2327 - accuracy: 0.9106\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.2406 - accuracy: 0.9058\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.2416 - accuracy: 0.9075\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.2261 - accuracy: 0.9113\n",
      "76/76 [==============================] - 1s 18ms/step - loss: 0.2966 - accuracy: 0.9003\n",
      "n_conv_1 = 768, k_conv_1 = 3,  n_conv_2 = 512, k_conv_2 = 3, \n",
      "          n_conv_3 = 256,  k_conv_3 = 2,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 512, dropout_1 = 0.2,\n",
      "          n_dense_2 = 512, dropout_2 = 0.25, activation_conv=  elu,\n",
      "          activation_dense=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001FAC8203B48>\n",
      "Epoch 1/60\n",
      "  1/152 [..............................] - ETA: 4s - loss: 1.8013 - accuracy: 0.1406WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0189s vs `on_train_batch_end` time: 0.0290s). Check your callbacks.\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 1.1323 - accuracy: 0.5176\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.8971 - accuracy: 0.6373\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.7772 - accuracy: 0.6839\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.7301 - accuracy: 0.7040\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.6843 - accuracy: 0.7214\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.6506 - accuracy: 0.7391\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.6067 - accuracy: 0.7561\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.6046 - accuracy: 0.7609\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.5501 - accuracy: 0.7812\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.5234 - accuracy: 0.7922\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.5208 - accuracy: 0.7937\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.4982 - accuracy: 0.8037\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.4851 - accuracy: 0.8078\n",
      "Epoch 14/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 7s 48ms/step - loss: 0.4849 - accuracy: 0.8096\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.4630 - accuracy: 0.8200\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.4621 - accuracy: 0.8194\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.4470 - accuracy: 0.8259\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.4316 - accuracy: 0.8313\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.4263 - accuracy: 0.8330\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.4260 - accuracy: 0.8347\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.4083 - accuracy: 0.8418\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.4096 - accuracy: 0.8400\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.4068 - accuracy: 0.8436\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.3983 - accuracy: 0.8458\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.3947 - accuracy: 0.8483\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.3812 - accuracy: 0.8525\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.3742 - accuracy: 0.8552\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.3747 - accuracy: 0.8536\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.3680 - accuracy: 0.8567\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.3624 - accuracy: 0.8616\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.3560 - accuracy: 0.8622\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.3468 - accuracy: 0.8648\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.3618 - accuracy: 0.8591\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.3395 - accuracy: 0.8688\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.3332 - accuracy: 0.8706\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.3381 - accuracy: 0.8698\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.3326 - accuracy: 0.8712\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.3252 - accuracy: 0.8736\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.3173 - accuracy: 0.8775\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.3121 - accuracy: 0.8802\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.3164 - accuracy: 0.8782\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.3035 - accuracy: 0.8817\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.3120 - accuracy: 0.8814\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.2984 - accuracy: 0.8855\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.3031 - accuracy: 0.8848\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2921 - accuracy: 0.8888\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.2866 - accuracy: 0.8909\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2829 - accuracy: 0.8928\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2755 - accuracy: 0.8935\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.2772 - accuracy: 0.8936\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.2646 - accuracy: 0.8992\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.2688 - accuracy: 0.8965\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.2612 - accuracy: 0.9009\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.2689 - accuracy: 0.8968\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.2553 - accuracy: 0.9031\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2531 - accuracy: 0.9043\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2477 - accuracy: 0.9058\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.2579 - accuracy: 0.9021\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.2404 - accuracy: 0.9078\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2428 - accuracy: 0.9096\n",
      "76/76 [==============================] - 1s 18ms/step - loss: 0.2687 - accuracy: 0.9097\n",
      "n_conv_1 = 512, k_conv_1 = 3,  n_conv_2 = 256, k_conv_2 = 2, \n",
      "          n_conv_3 = 512,  k_conv_3 = 3,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 512, dropout_1 = 0.3,\n",
      "          n_dense_2 = 256, dropout_2 = 0.25, activation_conv=  relu,\n",
      "          activation_dense=  elu\n",
      "Epoch 1/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 1.0192 - accuracy: 0.5664\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.6574 - accuracy: 0.7415\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.4803 - accuracy: 0.8226\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.3983 - accuracy: 0.8550\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.3687 - accuracy: 0.8663\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.3367 - accuracy: 0.8754\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3141 - accuracy: 0.8833\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.3139 - accuracy: 0.8865\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.2860 - accuracy: 0.8947\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.2741 - accuracy: 0.8998\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.2627 - accuracy: 0.9023\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.2656 - accuracy: 0.9020\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.2473 - accuracy: 0.9103\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.2314 - accuracy: 0.9145\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.2204 - accuracy: 0.9177\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.2258 - accuracy: 0.9186\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.2224 - accuracy: 0.9178\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.2150 - accuracy: 0.9208\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.1963 - accuracy: 0.9267\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.1998 - accuracy: 0.9259\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1916 - accuracy: 0.9280\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1903 - accuracy: 0.9296\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1846 - accuracy: 0.9313\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1729 - accuracy: 0.9353\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.1823 - accuracy: 0.9317\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.1783 - accuracy: 0.9331\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.1668 - accuracy: 0.9366\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1640 - accuracy: 0.9392\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1677 - accuracy: 0.9360\n",
      "Epoch 30/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1563 - accuracy: 0.9401\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.1584 - accuracy: 0.9397\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1545 - accuracy: 0.9422\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.1487 - accuracy: 0.9426\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.1454 - accuracy: 0.9447\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.1430 - accuracy: 0.9454\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.1418 - accuracy: 0.9440\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1415 - accuracy: 0.9462\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1339 - accuracy: 0.9493\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.1269 - accuracy: 0.9521\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1373 - accuracy: 0.9462\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.1258 - accuracy: 0.9504\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.1318 - accuracy: 0.9503\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.1244 - accuracy: 0.9524\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.1263 - accuracy: 0.9509\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1215 - accuracy: 0.9529\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1205 - accuracy: 0.9546\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.1153 - accuracy: 0.9541\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1176 - accuracy: 0.9539\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1104 - accuracy: 0.9558\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1095 - accuracy: 0.9575\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.1127 - accuracy: 0.9563\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.1122 - accuracy: 0.9559\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.1076 - accuracy: 0.9576\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.1084 - accuracy: 0.9593\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.1065 - accuracy: 0.9587\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.1054 - accuracy: 0.9588\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.0985 - accuracy: 0.9611\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.0965 - accuracy: 0.9614\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.0975 - accuracy: 0.9629\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.0999 - accuracy: 0.9615\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 0.2640 - accuracy: 0.9333\n",
      "n_conv_1 = 512, k_conv_1 = 3,  n_conv_2 = 256, k_conv_2 = 2, \n",
      "          n_conv_3 = 512,  k_conv_3 = 3,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 512, dropout_1 = 0.3,\n",
      "          n_dense_2 = 256, dropout_2 = 0.25, activation_conv=  relu,\n",
      "          activation_dense=  elu\n",
      "Epoch 1/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 1.0068 - accuracy: 0.5722\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.6221 - accuracy: 0.7584\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.4553 - accuracy: 0.8309\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3879 - accuracy: 0.8557\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.3605 - accuracy: 0.8662\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3292 - accuracy: 0.8782\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3201 - accuracy: 0.8822\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.2873 - accuracy: 0.8935\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.2765 - accuracy: 0.8969\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.2699 - accuracy: 0.9006\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.2591 - accuracy: 0.9046\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.2437 - accuracy: 0.9097\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.2357 - accuracy: 0.9148\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.2229 - accuracy: 0.9177\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.2173 - accuracy: 0.9208\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.2115 - accuracy: 0.9224\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.2054 - accuracy: 0.9258\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.2048 - accuracy: 0.9244\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1971 - accuracy: 0.9272\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1893 - accuracy: 0.9298\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1893 - accuracy: 0.9304\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.1787 - accuracy: 0.9341\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1793 - accuracy: 0.9330\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1690 - accuracy: 0.9372\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1605 - accuracy: 0.9404\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1566 - accuracy: 0.9422\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1625 - accuracy: 0.9383\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.1520 - accuracy: 0.9426\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1474 - accuracy: 0.9433\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1518 - accuracy: 0.9439\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1410 - accuracy: 0.9472\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.1491 - accuracy: 0.9452\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.1437 - accuracy: 0.9461\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1463 - accuracy: 0.9447\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1301 - accuracy: 0.9519\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1337 - accuracy: 0.9499\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.1240 - accuracy: 0.9529\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1277 - accuracy: 0.9520\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.1189 - accuracy: 0.9573\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.1187 - accuracy: 0.9557\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.1180 - accuracy: 0.9553\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1176 - accuracy: 0.9562\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.1062 - accuracy: 0.9599\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1111 - accuracy: 0.9570\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1146 - accuracy: 0.9560\n",
      "Epoch 46/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1162 - accuracy: 0.9560\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.1010 - accuracy: 0.9623\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1059 - accuracy: 0.9598\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.1046 - accuracy: 0.9597\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.0997 - accuracy: 0.9624\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.0976 - accuracy: 0.9629\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.0990 - accuracy: 0.9621\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.0950 - accuracy: 0.9647\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.1016 - accuracy: 0.9618\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.0957 - accuracy: 0.9636\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.0987 - accuracy: 0.9637\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.0868 - accuracy: 0.9665\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.0945 - accuracy: 0.9638\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.0904 - accuracy: 0.9650\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.0828 - accuracy: 0.9700\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 0.2837 - accuracy: 0.9330\n",
      "n_conv_1 = 512, k_conv_1 = 3,  n_conv_2 = 256, k_conv_2 = 2, \n",
      "          n_conv_3 = 512,  k_conv_3 = 3,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 512, dropout_1 = 0.3,\n",
      "          n_dense_2 = 256, dropout_2 = 0.25, activation_conv=  relu,\n",
      "          activation_dense=  elu\n",
      "Epoch 1/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 1.0141 - accuracy: 0.5649\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.6448 - accuracy: 0.7463\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.4788 - accuracy: 0.8221\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3986 - accuracy: 0.8536\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3632 - accuracy: 0.8648\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3404 - accuracy: 0.8703\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3112 - accuracy: 0.8848\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3065 - accuracy: 0.8862\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.2801 - accuracy: 0.8959\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.2761 - accuracy: 0.8954\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.2632 - accuracy: 0.9024\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.2499 - accuracy: 0.9071\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.2476 - accuracy: 0.9075\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.2345 - accuracy: 0.9142\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.2226 - accuracy: 0.9188\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.2187 - accuracy: 0.9203\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.2088 - accuracy: 0.9227\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.2072 - accuracy: 0.9232\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1943 - accuracy: 0.9273\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1965 - accuracy: 0.9271\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.1953 - accuracy: 0.9279\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.1833 - accuracy: 0.9319\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.1733 - accuracy: 0.9356\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.1782 - accuracy: 0.9344\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1650 - accuracy: 0.9378\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.1650 - accuracy: 0.9391\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.1615 - accuracy: 0.9397\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1588 - accuracy: 0.9403\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.1588 - accuracy: 0.9411\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1504 - accuracy: 0.9445\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1435 - accuracy: 0.9466\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.1507 - accuracy: 0.9436\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1410 - accuracy: 0.9477\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1350 - accuracy: 0.9483\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1485 - accuracy: 0.9446\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1324 - accuracy: 0.9499\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1358 - accuracy: 0.9489\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1320 - accuracy: 0.9511\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1259 - accuracy: 0.9531\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1226 - accuracy: 0.9535\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1193 - accuracy: 0.9553\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1277 - accuracy: 0.9524\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1155 - accuracy: 0.9567\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1181 - accuracy: 0.9553\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.1168 - accuracy: 0.9555\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1190 - accuracy: 0.9551\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1080 - accuracy: 0.9604\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.1081 - accuracy: 0.9588\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1048 - accuracy: 0.9593\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1008 - accuracy: 0.9618\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1078 - accuracy: 0.9601\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.0981 - accuracy: 0.9630\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.1036 - accuracy: 0.9596\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1006 - accuracy: 0.9633\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.0970 - accuracy: 0.9633\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.0960 - accuracy: 0.9631\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1061 - accuracy: 0.9598\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.0926 - accuracy: 0.9651\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.0938 - accuracy: 0.9661\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.0885 - accuracy: 0.9660\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 0.2620 - accuracy: 0.9364\n",
      "n_conv_1 = 512, k_conv_1 = 3,  n_conv_2 = 512, k_conv_2 = 2, \n",
      "          n_conv_3 = 512,  k_conv_3 = 2,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 256, dropout_1 = 0.3,\n",
      "          n_dense_2 = 256, dropout_2 = 0.25, activation_conv=  relu,\n",
      "          activation_dense=  elu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 1.0336 - accuracy: 0.5594\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.6673 - accuracy: 0.7394\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4901 - accuracy: 0.8161\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4102 - accuracy: 0.8485\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3627 - accuracy: 0.8669\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3378 - accuracy: 0.8759 1s\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3176 - accuracy: 0.8826\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2999 - accuracy: 0.8901\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2927 - accuracy: 0.8917\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2769 - accuracy: 0.8970\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2600 - accuracy: 0.9038\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2522 - accuracy: 0.9067\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2496 - accuracy: 0.9082\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2424 - accuracy: 0.9118\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2306 - accuracy: 0.9156\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2127 - accuracy: 0.9210\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2228 - accuracy: 0.9194\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2100 - accuracy: 0.9214\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2095 - accuracy: 0.9221\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1997 - accuracy: 0.9264\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1902 - accuracy: 0.9289\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1854 - accuracy: 0.9320\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1805 - accuracy: 0.9321\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1741 - accuracy: 0.9352\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1739 - accuracy: 0.9349\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1627 - accuracy: 0.9389 0s - l\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1717 - accuracy: 0.9358\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1725 - accuracy: 0.9359\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1567 - accuracy: 0.9411\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1555 - accuracy: 0.9409\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1481 - accuracy: 0.9429\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1430 - accuracy: 0.9470\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1515 - accuracy: 0.9424\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1501 - accuracy: 0.9438\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1333 - accuracy: 0.9509\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1338 - accuracy: 0.9488\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1334 - accuracy: 0.9487\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1347 - accuracy: 0.9490\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1357 - accuracy: 0.9483\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1256 - accuracy: 0.9521\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1201 - accuracy: 0.9545\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1196 - accuracy: 0.9544\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1199 - accuracy: 0.9545\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1165 - accuracy: 0.9564\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1139 - accuracy: 0.9572\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1131 - accuracy: 0.9569\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1147 - accuracy: 0.9561\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1058 - accuracy: 0.9591\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1130 - accuracy: 0.9572\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1063 - accuracy: 0.9599\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1030 - accuracy: 0.9598\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1054 - accuracy: 0.9598\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1011 - accuracy: 0.9616\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1111 - accuracy: 0.9584\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.0936 - accuracy: 0.9638\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.0976 - accuracy: 0.9626\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1024 - accuracy: 0.9612 0s - los\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.0980 - accuracy: 0.9633\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.0929 - accuracy: 0.9639\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.0858 - accuracy: 0.9675\n",
      "76/76 [==============================] - 1s 14ms/step - loss: 0.2399 - accuracy: 0.9391\n",
      "n_conv_1 = 512, k_conv_1 = 3,  n_conv_2 = 512, k_conv_2 = 2, \n",
      "          n_conv_3 = 512,  k_conv_3 = 2,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 256, dropout_1 = 0.3,\n",
      "          n_dense_2 = 256, dropout_2 = 0.25, activation_conv=  relu,\n",
      "          activation_dense=  elu\n",
      "Epoch 1/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 1.0288 - accuracy: 0.5606\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.6649 - accuracy: 0.7392\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4841 - accuracy: 0.8174\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4090 - accuracy: 0.8484\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3654 - accuracy: 0.8663\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3392 - accuracy: 0.8751\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3193 - accuracy: 0.8818\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3031 - accuracy: 0.8860\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2842 - accuracy: 0.8948\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2747 - accuracy: 0.8988\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2624 - accuracy: 0.9026\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2559 - accuracy: 0.9058\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2441 - accuracy: 0.9088\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2349 - accuracy: 0.9117\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2222 - accuracy: 0.9180\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2197 - accuracy: 0.9185\n",
      "Epoch 17/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2126 - accuracy: 0.9216\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2102 - accuracy: 0.9214\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2061 - accuracy: 0.9249\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1950 - accuracy: 0.9273\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2000 - accuracy: 0.9258\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1907 - accuracy: 0.9292\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1856 - accuracy: 0.9298\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1789 - accuracy: 0.9327\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1794 - accuracy: 0.9340\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1717 - accuracy: 0.9353\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1643 - accuracy: 0.9392\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1670 - accuracy: 0.9377\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1595 - accuracy: 0.9400\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1560 - accuracy: 0.9395\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1574 - accuracy: 0.9412 0s -\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1535 - accuracy: 0.9419\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1470 - accuracy: 0.9440\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1409 - accuracy: 0.9485\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1421 - accuracy: 0.9471\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1339 - accuracy: 0.9489\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1398 - accuracy: 0.9475\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1349 - accuracy: 0.9485\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1248 - accuracy: 0.9520\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1340 - accuracy: 0.9491\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1262 - accuracy: 0.9517\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1182 - accuracy: 0.9555\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1195 - accuracy: 0.9553\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1226 - accuracy: 0.9545\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1127 - accuracy: 0.9572\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1158 - accuracy: 0.9563\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1119 - accuracy: 0.9577\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1042 - accuracy: 0.9602\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1003 - accuracy: 0.9610\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1040 - accuracy: 0.9608\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1123 - accuracy: 0.9575\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1058 - accuracy: 0.9603\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1032 - accuracy: 0.9629\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.0931 - accuracy: 0.9653\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.0948 - accuracy: 0.9637\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1008 - accuracy: 0.9621\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.0980 - accuracy: 0.9629\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.0960 - accuracy: 0.9635\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.0912 - accuracy: 0.9663\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.0842 - accuracy: 0.9681\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 0.2652 - accuracy: 0.9366\n",
      "n_conv_1 = 512, k_conv_1 = 3,  n_conv_2 = 512, k_conv_2 = 2, \n",
      "          n_conv_3 = 512,  k_conv_3 = 2,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 256, dropout_1 = 0.3,\n",
      "          n_dense_2 = 256, dropout_2 = 0.25, activation_conv=  relu,\n",
      "          activation_dense=  elu\n",
      "Epoch 1/60\n",
      "  1/152 [..............................] - ETA: 2s - loss: 1.7977 - accuracy: 0.1328WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0129s vs `on_train_batch_end` time: 0.0199s). Check your callbacks.\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 1.0283 - accuracy: 0.5603\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.6618 - accuracy: 0.7395\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4884 - accuracy: 0.8185\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4178 - accuracy: 0.8428\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3629 - accuracy: 0.8665\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3397 - accuracy: 0.8749\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3222 - accuracy: 0.8805\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3102 - accuracy: 0.8853\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2901 - accuracy: 0.8921\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2739 - accuracy: 0.8982\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2675 - accuracy: 0.9010\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2574 - accuracy: 0.9052\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2440 - accuracy: 0.9090\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2464 - accuracy: 0.9100\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2436 - accuracy: 0.9105\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2238 - accuracy: 0.9180\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2144 - accuracy: 0.9214\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2089 - accuracy: 0.9232\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2085 - accuracy: 0.9232\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2013 - accuracy: 0.9262\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1908 - accuracy: 0.9287\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1906 - accuracy: 0.9300\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1830 - accuracy: 0.9317\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1863 - accuracy: 0.9308\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1750 - accuracy: 0.9343\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1752 - accuracy: 0.9341\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1802 - accuracy: 0.9340\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1648 - accuracy: 0.9392\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1555 - accuracy: 0.9423\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1522 - accuracy: 0.9429\n",
      "Epoch 31/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1544 - accuracy: 0.9420\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1508 - accuracy: 0.9445\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1437 - accuracy: 0.9470\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1567 - accuracy: 0.9422\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1434 - accuracy: 0.9466\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1364 - accuracy: 0.9491\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1358 - accuracy: 0.9489\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1275 - accuracy: 0.9530\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1311 - accuracy: 0.9514\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1295 - accuracy: 0.9518\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1332 - accuracy: 0.9487\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1287 - accuracy: 0.9528\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1195 - accuracy: 0.9567\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1166 - accuracy: 0.9562\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1170 - accuracy: 0.9568\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1287 - accuracy: 0.9522\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1130 - accuracy: 0.9584\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1160 - accuracy: 0.9563\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1087 - accuracy: 0.9598\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1145 - accuracy: 0.9580\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1085 - accuracy: 0.9598\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1074 - accuracy: 0.9596\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1013 - accuracy: 0.9630\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1009 - accuracy: 0.9627\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1032 - accuracy: 0.9609\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1004 - accuracy: 0.9626\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.0946 - accuracy: 0.9656\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.0928 - accuracy: 0.9650\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1008 - accuracy: 0.9635\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.0925 - accuracy: 0.9672\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 0.2363 - accuracy: 0.9407\n",
      "n_conv_1 = 512, k_conv_1 = 2,  n_conv_2 = 512, k_conv_2 = 3, \n",
      "          n_conv_3 = 256,  k_conv_3 = 2,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 256, dropout_1 = 0.3,\n",
      "          n_dense_2 = 256, dropout_2 = 0.25, activation_conv=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001FBEADFED08>,\n",
      "          activation_dense=  elu\n",
      "Epoch 1/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 1.1009 - accuracy: 0.5267\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.8759 - accuracy: 0.6192\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.7973 - accuracy: 0.6584\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.7408 - accuracy: 0.6890\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.6721 - accuracy: 0.7225\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.6227 - accuracy: 0.7501\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.5745 - accuracy: 0.7729\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.5536 - accuracy: 0.7827\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.5093 - accuracy: 0.8048\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.5032 - accuracy: 0.8049\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.4768 - accuracy: 0.8157\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.4457 - accuracy: 0.8310\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.4426 - accuracy: 0.8296\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.4287 - accuracy: 0.8355\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.4199 - accuracy: 0.8391\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.4088 - accuracy: 0.8437\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.4028 - accuracy: 0.8465\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3989 - accuracy: 0.8472\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3900 - accuracy: 0.8514\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3838 - accuracy: 0.8523\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3781 - accuracy: 0.8562\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3769 - accuracy: 0.8555\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3648 - accuracy: 0.8608\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3595 - accuracy: 0.8614\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3623 - accuracy: 0.8598\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3640 - accuracy: 0.8608\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3533 - accuracy: 0.8628\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3437 - accuracy: 0.8669\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3497 - accuracy: 0.8652\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3411 - accuracy: 0.8702\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3497 - accuracy: 0.8641\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3367 - accuracy: 0.8701\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3349 - accuracy: 0.8685\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3368 - accuracy: 0.8700\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3262 - accuracy: 0.8719\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3272 - accuracy: 0.8723\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3324 - accuracy: 0.8705\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3145 - accuracy: 0.8762\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3174 - accuracy: 0.8767\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3204 - accuracy: 0.8756\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3162 - accuracy: 0.8756\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3141 - accuracy: 0.8787\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3099 - accuracy: 0.8772\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3128 - accuracy: 0.8774\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3043 - accuracy: 0.8794\n",
      "Epoch 46/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3052 - accuracy: 0.8798\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3054 - accuracy: 0.8809\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3125 - accuracy: 0.8763\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3057 - accuracy: 0.8785\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2955 - accuracy: 0.8840\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2975 - accuracy: 0.8832\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2894 - accuracy: 0.8848\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2893 - accuracy: 0.8849\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2923 - accuracy: 0.8838\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2889 - accuracy: 0.8853\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2839 - accuracy: 0.8897\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2834 - accuracy: 0.8879\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2839 - accuracy: 0.8861\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2823 - accuracy: 0.8882\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2863 - accuracy: 0.8864\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 0.3091 - accuracy: 0.8770\n",
      "n_conv_1 = 512, k_conv_1 = 2,  n_conv_2 = 512, k_conv_2 = 3, \n",
      "          n_conv_3 = 256,  k_conv_3 = 2,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 256, dropout_1 = 0.3,\n",
      "          n_dense_2 = 256, dropout_2 = 0.25, activation_conv=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001FAE2B77EC8>,\n",
      "          activation_dense=  elu\n",
      "Epoch 1/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 1.1075 - accuracy: 0.5178\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.8823 - accuracy: 0.6173\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.7924 - accuracy: 0.6616\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.7223 - accuracy: 0.6988\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.6744 - accuracy: 0.7220\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.6064 - accuracy: 0.7613\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.5611 - accuracy: 0.7817\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.5313 - accuracy: 0.7917\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.5009 - accuracy: 0.8061\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.4948 - accuracy: 0.8085\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.4603 - accuracy: 0.8262\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.4621 - accuracy: 0.8236\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.4404 - accuracy: 0.8320\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.4143 - accuracy: 0.8422\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.4198 - accuracy: 0.8383\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.4056 - accuracy: 0.8447\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.4023 - accuracy: 0.8475\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3954 - accuracy: 0.8496\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3902 - accuracy: 0.8494\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3873 - accuracy: 0.8527\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3686 - accuracy: 0.8600\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3725 - accuracy: 0.8572\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3706 - accuracy: 0.8579\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3566 - accuracy: 0.8631\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3576 - accuracy: 0.8619\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3584 - accuracy: 0.8620\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3496 - accuracy: 0.8660\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3554 - accuracy: 0.8620\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3347 - accuracy: 0.8712\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3334 - accuracy: 0.8703\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3399 - accuracy: 0.8690\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3388 - accuracy: 0.8686\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3315 - accuracy: 0.8721\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3367 - accuracy: 0.8685\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3196 - accuracy: 0.8759\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3243 - accuracy: 0.8731\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3270 - accuracy: 0.8736\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3204 - accuracy: 0.8759\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3087 - accuracy: 0.8806\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3026 - accuracy: 0.8825\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3094 - accuracy: 0.8788\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3021 - accuracy: 0.8808\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3059 - accuracy: 0.8819\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3066 - accuracy: 0.8790\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3043 - accuracy: 0.8815\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2940 - accuracy: 0.8837\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2903 - accuracy: 0.8853\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3018 - accuracy: 0.8817\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2836 - accuracy: 0.8882\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2941 - accuracy: 0.8848\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2844 - accuracy: 0.8887\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2831 - accuracy: 0.8861\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2849 - accuracy: 0.8877\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2897 - accuracy: 0.8847\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2794 - accuracy: 0.8902\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2921 - accuracy: 0.8845\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2798 - accuracy: 0.8894\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2630 - accuracy: 0.8944\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2726 - accuracy: 0.8914\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2726 - accuracy: 0.8909\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 0.3093 - accuracy: 0.8823\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_conv_1 = 512, k_conv_1 = 2,  n_conv_2 = 512, k_conv_2 = 3, \n",
      "          n_conv_3 = 256,  k_conv_3 = 2,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 256, dropout_1 = 0.3,\n",
      "          n_dense_2 = 256, dropout_2 = 0.25, activation_conv=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001FBE757F748>,\n",
      "          activation_dense=  elu\n",
      "Epoch 1/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 1.1081 - accuracy: 0.5246\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.8825 - accuracy: 0.6226\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.7990 - accuracy: 0.6561\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.7349 - accuracy: 0.6887\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.6830 - accuracy: 0.7181\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.6199 - accuracy: 0.7534\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.5791 - accuracy: 0.7715\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.5358 - accuracy: 0.7893\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.5049 - accuracy: 0.8044\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.4948 - accuracy: 0.8075\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.4732 - accuracy: 0.8190\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.4553 - accuracy: 0.8259\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.4539 - accuracy: 0.8227\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.4309 - accuracy: 0.8345\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.4203 - accuracy: 0.8386\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.4101 - accuracy: 0.8439\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.4047 - accuracy: 0.8452\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3940 - accuracy: 0.8481\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3967 - accuracy: 0.8463\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3806 - accuracy: 0.8526\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3815 - accuracy: 0.8527\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3817 - accuracy: 0.8534\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3644 - accuracy: 0.8595\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3670 - accuracy: 0.8563\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3686 - accuracy: 0.8569\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3563 - accuracy: 0.8612\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3438 - accuracy: 0.8658\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3552 - accuracy: 0.8640\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3405 - accuracy: 0.8678\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3488 - accuracy: 0.8642\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3399 - accuracy: 0.8669\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3365 - accuracy: 0.8691\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3319 - accuracy: 0.8714\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3320 - accuracy: 0.8685\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3343 - accuracy: 0.8696\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3392 - accuracy: 0.8673\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3120 - accuracy: 0.8755\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3274 - accuracy: 0.8719\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3145 - accuracy: 0.8779\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3217 - accuracy: 0.8733\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3114 - accuracy: 0.8766\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3208 - accuracy: 0.8729\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3083 - accuracy: 0.8790\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3109 - accuracy: 0.8761\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3038 - accuracy: 0.8804\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3014 - accuracy: 0.8817\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3005 - accuracy: 0.8809\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2938 - accuracy: 0.8833\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3062 - accuracy: 0.8803\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2945 - accuracy: 0.8829\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2893 - accuracy: 0.8830\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2913 - accuracy: 0.8846\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2837 - accuracy: 0.8857\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2774 - accuracy: 0.8905\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2811 - accuracy: 0.8887\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2926 - accuracy: 0.8838\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2858 - accuracy: 0.8862\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2717 - accuracy: 0.8897\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2767 - accuracy: 0.8905\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2779 - accuracy: 0.8908\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 0.3012 - accuracy: 0.8849\n",
      "n_conv_1 = 768, k_conv_1 = 2,  n_conv_2 = 512, k_conv_2 = 2, \n",
      "          n_conv_3 = 256,  k_conv_3 = 3,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 256, dropout_1 = 0.2,\n",
      "          n_dense_2 = 256, dropout_2 = 0.25, activation_conv=  elu,\n",
      "          activation_dense=  elu\n",
      "Epoch 1/60\n",
      "152/152 [==============================] - 7s 43ms/step - loss: 1.1968 - accuracy: 0.4933\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 1.0735 - accuracy: 0.5368\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 1.0254 - accuracy: 0.5622\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.9491 - accuracy: 0.6003\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.8723 - accuracy: 0.6321\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.8181 - accuracy: 0.6555\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.7653 - accuracy: 0.6778\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.7112 - accuracy: 0.7022\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.6669 - accuracy: 0.7229\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.6328 - accuracy: 0.7415\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.5796 - accuracy: 0.7650\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.5451 - accuracy: 0.7818\n",
      "Epoch 13/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 6s 42ms/step - loss: 0.5209 - accuracy: 0.7944\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.4836 - accuracy: 0.8115\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 6s 43ms/step - loss: 0.4604 - accuracy: 0.8208\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.4382 - accuracy: 0.8285\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 6s 43ms/step - loss: 0.4149 - accuracy: 0.8390\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.4112 - accuracy: 0.8398\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.3960 - accuracy: 0.8441\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.3765 - accuracy: 0.8557\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.3734 - accuracy: 0.8557\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.3599 - accuracy: 0.8607\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.3532 - accuracy: 0.8609\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 6s 43ms/step - loss: 0.3444 - accuracy: 0.8636\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.3338 - accuracy: 0.8685\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.3433 - accuracy: 0.8665\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.3192 - accuracy: 0.8748\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.3149 - accuracy: 0.8767\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.3109 - accuracy: 0.8784\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.3104 - accuracy: 0.8775\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.3035 - accuracy: 0.8819\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2966 - accuracy: 0.8856\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.3020 - accuracy: 0.8813\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2832 - accuracy: 0.8877\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2802 - accuracy: 0.8910\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2767 - accuracy: 0.8926\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2746 - accuracy: 0.8928\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2703 - accuracy: 0.8948\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2636 - accuracy: 0.8971\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2618 - accuracy: 0.8994\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2607 - accuracy: 0.8966\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2582 - accuracy: 0.8987\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2456 - accuracy: 0.9034\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2545 - accuracy: 0.8989\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2456 - accuracy: 0.9035\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2439 - accuracy: 0.9054\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2400 - accuracy: 0.9060\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2351 - accuracy: 0.9081\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2367 - accuracy: 0.9067\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2268 - accuracy: 0.9107\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2301 - accuracy: 0.9101\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2328 - accuracy: 0.9076\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 6s 43ms/step - loss: 0.2262 - accuracy: 0.9114\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2222 - accuracy: 0.9135\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2269 - accuracy: 0.9112\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2179 - accuracy: 0.9143\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2140 - accuracy: 0.9142\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2047 - accuracy: 0.9200\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2157 - accuracy: 0.9160\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2130 - accuracy: 0.9175\n",
      "76/76 [==============================] - 1s 16ms/step - loss: 0.3118 - accuracy: 0.8914\n",
      "n_conv_1 = 768, k_conv_1 = 2,  n_conv_2 = 512, k_conv_2 = 2, \n",
      "          n_conv_3 = 256,  k_conv_3 = 3,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 256, dropout_1 = 0.2,\n",
      "          n_dense_2 = 256, dropout_2 = 0.25, activation_conv=  elu,\n",
      "          activation_dense=  elu\n",
      "Epoch 1/60\n",
      "  1/152 [..............................] - ETA: 3s - loss: 1.7861 - accuracy: 0.2031WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0160s vs `on_train_batch_end` time: 0.0259s). Check your callbacks.\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 1.1995 - accuracy: 0.4884\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 1.0673 - accuracy: 0.5412\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 1.0062 - accuracy: 0.5756\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.9409 - accuracy: 0.6038\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.8692 - accuracy: 0.6305\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.8065 - accuracy: 0.6601\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.7472 - accuracy: 0.6878\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 6s 43ms/step - loss: 0.7113 - accuracy: 0.7027\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.6513 - accuracy: 0.7327\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.5981 - accuracy: 0.7583\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 6s 43ms/step - loss: 0.5587 - accuracy: 0.7778\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.5203 - accuracy: 0.7937\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.4938 - accuracy: 0.8086\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.4666 - accuracy: 0.8181\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 6s 43ms/step - loss: 0.4377 - accuracy: 0.8283\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.4269 - accuracy: 0.8343\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.4090 - accuracy: 0.8417\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.3934 - accuracy: 0.8478\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.3839 - accuracy: 0.8536\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.3746 - accuracy: 0.8539\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 6s 43ms/step - loss: 0.3679 - accuracy: 0.8549\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.3535 - accuracy: 0.8616\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.3456 - accuracy: 0.8648\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 6s 43ms/step - loss: 0.3424 - accuracy: 0.8672\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.3307 - accuracy: 0.8716\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 6s 43ms/step - loss: 0.3248 - accuracy: 0.8728\n",
      "Epoch 27/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 6s 42ms/step - loss: 0.3246 - accuracy: 0.8737\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 6s 43ms/step - loss: 0.3107 - accuracy: 0.8775\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 6s 43ms/step - loss: 0.3070 - accuracy: 0.8797\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 6s 43ms/step - loss: 0.3078 - accuracy: 0.8794\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 6s 43ms/step - loss: 0.3010 - accuracy: 0.8835\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2882 - accuracy: 0.8859\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2854 - accuracy: 0.8869\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2834 - accuracy: 0.8890\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2898 - accuracy: 0.8875\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 6s 43ms/step - loss: 0.2705 - accuracy: 0.8941\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 6s 43ms/step - loss: 0.2731 - accuracy: 0.8934\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2675 - accuracy: 0.8936\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2624 - accuracy: 0.9000\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2549 - accuracy: 0.8997\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2507 - accuracy: 0.9018\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2465 - accuracy: 0.9021\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 6s 43ms/step - loss: 0.2573 - accuracy: 0.9006\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 6s 43ms/step - loss: 0.2486 - accuracy: 0.9041\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2421 - accuracy: 0.9056\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 6s 43ms/step - loss: 0.2410 - accuracy: 0.9047\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 6s 43ms/step - loss: 0.2398 - accuracy: 0.9066\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 6s 43ms/step - loss: 0.2384 - accuracy: 0.9067\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2274 - accuracy: 0.9114\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2255 - accuracy: 0.9105\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 6s 43ms/step - loss: 0.2306 - accuracy: 0.9094\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2283 - accuracy: 0.9118\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2167 - accuracy: 0.9153\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2235 - accuracy: 0.9118\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2180 - accuracy: 0.9136 0s - loss: 0.2158 \n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2165 - accuracy: 0.9145\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 6s 43ms/step - loss: 0.2176 - accuracy: 0.9149\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2089 - accuracy: 0.9173\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2091 - accuracy: 0.9184\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2132 - accuracy: 0.9185\n",
      "76/76 [==============================] - 1s 16ms/step - loss: 0.2573 - accuracy: 0.9132\n",
      "n_conv_1 = 768, k_conv_1 = 2,  n_conv_2 = 512, k_conv_2 = 2, \n",
      "          n_conv_3 = 256,  k_conv_3 = 3,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 256, dropout_1 = 0.2,\n",
      "          n_dense_2 = 256, dropout_2 = 0.25, activation_conv=  elu,\n",
      "          activation_dense=  elu\n",
      "Epoch 1/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 1.1825 - accuracy: 0.4989\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 1.0722 - accuracy: 0.5409\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 1.0225 - accuracy: 0.5660\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.9565 - accuracy: 0.5948\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.8852 - accuracy: 0.6291\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.8244 - accuracy: 0.6539\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.7779 - accuracy: 0.6759\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.7232 - accuracy: 0.6988\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.6808 - accuracy: 0.7185\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.6470 - accuracy: 0.7313\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.5923 - accuracy: 0.7584\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.5532 - accuracy: 0.7775\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.5242 - accuracy: 0.7914\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.4904 - accuracy: 0.8063\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.4633 - accuracy: 0.8193\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.4426 - accuracy: 0.8248\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.4269 - accuracy: 0.8330\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.4189 - accuracy: 0.8357\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.4044 - accuracy: 0.8420\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.3876 - accuracy: 0.8484\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.3729 - accuracy: 0.8540\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.3642 - accuracy: 0.8582\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.3600 - accuracy: 0.8561\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.3441 - accuracy: 0.8655\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.3379 - accuracy: 0.8689\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.3336 - accuracy: 0.8697\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.3244 - accuracy: 0.8743\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.3204 - accuracy: 0.8765\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.3149 - accuracy: 0.8781\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.3055 - accuracy: 0.8834\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.3023 - accuracy: 0.8813\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2946 - accuracy: 0.8864\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.3012 - accuracy: 0.8829\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2836 - accuracy: 0.8898\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2895 - accuracy: 0.8877\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2823 - accuracy: 0.8896\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2751 - accuracy: 0.8938\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2663 - accuracy: 0.8982\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2711 - accuracy: 0.8965\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2651 - accuracy: 0.8954\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2633 - accuracy: 0.8977\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2622 - accuracy: 0.8990\n",
      "Epoch 43/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2488 - accuracy: 0.9017\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2511 - accuracy: 0.9026\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2441 - accuracy: 0.9061\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2444 - accuracy: 0.9039\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2427 - accuracy: 0.9064\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2399 - accuracy: 0.9075\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2380 - accuracy: 0.9068\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2330 - accuracy: 0.9103\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2360 - accuracy: 0.9085\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2318 - accuracy: 0.9081\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2263 - accuracy: 0.9125\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2237 - accuracy: 0.9127\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2211 - accuracy: 0.9143\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2142 - accuracy: 0.9163\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2121 - accuracy: 0.9168\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2229 - accuracy: 0.9136\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2169 - accuracy: 0.9165\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2096 - accuracy: 0.9186\n",
      "76/76 [==============================] - 1s 16ms/step - loss: 0.2576 - accuracy: 0.9162\n",
      "n_conv_1 = 768, k_conv_1 = 3,  n_conv_2 = 256, k_conv_2 = 3, \n",
      "          n_conv_3 = 512,  k_conv_3 = 3,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 512, dropout_1 = 0.3,\n",
      "          n_dense_2 = 256, dropout_2 = 0.25, activation_conv=  elu,\n",
      "          activation_dense=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001FAC9E06508>\n",
      "Epoch 1/60\n",
      "  1/152 [..............................] - ETA: 3s - loss: 1.7975 - accuracy: 0.1328WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0150s vs `on_train_batch_end` time: 0.0229s). Check your callbacks.\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 1.1511 - accuracy: 0.5151\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.8990 - accuracy: 0.6320\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.8140 - accuracy: 0.6715\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.7677 - accuracy: 0.6914\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.7109 - accuracy: 0.7128\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.6848 - accuracy: 0.7269\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.6482 - accuracy: 0.7417\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.6410 - accuracy: 0.7419\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.6034 - accuracy: 0.7610\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.5925 - accuracy: 0.7629\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.5772 - accuracy: 0.7682\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.5623 - accuracy: 0.7772\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.5470 - accuracy: 0.7832\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.5283 - accuracy: 0.7900\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.5152 - accuracy: 0.7922\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.5028 - accuracy: 0.8028\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.4889 - accuracy: 0.8060\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.4848 - accuracy: 0.8109\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.4672 - accuracy: 0.8155\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.4604 - accuracy: 0.8199\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.4534 - accuracy: 0.8237\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.4435 - accuracy: 0.8282\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.4417 - accuracy: 0.8282\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.4382 - accuracy: 0.8295\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.4323 - accuracy: 0.8279\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.4173 - accuracy: 0.8373\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.4156 - accuracy: 0.8375\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.4078 - accuracy: 0.8416\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.4059 - accuracy: 0.8434\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3944 - accuracy: 0.8465\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3912 - accuracy: 0.8479\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3901 - accuracy: 0.8482\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3855 - accuracy: 0.8508\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3739 - accuracy: 0.8541\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3657 - accuracy: 0.8578\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3774 - accuracy: 0.8542\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3579 - accuracy: 0.8598\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3567 - accuracy: 0.8624\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3508 - accuracy: 0.8615\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3438 - accuracy: 0.8650\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3413 - accuracy: 0.8675\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3433 - accuracy: 0.8646\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3288 - accuracy: 0.8717\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3298 - accuracy: 0.8725\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3260 - accuracy: 0.8715\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3267 - accuracy: 0.8716\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3146 - accuracy: 0.8760\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3286 - accuracy: 0.8718\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3180 - accuracy: 0.8737\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3040 - accuracy: 0.8787\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3070 - accuracy: 0.8770\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3031 - accuracy: 0.8817\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3013 - accuracy: 0.8818\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2958 - accuracy: 0.8819\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2959 - accuracy: 0.8810\n",
      "Epoch 56/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2910 - accuracy: 0.8829\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2909 - accuracy: 0.8827\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2803 - accuracy: 0.8876\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2846 - accuracy: 0.8844\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2824 - accuracy: 0.8886\n",
      "76/76 [==============================] - 1s 14ms/step - loss: 0.3152 - accuracy: 0.8890\n",
      "n_conv_1 = 768, k_conv_1 = 3,  n_conv_2 = 256, k_conv_2 = 3, \n",
      "          n_conv_3 = 512,  k_conv_3 = 3,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 512, dropout_1 = 0.3,\n",
      "          n_dense_2 = 256, dropout_2 = 0.25, activation_conv=  elu,\n",
      "          activation_dense=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001FBE75AA748>\n",
      "Epoch 1/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 1.1762 - accuracy: 0.4982\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.9198 - accuracy: 0.6229\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.8287 - accuracy: 0.6644\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.7603 - accuracy: 0.6959\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.7284 - accuracy: 0.7080\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.6883 - accuracy: 0.7249\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.6742 - accuracy: 0.7298\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.6258 - accuracy: 0.7513\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.6062 - accuracy: 0.7576\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.5958 - accuracy: 0.7624\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.5747 - accuracy: 0.7723\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.5632 - accuracy: 0.7758\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.5301 - accuracy: 0.7904\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.5182 - accuracy: 0.7978\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.5024 - accuracy: 0.8041\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.5038 - accuracy: 0.8054\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.4756 - accuracy: 0.8160\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.4803 - accuracy: 0.8108\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.4549 - accuracy: 0.8226\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.4559 - accuracy: 0.8235\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.4465 - accuracy: 0.8288\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.4369 - accuracy: 0.8289\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.4324 - accuracy: 0.8318\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.4184 - accuracy: 0.8394\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.4193 - accuracy: 0.8383\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.4113 - accuracy: 0.8404\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.4043 - accuracy: 0.8471\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.4010 - accuracy: 0.8464\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3891 - accuracy: 0.8526\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3901 - accuracy: 0.8506\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3730 - accuracy: 0.8552\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3764 - accuracy: 0.8556\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3740 - accuracy: 0.8574\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3695 - accuracy: 0.8563\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3546 - accuracy: 0.8649\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3488 - accuracy: 0.8663\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3637 - accuracy: 0.8606\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3473 - accuracy: 0.8658\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3378 - accuracy: 0.8699\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3360 - accuracy: 0.8700\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3295 - accuracy: 0.8732\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3283 - accuracy: 0.8720\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3287 - accuracy: 0.8733\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3252 - accuracy: 0.8721\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3166 - accuracy: 0.8776\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3129 - accuracy: 0.8783\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3119 - accuracy: 0.8802\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3127 - accuracy: 0.8784\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2985 - accuracy: 0.8832\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3008 - accuracy: 0.8825\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2912 - accuracy: 0.8869\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2881 - accuracy: 0.8880\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2892 - accuracy: 0.8856\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2932 - accuracy: 0.8859\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2829 - accuracy: 0.8895\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2736 - accuracy: 0.8928\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2720 - accuracy: 0.8932\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2667 - accuracy: 0.8949\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2664 - accuracy: 0.8953\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2647 - accuracy: 0.8974\n",
      "76/76 [==============================] - 1s 14ms/step - loss: 0.3379 - accuracy: 0.8840\n",
      "n_conv_1 = 768, k_conv_1 = 3,  n_conv_2 = 256, k_conv_2 = 3, \n",
      "          n_conv_3 = 512,  k_conv_3 = 3,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 512, dropout_1 = 0.3,\n",
      "          n_dense_2 = 256, dropout_2 = 0.25, activation_conv=  elu,\n",
      "          activation_dense=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001FAE88A7A08>\n",
      "Epoch 1/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 1.1718 - accuracy: 0.5025\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.9225 - accuracy: 0.6193\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.8129 - accuracy: 0.6720\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.7812 - accuracy: 0.6832\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.7299 - accuracy: 0.7071\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.7062 - accuracy: 0.7164\n",
      "Epoch 7/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 6s 38ms/step - loss: 0.6668 - accuracy: 0.7343\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.6280 - accuracy: 0.7477\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.6102 - accuracy: 0.7547\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.5903 - accuracy: 0.7660\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.5620 - accuracy: 0.7759\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.5533 - accuracy: 0.7807\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.5329 - accuracy: 0.7890\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.5198 - accuracy: 0.7957\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.5074 - accuracy: 0.7998\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.4959 - accuracy: 0.8076\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.4803 - accuracy: 0.8147\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.4698 - accuracy: 0.8159\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.4571 - accuracy: 0.8221\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.4474 - accuracy: 0.8283\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.4423 - accuracy: 0.8292\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.4335 - accuracy: 0.8306\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.4271 - accuracy: 0.8373\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.4243 - accuracy: 0.8369\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.4210 - accuracy: 0.8370\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.4075 - accuracy: 0.8426\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3961 - accuracy: 0.8474\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3920 - accuracy: 0.8480\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3870 - accuracy: 0.8503\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3800 - accuracy: 0.8523\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3840 - accuracy: 0.8521\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3712 - accuracy: 0.8570\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3674 - accuracy: 0.8582\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3696 - accuracy: 0.8570\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3563 - accuracy: 0.8611\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3495 - accuracy: 0.8630\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3513 - accuracy: 0.8651\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3472 - accuracy: 0.8637\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3430 - accuracy: 0.8653\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3419 - accuracy: 0.8682\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3340 - accuracy: 0.8697\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3303 - accuracy: 0.8708\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3204 - accuracy: 0.8745\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3215 - accuracy: 0.8738\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3190 - accuracy: 0.8738\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3127 - accuracy: 0.8753\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3064 - accuracy: 0.8789\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3084 - accuracy: 0.8788\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3044 - accuracy: 0.8811\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3087 - accuracy: 0.8776\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2969 - accuracy: 0.8817\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2932 - accuracy: 0.8839\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2894 - accuracy: 0.8856\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2996 - accuracy: 0.8815\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2836 - accuracy: 0.8876\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2778 - accuracy: 0.8886\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2673 - accuracy: 0.8925\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2780 - accuracy: 0.8879\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2695 - accuracy: 0.8911\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2631 - accuracy: 0.8937\n",
      "76/76 [==============================] - 1s 14ms/step - loss: 0.3116 - accuracy: 0.8930\n",
      "n_conv_1 = 768, k_conv_1 = 3,  n_conv_2 = 512, k_conv_2 = 2, \n",
      "          n_conv_3 = 256,  k_conv_3 = 3,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 512, dropout_1 = 0.2,\n",
      "          n_dense_2 = 512, dropout_2 = 0.25, activation_conv=  elu,\n",
      "          activation_dense=  relu\n",
      "Epoch 1/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 1.0939 - accuracy: 0.5350\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.8778 - accuracy: 0.6309\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.7339 - accuracy: 0.7036\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.6376 - accuracy: 0.7449\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.5941 - accuracy: 0.7665\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.5557 - accuracy: 0.7805\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.5105 - accuracy: 0.7980\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.5130 - accuracy: 0.7999\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.4718 - accuracy: 0.8162\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.4488 - accuracy: 0.8254\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.4539 - accuracy: 0.8263\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.4243 - accuracy: 0.8352\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.4147 - accuracy: 0.8396\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.4048 - accuracy: 0.8431\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.3966 - accuracy: 0.8464\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.3820 - accuracy: 0.8518\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.3735 - accuracy: 0.8545\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.3671 - accuracy: 0.8600\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.3508 - accuracy: 0.8660\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.3416 - accuracy: 0.8688\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.3464 - accuracy: 0.8670\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.3415 - accuracy: 0.8678\n",
      "Epoch 23/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 6s 42ms/step - loss: 0.3326 - accuracy: 0.8709\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.3202 - accuracy: 0.8749\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.3203 - accuracy: 0.8752\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.3221 - accuracy: 0.8770\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.3056 - accuracy: 0.8814\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.3087 - accuracy: 0.8791\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.3085 - accuracy: 0.8822\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2951 - accuracy: 0.8865\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2956 - accuracy: 0.8866\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2917 - accuracy: 0.8868\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2852 - accuracy: 0.8882\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2847 - accuracy: 0.8884\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2826 - accuracy: 0.8912\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2725 - accuracy: 0.8949\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2858 - accuracy: 0.8903\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2676 - accuracy: 0.8954\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2715 - accuracy: 0.8945\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2634 - accuracy: 0.8950\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2651 - accuracy: 0.8972\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2637 - accuracy: 0.8982\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2663 - accuracy: 0.8955\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2517 - accuracy: 0.9022\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2534 - accuracy: 0.9011\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2454 - accuracy: 0.9039\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2451 - accuracy: 0.9053\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2411 - accuracy: 0.9065\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2450 - accuracy: 0.9040\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2419 - accuracy: 0.9028\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2465 - accuracy: 0.9026\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2310 - accuracy: 0.9094\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2293 - accuracy: 0.9102\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2298 - accuracy: 0.9087\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2339 - accuracy: 0.9077\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2350 - accuracy: 0.9078\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2223 - accuracy: 0.9125\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2193 - accuracy: 0.9144\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2191 - accuracy: 0.9146\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2135 - accuracy: 0.9167\n",
      "76/76 [==============================] - 1s 16ms/step - loss: 0.2740 - accuracy: 0.9029\n",
      "n_conv_1 = 768, k_conv_1 = 3,  n_conv_2 = 512, k_conv_2 = 2, \n",
      "          n_conv_3 = 256,  k_conv_3 = 3,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 512, dropout_1 = 0.2,\n",
      "          n_dense_2 = 512, dropout_2 = 0.25, activation_conv=  elu,\n",
      "          activation_dense=  relu\n",
      "Epoch 1/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 1.1022 - accuracy: 0.5317\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.8790 - accuracy: 0.6282\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.7290 - accuracy: 0.7031\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.6397 - accuracy: 0.7440\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.5958 - accuracy: 0.7644\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.5480 - accuracy: 0.7856\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.5410 - accuracy: 0.7900\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.5024 - accuracy: 0.8082\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.4668 - accuracy: 0.8215\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.4518 - accuracy: 0.8262\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.4258 - accuracy: 0.8380\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.4404 - accuracy: 0.8328\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.4106 - accuracy: 0.8437\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.4003 - accuracy: 0.8478\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.3850 - accuracy: 0.8543\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.3937 - accuracy: 0.8495\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.3625 - accuracy: 0.8625\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.3618 - accuracy: 0.8604\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.3644 - accuracy: 0.8609\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.3386 - accuracy: 0.8691\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 6s 43ms/step - loss: 0.3500 - accuracy: 0.8658\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.3357 - accuracy: 0.8735\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.3204 - accuracy: 0.8770\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.3306 - accuracy: 0.8744\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.3067 - accuracy: 0.8815\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.3186 - accuracy: 0.8778\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.3074 - accuracy: 0.8810\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.3083 - accuracy: 0.8815\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.3096 - accuracy: 0.8805\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2999 - accuracy: 0.8850\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2957 - accuracy: 0.8840\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2924 - accuracy: 0.8877\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2806 - accuracy: 0.8887\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2805 - accuracy: 0.8907\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2790 - accuracy: 0.8897\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2844 - accuracy: 0.8904\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2734 - accuracy: 0.8949\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2623 - accuracy: 0.8987\n",
      "Epoch 39/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2637 - accuracy: 0.8963\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2692 - accuracy: 0.8957\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2734 - accuracy: 0.8937\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2663 - accuracy: 0.8967\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2539 - accuracy: 0.9001\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2514 - accuracy: 0.9035\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2528 - accuracy: 0.9014\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2616 - accuracy: 0.8992\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2416 - accuracy: 0.9040\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2451 - accuracy: 0.9040\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2445 - accuracy: 0.9053\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2332 - accuracy: 0.9099\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2426 - accuracy: 0.9051\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2312 - accuracy: 0.9114\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2361 - accuracy: 0.9109\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2266 - accuracy: 0.9129\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2262 - accuracy: 0.9111\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2178 - accuracy: 0.9170\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2162 - accuracy: 0.9168\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2292 - accuracy: 0.9111\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2103 - accuracy: 0.9185\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2114 - accuracy: 0.9182\n",
      "76/76 [==============================] - 1s 16ms/step - loss: 0.2743 - accuracy: 0.9140\n",
      "n_conv_1 = 768, k_conv_1 = 3,  n_conv_2 = 512, k_conv_2 = 2, \n",
      "          n_conv_3 = 256,  k_conv_3 = 3,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 512, dropout_1 = 0.2,\n",
      "          n_dense_2 = 512, dropout_2 = 0.25, activation_conv=  elu,\n",
      "          activation_dense=  relu\n",
      "Epoch 1/60\n",
      "  1/152 [..............................] - ETA: 3s - loss: 1.7979 - accuracy: 0.1719WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0169s vs `on_train_batch_end` time: 0.0259s). Check your callbacks.\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 1.1057 - accuracy: 0.5300\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.8840 - accuracy: 0.6291\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.7310 - accuracy: 0.7031\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.6477 - accuracy: 0.7435\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.5743 - accuracy: 0.7742\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.5560 - accuracy: 0.7838\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.5244 - accuracy: 0.7962\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.4891 - accuracy: 0.8114\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.4728 - accuracy: 0.8182\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.4577 - accuracy: 0.8207\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.4434 - accuracy: 0.8296\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.4375 - accuracy: 0.8325\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.4212 - accuracy: 0.8376\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.3952 - accuracy: 0.8498\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.3994 - accuracy: 0.8489\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.3863 - accuracy: 0.8499\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.3778 - accuracy: 0.8581\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.3519 - accuracy: 0.8633\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.3723 - accuracy: 0.8589\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.3469 - accuracy: 0.8649\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.3437 - accuracy: 0.8684\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.3340 - accuracy: 0.8733\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.3425 - accuracy: 0.8686\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.3233 - accuracy: 0.8766\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.3261 - accuracy: 0.8767\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.3102 - accuracy: 0.8815\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.3187 - accuracy: 0.8772\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.3153 - accuracy: 0.8796\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.3010 - accuracy: 0.8843\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2923 - accuracy: 0.8889\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2934 - accuracy: 0.8872\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2829 - accuracy: 0.8912\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2874 - accuracy: 0.8876\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2840 - accuracy: 0.8905\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2754 - accuracy: 0.8935\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2753 - accuracy: 0.8930\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2765 - accuracy: 0.8924\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2794 - accuracy: 0.8913\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2727 - accuracy: 0.8942\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2643 - accuracy: 0.8962\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2658 - accuracy: 0.8983\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2779 - accuracy: 0.8940\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2591 - accuracy: 0.9003\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2528 - accuracy: 0.9015\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2494 - accuracy: 0.9045\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2573 - accuracy: 0.9013\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2507 - accuracy: 0.9040\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2391 - accuracy: 0.9076\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2452 - accuracy: 0.9061\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2458 - accuracy: 0.9058\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2350 - accuracy: 0.9091\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2494 - accuracy: 0.9028\n",
      "Epoch 53/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2363 - accuracy: 0.9106\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2404 - accuracy: 0.9072\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2284 - accuracy: 0.9107\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2127 - accuracy: 0.9174\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2214 - accuracy: 0.9155\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2166 - accuracy: 0.9165\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2258 - accuracy: 0.9114\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.2265 - accuracy: 0.9136\n",
      "76/76 [==============================] - 1s 16ms/step - loss: 0.2957 - accuracy: 0.9006\n",
      "n_conv_1 = 512, k_conv_1 = 2,  n_conv_2 = 512, k_conv_2 = 2, \n",
      "          n_conv_3 = 256,  k_conv_3 = 3,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 512, dropout_1 = 0.2,\n",
      "          n_dense_2 = 512, dropout_2 = 0.25, activation_conv=  elu,\n",
      "          activation_dense=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001FAC9818248>\n",
      "Epoch 1/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 1.1572 - accuracy: 0.5096\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 1.0246 - accuracy: 0.5627\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.9437 - accuracy: 0.5988\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.8773 - accuracy: 0.6317\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.8239 - accuracy: 0.6543\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.7757 - accuracy: 0.6773\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.7439 - accuracy: 0.6892\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.6938 - accuracy: 0.7149\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.6809 - accuracy: 0.7230\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.6489 - accuracy: 0.7367\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.6086 - accuracy: 0.7533\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.5626 - accuracy: 0.7778\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.5487 - accuracy: 0.7816\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.5169 - accuracy: 0.7964\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.5132 - accuracy: 0.8003\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4962 - accuracy: 0.8075\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4703 - accuracy: 0.8171\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4722 - accuracy: 0.8155\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4532 - accuracy: 0.8231\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4563 - accuracy: 0.8209\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4475 - accuracy: 0.8255\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4319 - accuracy: 0.8322\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4204 - accuracy: 0.8358\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4129 - accuracy: 0.8398\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4046 - accuracy: 0.8453\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3993 - accuracy: 0.8453\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3958 - accuracy: 0.8467\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3885 - accuracy: 0.8508\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3841 - accuracy: 0.8512\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3873 - accuracy: 0.8488\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3761 - accuracy: 0.8524\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3718 - accuracy: 0.8556\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3673 - accuracy: 0.8582\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3567 - accuracy: 0.8628\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3515 - accuracy: 0.8647\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3488 - accuracy: 0.8638\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3481 - accuracy: 0.8648\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3363 - accuracy: 0.8682\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3427 - accuracy: 0.8663\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3387 - accuracy: 0.8684\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3251 - accuracy: 0.8752\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3264 - accuracy: 0.8726\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3265 - accuracy: 0.8721\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3203 - accuracy: 0.8732\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3118 - accuracy: 0.8795\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3120 - accuracy: 0.8779\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2991 - accuracy: 0.8828\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3074 - accuracy: 0.8785\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2958 - accuracy: 0.8839\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3028 - accuracy: 0.8817\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2945 - accuracy: 0.8849\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2905 - accuracy: 0.8858\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2840 - accuracy: 0.8888\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2845 - accuracy: 0.8877\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2756 - accuracy: 0.8923\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2764 - accuracy: 0.8911\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2732 - accuracy: 0.8927\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2719 - accuracy: 0.8933\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2667 - accuracy: 0.8946\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2674 - accuracy: 0.8954\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 0.3133 - accuracy: 0.8923\n",
      "n_conv_1 = 512, k_conv_1 = 2,  n_conv_2 = 512, k_conv_2 = 2, \n",
      "          n_conv_3 = 256,  k_conv_3 = 3,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 512, dropout_1 = 0.2,\n",
      "          n_dense_2 = 512, dropout_2 = 0.25, activation_conv=  elu,\n",
      "          activation_dense=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001FAC956C588>\n",
      "Epoch 1/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 1.1446 - accuracy: 0.5157\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 1.0085 - accuracy: 0.5721\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.9394 - accuracy: 0.6027\n",
      "Epoch 4/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 5s 31ms/step - loss: 0.8748 - accuracy: 0.6331\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.8246 - accuracy: 0.6534\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.7684 - accuracy: 0.6833\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.7417 - accuracy: 0.6935\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.7002 - accuracy: 0.7146\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.6635 - accuracy: 0.7297\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.6297 - accuracy: 0.7428\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.5972 - accuracy: 0.7593\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.5669 - accuracy: 0.7743\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.5370 - accuracy: 0.7849\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.5063 - accuracy: 0.8011\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.5090 - accuracy: 0.8008\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4815 - accuracy: 0.8129\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4772 - accuracy: 0.8145\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4620 - accuracy: 0.8202\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4593 - accuracy: 0.8192\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4382 - accuracy: 0.8286\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4304 - accuracy: 0.8324\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4270 - accuracy: 0.8348\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4184 - accuracy: 0.8361\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4095 - accuracy: 0.8423\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4048 - accuracy: 0.8432\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3995 - accuracy: 0.8452\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3865 - accuracy: 0.8517\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3948 - accuracy: 0.8474\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3819 - accuracy: 0.8517\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3769 - accuracy: 0.8555\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3664 - accuracy: 0.8576\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3756 - accuracy: 0.8539\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3607 - accuracy: 0.8625\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3522 - accuracy: 0.8626\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3591 - accuracy: 0.8606\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3599 - accuracy: 0.8591\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3441 - accuracy: 0.8650 0s - loss: 0.3450 - accuracy: \n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3449 - accuracy: 0.8648\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3366 - accuracy: 0.8690\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3312 - accuracy: 0.8707\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3314 - accuracy: 0.8708\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3277 - accuracy: 0.8713\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3368 - accuracy: 0.8696\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3157 - accuracy: 0.8752\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3139 - accuracy: 0.8778\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3111 - accuracy: 0.8780\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3048 - accuracy: 0.8809\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3036 - accuracy: 0.8799\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3021 - accuracy: 0.8786\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3048 - accuracy: 0.8799\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2959 - accuracy: 0.8841\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2869 - accuracy: 0.8856\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2871 - accuracy: 0.8884\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2882 - accuracy: 0.8877 0s - loss: 0.2885 - accuracy: 0.\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2837 - accuracy: 0.8885\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2790 - accuracy: 0.8908\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2768 - accuracy: 0.8911\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2724 - accuracy: 0.8937\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2598 - accuracy: 0.8959\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2709 - accuracy: 0.8945\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 0.3128 - accuracy: 0.8888\n",
      "n_conv_1 = 512, k_conv_1 = 2,  n_conv_2 = 512, k_conv_2 = 2, \n",
      "          n_conv_3 = 256,  k_conv_3 = 3,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 512, dropout_1 = 0.2,\n",
      "          n_dense_2 = 512, dropout_2 = 0.25, activation_conv=  elu,\n",
      "          activation_dense=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001FBE87BD788>\n",
      "Epoch 1/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 1.1498 - accuracy: 0.5133\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 1.0285 - accuracy: 0.5626\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.9554 - accuracy: 0.5907\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.8887 - accuracy: 0.6221\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.8321 - accuracy: 0.6513\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.7881 - accuracy: 0.6715\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.7597 - accuracy: 0.6849\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.7075 - accuracy: 0.7088\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.6749 - accuracy: 0.7254\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.6357 - accuracy: 0.7437 0s - loss: 0.6352 - accu\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.6060 - accuracy: 0.7553\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.5882 - accuracy: 0.7652\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.5452 - accuracy: 0.7815 \n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.5302 - accuracy: 0.7894\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.5083 - accuracy: 0.8005\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4996 - accuracy: 0.8008\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4793 - accuracy: 0.8132\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4689 - accuracy: 0.8155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4622 - accuracy: 0.8194\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4469 - accuracy: 0.8232\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4411 - accuracy: 0.8263\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4408 - accuracy: 0.8276\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4322 - accuracy: 0.8314\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4156 - accuracy: 0.8360\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4123 - accuracy: 0.8385\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4076 - accuracy: 0.8382\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4067 - accuracy: 0.8402\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3946 - accuracy: 0.8461\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3898 - accuracy: 0.8465\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3810 - accuracy: 0.8500\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3756 - accuracy: 0.8526\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3739 - accuracy: 0.8529\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3683 - accuracy: 0.8560\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3619 - accuracy: 0.8560\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3567 - accuracy: 0.8592\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3634 - accuracy: 0.8584\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3446 - accuracy: 0.8652\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3492 - accuracy: 0.8631\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3503 - accuracy: 0.8622\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3467 - accuracy: 0.8643\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3345 - accuracy: 0.8689\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3246 - accuracy: 0.8717\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3266 - accuracy: 0.8713\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3246 - accuracy: 0.8725\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3170 - accuracy: 0.8767\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3065 - accuracy: 0.8784\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3099 - accuracy: 0.8774\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3009 - accuracy: 0.8803\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3054 - accuracy: 0.8802\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2929 - accuracy: 0.8839\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2970 - accuracy: 0.8834\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2924 - accuracy: 0.8869\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2805 - accuracy: 0.8919\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2877 - accuracy: 0.8870\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2807 - accuracy: 0.8891\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2765 - accuracy: 0.8924\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2718 - accuracy: 0.8936\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2773 - accuracy: 0.8920\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2678 - accuracy: 0.8968\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2563 - accuracy: 0.8991\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 0.3288 - accuracy: 0.8889\n",
      "n_conv_1 = 768, k_conv_1 = 3,  n_conv_2 = 256, k_conv_2 = 2, \n",
      "          n_conv_3 = 256,  k_conv_3 = 3,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 256, dropout_1 = 0.2,\n",
      "          n_dense_2 = 512, dropout_2 = 0.25, activation_conv=  relu,\n",
      "          activation_dense=  elu\n",
      "Epoch 1/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 1.0350 - accuracy: 0.5592\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.6660 - accuracy: 0.7404\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.4959 - accuracy: 0.8133\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.4241 - accuracy: 0.8404\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.3831 - accuracy: 0.8575\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.3557 - accuracy: 0.8676\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.3326 - accuracy: 0.8772\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.3138 - accuracy: 0.8846\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.3008 - accuracy: 0.8883\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2918 - accuracy: 0.8911\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2761 - accuracy: 0.8975\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2645 - accuracy: 0.9015\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2507 - accuracy: 0.9057\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2460 - accuracy: 0.9094\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2361 - accuracy: 0.9123\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2314 - accuracy: 0.9151\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2219 - accuracy: 0.9183\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2121 - accuracy: 0.9226\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2218 - accuracy: 0.9163\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2075 - accuracy: 0.9231\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1983 - accuracy: 0.9259\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1925 - accuracy: 0.9294\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1845 - accuracy: 0.9307\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1845 - accuracy: 0.9307\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1895 - accuracy: 0.9304\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1761 - accuracy: 0.9348\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1740 - accuracy: 0.9348 0s - loss: 0.1733 - \n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1699 - accuracy: 0.9372\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1687 - accuracy: 0.9365\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1569 - accuracy: 0.9415\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1604 - accuracy: 0.9400\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1577 - accuracy: 0.9400\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1577 - accuracy: 0.9403\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1473 - accuracy: 0.9454\n",
      "Epoch 35/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1485 - accuracy: 0.9450\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1455 - accuracy: 0.9459 0s - loss: 0.1435 - ac\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1459 - accuracy: 0.9456\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1391 - accuracy: 0.9480\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1367 - accuracy: 0.9492\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1380 - accuracy: 0.9485\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1267 - accuracy: 0.9523\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1261 - accuracy: 0.9523\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1271 - accuracy: 0.9526\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1312 - accuracy: 0.9506\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1240 - accuracy: 0.9548\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1245 - accuracy: 0.9537\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1114 - accuracy: 0.9579\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1160 - accuracy: 0.9564\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1122 - accuracy: 0.9581\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1085 - accuracy: 0.9589\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1068 - accuracy: 0.9597\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1168 - accuracy: 0.9577\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1056 - accuracy: 0.9593\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1060 - accuracy: 0.9595\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1096 - accuracy: 0.9593\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1044 - accuracy: 0.9611\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1049 - accuracy: 0.9607\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.0914 - accuracy: 0.9650\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1041 - accuracy: 0.9614\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1068 - accuracy: 0.9620\n",
      "76/76 [==============================] - 1s 14ms/step - loss: 0.2298 - accuracy: 0.9392\n",
      "n_conv_1 = 768, k_conv_1 = 3,  n_conv_2 = 256, k_conv_2 = 2, \n",
      "          n_conv_3 = 256,  k_conv_3 = 3,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 256, dropout_1 = 0.2,\n",
      "          n_dense_2 = 512, dropout_2 = 0.25, activation_conv=  relu,\n",
      "          activation_dense=  elu\n",
      "Epoch 1/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 1.0384 - accuracy: 0.5545\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.6584 - accuracy: 0.7466\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.4935 - accuracy: 0.8142\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.4125 - accuracy: 0.8471\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.3752 - accuracy: 0.8594\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.3469 - accuracy: 0.8709\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.3251 - accuracy: 0.8755\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.3125 - accuracy: 0.8819\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2945 - accuracy: 0.8907\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2868 - accuracy: 0.8916\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2783 - accuracy: 0.8958\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2695 - accuracy: 0.9002\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2547 - accuracy: 0.9040\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2447 - accuracy: 0.9096\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2378 - accuracy: 0.9105\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2344 - accuracy: 0.9117\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2221 - accuracy: 0.9189\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2237 - accuracy: 0.9174\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2146 - accuracy: 0.9203\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2139 - accuracy: 0.9196\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2071 - accuracy: 0.9232\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1903 - accuracy: 0.9289\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1931 - accuracy: 0.9272\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1898 - accuracy: 0.9293\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1878 - accuracy: 0.9290\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1851 - accuracy: 0.9303\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1811 - accuracy: 0.9314\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1730 - accuracy: 0.9340\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1715 - accuracy: 0.9357\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1656 - accuracy: 0.9376\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1647 - accuracy: 0.9363\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1599 - accuracy: 0.9402\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1567 - accuracy: 0.9407\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1561 - accuracy: 0.9428\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1530 - accuracy: 0.9434\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1461 - accuracy: 0.9444\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1394 - accuracy: 0.9486\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1405 - accuracy: 0.9474\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1413 - accuracy: 0.9482\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1520 - accuracy: 0.9430\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1328 - accuracy: 0.9496\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1328 - accuracy: 0.9476\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1324 - accuracy: 0.9498\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1276 - accuracy: 0.9513\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1247 - accuracy: 0.9520\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1210 - accuracy: 0.9542\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1196 - accuracy: 0.9548\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1164 - accuracy: 0.9562\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1212 - accuracy: 0.9551\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1196 - accuracy: 0.9543\n",
      "Epoch 51/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1119 - accuracy: 0.9582\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1136 - accuracy: 0.9576\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1041 - accuracy: 0.9601\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1070 - accuracy: 0.9589\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1136 - accuracy: 0.9576\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1040 - accuracy: 0.9611\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.0981 - accuracy: 0.9630\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1148 - accuracy: 0.9582\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1084 - accuracy: 0.9600\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1034 - accuracy: 0.9614\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 0.2538 - accuracy: 0.9328\n",
      "n_conv_1 = 768, k_conv_1 = 3,  n_conv_2 = 256, k_conv_2 = 2, \n",
      "          n_conv_3 = 256,  k_conv_3 = 3,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 256, dropout_1 = 0.2,\n",
      "          n_dense_2 = 512, dropout_2 = 0.25, activation_conv=  relu,\n",
      "          activation_dense=  elu\n",
      "Epoch 1/60\n",
      "  1/152 [..............................] - ETA: 2s - loss: 1.7924 - accuracy: 0.2031WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0130s vs `on_train_batch_end` time: 0.0199s). Check your callbacks.\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 1.0289 - accuracy: 0.5648\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.6643 - accuracy: 0.7389\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.5020 - accuracy: 0.8113\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.4232 - accuracy: 0.8415\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.3775 - accuracy: 0.8602\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.3646 - accuracy: 0.8657\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.3338 - accuracy: 0.8772\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.3111 - accuracy: 0.8845\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.3008 - accuracy: 0.8871\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2849 - accuracy: 0.8960\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2791 - accuracy: 0.8971\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2650 - accuracy: 0.9034\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2509 - accuracy: 0.9063\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2515 - accuracy: 0.9068\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2391 - accuracy: 0.9126\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2400 - accuracy: 0.9104\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2213 - accuracy: 0.9192\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2161 - accuracy: 0.9193\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2196 - accuracy: 0.9195\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2059 - accuracy: 0.9253\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2085 - accuracy: 0.9237\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2032 - accuracy: 0.9234\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1898 - accuracy: 0.9304\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1874 - accuracy: 0.9309\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1830 - accuracy: 0.9331\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1825 - accuracy: 0.9333\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1812 - accuracy: 0.9325\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1668 - accuracy: 0.9382\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1671 - accuracy: 0.9387\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1616 - accuracy: 0.9403\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1553 - accuracy: 0.9428\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1553 - accuracy: 0.9417\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1611 - accuracy: 0.9394\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1519 - accuracy: 0.9445\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1478 - accuracy: 0.9449\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1561 - accuracy: 0.9428\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1434 - accuracy: 0.9459\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1397 - accuracy: 0.9473\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1408 - accuracy: 0.9489\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1383 - accuracy: 0.9490\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1262 - accuracy: 0.9526\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1304 - accuracy: 0.9507\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1317 - accuracy: 0.9510\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1266 - accuracy: 0.9525\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1218 - accuracy: 0.9541\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1405 - accuracy: 0.9489\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1219 - accuracy: 0.9552\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1206 - accuracy: 0.9559\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1104 - accuracy: 0.9585\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1231 - accuracy: 0.9554\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1173 - accuracy: 0.9558\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1043 - accuracy: 0.9602\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1090 - accuracy: 0.9585\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1117 - accuracy: 0.9581\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1064 - accuracy: 0.9601\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1043 - accuracy: 0.9615\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1041 - accuracy: 0.9600\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1012 - accuracy: 0.9636\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.0986 - accuracy: 0.9620\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1020 - accuracy: 0.9625\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 0.2393 - accuracy: 0.9365\n",
      "n_conv_1 = 512, k_conv_1 = 3,  n_conv_2 = 256, k_conv_2 = 3, \n",
      "          n_conv_3 = 256,  k_conv_3 = 3,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 256, dropout_1 = 0.3,\n",
      "          n_dense_2 = 512, dropout_2 = 0.25, activation_conv=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001FAD89C4DC8>,\n",
      "          activation_dense=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001FAD89C45C8>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 1.1123 - accuracy: 0.5274\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.7873 - accuracy: 0.6770\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.6838 - accuracy: 0.7266\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.6077 - accuracy: 0.7580\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.5790 - accuracy: 0.7691\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.5414 - accuracy: 0.7848\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.5143 - accuracy: 0.7982\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.4844 - accuracy: 0.8122\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.4605 - accuracy: 0.8221\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.4447 - accuracy: 0.8274\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.4447 - accuracy: 0.8274\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.4413 - accuracy: 0.8306\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.4159 - accuracy: 0.8391\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3996 - accuracy: 0.8459\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3951 - accuracy: 0.8493\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3893 - accuracy: 0.8510\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3847 - accuracy: 0.8520\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3870 - accuracy: 0.8532\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3715 - accuracy: 0.8578\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3713 - accuracy: 0.8568\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3572 - accuracy: 0.8626\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3613 - accuracy: 0.8626\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3438 - accuracy: 0.8668\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3583 - accuracy: 0.8634\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3415 - accuracy: 0.8674\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3491 - accuracy: 0.8658\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3417 - accuracy: 0.8678\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3287 - accuracy: 0.8728\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3385 - accuracy: 0.8718\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3355 - accuracy: 0.8697\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3303 - accuracy: 0.8753\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3249 - accuracy: 0.8754\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3176 - accuracy: 0.8782\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3137 - accuracy: 0.8784\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3256 - accuracy: 0.8741\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3248 - accuracy: 0.8760\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3130 - accuracy: 0.8783\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3095 - accuracy: 0.8803\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3079 - accuracy: 0.8804\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3029 - accuracy: 0.8821\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3017 - accuracy: 0.8831\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2989 - accuracy: 0.8831\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2955 - accuracy: 0.8864\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3056 - accuracy: 0.8812\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2962 - accuracy: 0.8848\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2878 - accuracy: 0.8887\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2910 - accuracy: 0.8872\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2942 - accuracy: 0.8852\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2910 - accuracy: 0.8885\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2901 - accuracy: 0.8869\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2804 - accuracy: 0.8917\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2733 - accuracy: 0.8949\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2776 - accuracy: 0.8935\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2783 - accuracy: 0.8903\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2725 - accuracy: 0.8942\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2770 - accuracy: 0.8925\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2738 - accuracy: 0.8934\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2742 - accuracy: 0.8923\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2638 - accuracy: 0.8971\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2686 - accuracy: 0.8963\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 0.2825 - accuracy: 0.8950\n",
      "n_conv_1 = 512, k_conv_1 = 3,  n_conv_2 = 256, k_conv_2 = 3, \n",
      "          n_conv_3 = 256,  k_conv_3 = 3,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 256, dropout_1 = 0.3,\n",
      "          n_dense_2 = 512, dropout_2 = 0.25, activation_conv=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001FAC95F2748>,\n",
      "          activation_dense=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001FBEE92AD88>\n",
      "Epoch 1/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 1.0971 - accuracy: 0.5349\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.7846 - accuracy: 0.6799\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.6607 - accuracy: 0.7358\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.6147 - accuracy: 0.7523\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.5562 - accuracy: 0.7811\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.5222 - accuracy: 0.7956\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.5044 - accuracy: 0.8037\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.4718 - accuracy: 0.8169\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.4633 - accuracy: 0.8195\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.4396 - accuracy: 0.8295\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.4202 - accuracy: 0.8384\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.4217 - accuracy: 0.8364\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.4037 - accuracy: 0.8436\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3939 - accuracy: 0.8505\n",
      "Epoch 15/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3977 - accuracy: 0.8480\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3859 - accuracy: 0.8503\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3760 - accuracy: 0.8583\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3611 - accuracy: 0.8613\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3619 - accuracy: 0.8619\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3691 - accuracy: 0.8605\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3500 - accuracy: 0.8671\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3432 - accuracy: 0.8699\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3518 - accuracy: 0.8676\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3489 - accuracy: 0.8658\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3509 - accuracy: 0.8657\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3277 - accuracy: 0.8771\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3288 - accuracy: 0.8730\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3266 - accuracy: 0.8757\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3213 - accuracy: 0.8764\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3263 - accuracy: 0.8756\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3218 - accuracy: 0.8751\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3176 - accuracy: 0.8764\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3188 - accuracy: 0.8762\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3200 - accuracy: 0.8766\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3203 - accuracy: 0.8761\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3024 - accuracy: 0.8848\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2983 - accuracy: 0.8844\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3082 - accuracy: 0.8835\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3107 - accuracy: 0.8801\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3104 - accuracy: 0.8801\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2994 - accuracy: 0.8825\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2891 - accuracy: 0.8883\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2952 - accuracy: 0.8855\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2884 - accuracy: 0.8880\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2926 - accuracy: 0.8861\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2895 - accuracy: 0.8867\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2864 - accuracy: 0.8878\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2840 - accuracy: 0.8884\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2902 - accuracy: 0.8866\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2757 - accuracy: 0.8910\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2902 - accuracy: 0.8875\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2809 - accuracy: 0.8893\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2641 - accuracy: 0.8947\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2727 - accuracy: 0.8915\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2863 - accuracy: 0.8886\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2806 - accuracy: 0.8889\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2664 - accuracy: 0.8944\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2660 - accuracy: 0.8950\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2704 - accuracy: 0.8913\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2697 - accuracy: 0.8933\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 0.3162 - accuracy: 0.8850\n",
      "n_conv_1 = 512, k_conv_1 = 3,  n_conv_2 = 256, k_conv_2 = 3, \n",
      "          n_conv_3 = 256,  k_conv_3 = 3,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 256, dropout_1 = 0.3,\n",
      "          n_dense_2 = 512, dropout_2 = 0.25, activation_conv=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001FAE88B2648>,\n",
      "          activation_dense=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001FAC995CD88>\n",
      "Epoch 1/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 1.1164 - accuracy: 0.5243\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.7857 - accuracy: 0.6786\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.6729 - accuracy: 0.7300\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.6252 - accuracy: 0.7498\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.5632 - accuracy: 0.7765\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.5291 - accuracy: 0.7891\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.5038 - accuracy: 0.8011\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.4814 - accuracy: 0.8113\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.4609 - accuracy: 0.8204\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.4360 - accuracy: 0.8288\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.4227 - accuracy: 0.8383\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.4249 - accuracy: 0.8330\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.4046 - accuracy: 0.8435\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.4000 - accuracy: 0.8458\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3954 - accuracy: 0.8465\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3852 - accuracy: 0.8508\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3763 - accuracy: 0.8550\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3808 - accuracy: 0.8523\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3683 - accuracy: 0.8591\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3631 - accuracy: 0.8591\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3652 - accuracy: 0.8572\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3547 - accuracy: 0.8616\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3481 - accuracy: 0.8657\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3435 - accuracy: 0.8696\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3422 - accuracy: 0.8681\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3398 - accuracy: 0.8687\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3384 - accuracy: 0.8687\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3454 - accuracy: 0.8686\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3351 - accuracy: 0.8709\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3400 - accuracy: 0.8691\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3285 - accuracy: 0.8718\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3211 - accuracy: 0.8749\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3163 - accuracy: 0.8769\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3224 - accuracy: 0.8736\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3178 - accuracy: 0.8754\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3117 - accuracy: 0.8769\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3104 - accuracy: 0.8772\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3086 - accuracy: 0.8792\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3134 - accuracy: 0.8779\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3023 - accuracy: 0.8805\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2987 - accuracy: 0.8839\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3028 - accuracy: 0.8817\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2935 - accuracy: 0.8839\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2912 - accuracy: 0.8868\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2918 - accuracy: 0.8858\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2944 - accuracy: 0.8834\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2949 - accuracy: 0.8846\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2966 - accuracy: 0.8847\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2828 - accuracy: 0.8880\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2821 - accuracy: 0.8898\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2797 - accuracy: 0.8898\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2836 - accuracy: 0.8896\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2895 - accuracy: 0.8880\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2772 - accuracy: 0.8927\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2734 - accuracy: 0.8936\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2748 - accuracy: 0.8918\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2814 - accuracy: 0.8891\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2697 - accuracy: 0.8919\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2750 - accuracy: 0.8936\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.2773 - accuracy: 0.8910\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 0.3144 - accuracy: 0.8819\n",
      "n_conv_1 = 512, k_conv_1 = 2,  n_conv_2 = 256, k_conv_2 = 2, \n",
      "          n_conv_3 = 512,  k_conv_3 = 2,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 512, dropout_1 = 0.2,\n",
      "          n_dense_2 = 256, dropout_2 = 0.25, activation_conv=  relu,\n",
      "          activation_dense=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001FBE85A9F48>\n",
      "Epoch 1/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 1.0786 - accuracy: 0.5393\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.7416 - accuracy: 0.6987\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.5864 - accuracy: 0.7714\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.4865 - accuracy: 0.8169\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.4232 - accuracy: 0.8420\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.3923 - accuracy: 0.8524\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.3567 - accuracy: 0.8680\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.3255 - accuracy: 0.8790\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.3220 - accuracy: 0.8799\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.3017 - accuracy: 0.8875\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.2809 - accuracy: 0.8967\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.2726 - accuracy: 0.8994\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.2674 - accuracy: 0.9015\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.2475 - accuracy: 0.9066\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.2428 - accuracy: 0.9095\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.2264 - accuracy: 0.9158\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.2295 - accuracy: 0.9156\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.2229 - accuracy: 0.9155\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.2145 - accuracy: 0.9203\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.2135 - accuracy: 0.9206\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1988 - accuracy: 0.9256\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1961 - accuracy: 0.9255\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1987 - accuracy: 0.9238\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1938 - accuracy: 0.9280\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1911 - accuracy: 0.9283\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1834 - accuracy: 0.9306\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1712 - accuracy: 0.9357\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1791 - accuracy: 0.9324\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1675 - accuracy: 0.9370\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1721 - accuracy: 0.9350\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1583 - accuracy: 0.9395\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1616 - accuracy: 0.9381\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1562 - accuracy: 0.9407\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1494 - accuracy: 0.9430\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1520 - accuracy: 0.9406\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1546 - accuracy: 0.9418\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1418 - accuracy: 0.9448\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1411 - accuracy: 0.9461\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1380 - accuracy: 0.9460\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1484 - accuracy: 0.9440\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1307 - accuracy: 0.9502\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1307 - accuracy: 0.9494\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1331 - accuracy: 0.9484\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1228 - accuracy: 0.9534\n",
      "Epoch 45/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1340 - accuracy: 0.9494\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1166 - accuracy: 0.9549\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1178 - accuracy: 0.9539\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1157 - accuracy: 0.9564\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1225 - accuracy: 0.9528\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1178 - accuracy: 0.9549\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1108 - accuracy: 0.9583\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1118 - accuracy: 0.9579\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1174 - accuracy: 0.9558\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1039 - accuracy: 0.9602\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1016 - accuracy: 0.9607\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.0978 - accuracy: 0.9629\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1002 - accuracy: 0.9615\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1087 - accuracy: 0.9581\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1069 - accuracy: 0.9591\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.0969 - accuracy: 0.9621\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 0.2633 - accuracy: 0.9366\n",
      "n_conv_1 = 512, k_conv_1 = 2,  n_conv_2 = 256, k_conv_2 = 2, \n",
      "          n_conv_3 = 512,  k_conv_3 = 2,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 512, dropout_1 = 0.2,\n",
      "          n_dense_2 = 256, dropout_2 = 0.25, activation_conv=  relu,\n",
      "          activation_dense=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001FBE86D7FC8>\n",
      "Epoch 1/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 1.0820 - accuracy: 0.5417\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.7596 - accuracy: 0.6833\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.5818 - accuracy: 0.7716\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.4813 - accuracy: 0.8146\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.4123 - accuracy: 0.8448\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.3802 - accuracy: 0.8560\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.3452 - accuracy: 0.8708\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.3222 - accuracy: 0.8784\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.3042 - accuracy: 0.8861\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.2930 - accuracy: 0.8904\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.2746 - accuracy: 0.8964\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.2636 - accuracy: 0.9010\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.2608 - accuracy: 0.9020\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.2388 - accuracy: 0.9083\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.2379 - accuracy: 0.9115\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.2296 - accuracy: 0.9134\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.2254 - accuracy: 0.9153\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.2237 - accuracy: 0.9164\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.2177 - accuracy: 0.9187\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.2140 - accuracy: 0.9182\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.2062 - accuracy: 0.9221\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1971 - accuracy: 0.9245\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1885 - accuracy: 0.9288\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1868 - accuracy: 0.9283\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1860 - accuracy: 0.9287\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1846 - accuracy: 0.9295\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1810 - accuracy: 0.9309\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1715 - accuracy: 0.9346\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1738 - accuracy: 0.9325\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1634 - accuracy: 0.9370\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1781 - accuracy: 0.9332\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1536 - accuracy: 0.9413\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1614 - accuracy: 0.9391\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1453 - accuracy: 0.9425\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1460 - accuracy: 0.9445\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1443 - accuracy: 0.9438\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1422 - accuracy: 0.9437\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1416 - accuracy: 0.9454\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1501 - accuracy: 0.9421\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1430 - accuracy: 0.9450\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1258 - accuracy: 0.9514\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1275 - accuracy: 0.9498\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1322 - accuracy: 0.9493\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1242 - accuracy: 0.9519\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1218 - accuracy: 0.9529\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1159 - accuracy: 0.9558\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1235 - accuracy: 0.9525\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1240 - accuracy: 0.9533\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1174 - accuracy: 0.9546\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1128 - accuracy: 0.9561\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1173 - accuracy: 0.9555\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1032 - accuracy: 0.9589\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1116 - accuracy: 0.9571\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1012 - accuracy: 0.9605\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1121 - accuracy: 0.9566\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1172 - accuracy: 0.9559\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.0998 - accuracy: 0.9611\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1048 - accuracy: 0.9593\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1011 - accuracy: 0.9619\n",
      "Epoch 60/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 4s 24ms/step - loss: 0.0956 - accuracy: 0.9624\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 0.2668 - accuracy: 0.9341\n",
      "n_conv_1 = 512, k_conv_1 = 2,  n_conv_2 = 256, k_conv_2 = 2, \n",
      "          n_conv_3 = 512,  k_conv_3 = 2,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 512, dropout_1 = 0.2,\n",
      "          n_dense_2 = 256, dropout_2 = 0.25, activation_conv=  relu,\n",
      "          activation_dense=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001FBEB3BCD88>\n",
      "Epoch 1/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 1.0690 - accuracy: 0.5455\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.7486 - accuracy: 0.6915\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.5903 - accuracy: 0.7687\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.4877 - accuracy: 0.8124\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.4253 - accuracy: 0.8396\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.3779 - accuracy: 0.8577\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.3540 - accuracy: 0.8655\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.3257 - accuracy: 0.8779\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.3051 - accuracy: 0.8834\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.2935 - accuracy: 0.8910\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.2867 - accuracy: 0.8918\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.2802 - accuracy: 0.8938\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.2592 - accuracy: 0.9032\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.2572 - accuracy: 0.9046\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.2418 - accuracy: 0.9091\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.2263 - accuracy: 0.9146\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.2276 - accuracy: 0.9161\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.2179 - accuracy: 0.9164\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.2142 - accuracy: 0.9200\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.2093 - accuracy: 0.9222\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1983 - accuracy: 0.9262\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.2027 - accuracy: 0.9252\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1844 - accuracy: 0.9308\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1870 - accuracy: 0.9306\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1833 - accuracy: 0.9299\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1839 - accuracy: 0.9313\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1801 - accuracy: 0.9327\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1687 - accuracy: 0.9375\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1696 - accuracy: 0.9356\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1616 - accuracy: 0.9397\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1640 - accuracy: 0.9374\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1539 - accuracy: 0.9400\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1503 - accuracy: 0.9424\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1592 - accuracy: 0.9403\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1520 - accuracy: 0.9420\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1457 - accuracy: 0.9445\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1401 - accuracy: 0.9468\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1439 - accuracy: 0.9447\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1392 - accuracy: 0.9466\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1304 - accuracy: 0.9499\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1392 - accuracy: 0.9483\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1373 - accuracy: 0.9484\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1313 - accuracy: 0.9502\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1285 - accuracy: 0.9513\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1182 - accuracy: 0.9546\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1256 - accuracy: 0.9524\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1251 - accuracy: 0.9529\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1098 - accuracy: 0.9577\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1157 - accuracy: 0.9554\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1126 - accuracy: 0.9575\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1160 - accuracy: 0.9560\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1141 - accuracy: 0.9563\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1151 - accuracy: 0.9565\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1035 - accuracy: 0.9608\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1014 - accuracy: 0.9623\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1077 - accuracy: 0.9588\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1005 - accuracy: 0.9614\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.0992 - accuracy: 0.9611\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.0929 - accuracy: 0.9642\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1063 - accuracy: 0.9602\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 0.2591 - accuracy: 0.9382\n",
      "n_conv_1 = 512, k_conv_1 = 2,  n_conv_2 = 512, k_conv_2 = 2, \n",
      "          n_conv_3 = 512,  k_conv_3 = 2,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 512, dropout_1 = 0.2,\n",
      "          n_dense_2 = 512, dropout_2 = 0.25, activation_conv=  relu,\n",
      "          activation_dense=  elu\n",
      "Epoch 1/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 1.0297 - accuracy: 0.5622\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.6825 - accuracy: 0.7238\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.5248 - accuracy: 0.7976\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.4480 - accuracy: 0.8327\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.3878 - accuracy: 0.8538\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.3517 - accuracy: 0.8688\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.3320 - accuracy: 0.8765\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.3017 - accuracy: 0.8897\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2872 - accuracy: 0.8928\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2656 - accuracy: 0.9019\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2621 - accuracy: 0.9023\n",
      "Epoch 12/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2408 - accuracy: 0.9128\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2393 - accuracy: 0.9118\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2345 - accuracy: 0.9122\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2184 - accuracy: 0.9193\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2212 - accuracy: 0.9177\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2020 - accuracy: 0.9247\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1959 - accuracy: 0.9265\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1951 - accuracy: 0.9272\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1909 - accuracy: 0.9295\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1847 - accuracy: 0.9324\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1694 - accuracy: 0.9370\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1738 - accuracy: 0.9348\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1760 - accuracy: 0.9342\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1633 - accuracy: 0.9378\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1627 - accuracy: 0.9396\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1609 - accuracy: 0.9397\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1509 - accuracy: 0.9429\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1594 - accuracy: 0.9397\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1424 - accuracy: 0.9453\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1441 - accuracy: 0.9463\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1441 - accuracy: 0.9464\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1320 - accuracy: 0.9500\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1284 - accuracy: 0.9506\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1361 - accuracy: 0.9486\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1310 - accuracy: 0.9513\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1310 - accuracy: 0.9511\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1292 - accuracy: 0.9525\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1285 - accuracy: 0.9513\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1212 - accuracy: 0.9535\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1195 - accuracy: 0.9541\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1324 - accuracy: 0.9519\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1125 - accuracy: 0.9568\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1093 - accuracy: 0.9587\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1105 - accuracy: 0.9566\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1006 - accuracy: 0.9621\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.0977 - accuracy: 0.9633\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1031 - accuracy: 0.9603\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.0999 - accuracy: 0.9631\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1071 - accuracy: 0.9595\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.0980 - accuracy: 0.9635\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1115 - accuracy: 0.9584\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.0900 - accuracy: 0.9658\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1010 - accuracy: 0.9625\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.0883 - accuracy: 0.9672\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.0981 - accuracy: 0.9634\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.0878 - accuracy: 0.9674\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.0907 - accuracy: 0.9660\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.0901 - accuracy: 0.9674\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.0918 - accuracy: 0.9661\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 0.2559 - accuracy: 0.9356\n",
      "n_conv_1 = 512, k_conv_1 = 2,  n_conv_2 = 512, k_conv_2 = 2, \n",
      "          n_conv_3 = 512,  k_conv_3 = 2,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 512, dropout_1 = 0.2,\n",
      "          n_dense_2 = 512, dropout_2 = 0.25, activation_conv=  relu,\n",
      "          activation_dense=  elu\n",
      "Epoch 1/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 1.0238 - accuracy: 0.5652\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.6881 - accuracy: 0.7191\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.5414 - accuracy: 0.7885\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.4593 - accuracy: 0.8268\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.4008 - accuracy: 0.8501\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.3622 - accuracy: 0.8629\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.3394 - accuracy: 0.8723\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.3181 - accuracy: 0.8818\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.3000 - accuracy: 0.8876\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2732 - accuracy: 0.8981\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2643 - accuracy: 0.9021\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2516 - accuracy: 0.9068\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2451 - accuracy: 0.9089\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2466 - accuracy: 0.9105\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2267 - accuracy: 0.9160\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2096 - accuracy: 0.9234\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2200 - accuracy: 0.9188\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2039 - accuracy: 0.9243\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1995 - accuracy: 0.9248\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1943 - accuracy: 0.9276\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1853 - accuracy: 0.9315\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1815 - accuracy: 0.9326\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1801 - accuracy: 0.9336\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1747 - accuracy: 0.9347\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1687 - accuracy: 0.9371\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1681 - accuracy: 0.9368\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1617 - accuracy: 0.9404\n",
      "Epoch 28/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1555 - accuracy: 0.9399 0s - loss: 0.1551 - accuracy: 0.\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1572 - accuracy: 0.9409\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1616 - accuracy: 0.9410\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1510 - accuracy: 0.9442\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1446 - accuracy: 0.9459\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1369 - accuracy: 0.9485\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1427 - accuracy: 0.9459\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1266 - accuracy: 0.9518\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1474 - accuracy: 0.9454\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1318 - accuracy: 0.9507\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1189 - accuracy: 0.9549\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1290 - accuracy: 0.9518\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1207 - accuracy: 0.9543\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1182 - accuracy: 0.9555\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1223 - accuracy: 0.9534\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1193 - accuracy: 0.9553\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1214 - accuracy: 0.9559\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1125 - accuracy: 0.9586\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1094 - accuracy: 0.9595\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1088 - accuracy: 0.9585\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1070 - accuracy: 0.9592\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1179 - accuracy: 0.9569\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1033 - accuracy: 0.9610\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1008 - accuracy: 0.9617\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.0951 - accuracy: 0.9642\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.0928 - accuracy: 0.9641\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.0930 - accuracy: 0.9653\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1018 - accuracy: 0.9629\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.0981 - accuracy: 0.9635\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.0952 - accuracy: 0.9648\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.0883 - accuracy: 0.9659\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.0807 - accuracy: 0.9702\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.0992 - accuracy: 0.9644\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 0.2612 - accuracy: 0.9343\n",
      "n_conv_1 = 512, k_conv_1 = 2,  n_conv_2 = 512, k_conv_2 = 2, \n",
      "          n_conv_3 = 512,  k_conv_3 = 2,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 512, dropout_1 = 0.2,\n",
      "          n_dense_2 = 512, dropout_2 = 0.25, activation_conv=  relu,\n",
      "          activation_dense=  elu\n",
      "Epoch 1/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 1.0457 - accuracy: 0.5565\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.6979 - accuracy: 0.7143\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.5382 - accuracy: 0.7933\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.4594 - accuracy: 0.8260\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.3975 - accuracy: 0.8530\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.3634 - accuracy: 0.8680\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.3307 - accuracy: 0.8776\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.3138 - accuracy: 0.8840\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2908 - accuracy: 0.8948\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2708 - accuracy: 0.9010\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2610 - accuracy: 0.9045\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2502 - accuracy: 0.9069\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2375 - accuracy: 0.9135\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2360 - accuracy: 0.9128\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2264 - accuracy: 0.9165\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2243 - accuracy: 0.9181\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2177 - accuracy: 0.9195\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2012 - accuracy: 0.9246\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1991 - accuracy: 0.9269\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1917 - accuracy: 0.9293\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1951 - accuracy: 0.9288\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1834 - accuracy: 0.9321\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1844 - accuracy: 0.9324\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1697 - accuracy: 0.9375\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1688 - accuracy: 0.9379\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1708 - accuracy: 0.9375\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1683 - accuracy: 0.9378\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1588 - accuracy: 0.9419\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1677 - accuracy: 0.9371\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1514 - accuracy: 0.9435\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1463 - accuracy: 0.9455\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1426 - accuracy: 0.9456\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1501 - accuracy: 0.9436\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1460 - accuracy: 0.9457\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1457 - accuracy: 0.9459\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1317 - accuracy: 0.9511\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1305 - accuracy: 0.9512\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1339 - accuracy: 0.9498\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1280 - accuracy: 0.9522\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1178 - accuracy: 0.9548\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1255 - accuracy: 0.9519\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1183 - accuracy: 0.9557\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1170 - accuracy: 0.9561\n",
      "Epoch 44/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1189 - accuracy: 0.9551\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1160 - accuracy: 0.9560\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1082 - accuracy: 0.9586\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1127 - accuracy: 0.9573\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1086 - accuracy: 0.9592\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1082 - accuracy: 0.9582\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1161 - accuracy: 0.9561\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.0973 - accuracy: 0.9623\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1036 - accuracy: 0.9602\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1079 - accuracy: 0.9599\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1005 - accuracy: 0.9620\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.0981 - accuracy: 0.9633\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1006 - accuracy: 0.9631\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.0913 - accuracy: 0.9655\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.0997 - accuracy: 0.9626\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.0964 - accuracy: 0.9637\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.0845 - accuracy: 0.9681\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 0.2421 - accuracy: 0.9400\n",
      "n_conv_1 = 512, k_conv_1 = 2,  n_conv_2 = 512, k_conv_2 = 3, \n",
      "          n_conv_3 = 512,  k_conv_3 = 2,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 256, dropout_1 = 0.3,\n",
      "          n_dense_2 = 512, dropout_2 = 0.25, activation_conv=  elu,\n",
      "          activation_dense=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001FBEE8B5EC8>\n",
      "Epoch 1/60\n",
      "  1/152 [..............................] - ETA: 3s - loss: 1.7948 - accuracy: 0.1445WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0150s vs `on_train_batch_end` time: 0.0228s). Check your callbacks.\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 1.1713 - accuracy: 0.5045\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 1.0527 - accuracy: 0.5541\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.9843 - accuracy: 0.5818\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.9311 - accuracy: 0.6067\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.8618 - accuracy: 0.6366\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.7908 - accuracy: 0.6734\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.7494 - accuracy: 0.6909\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.7154 - accuracy: 0.7054\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.6711 - accuracy: 0.7263\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.6289 - accuracy: 0.7444\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.6057 - accuracy: 0.7568\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.5862 - accuracy: 0.7607\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.5632 - accuracy: 0.7711\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.5492 - accuracy: 0.7792\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.5247 - accuracy: 0.7912\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.5187 - accuracy: 0.7968\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.4955 - accuracy: 0.8036\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.4903 - accuracy: 0.8052\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.4851 - accuracy: 0.8090\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.4696 - accuracy: 0.8158\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.4639 - accuracy: 0.8179\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.4618 - accuracy: 0.8183\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.4469 - accuracy: 0.8268\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.4432 - accuracy: 0.8280\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.4364 - accuracy: 0.8283\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.4248 - accuracy: 0.8328\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.4187 - accuracy: 0.8365\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.4233 - accuracy: 0.8353\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.4096 - accuracy: 0.8400\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.3990 - accuracy: 0.8459\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.3934 - accuracy: 0.8456\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.3935 - accuracy: 0.8469\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.3874 - accuracy: 0.8500\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.3793 - accuracy: 0.8517\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.3803 - accuracy: 0.8521\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.3754 - accuracy: 0.8550\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.3624 - accuracy: 0.8596\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.3517 - accuracy: 0.8624\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.3582 - accuracy: 0.8609\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.3532 - accuracy: 0.8643\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.3471 - accuracy: 0.8660\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.3384 - accuracy: 0.8680\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.3499 - accuracy: 0.8640\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.3371 - accuracy: 0.8685\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.3384 - accuracy: 0.8668\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.3217 - accuracy: 0.8740\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.3250 - accuracy: 0.8732\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.3282 - accuracy: 0.8709\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.3145 - accuracy: 0.8766\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.3139 - accuracy: 0.8755\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.3097 - accuracy: 0.8781\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.3115 - accuracy: 0.8768\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.3127 - accuracy: 0.8776\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.3029 - accuracy: 0.8802\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.2987 - accuracy: 0.8814\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.2912 - accuracy: 0.8865\n",
      "Epoch 57/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 6s 37ms/step - loss: 0.2957 - accuracy: 0.8839\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.2896 - accuracy: 0.8855\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.2808 - accuracy: 0.8877\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.2843 - accuracy: 0.8868\n",
      "76/76 [==============================] - 1s 14ms/step - loss: 0.3074 - accuracy: 0.8841\n",
      "n_conv_1 = 512, k_conv_1 = 2,  n_conv_2 = 512, k_conv_2 = 3, \n",
      "          n_conv_3 = 512,  k_conv_3 = 2,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 256, dropout_1 = 0.3,\n",
      "          n_dense_2 = 512, dropout_2 = 0.25, activation_conv=  elu,\n",
      "          activation_dense=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001FAD8963AC8>\n",
      "Epoch 1/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 1.1796 - accuracy: 0.4994\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 1.0481 - accuracy: 0.5526\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.9804 - accuracy: 0.5830\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.9205 - accuracy: 0.6163\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.8433 - accuracy: 0.6483\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.7951 - accuracy: 0.6695\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.7438 - accuracy: 0.6966\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.7031 - accuracy: 0.7142\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.6701 - accuracy: 0.7259\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.6308 - accuracy: 0.7416\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.6089 - accuracy: 0.7557\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.5690 - accuracy: 0.7709\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.5614 - accuracy: 0.7758\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.5507 - accuracy: 0.7808\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.5204 - accuracy: 0.7939\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.5127 - accuracy: 0.7973\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.4942 - accuracy: 0.8094\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.4862 - accuracy: 0.8091\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.4759 - accuracy: 0.8122\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.4739 - accuracy: 0.8165\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.4568 - accuracy: 0.8224\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.4502 - accuracy: 0.8256\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.4423 - accuracy: 0.8291\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.4406 - accuracy: 0.8304\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.4216 - accuracy: 0.8361\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.4248 - accuracy: 0.8355\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.4138 - accuracy: 0.8387\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.4080 - accuracy: 0.8443\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.4153 - accuracy: 0.8383\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.3985 - accuracy: 0.8463\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.3938 - accuracy: 0.8491\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.3845 - accuracy: 0.8498\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.3740 - accuracy: 0.8539\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.3736 - accuracy: 0.8566\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.3668 - accuracy: 0.8571\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.3752 - accuracy: 0.8541\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.3653 - accuracy: 0.8583\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.3590 - accuracy: 0.8622\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.3573 - accuracy: 0.8601\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.3467 - accuracy: 0.8668\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.3412 - accuracy: 0.8660\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.3370 - accuracy: 0.8688\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.3326 - accuracy: 0.8698\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.3329 - accuracy: 0.8719\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.3318 - accuracy: 0.8705\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.3236 - accuracy: 0.8721\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.3197 - accuracy: 0.8750\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.3267 - accuracy: 0.8724\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.3128 - accuracy: 0.8760\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.3067 - accuracy: 0.8809\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.3036 - accuracy: 0.8799\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.2993 - accuracy: 0.8822\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.3124 - accuracy: 0.8782\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.2976 - accuracy: 0.8842\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.2894 - accuracy: 0.8868\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.2873 - accuracy: 0.8865\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.2790 - accuracy: 0.8916\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.2869 - accuracy: 0.8870\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.2759 - accuracy: 0.8937\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.2726 - accuracy: 0.8942\n",
      "76/76 [==============================] - 1s 14ms/step - loss: 0.3329 - accuracy: 0.8854\n",
      "n_conv_1 = 512, k_conv_1 = 2,  n_conv_2 = 512, k_conv_2 = 3, \n",
      "          n_conv_3 = 512,  k_conv_3 = 2,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 256, dropout_1 = 0.3,\n",
      "          n_dense_2 = 512, dropout_2 = 0.25, activation_conv=  elu,\n",
      "          activation_dense=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001FAC106E4C8>\n",
      "Epoch 1/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 1.1727 - accuracy: 0.5046\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 1.0517 - accuracy: 0.5521\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.9879 - accuracy: 0.5798\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.9099 - accuracy: 0.6163\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.8684 - accuracy: 0.6351\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.8089 - accuracy: 0.6624\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.7536 - accuracy: 0.6902\n",
      "Epoch 8/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 6s 36ms/step - loss: 0.7013 - accuracy: 0.7118\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.6749 - accuracy: 0.7253\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.6402 - accuracy: 0.7379\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.6164 - accuracy: 0.7489\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.5829 - accuracy: 0.7648\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.5639 - accuracy: 0.7756\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.5563 - accuracy: 0.7789\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.5285 - accuracy: 0.7887\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.5199 - accuracy: 0.7948\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.5037 - accuracy: 0.8009\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.4921 - accuracy: 0.8065\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.4926 - accuracy: 0.8064\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.4708 - accuracy: 0.8157\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.4635 - accuracy: 0.8224\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.4461 - accuracy: 0.8251\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.4409 - accuracy: 0.8283\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.4422 - accuracy: 0.8292\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.4275 - accuracy: 0.8340\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.4187 - accuracy: 0.8401\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.4156 - accuracy: 0.8385\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.4054 - accuracy: 0.8433\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.4024 - accuracy: 0.8456\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.3930 - accuracy: 0.8494\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.3907 - accuracy: 0.8491\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.3781 - accuracy: 0.8540\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.3692 - accuracy: 0.8579\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.3717 - accuracy: 0.8557\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.3681 - accuracy: 0.8576\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.3544 - accuracy: 0.8603\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.3561 - accuracy: 0.8633\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.3565 - accuracy: 0.8611\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.3487 - accuracy: 0.8637\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.3354 - accuracy: 0.8698\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.3407 - accuracy: 0.8660\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.3283 - accuracy: 0.8738\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.3295 - accuracy: 0.8699\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.3352 - accuracy: 0.8718\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.3203 - accuracy: 0.8767\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.3219 - accuracy: 0.8738\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.3122 - accuracy: 0.8799\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.3137 - accuracy: 0.8756\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.3088 - accuracy: 0.8813\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.3045 - accuracy: 0.8803\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.2995 - accuracy: 0.8822\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.3003 - accuracy: 0.8835\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.2830 - accuracy: 0.8890\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.2950 - accuracy: 0.8856\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.2833 - accuracy: 0.8915\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.2828 - accuracy: 0.8895\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.2815 - accuracy: 0.8923\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.2749 - accuracy: 0.8935\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.2702 - accuracy: 0.8944\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.2656 - accuracy: 0.8961\n",
      "76/76 [==============================] - 1s 14ms/step - loss: 0.2973 - accuracy: 0.8928\n",
      "n_conv_1 = 768, k_conv_1 = 3,  n_conv_2 = 512, k_conv_2 = 2, \n",
      "          n_conv_3 = 256,  k_conv_3 = 2,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 256, dropout_1 = 0.2,\n",
      "          n_dense_2 = 256, dropout_2 = 0.25, activation_conv=  elu,\n",
      "          activation_dense=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001FBEB48A988>\n",
      "Epoch 1/60\n",
      "  1/152 [..............................] - ETA: 3s - loss: 1.7975 - accuracy: 0.1875WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0157s vs `on_train_batch_end` time: 0.0248s). Check your callbacks.\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 1.1547 - accuracy: 0.5117\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.9302 - accuracy: 0.6100\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.8130 - accuracy: 0.6640\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.7574 - accuracy: 0.6904\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.6965 - accuracy: 0.7145\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.6684 - accuracy: 0.7291\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.6273 - accuracy: 0.7502\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.6086 - accuracy: 0.7570\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.5922 - accuracy: 0.7635\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.5651 - accuracy: 0.7766\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.5483 - accuracy: 0.7807\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.5443 - accuracy: 0.7847\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.5183 - accuracy: 0.7977\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.5040 - accuracy: 0.8042\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.4845 - accuracy: 0.8113\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.4775 - accuracy: 0.8150\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.4694 - accuracy: 0.8187\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.4571 - accuracy: 0.8233\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.4481 - accuracy: 0.8279\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.4364 - accuracy: 0.8323\n",
      "Epoch 21/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 6s 41ms/step - loss: 0.4244 - accuracy: 0.8382\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.4230 - accuracy: 0.8373\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.4157 - accuracy: 0.8411\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.4112 - accuracy: 0.8444\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.4025 - accuracy: 0.8489\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.4057 - accuracy: 0.8466\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.3904 - accuracy: 0.8500\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.3855 - accuracy: 0.8538\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.3847 - accuracy: 0.8540\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.3815 - accuracy: 0.8550\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.3678 - accuracy: 0.8601\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.3630 - accuracy: 0.8620\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.3736 - accuracy: 0.8585\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.3518 - accuracy: 0.8668\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.3499 - accuracy: 0.8672\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.3474 - accuracy: 0.8683\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.3452 - accuracy: 0.8694\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.3459 - accuracy: 0.8696\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.3382 - accuracy: 0.8708\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.3288 - accuracy: 0.8746\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.3229 - accuracy: 0.8780\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.3206 - accuracy: 0.8793\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.3150 - accuracy: 0.8813\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.3207 - accuracy: 0.8772\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.3097 - accuracy: 0.8822\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.3115 - accuracy: 0.8828\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.3085 - accuracy: 0.8827\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.3072 - accuracy: 0.8842\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.2931 - accuracy: 0.8871\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.2894 - accuracy: 0.8896\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.2959 - accuracy: 0.8869\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.2870 - accuracy: 0.8907\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.2849 - accuracy: 0.8905\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.2810 - accuracy: 0.8934\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.2787 - accuracy: 0.8936\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.2724 - accuracy: 0.8975\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.2746 - accuracy: 0.8952\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.2687 - accuracy: 0.8967\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.2705 - accuracy: 0.8961\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.2652 - accuracy: 0.8983\n",
      "76/76 [==============================] - 1s 16ms/step - loss: 0.2728 - accuracy: 0.9014\n",
      "n_conv_1 = 768, k_conv_1 = 3,  n_conv_2 = 512, k_conv_2 = 2, \n",
      "          n_conv_3 = 256,  k_conv_3 = 2,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 256, dropout_1 = 0.2,\n",
      "          n_dense_2 = 256, dropout_2 = 0.25, activation_conv=  elu,\n",
      "          activation_dense=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001FBEB7048C8>\n",
      "Epoch 1/60\n",
      "  1/152 [..............................] - ETA: 3s - loss: 1.7972 - accuracy: 0.1445WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0160s vs `on_train_batch_end` time: 0.0260s). Check your callbacks.\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 1.1495 - accuracy: 0.5137\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.9426 - accuracy: 0.6088\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.8110 - accuracy: 0.6700\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.7559 - accuracy: 0.6926\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.7149 - accuracy: 0.7115\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.6798 - accuracy: 0.7239\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.6349 - accuracy: 0.7453\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.6219 - accuracy: 0.7516\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.5868 - accuracy: 0.7678\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.5639 - accuracy: 0.7744\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.5387 - accuracy: 0.7864\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.5339 - accuracy: 0.7904\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.5087 - accuracy: 0.8029\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.4986 - accuracy: 0.8051\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.4849 - accuracy: 0.8137\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.4674 - accuracy: 0.8183\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.4631 - accuracy: 0.8222\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.4461 - accuracy: 0.8317\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.4404 - accuracy: 0.8332\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.4278 - accuracy: 0.8352\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.4227 - accuracy: 0.8362\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.4236 - accuracy: 0.8363\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.4177 - accuracy: 0.8421\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.3985 - accuracy: 0.8501\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.3890 - accuracy: 0.8512\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.3911 - accuracy: 0.8507\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.3825 - accuracy: 0.8547\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.3881 - accuracy: 0.8523\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.3725 - accuracy: 0.8565\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.3697 - accuracy: 0.8610\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.3615 - accuracy: 0.8624\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.3548 - accuracy: 0.8635\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.3670 - accuracy: 0.8599\n",
      "Epoch 34/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 6s 41ms/step - loss: 0.3524 - accuracy: 0.8648\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.3438 - accuracy: 0.8682\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.3443 - accuracy: 0.8692\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.3460 - accuracy: 0.8677\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.3355 - accuracy: 0.8702\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.3305 - accuracy: 0.8734\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.3250 - accuracy: 0.8756\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.3205 - accuracy: 0.8747\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.3190 - accuracy: 0.8759\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.3237 - accuracy: 0.8761\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.3163 - accuracy: 0.8761\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.3086 - accuracy: 0.8795\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.3048 - accuracy: 0.8822\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.2968 - accuracy: 0.8844\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.3064 - accuracy: 0.8803\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.2950 - accuracy: 0.8850\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.2947 - accuracy: 0.8859\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.2879 - accuracy: 0.8870\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.2919 - accuracy: 0.8879\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.2824 - accuracy: 0.8878\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.2823 - accuracy: 0.8894\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.2851 - accuracy: 0.8890\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.2815 - accuracy: 0.8891\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.2753 - accuracy: 0.8938\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.2646 - accuracy: 0.8971\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.2671 - accuracy: 0.8956\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.2639 - accuracy: 0.8968\n",
      "76/76 [==============================] - 1s 16ms/step - loss: 0.3026 - accuracy: 0.8887\n",
      "n_conv_1 = 768, k_conv_1 = 3,  n_conv_2 = 512, k_conv_2 = 2, \n",
      "          n_conv_3 = 256,  k_conv_3 = 2,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 256, dropout_1 = 0.2,\n",
      "          n_dense_2 = 256, dropout_2 = 0.25, activation_conv=  elu,\n",
      "          activation_dense=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001FBEB77C488>\n",
      "Epoch 1/60\n",
      "  1/152 [..............................] - ETA: 3s - loss: 1.7914 - accuracy: 0.2109WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0150s vs `on_train_batch_end` time: 0.0239s). Check your callbacks.\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 1.1507 - accuracy: 0.5112\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.9286 - accuracy: 0.6184\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.8057 - accuracy: 0.6719\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.7536 - accuracy: 0.6952\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.6946 - accuracy: 0.7205\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.6829 - accuracy: 0.7272\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.6432 - accuracy: 0.7438\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.6181 - accuracy: 0.7532\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.5877 - accuracy: 0.7636\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.5915 - accuracy: 0.7670\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.5544 - accuracy: 0.7806\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.5316 - accuracy: 0.7877\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.5192 - accuracy: 0.7966\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.5100 - accuracy: 0.7991\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.5065 - accuracy: 0.8025\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.4849 - accuracy: 0.8126\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.4840 - accuracy: 0.8125\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.4570 - accuracy: 0.8231\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.4518 - accuracy: 0.8248\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.4429 - accuracy: 0.8292\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.4300 - accuracy: 0.8349\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.4311 - accuracy: 0.8348\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.4250 - accuracy: 0.8369\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.4128 - accuracy: 0.8419\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.4396 - accuracy: 0.8324\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.3981 - accuracy: 0.8501\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.3982 - accuracy: 0.8476\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.3846 - accuracy: 0.8546\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.3859 - accuracy: 0.8519\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.3760 - accuracy: 0.8566\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.3742 - accuracy: 0.8566\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.3650 - accuracy: 0.8623\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.3628 - accuracy: 0.8626\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.3627 - accuracy: 0.8620\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.3517 - accuracy: 0.8660\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.3430 - accuracy: 0.8701\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.3437 - accuracy: 0.8682\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.3391 - accuracy: 0.8707\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.3285 - accuracy: 0.8714\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.3421 - accuracy: 0.8696\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.3259 - accuracy: 0.8728\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.3217 - accuracy: 0.8756\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.3214 - accuracy: 0.8761\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.3099 - accuracy: 0.8791\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.3137 - accuracy: 0.8808\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.3115 - accuracy: 0.8806\n",
      "Epoch 47/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 6s 41ms/step - loss: 0.3064 - accuracy: 0.8802\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.2997 - accuracy: 0.8841\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.3013 - accuracy: 0.8853\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.2870 - accuracy: 0.8887\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.2937 - accuracy: 0.8870\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.2896 - accuracy: 0.8884\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.2872 - accuracy: 0.8900\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.2788 - accuracy: 0.8908\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.2776 - accuracy: 0.8930\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.2729 - accuracy: 0.8936\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.2750 - accuracy: 0.8928\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.2697 - accuracy: 0.8952\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.2682 - accuracy: 0.8964\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.2663 - accuracy: 0.8976\n",
      "76/76 [==============================] - 1s 16ms/step - loss: 0.3150 - accuracy: 0.8859\n",
      "n_conv_1 = 768, k_conv_1 = 2,  n_conv_2 = 256, k_conv_2 = 2, \n",
      "          n_conv_3 = 256,  k_conv_3 = 2,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 256, dropout_1 = 0.3,\n",
      "          n_dense_2 = 512, dropout_2 = 0.25, activation_conv=  relu,\n",
      "          activation_dense=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001FBEB70A6C8>\n",
      "Epoch 1/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 1.1010 - accuracy: 0.5334\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.7628 - accuracy: 0.6816\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.6229 - accuracy: 0.7480\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.5095 - accuracy: 0.7993\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.4372 - accuracy: 0.8347\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3973 - accuracy: 0.8495\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3587 - accuracy: 0.8663\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3471 - accuracy: 0.8677\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3217 - accuracy: 0.8801\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3116 - accuracy: 0.8844\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.2952 - accuracy: 0.8909\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.2745 - accuracy: 0.8975\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.2759 - accuracy: 0.8985\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.2606 - accuracy: 0.9037\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.2508 - accuracy: 0.9055\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.2429 - accuracy: 0.9087\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.2433 - accuracy: 0.9093\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.2288 - accuracy: 0.9146\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.2262 - accuracy: 0.9140\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.2262 - accuracy: 0.9154\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2137 - accuracy: 0.9204\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.2109 - accuracy: 0.9219\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.2008 - accuracy: 0.9231\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1944 - accuracy: 0.9253\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1897 - accuracy: 0.9293\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.1999 - accuracy: 0.9252\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1896 - accuracy: 0.9283\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.1898 - accuracy: 0.9281\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1798 - accuracy: 0.9307\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1756 - accuracy: 0.9342\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1749 - accuracy: 0.9341\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1694 - accuracy: 0.9360\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.1731 - accuracy: 0.9335\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1706 - accuracy: 0.9355\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.1622 - accuracy: 0.9393\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.1587 - accuracy: 0.9396\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.1574 - accuracy: 0.9393\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1573 - accuracy: 0.9409\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1497 - accuracy: 0.9430\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1525 - accuracy: 0.9406\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1496 - accuracy: 0.9427\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1571 - accuracy: 0.9403\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1428 - accuracy: 0.9446\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1415 - accuracy: 0.9455\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1344 - accuracy: 0.9489\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.1404 - accuracy: 0.9456\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.1363 - accuracy: 0.9478\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.1368 - accuracy: 0.9472\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1280 - accuracy: 0.9505\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.1298 - accuracy: 0.9502\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1283 - accuracy: 0.9497\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1241 - accuracy: 0.9527\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.1239 - accuracy: 0.9516\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1172 - accuracy: 0.9544\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1263 - accuracy: 0.9512\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1185 - accuracy: 0.9539\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1204 - accuracy: 0.9541\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.1155 - accuracy: 0.9550\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1157 - accuracy: 0.9551\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1152 - accuracy: 0.9554\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 0.2578 - accuracy: 0.9252\n",
      "n_conv_1 = 768, k_conv_1 = 2,  n_conv_2 = 256, k_conv_2 = 2, \n",
      "          n_conv_3 = 256,  k_conv_3 = 2,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 256, dropout_1 = 0.3,\n",
      "          n_dense_2 = 512, dropout_2 = 0.25, activation_conv=  relu,\n",
      "          activation_dense=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001FBEB7056C8>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 1.0872 - accuracy: 0.5332\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.7646 - accuracy: 0.6809\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.6166 - accuracy: 0.7548\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.5166 - accuracy: 0.8015\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.4619 - accuracy: 0.8243\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.4109 - accuracy: 0.8443\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3833 - accuracy: 0.8550\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3553 - accuracy: 0.8652\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3394 - accuracy: 0.8712\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3178 - accuracy: 0.8783\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2990 - accuracy: 0.8872\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2943 - accuracy: 0.8871\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.2852 - accuracy: 0.8928\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2703 - accuracy: 0.8985\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.2650 - accuracy: 0.8997\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.2533 - accuracy: 0.9045\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2504 - accuracy: 0.9083\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.2441 - accuracy: 0.9094\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2324 - accuracy: 0.9148\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.2250 - accuracy: 0.9155\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.2270 - accuracy: 0.9146\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2217 - accuracy: 0.9184\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2092 - accuracy: 0.9214\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.2053 - accuracy: 0.9227\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.2013 - accuracy: 0.9230\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1966 - accuracy: 0.9262\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1921 - accuracy: 0.9268\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.1903 - accuracy: 0.9293\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1997 - accuracy: 0.9261\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1827 - accuracy: 0.9315\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1833 - accuracy: 0.9312\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1757 - accuracy: 0.9337\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1802 - accuracy: 0.9316\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1754 - accuracy: 0.9351\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1668 - accuracy: 0.9368\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1567 - accuracy: 0.9406\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1579 - accuracy: 0.9405\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1700 - accuracy: 0.9361\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1560 - accuracy: 0.9411\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1466 - accuracy: 0.9445\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1509 - accuracy: 0.9436\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1544 - accuracy: 0.9410\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1501 - accuracy: 0.9437\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1547 - accuracy: 0.9424\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.1371 - accuracy: 0.9472\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.1357 - accuracy: 0.9481\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1414 - accuracy: 0.9469\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1317 - accuracy: 0.9497\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1320 - accuracy: 0.9496\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1377 - accuracy: 0.9486\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.1282 - accuracy: 0.9508\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1185 - accuracy: 0.9541\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1245 - accuracy: 0.9530\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1304 - accuracy: 0.9499\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1222 - accuracy: 0.9528\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1179 - accuracy: 0.9543\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1218 - accuracy: 0.9537\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1206 - accuracy: 0.9523\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1199 - accuracy: 0.9544\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1099 - accuracy: 0.9575\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 0.2736 - accuracy: 0.9259\n",
      "n_conv_1 = 768, k_conv_1 = 2,  n_conv_2 = 256, k_conv_2 = 2, \n",
      "          n_conv_3 = 256,  k_conv_3 = 2,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 256, dropout_1 = 0.3,\n",
      "          n_dense_2 = 512, dropout_2 = 0.25, activation_conv=  relu,\n",
      "          activation_dense=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001FAC97286C8>\n",
      "Epoch 1/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 1.1154 - accuracy: 0.5251\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.7956 - accuracy: 0.6659\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.6222 - accuracy: 0.7484\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.5244 - accuracy: 0.7912\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.4592 - accuracy: 0.8236\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.4081 - accuracy: 0.8460\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3795 - accuracy: 0.8580\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.3494 - accuracy: 0.8702\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3360 - accuracy: 0.8729\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3113 - accuracy: 0.8839\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.3041 - accuracy: 0.8866\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.2884 - accuracy: 0.8919\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2816 - accuracy: 0.8944\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2632 - accuracy: 0.9015\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.2648 - accuracy: 0.9013\n",
      "Epoch 16/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2570 - accuracy: 0.9023\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2378 - accuracy: 0.9095\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2334 - accuracy: 0.9120\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.2307 - accuracy: 0.9130\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2318 - accuracy: 0.9116\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.2170 - accuracy: 0.9189\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2220 - accuracy: 0.9174\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2088 - accuracy: 0.9223\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2101 - accuracy: 0.9220\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1963 - accuracy: 0.9270\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1948 - accuracy: 0.9274\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.1845 - accuracy: 0.9315\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1929 - accuracy: 0.9273\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1854 - accuracy: 0.9311\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1805 - accuracy: 0.9331\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1743 - accuracy: 0.9358\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1776 - accuracy: 0.9345\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1778 - accuracy: 0.9341\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.1736 - accuracy: 0.9353\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1655 - accuracy: 0.9382\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1627 - accuracy: 0.9386\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1573 - accuracy: 0.9423\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1622 - accuracy: 0.9386\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1616 - accuracy: 0.9400\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1538 - accuracy: 0.9415\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1446 - accuracy: 0.9462\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1443 - accuracy: 0.9452\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1350 - accuracy: 0.9492\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1594 - accuracy: 0.9413\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1372 - accuracy: 0.9478\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1408 - accuracy: 0.9475\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1386 - accuracy: 0.9481\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1330 - accuracy: 0.9489\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1311 - accuracy: 0.9501\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1279 - accuracy: 0.9507\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1286 - accuracy: 0.9527\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1285 - accuracy: 0.9517\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1347 - accuracy: 0.9483\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1246 - accuracy: 0.9524\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1180 - accuracy: 0.9548\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1274 - accuracy: 0.9523\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1124 - accuracy: 0.9577\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.1106 - accuracy: 0.9572\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.1142 - accuracy: 0.9563\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.1189 - accuracy: 0.9545\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 0.2504 - accuracy: 0.9277\n",
      "n_conv_1 = 512, k_conv_1 = 3,  n_conv_2 = 256, k_conv_2 = 2, \n",
      "          n_conv_3 = 512,  k_conv_3 = 3,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 256, dropout_1 = 0.2,\n",
      "          n_dense_2 = 256, dropout_2 = 0.25, activation_conv=  elu,\n",
      "          activation_dense=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001FAC9B71108>\n",
      "Epoch 1/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 1.1556 - accuracy: 0.5128\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.9040 - accuracy: 0.6318\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.8201 - accuracy: 0.6691\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.7660 - accuracy: 0.6880\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.7503 - accuracy: 0.6976\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.7055 - accuracy: 0.7142\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.6812 - accuracy: 0.7249\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.6502 - accuracy: 0.7393\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.6383 - accuracy: 0.7431\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.6180 - accuracy: 0.7509\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.6156 - accuracy: 0.7547\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.5860 - accuracy: 0.7634\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.5763 - accuracy: 0.7666\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.5578 - accuracy: 0.7762\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.5530 - accuracy: 0.7776\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.5283 - accuracy: 0.7885\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.5361 - accuracy: 0.7871\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.5113 - accuracy: 0.7966\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.5030 - accuracy: 0.8022\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.4895 - accuracy: 0.8076\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.4748 - accuracy: 0.8110\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.4673 - accuracy: 0.8159\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.4695 - accuracy: 0.8174\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.4571 - accuracy: 0.8212\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.4455 - accuracy: 0.8267\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.4437 - accuracy: 0.8243\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.4348 - accuracy: 0.8322\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.4283 - accuracy: 0.8307\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.4270 - accuracy: 0.8352\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.4175 - accuracy: 0.8375\n",
      "Epoch 31/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 4s 25ms/step - loss: 0.4091 - accuracy: 0.8402\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.4034 - accuracy: 0.8424\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3901 - accuracy: 0.8501\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3924 - accuracy: 0.8495\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3860 - accuracy: 0.8489\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3815 - accuracy: 0.8532\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3874 - accuracy: 0.8497\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3784 - accuracy: 0.8532\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3874 - accuracy: 0.8492\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3694 - accuracy: 0.8581\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3644 - accuracy: 0.8595\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3752 - accuracy: 0.8569\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3511 - accuracy: 0.8644\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3541 - accuracy: 0.8626\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3560 - accuracy: 0.8625\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3447 - accuracy: 0.8658\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3408 - accuracy: 0.8656\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3388 - accuracy: 0.8689\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3340 - accuracy: 0.8701\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3287 - accuracy: 0.8730\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3284 - accuracy: 0.8729\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3254 - accuracy: 0.8710\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3235 - accuracy: 0.8741\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3197 - accuracy: 0.8747\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3225 - accuracy: 0.8734\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3180 - accuracy: 0.8752\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3093 - accuracy: 0.8788\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3144 - accuracy: 0.8772\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3063 - accuracy: 0.8790\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3002 - accuracy: 0.8814\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 0.3118 - accuracy: 0.8858\n",
      "n_conv_1 = 512, k_conv_1 = 3,  n_conv_2 = 256, k_conv_2 = 2, \n",
      "          n_conv_3 = 512,  k_conv_3 = 3,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 256, dropout_1 = 0.2,\n",
      "          n_dense_2 = 256, dropout_2 = 0.25, activation_conv=  elu,\n",
      "          activation_dense=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001FAC9A60C88>\n",
      "Epoch 1/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 1.1502 - accuracy: 0.5154\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.9402 - accuracy: 0.6136\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.8072 - accuracy: 0.6724\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.7747 - accuracy: 0.6882\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.7298 - accuracy: 0.7025\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.7013 - accuracy: 0.7170\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.6732 - accuracy: 0.7305\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.6546 - accuracy: 0.7363\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.6321 - accuracy: 0.7453\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.6114 - accuracy: 0.7541\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.5842 - accuracy: 0.7662\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.5931 - accuracy: 0.7623\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.5599 - accuracy: 0.7762\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.5435 - accuracy: 0.7836\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.5446 - accuracy: 0.7829\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.5315 - accuracy: 0.7904\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.5091 - accuracy: 0.8013\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.5055 - accuracy: 0.8020\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.5021 - accuracy: 0.8020\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.4767 - accuracy: 0.8141\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.4767 - accuracy: 0.8141\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.4570 - accuracy: 0.8252\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.4589 - accuracy: 0.8213\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.4531 - accuracy: 0.8250\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.4454 - accuracy: 0.8265\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.4337 - accuracy: 0.8319\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.4227 - accuracy: 0.8368\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.4247 - accuracy: 0.8349\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.4211 - accuracy: 0.8383\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.4074 - accuracy: 0.8435\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.4065 - accuracy: 0.8439\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3993 - accuracy: 0.8447\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3957 - accuracy: 0.8466\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3929 - accuracy: 0.8498\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3887 - accuracy: 0.8495\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3812 - accuracy: 0.8524\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3725 - accuracy: 0.8561\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3739 - accuracy: 0.8544\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3678 - accuracy: 0.8581\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3679 - accuracy: 0.8570\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3574 - accuracy: 0.8616\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3640 - accuracy: 0.8612\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3559 - accuracy: 0.8609\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3386 - accuracy: 0.8701\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3424 - accuracy: 0.8656\n",
      "Epoch 46/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3425 - accuracy: 0.8665\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3408 - accuracy: 0.8651\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3281 - accuracy: 0.8715\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3342 - accuracy: 0.8665\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3297 - accuracy: 0.8722\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3249 - accuracy: 0.8728\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3142 - accuracy: 0.8770\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3184 - accuracy: 0.8756\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3120 - accuracy: 0.8765\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3078 - accuracy: 0.8791\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3092 - accuracy: 0.8796\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3081 - accuracy: 0.8794\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3038 - accuracy: 0.8800\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.2967 - accuracy: 0.8828\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.2935 - accuracy: 0.8830\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 0.3318 - accuracy: 0.8738\n",
      "n_conv_1 = 512, k_conv_1 = 3,  n_conv_2 = 256, k_conv_2 = 2, \n",
      "          n_conv_3 = 512,  k_conv_3 = 3,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 256, dropout_1 = 0.2,\n",
      "          n_dense_2 = 256, dropout_2 = 0.25, activation_conv=  elu,\n",
      "          activation_dense=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001FBE9D97A48>\n",
      "Epoch 1/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 1.1602 - accuracy: 0.5127\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.9297 - accuracy: 0.6248\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.8201 - accuracy: 0.6694\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.7574 - accuracy: 0.6955\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.7308 - accuracy: 0.7034\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.7185 - accuracy: 0.7106\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.6744 - accuracy: 0.7316\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.6509 - accuracy: 0.7397\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.6298 - accuracy: 0.7476\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.6348 - accuracy: 0.7462\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.6133 - accuracy: 0.7539\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.5869 - accuracy: 0.7676\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.5825 - accuracy: 0.7679\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.5548 - accuracy: 0.7802\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.5466 - accuracy: 0.7815\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.5369 - accuracy: 0.7893\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.5284 - accuracy: 0.7936\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.5107 - accuracy: 0.8013\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.4937 - accuracy: 0.8067\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.5038 - accuracy: 0.8016 \n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.4779 - accuracy: 0.8135\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.4638 - accuracy: 0.8194\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.4719 - accuracy: 0.8173\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.4533 - accuracy: 0.8249\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.4496 - accuracy: 0.8250\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.4515 - accuracy: 0.8258\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.4377 - accuracy: 0.8313\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.4306 - accuracy: 0.8337\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.4355 - accuracy: 0.8320\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.4185 - accuracy: 0.8399\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.4176 - accuracy: 0.8418\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.4117 - accuracy: 0.8432\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.4014 - accuracy: 0.8446\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3980 - accuracy: 0.8472\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3961 - accuracy: 0.8472\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3925 - accuracy: 0.8499\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3925 - accuracy: 0.8493\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3779 - accuracy: 0.8547\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3713 - accuracy: 0.8557\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3690 - accuracy: 0.8585\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3632 - accuracy: 0.8592\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3606 - accuracy: 0.8632\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3578 - accuracy: 0.8613\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3577 - accuracy: 0.8622\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3491 - accuracy: 0.8660\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3504 - accuracy: 0.8647\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3439 - accuracy: 0.8675\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3396 - accuracy: 0.8672\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3477 - accuracy: 0.8635\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3381 - accuracy: 0.8711\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3398 - accuracy: 0.8672\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3200 - accuracy: 0.8760\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3202 - accuracy: 0.8758\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3242 - accuracy: 0.8747\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3178 - accuracy: 0.8774\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3119 - accuracy: 0.8769\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3100 - accuracy: 0.8790\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3036 - accuracy: 0.8831\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3057 - accuracy: 0.8818\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3067 - accuracy: 0.8807\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 0.3169 - accuracy: 0.8853\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_conv_1 = 512, k_conv_1 = 3,  n_conv_2 = 512, k_conv_2 = 2, \n",
      "          n_conv_3 = 512,  k_conv_3 = 2,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 256, dropout_1 = 0.3,\n",
      "          n_dense_2 = 256, dropout_2 = 0.25, activation_conv=  relu,\n",
      "          activation_dense=  elu\n",
      "Epoch 1/60\n",
      "228/228 [==============================] - 8s 34ms/step - loss: 0.9303 - accuracy: 0.6063\n",
      "Epoch 2/60\n",
      "228/228 [==============================] - 7s 31ms/step - loss: 0.5252 - accuracy: 0.7997\n",
      "Epoch 3/60\n",
      "228/228 [==============================] - 7s 31ms/step - loss: 0.4067 - accuracy: 0.8485\n",
      "Epoch 4/60\n",
      "228/228 [==============================] - 7s 31ms/step - loss: 0.3524 - accuracy: 0.8683\n",
      "Epoch 5/60\n",
      "228/228 [==============================] - 7s 31ms/step - loss: 0.3081 - accuracy: 0.8859\n",
      "Epoch 6/60\n",
      "228/228 [==============================] - 7s 31ms/step - loss: 0.2973 - accuracy: 0.8898\n",
      "Epoch 7/60\n",
      "228/228 [==============================] - 7s 31ms/step - loss: 0.2804 - accuracy: 0.8979\n",
      "Epoch 8/60\n",
      "228/228 [==============================] - 7s 31ms/step - loss: 0.2647 - accuracy: 0.9026\n",
      "Epoch 9/60\n",
      "228/228 [==============================] - 7s 31ms/step - loss: 0.2542 - accuracy: 0.9061\n",
      "Epoch 10/60\n",
      "228/228 [==============================] - 7s 31ms/step - loss: 0.2373 - accuracy: 0.9128\n",
      "Epoch 11/60\n",
      "228/228 [==============================] - 7s 31ms/step - loss: 0.2261 - accuracy: 0.9180\n",
      "Epoch 12/60\n",
      "228/228 [==============================] - 7s 31ms/step - loss: 0.2221 - accuracy: 0.9181\n",
      "Epoch 13/60\n",
      "228/228 [==============================] - 7s 31ms/step - loss: 0.2228 - accuracy: 0.9179\n",
      "Epoch 14/60\n",
      "228/228 [==============================] - 7s 31ms/step - loss: 0.2036 - accuracy: 0.9256\n",
      "Epoch 15/60\n",
      "228/228 [==============================] - 7s 31ms/step - loss: 0.1992 - accuracy: 0.9273\n",
      "Epoch 16/60\n",
      "228/228 [==============================] - 7s 31ms/step - loss: 0.1990 - accuracy: 0.9270\n",
      "Epoch 17/60\n",
      "228/228 [==============================] - 7s 31ms/step - loss: 0.1853 - accuracy: 0.9308\n",
      "Epoch 18/60\n",
      "228/228 [==============================] - 7s 31ms/step - loss: 0.1819 - accuracy: 0.9341\n",
      "Epoch 19/60\n",
      "228/228 [==============================] - 7s 31ms/step - loss: 0.1748 - accuracy: 0.9358\n",
      "Epoch 20/60\n",
      "228/228 [==============================] - 7s 31ms/step - loss: 0.1755 - accuracy: 0.9356\n",
      "Epoch 21/60\n",
      "228/228 [==============================] - 7s 31ms/step - loss: 0.1675 - accuracy: 0.9376\n",
      "Epoch 22/60\n",
      "228/228 [==============================] - 7s 31ms/step - loss: 0.1614 - accuracy: 0.9401\n",
      "Epoch 23/60\n",
      "228/228 [==============================] - 7s 31ms/step - loss: 0.1593 - accuracy: 0.9412\n",
      "Epoch 24/60\n",
      "228/228 [==============================] - 7s 31ms/step - loss: 0.1581 - accuracy: 0.9409\n",
      "Epoch 25/60\n",
      "228/228 [==============================] - 7s 31ms/step - loss: 0.1490 - accuracy: 0.9455\n",
      "Epoch 26/60\n",
      "228/228 [==============================] - 7s 31ms/step - loss: 0.1500 - accuracy: 0.9452\n",
      "Epoch 27/60\n",
      "228/228 [==============================] - 7s 31ms/step - loss: 0.1411 - accuracy: 0.9474\n",
      "Epoch 28/60\n",
      "228/228 [==============================] - 7s 31ms/step - loss: 0.1422 - accuracy: 0.9475\n",
      "Epoch 29/60\n",
      "228/228 [==============================] - 7s 31ms/step - loss: 0.1351 - accuracy: 0.9496\n",
      "Epoch 30/60\n",
      "228/228 [==============================] - 7s 31ms/step - loss: 0.1366 - accuracy: 0.9485\n",
      "Epoch 31/60\n",
      "228/228 [==============================] - 7s 31ms/step - loss: 0.1353 - accuracy: 0.9488\n",
      "Epoch 32/60\n",
      "228/228 [==============================] - 7s 31ms/step - loss: 0.1290 - accuracy: 0.9522\n",
      "Epoch 33/60\n",
      "228/228 [==============================] - 7s 31ms/step - loss: 0.1254 - accuracy: 0.9532\n",
      "Epoch 34/60\n",
      "228/228 [==============================] - 7s 31ms/step - loss: 0.1220 - accuracy: 0.9546\n",
      "Epoch 35/60\n",
      "228/228 [==============================] - 7s 31ms/step - loss: 0.1209 - accuracy: 0.9550\n",
      "Epoch 36/60\n",
      "228/228 [==============================] - 7s 31ms/step - loss: 0.1194 - accuracy: 0.9551\n",
      "Epoch 37/60\n",
      "228/228 [==============================] - 7s 31ms/step - loss: 0.1140 - accuracy: 0.9567\n",
      "Epoch 38/60\n",
      "228/228 [==============================] - 7s 31ms/step - loss: 0.1127 - accuracy: 0.9578\n",
      "Epoch 39/60\n",
      "228/228 [==============================] - 7s 31ms/step - loss: 0.1075 - accuracy: 0.9593\n",
      "Epoch 40/60\n",
      "228/228 [==============================] - 7s 31ms/step - loss: 0.1062 - accuracy: 0.9600\n",
      "Epoch 41/60\n",
      "228/228 [==============================] - 7s 31ms/step - loss: 0.1059 - accuracy: 0.9607\n",
      "Epoch 42/60\n",
      "228/228 [==============================] - 7s 31ms/step - loss: 0.1036 - accuracy: 0.9616\n",
      "Epoch 43/60\n",
      "228/228 [==============================] - 7s 31ms/step - loss: 0.1067 - accuracy: 0.9595\n",
      "Epoch 44/60\n",
      "228/228 [==============================] - 7s 31ms/step - loss: 0.0973 - accuracy: 0.9633\n",
      "Epoch 45/60\n",
      "228/228 [==============================] - 7s 31ms/step - loss: 0.1032 - accuracy: 0.9612\n",
      "Epoch 46/60\n",
      "228/228 [==============================] - 7s 31ms/step - loss: 0.0950 - accuracy: 0.9648\n",
      "Epoch 47/60\n",
      "228/228 [==============================] - 7s 31ms/step - loss: 0.0969 - accuracy: 0.9641\n",
      "Epoch 48/60\n",
      "228/228 [==============================] - 7s 31ms/step - loss: 0.0924 - accuracy: 0.9660\n",
      "Epoch 49/60\n",
      "228/228 [==============================] - 7s 31ms/step - loss: 0.0905 - accuracy: 0.9661\n",
      "Epoch 50/60\n",
      "228/228 [==============================] - 7s 31ms/step - loss: 0.0936 - accuracy: 0.9655\n",
      "Epoch 51/60\n",
      "228/228 [==============================] - 7s 31ms/step - loss: 0.0861 - accuracy: 0.9680\n",
      "Epoch 52/60\n",
      "228/228 [==============================] - 7s 31ms/step - loss: 0.0856 - accuracy: 0.9678\n",
      "Epoch 53/60\n",
      "228/228 [==============================] - 7s 31ms/step - loss: 0.0837 - accuracy: 0.9688\n",
      "Epoch 54/60\n",
      "228/228 [==============================] - 7s 31ms/step - loss: 0.0891 - accuracy: 0.9668\n",
      "Epoch 55/60\n",
      "228/228 [==============================] - 7s 31ms/step - loss: 0.0872 - accuracy: 0.9688\n",
      "Epoch 56/60\n",
      "228/228 [==============================] - 7s 31ms/step - loss: 0.0813 - accuracy: 0.9700\n",
      "Epoch 57/60\n",
      "228/228 [==============================] - 7s 31ms/step - loss: 0.0818 - accuracy: 0.9698\n",
      "Epoch 58/60\n",
      "228/228 [==============================] - 7s 31ms/step - loss: 0.0847 - accuracy: 0.9686\n",
      "Epoch 59/60\n",
      "228/228 [==============================] - 7s 31ms/step - loss: 0.0781 - accuracy: 0.9714\n",
      "Epoch 60/60\n",
      "228/228 [==============================] - 7s 31ms/step - loss: 0.0758 - accuracy: 0.9718\n",
      "Wall time: 7h 56min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rscv = RandomizedSearchCV(model, param_distributions=params, cv=cv, n_iter=n_tune_iter)\n",
    "rscv_results = rscv.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score is: 0.9388105273246765 using {'n_dense_2': 256, 'n_dense_1': 256, 'n_conv_3': 512, 'n_conv_2': 512, 'n_conv_1': 512, 'maxpooling_pool_size': 3, 'k_conv_3': 2, 'k_conv_2': 2, 'k_conv_1': 3, 'dropout_2': 0.25, 'dropout_1': 0.3, 'avepooling_pool_size': 3, 'activation_dense': 'elu', 'activation_conv': 'relu'}\n"
     ]
    }
   ],
   "source": [
    "print('Best score is: {} using {}'.format(rscv_results.best_score_,\n",
    "rscv_results.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = rscv_results.best_estimator_\n",
    "best_param = rscv_results.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JkbhJMox8Jl9"
   },
   "source": [
    "### Test the best model based on the validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kZwGk5dR8JmS"
   },
   "outputs": [],
   "source": [
    "y_hat = best_model.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E_GNq-R_8JmZ",
    "outputId": "0fc16efe-7739-4394-f1a3-46da92e79584"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 1.], dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = to_categorical(y_hat)\n",
    "y_hat[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SFqRQ5XB8Jmc",
    "outputId": "a957fbed-92f8-4bdd-d24b-5df3361a8bac"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 1.], dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FTWf6Cf-8Jme",
    "outputId": "1256b170-33dc-4171-f2ff-7a3d7ddd74e3"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_hat)\n",
    "_ = plt.axvline(x=0.5, color='orange')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 1.] [0. 0. 0. 0. 0. 1.] [0. 0. 0. 0. 0. 1.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "95.64546016059296"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import  accuracy_score as score\n",
    "y_pred_classes = y_hat.round()\n",
    "print(y_valid[0], y_hat[0], y_pred_classes[0])\n",
    "acc = score(y_valid, y_pred_classes) * 100\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RNljSx3v8Jmh"
   },
   "outputs": [],
   "source": [
    "pct_auc = roc_auc_score(y_valid, y_hat)*100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SO_N9lJG8Jmj",
    "outputId": "20968a52-8ca0-44d3-abf6-a1382bba5cde"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'97.41'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"{:0.2f}\".format(pct_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vU3hnA298Jmo"
   },
   "outputs": [],
   "source": [
    "float_y_hat = []\n",
    "for y in y_hat:\n",
    "    float_y_hat.append(y[0:6].round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zrTf-aQl8Jmr"
   },
   "outputs": [],
   "source": [
    "ydf = pd.DataFrame(list(zip(float_y_hat, y_valid)), columns=['y_hat', 'y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zAyKh_mX8Jmu",
    "outputId": "611224b8-f980-47df-d596-9aa3a5811009"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_hat</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            y_hat                               y\n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0]  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0]\n",
       "1  [0.0, 0.0, 1.0, 0.0, 0.0, 0.0]  [0.0, 0.0, 1.0, 0.0, 0.0, 0.0]\n",
       "2  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0]  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0]\n",
       "3  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0]  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
       "4  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0]  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0]\n",
       "5  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0]  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0]\n",
       "6  [0.0, 0.0, 0.0, 1.0, 0.0, 0.0]  [0.0, 0.0, 0.0, 1.0, 0.0, 0.0]\n",
       "7  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0]  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0]\n",
       "8  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0]  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
       "9  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0]  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ydf.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_dense_2</th>\n",
       "      <th>n_dense_1</th>\n",
       "      <th>n_conv_3</th>\n",
       "      <th>n_conv_2</th>\n",
       "      <th>n_conv_1</th>\n",
       "      <th>maxpooling_pool_size</th>\n",
       "      <th>k_conv_3</th>\n",
       "      <th>k_conv_2</th>\n",
       "      <th>k_conv_1</th>\n",
       "      <th>dropout_2</th>\n",
       "      <th>dropout_1</th>\n",
       "      <th>avepooling_pool_size</th>\n",
       "      <th>activation_dense</th>\n",
       "      <th>activation_conv</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>elu</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.938811</td>\n",
       "      <td>0.001690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>256</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>relu</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.938210</td>\n",
       "      <td>0.001707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>relu</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.937249</td>\n",
       "      <td>0.003460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>elu</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.936648</td>\n",
       "      <td>0.002447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>256</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>256</td>\n",
       "      <td>512</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>&lt;tensorflow.python.keras.layers.advanced_activ...</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.936305</td>\n",
       "      <td>0.001718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>512</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>768</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>elu</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.936151</td>\n",
       "      <td>0.002595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>512</td>\n",
       "      <td>256</td>\n",
       "      <td>768</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>elu</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.935945</td>\n",
       "      <td>0.001779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>512</td>\n",
       "      <td>256</td>\n",
       "      <td>768</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>relu</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.935859</td>\n",
       "      <td>0.000328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>256</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>256</td>\n",
       "      <td>512</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>elu</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.934229</td>\n",
       "      <td>0.001524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>256</td>\n",
       "      <td>512</td>\n",
       "      <td>256</td>\n",
       "      <td>512</td>\n",
       "      <td>768</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>&lt;tensorflow.python.keras.layers.advanced_activ...</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.933440</td>\n",
       "      <td>0.003776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>512</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>768</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>&lt;tensorflow.python.keras.layers.advanced_activ...</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.926250</td>\n",
       "      <td>0.001084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>256</td>\n",
       "      <td>512</td>\n",
       "      <td>768</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>elu</td>\n",
       "      <td>elu</td>\n",
       "      <td>0.919695</td>\n",
       "      <td>0.003118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>512</td>\n",
       "      <td>768</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>elu</td>\n",
       "      <td>elu</td>\n",
       "      <td>0.906929</td>\n",
       "      <td>0.011060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>256</td>\n",
       "      <td>512</td>\n",
       "      <td>768</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>&lt;tensorflow.python.keras.layers.advanced_activ...</td>\n",
       "      <td>elu</td>\n",
       "      <td>0.906260</td>\n",
       "      <td>0.004205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>256</td>\n",
       "      <td>512</td>\n",
       "      <td>768</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>relu</td>\n",
       "      <td>elu</td>\n",
       "      <td>0.905848</td>\n",
       "      <td>0.005825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>256</td>\n",
       "      <td>512</td>\n",
       "      <td>256</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>relu</td>\n",
       "      <td>elu</td>\n",
       "      <td>0.901284</td>\n",
       "      <td>0.008995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>512</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>relu</td>\n",
       "      <td>&lt;tensorflow.python.keras.layers.advanced_activ...</td>\n",
       "      <td>0.899842</td>\n",
       "      <td>0.003802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>256</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>256</td>\n",
       "      <td>512</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>relu</td>\n",
       "      <td>&lt;tensorflow.python.keras.layers.advanced_activ...</td>\n",
       "      <td>0.899276</td>\n",
       "      <td>0.004207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>256</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>256</td>\n",
       "      <td>512</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>relu</td>\n",
       "      <td>&lt;tensorflow.python.keras.layers.advanced_activ...</td>\n",
       "      <td>0.892927</td>\n",
       "      <td>0.005266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>512</td>\n",
       "      <td>768</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>&lt;tensorflow.python.keras.layers.advanced_activ...</td>\n",
       "      <td>elu</td>\n",
       "      <td>0.892000</td>\n",
       "      <td>0.006761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>256</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>&lt;tensorflow.python.keras.layers.advanced_activ...</td>\n",
       "      <td>elu</td>\n",
       "      <td>0.889993</td>\n",
       "      <td>0.001638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>256</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>256</td>\n",
       "      <td>768</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>&lt;tensorflow.python.keras.layers.advanced_activ...</td>\n",
       "      <td>elu</td>\n",
       "      <td>0.889667</td>\n",
       "      <td>0.000367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>256</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>256</td>\n",
       "      <td>768</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>&lt;tensorflow.python.keras.layers.advanced_activ...</td>\n",
       "      <td>elu</td>\n",
       "      <td>0.888689</td>\n",
       "      <td>0.003685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>512</td>\n",
       "      <td>256</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>&lt;tensorflow.python.keras.layers.advanced_activ...</td>\n",
       "      <td>elu</td>\n",
       "      <td>0.887436</td>\n",
       "      <td>0.003843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>512</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>512</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>&lt;tensorflow.python.keras.layers.advanced_activ...</td>\n",
       "      <td>&lt;tensorflow.python.keras.layers.advanced_activ...</td>\n",
       "      <td>0.887299</td>\n",
       "      <td>0.005620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>512</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>elu</td>\n",
       "      <td>&lt;tensorflow.python.keras.layers.advanced_activ...</td>\n",
       "      <td>0.886818</td>\n",
       "      <td>0.002551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>256</td>\n",
       "      <td>768</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>elu</td>\n",
       "      <td>&lt;tensorflow.python.keras.layers.advanced_activ...</td>\n",
       "      <td>0.881722</td>\n",
       "      <td>0.001598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>512</td>\n",
       "      <td>256</td>\n",
       "      <td>512</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>&lt;tensorflow.python.keras.layers.advanced_activ...</td>\n",
       "      <td>elu</td>\n",
       "      <td>0.881619</td>\n",
       "      <td>0.005548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>elu</td>\n",
       "      <td>&lt;tensorflow.python.keras.layers.advanced_activ...</td>\n",
       "      <td>0.881430</td>\n",
       "      <td>0.003297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>512</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>&lt;tensorflow.python.keras.layers.advanced_activ...</td>\n",
       "      <td>elu</td>\n",
       "      <td>0.881139</td>\n",
       "      <td>0.011428</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    n_dense_2  n_dense_1  n_conv_3  n_conv_2  n_conv_1  maxpooling_pool_size  \\\n",
       "16        256        256       512       512       512                     3   \n",
       "8         256        512       512       512       512                     3   \n",
       "10        256        256       256       512       512                     3   \n",
       "25        512        512       512       512       512                     3   \n",
       "24        256        512       512       256       512                     3   \n",
       "22        512        256       256       256       768                     3   \n",
       "11        256        256       512       256       768                     3   \n",
       "1         256        256       512       256       768                     3   \n",
       "15        256        512       512       256       512                     3   \n",
       "4         256        512       256       512       768                     3   \n",
       "28        512        256       256       256       768                     3   \n",
       "3         512        512       256       512       768                     3   \n",
       "18        256        256       256       512       768                     3   \n",
       "14        512        512       256       512       768                     3   \n",
       "20        512        512       256       512       768                     3   \n",
       "5         256        512       256       512       512                     3   \n",
       "2         256        256       256       256       512                     3   \n",
       "7         256        512       512       256       512                     3   \n",
       "12        256        512       512       256       512                     3   \n",
       "27        256        256       256       512       768                     3   \n",
       "21        512        512       256       512       512                     3   \n",
       "0         256        512       512       256       768                     3   \n",
       "19        256        512       512       256       768                     3   \n",
       "26        512        256       512       512       512                     3   \n",
       "23        512        256       256       256       512                     3   \n",
       "13        256        256       256       256       512                     3   \n",
       "6         512        512       512       256       768                     3   \n",
       "29        256        256       512       256       512                     3   \n",
       "17        256        256       256       512       512                     3   \n",
       "9         256        256       256       256       512                     3   \n",
       "\n",
       "    k_conv_3  k_conv_2  k_conv_1  dropout_2  dropout_1  avepooling_pool_size  \\\n",
       "16         2         2         3       0.25        0.3                     3   \n",
       "8          2         3         3       0.25        0.3                     3   \n",
       "10         3         3         3       0.25        0.3                     3   \n",
       "25         2         2         2       0.25        0.2                     3   \n",
       "24         2         2         2       0.25        0.2                     3   \n",
       "22         3         2         3       0.25        0.2                     3   \n",
       "11         2         3         2       0.25        0.3                     3   \n",
       "1          2         3         2       0.25        0.3                     3   \n",
       "15         3         2         3       0.25        0.3                     3   \n",
       "4          3         3         2       0.25        0.2                     3   \n",
       "28         2         2         2       0.25        0.3                     3   \n",
       "3          3         3         2       0.25        0.2                     3   \n",
       "18         3         2         2       0.25        0.2                     3   \n",
       "14         2         3         3       0.25        0.2                     3   \n",
       "20         3         2         3       0.25        0.2                     3   \n",
       "5          3         3         3       0.25        0.3                     3   \n",
       "2          2         3         2       0.25        0.2                     3   \n",
       "7          3         3         2       0.25        0.3                     3   \n",
       "12         3         2         2       0.25        0.2                     3   \n",
       "27         2         2         3       0.25        0.2                     3   \n",
       "21         3         2         2       0.25        0.2                     3   \n",
       "0          3         3         2       0.25        0.3                     3   \n",
       "19         3         3         3       0.25        0.3                     3   \n",
       "26         2         3         2       0.25        0.3                     3   \n",
       "23         3         3         3       0.25        0.3                     3   \n",
       "13         3         2         3       0.25        0.3                     3   \n",
       "6          3         3         2       0.25        0.2                     3   \n",
       "29         3         2         3       0.25        0.2                     3   \n",
       "17         2         3         2       0.25        0.3                     3   \n",
       "9          2         2         3       0.25        0.3                     3   \n",
       "\n",
       "                                     activation_dense  \\\n",
       "16                                                elu   \n",
       "8                                                relu   \n",
       "10                                               relu   \n",
       "25                                                elu   \n",
       "24  <tensorflow.python.keras.layers.advanced_activ...   \n",
       "22                                                elu   \n",
       "11                                                elu   \n",
       "1                                                relu   \n",
       "15                                                elu   \n",
       "4   <tensorflow.python.keras.layers.advanced_activ...   \n",
       "28  <tensorflow.python.keras.layers.advanced_activ...   \n",
       "3                                                 elu   \n",
       "18                                                elu   \n",
       "14  <tensorflow.python.keras.layers.advanced_activ...   \n",
       "20                                               relu   \n",
       "5                                                relu   \n",
       "2                                                relu   \n",
       "7                                                relu   \n",
       "12                                               relu   \n",
       "27  <tensorflow.python.keras.layers.advanced_activ...   \n",
       "21  <tensorflow.python.keras.layers.advanced_activ...   \n",
       "0   <tensorflow.python.keras.layers.advanced_activ...   \n",
       "19  <tensorflow.python.keras.layers.advanced_activ...   \n",
       "26  <tensorflow.python.keras.layers.advanced_activ...   \n",
       "23  <tensorflow.python.keras.layers.advanced_activ...   \n",
       "13                                                elu   \n",
       "6                                                 elu   \n",
       "29  <tensorflow.python.keras.layers.advanced_activ...   \n",
       "17                                                elu   \n",
       "9   <tensorflow.python.keras.layers.advanced_activ...   \n",
       "\n",
       "                                      activation_conv      mean       std  \n",
       "16                                               relu  0.938811  0.001690  \n",
       "8                                                relu  0.938210  0.001707  \n",
       "10                                               relu  0.937249  0.003460  \n",
       "25                                               relu  0.936648  0.002447  \n",
       "24                                               relu  0.936305  0.001718  \n",
       "22                                               relu  0.936151  0.002595  \n",
       "11                                               relu  0.935945  0.001779  \n",
       "1                                                relu  0.935859  0.000328  \n",
       "15                                               relu  0.934229  0.001524  \n",
       "4                                                relu  0.933440  0.003776  \n",
       "28                                               relu  0.926250  0.001084  \n",
       "3                                                 elu  0.919695  0.003118  \n",
       "18                                                elu  0.906929  0.011060  \n",
       "14                                                elu  0.906260  0.004205  \n",
       "20                                                elu  0.905848  0.005825  \n",
       "5                                                 elu  0.901284  0.008995  \n",
       "2   <tensorflow.python.keras.layers.advanced_activ...  0.899842  0.003802  \n",
       "7   <tensorflow.python.keras.layers.advanced_activ...  0.899276  0.004207  \n",
       "12  <tensorflow.python.keras.layers.advanced_activ...  0.892927  0.005266  \n",
       "27                                                elu  0.892000  0.006761  \n",
       "21                                                elu  0.889993  0.001638  \n",
       "0                                                 elu  0.889667  0.000367  \n",
       "19                                                elu  0.888689  0.003685  \n",
       "26                                                elu  0.887436  0.003843  \n",
       "23  <tensorflow.python.keras.layers.advanced_activ...  0.887299  0.005620  \n",
       "13  <tensorflow.python.keras.layers.advanced_activ...  0.886818  0.002551  \n",
       "6   <tensorflow.python.keras.layers.advanced_activ...  0.881722  0.001598  \n",
       "29                                                elu  0.881619  0.005548  \n",
       "17  <tensorflow.python.keras.layers.advanced_activ...  0.881430  0.003297  \n",
       "9                                                 elu  0.881139  0.011428  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame(rscv_results.cv_results_['params'])\n",
    "results_df['mean'] = rscv_results.cv_results_['mean_test_score']\n",
    "results_df['std'] = rscv_results.cv_results_['std_test_score']\n",
    "results_df.sort_values('mean', ascending=False, ignore_index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating best model from the best param and train it for 60 epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best score is: 0.9388105273246765 using {'n_dense_2': 256, 'n_dense_1': 256, 'n_conv_3': 512, 'n_conv_2': 512, 'n_conv_1': 512, 'maxpooling_pool_size': 3, 'k_conv_3': 2, 'k_conv_2': 2, 'k_conv_1': 3, 'dropout_2': 0.25, 'dropout_1': 0.3, 'avepooling_pool_size': 3, 'activation_dense': 'elu', 'activation_conv': 'relu'}list(best_param.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_dense_2= 256\n",
    "n_dense_1= 256\n",
    "n_conv_3= 512\n",
    "n_conv_2= 512\n",
    "n_conv_1= 512\n",
    "maxpooling_pool_size= 3\n",
    "k_conv_3= 2\n",
    "k_conv_2= 2\n",
    "k_conv_1= 3\n",
    "dropout_2= 0.25\n",
    "dropout_1= 0.3\n",
    "avepooling_pool_size= 3\n",
    "activation_dense = 'elu'\n",
    "activation_conv = 'relu'\n",
    "model = Sequential()\n",
    "model.add(Conv1D(n_conv_1, k_conv_1, activation=activation_conv, input_shape=input_shape[1:]))\n",
    "model.add(MaxPool1D(pool_size = maxpooling_pool_size))\n",
    "model.add(Conv1D(n_conv_2, k_conv_2, activation=activation_conv))\n",
    "model.add(AveragePooling1D(pool_size = avepooling_pool_size))\n",
    "model.add(Conv1D(n_conv_3, k_conv_3, activation=activation_conv))\n",
    "# model.add(GlobalMaxPooling1D())\n",
    "model.add(GlobalAveragePooling1D())\n",
    "model.add(Dense(n_dense_1, activation=activation_dense))\n",
    "model.add(Dropout(dropout_1))\n",
    "model.add(Dense(n_dense_2, activation=activation_dense))\n",
    "model.add(Dropout(dropout_2))\n",
    "model.add(Dense(n_class, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir= 'model_ouput/tune-sklearn-1'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "modelcheckpoint = ModelCheckpoint(filepath=output_dir+\n",
    "                                  \"/weights.{epoch:02d}.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "228/228 [==============================] - 8s 34ms/step - loss: 0.9290 - accuracy: 0.6087 - val_loss: 0.5920 - val_accuracy: 0.7866\n",
      "Epoch 2/60\n",
      "228/228 [==============================] - 7s 33ms/step - loss: 0.5357 - accuracy: 0.7956 - val_loss: 0.4419 - val_accuracy: 0.8266\n",
      "Epoch 3/60\n",
      "228/228 [==============================] - 7s 33ms/step - loss: 0.4041 - accuracy: 0.8524 - val_loss: 0.3407 - val_accuracy: 0.8845\n",
      "Epoch 4/60\n",
      "228/228 [==============================] - 7s 33ms/step - loss: 0.3545 - accuracy: 0.8677 - val_loss: 0.3052 - val_accuracy: 0.8857\n",
      "Epoch 5/60\n",
      "228/228 [==============================] - 7s 33ms/step - loss: 0.3254 - accuracy: 0.8804 - val_loss: 0.3100 - val_accuracy: 0.8899\n",
      "Epoch 6/60\n",
      "228/228 [==============================] - 7s 33ms/step - loss: 0.3043 - accuracy: 0.8872 - val_loss: 0.2844 - val_accuracy: 0.8950\n",
      "Epoch 7/60\n",
      "228/228 [==============================] - 7s 33ms/step - loss: 0.2807 - accuracy: 0.8964 - val_loss: 0.2526 - val_accuracy: 0.9055\n",
      "Epoch 8/60\n",
      "228/228 [==============================] - 8s 33ms/step - loss: 0.2631 - accuracy: 0.9022 - val_loss: 0.2719 - val_accuracy: 0.8975\n",
      "Epoch 9/60\n",
      "228/228 [==============================] - 8s 33ms/step - loss: 0.2543 - accuracy: 0.9065 - val_loss: 0.2485 - val_accuracy: 0.9087\n",
      "Epoch 10/60\n",
      "228/228 [==============================] - 8s 33ms/step - loss: 0.2442 - accuracy: 0.9115 - val_loss: 0.2516 - val_accuracy: 0.9077\n",
      "Epoch 11/60\n",
      "228/228 [==============================] - 8s 33ms/step - loss: 0.2347 - accuracy: 0.9145 - val_loss: 0.2459 - val_accuracy: 0.9081\n",
      "Epoch 12/60\n",
      "228/228 [==============================] - 8s 33ms/step - loss: 0.2236 - accuracy: 0.9183 - val_loss: 0.2327 - val_accuracy: 0.9138\n",
      "Epoch 13/60\n",
      "228/228 [==============================] - 8s 33ms/step - loss: 0.2170 - accuracy: 0.9202 - val_loss: 0.2113 - val_accuracy: 0.9280\n",
      "Epoch 14/60\n",
      "228/228 [==============================] - 8s 33ms/step - loss: 0.2056 - accuracy: 0.9247 - val_loss: 0.2253 - val_accuracy: 0.9214\n",
      "Epoch 15/60\n",
      "228/228 [==============================] - 8s 33ms/step - loss: 0.2020 - accuracy: 0.9258 - val_loss: 0.2019 - val_accuracy: 0.9267\n",
      "Epoch 16/60\n",
      "228/228 [==============================] - 8s 33ms/step - loss: 0.1943 - accuracy: 0.9290 - val_loss: 0.2121 - val_accuracy: 0.9253\n",
      "Epoch 17/60\n",
      "228/228 [==============================] - 8s 33ms/step - loss: 0.1883 - accuracy: 0.9311 - val_loss: 0.1920 - val_accuracy: 0.9302\n",
      "Epoch 18/60\n",
      "228/228 [==============================] - 8s 33ms/step - loss: 0.1843 - accuracy: 0.9322 - val_loss: 0.2087 - val_accuracy: 0.9284\n",
      "Epoch 19/60\n",
      "228/228 [==============================] - 8s 33ms/step - loss: 0.1780 - accuracy: 0.9354 - val_loss: 0.1936 - val_accuracy: 0.9342\n",
      "Epoch 20/60\n",
      "228/228 [==============================] - 8s 33ms/step - loss: 0.1686 - accuracy: 0.9383 - val_loss: 0.1942 - val_accuracy: 0.9265\n",
      "Epoch 21/60\n",
      "228/228 [==============================] - 8s 33ms/step - loss: 0.1727 - accuracy: 0.9369 - val_loss: 0.2044 - val_accuracy: 0.9274\n",
      "Epoch 22/60\n",
      "228/228 [==============================] - 8s 33ms/step - loss: 0.1655 - accuracy: 0.9398 - val_loss: 0.1895 - val_accuracy: 0.9390\n",
      "Epoch 23/60\n",
      "228/228 [==============================] - 8s 33ms/step - loss: 0.1615 - accuracy: 0.9405 - val_loss: 0.1785 - val_accuracy: 0.9398\n",
      "Epoch 24/60\n",
      "228/228 [==============================] - 8s 33ms/step - loss: 0.1552 - accuracy: 0.9428 - val_loss: 0.1756 - val_accuracy: 0.9401\n",
      "Epoch 25/60\n",
      "228/228 [==============================] - 8s 33ms/step - loss: 0.1517 - accuracy: 0.9444 - val_loss: 0.1850 - val_accuracy: 0.9356\n",
      "Epoch 26/60\n",
      "228/228 [==============================] - 8s 33ms/step - loss: 0.1501 - accuracy: 0.9451 - val_loss: 0.1768 - val_accuracy: 0.9341\n",
      "Epoch 27/60\n",
      "228/228 [==============================] - 8s 33ms/step - loss: 0.1497 - accuracy: 0.9451 - val_loss: 0.1840 - val_accuracy: 0.9367\n",
      "Epoch 28/60\n",
      "228/228 [==============================] - 8s 33ms/step - loss: 0.1408 - accuracy: 0.9478 - val_loss: 0.1712 - val_accuracy: 0.9376\n",
      "Epoch 29/60\n",
      "228/228 [==============================] - 8s 33ms/step - loss: 0.1370 - accuracy: 0.9494 - val_loss: 0.1723 - val_accuracy: 0.9443\n",
      "Epoch 30/60\n",
      "228/228 [==============================] - 8s 33ms/step - loss: 0.1367 - accuracy: 0.9502 - val_loss: 0.1811 - val_accuracy: 0.9432\n",
      "Epoch 31/60\n",
      "228/228 [==============================] - 8s 33ms/step - loss: 0.1294 - accuracy: 0.9519 - val_loss: 0.2296 - val_accuracy: 0.9254\n",
      "Epoch 32/60\n",
      "228/228 [==============================] - 8s 33ms/step - loss: 0.1267 - accuracy: 0.9528 - val_loss: 0.1732 - val_accuracy: 0.9477\n",
      "Epoch 33/60\n",
      "228/228 [==============================] - 8s 33ms/step - loss: 0.1256 - accuracy: 0.9542 - val_loss: 0.1726 - val_accuracy: 0.9421\n",
      "Epoch 34/60\n",
      "228/228 [==============================] - 8s 33ms/step - loss: 0.1238 - accuracy: 0.9543 - val_loss: 0.1761 - val_accuracy: 0.9443\n",
      "Epoch 35/60\n",
      "228/228 [==============================] - 8s 33ms/step - loss: 0.1180 - accuracy: 0.9567 - val_loss: 0.2162 - val_accuracy: 0.9370\n",
      "Epoch 36/60\n",
      "228/228 [==============================] - 8s 34ms/step - loss: 0.1173 - accuracy: 0.9578 - val_loss: 0.1762 - val_accuracy: 0.9464\n",
      "Epoch 37/60\n",
      "228/228 [==============================] - 8s 34ms/step - loss: 0.1129 - accuracy: 0.9588 - val_loss: 0.2001 - val_accuracy: 0.9336\n",
      "Epoch 38/60\n",
      "228/228 [==============================] - 8s 33ms/step - loss: 0.1137 - accuracy: 0.9591 - val_loss: 0.1651 - val_accuracy: 0.9427\n",
      "Epoch 39/60\n",
      "228/228 [==============================] - 8s 34ms/step - loss: 0.1043 - accuracy: 0.9616 - val_loss: 0.1706 - val_accuracy: 0.9487\n",
      "Epoch 40/60\n",
      "228/228 [==============================] - 8s 33ms/step - loss: 0.1088 - accuracy: 0.9604 - val_loss: 0.1596 - val_accuracy: 0.9509\n",
      "Epoch 41/60\n",
      "228/228 [==============================] - 8s 33ms/step - loss: 0.1038 - accuracy: 0.9624 - val_loss: 0.1852 - val_accuracy: 0.9410\n",
      "Epoch 42/60\n",
      "228/228 [==============================] - 8s 33ms/step - loss: 0.1033 - accuracy: 0.9616 - val_loss: 0.1638 - val_accuracy: 0.9486\n",
      "Epoch 43/60\n",
      "228/228 [==============================] - 8s 33ms/step - loss: 0.0995 - accuracy: 0.9628 - val_loss: 0.1738 - val_accuracy: 0.9467\n",
      "Epoch 44/60\n",
      "228/228 [==============================] - 8s 33ms/step - loss: 0.1012 - accuracy: 0.9638 - val_loss: 0.1641 - val_accuracy: 0.9517\n",
      "Epoch 45/60\n",
      "228/228 [==============================] - 8s 33ms/step - loss: 0.0911 - accuracy: 0.9666 - val_loss: 0.1677 - val_accuracy: 0.9504\n",
      "Epoch 46/60\n",
      "228/228 [==============================] - 8s 33ms/step - loss: 0.0983 - accuracy: 0.9642 - val_loss: 0.1717 - val_accuracy: 0.9495\n",
      "Epoch 47/60\n",
      "228/228 [==============================] - 8s 33ms/step - loss: 0.0949 - accuracy: 0.9660 - val_loss: 0.1604 - val_accuracy: 0.9495\n",
      "Epoch 48/60\n",
      "228/228 [==============================] - 8s 33ms/step - loss: 0.0921 - accuracy: 0.9673 - val_loss: 0.1505 - val_accuracy: 0.9538\n",
      "Epoch 49/60\n",
      "228/228 [==============================] - 8s 34ms/step - loss: 0.0924 - accuracy: 0.9662 - val_loss: 0.1616 - val_accuracy: 0.9512\n",
      "Epoch 50/60\n",
      "228/228 [==============================] - 8s 33ms/step - loss: 0.0892 - accuracy: 0.9675 - val_loss: 0.1812 - val_accuracy: 0.9460\n",
      "Epoch 51/60\n",
      "228/228 [==============================] - 8s 33ms/step - loss: 0.0868 - accuracy: 0.9681 - val_loss: 0.1594 - val_accuracy: 0.9543\n",
      "Epoch 52/60\n",
      "228/228 [==============================] - 8s 34ms/step - loss: 0.0866 - accuracy: 0.9694 - val_loss: 0.1822 - val_accuracy: 0.9501\n",
      "Epoch 53/60\n",
      "228/228 [==============================] - 8s 34ms/step - loss: 0.0814 - accuracy: 0.9701 - val_loss: 0.1609 - val_accuracy: 0.9531\n",
      "Epoch 54/60\n",
      "228/228 [==============================] - 8s 34ms/step - loss: 0.0843 - accuracy: 0.9699 - val_loss: 0.1757 - val_accuracy: 0.9501\n",
      "Epoch 55/60\n",
      "228/228 [==============================] - 8s 34ms/step - loss: 0.0807 - accuracy: 0.9709 - val_loss: 0.1571 - val_accuracy: 0.9574\n",
      "Epoch 56/60\n",
      "228/228 [==============================] - 8s 34ms/step - loss: 0.0769 - accuracy: 0.9720 - val_loss: 0.1634 - val_accuracy: 0.9552\n",
      "Epoch 57/60\n",
      "228/228 [==============================] - 8s 34ms/step - loss: 0.0803 - accuracy: 0.9705 - val_loss: 0.1610 - val_accuracy: 0.9534\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/60\n",
      "228/228 [==============================] - 8s 33ms/step - loss: 0.0773 - accuracy: 0.9720 - val_loss: 0.1527 - val_accuracy: 0.9557\n",
      "Epoch 59/60\n",
      "228/228 [==============================] - 8s 33ms/step - loss: 0.0735 - accuracy: 0.9737 - val_loss: 0.1595 - val_accuracy: 0.9577\n",
      "Epoch 60/60\n",
      "228/228 [==============================] - 8s 33ms/step - loss: 0.0768 - accuracy: 0.9726 - val_loss: 0.1647 - val_accuracy: 0.9541\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1fbeb328ac8>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, \n",
    "         batch_size=batch_size, epochs=epochs, verbose=1, \n",
    "         validation_data=(X_valid, y_valid), \n",
    "         callbacks=[modelcheckpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z8t0nVCw8JmP"
   },
   "outputs": [],
   "source": [
    "model.load_weights(output_dir+\"/weights.59.hdf5\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kZwGk5dR8JmS"
   },
   "outputs": [],
   "source": [
    "y_hat = model.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EPc5_h6K8JmW",
    "outputId": "cad99da9-9f89-437f-854b-a315616ed50f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6476"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E_GNq-R_8JmZ",
    "outputId": "0fc16efe-7739-4394-f1a3-46da92e79584"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.7669195e-04, 1.1186725e-06, 5.7920484e-08, 3.1209322e-07,\n",
       "       1.1823817e-05, 9.9900997e-01], dtype=float32)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SFqRQ5XB8Jmc",
    "outputId": "a957fbed-92f8-4bdd-d24b-5df3361a8bac"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 1.], dtype=float32)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FTWf6Cf-8Jme",
    "outputId": "1256b170-33dc-4171-f2ff-7a3d7ddd74e3"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_hat)\n",
    "_ = plt.axvline(x=0.5, color='orange')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RNljSx3v8Jmh"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'99.75'"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pct_auc = roc_auc_score(y_valid, y_hat)*100.0\n",
    "\"{:0.2f}\".format(pct_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SO_N9lJG8Jmj",
    "outputId": "20968a52-8ca0-44d3-abf6-a1382bba5cde"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'95.61'"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_classes = y_hat.round()\n",
    "acc = score(y_valid, y_pred_classes) * 100\n",
    "\"{:0.2f}\".format(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vU3hnA298Jmo"
   },
   "outputs": [],
   "source": [
    "float_y_hat = []\n",
    "for y in y_hat:\n",
    "    float_y_hat.append(y[0:6].round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zrTf-aQl8Jmr"
   },
   "outputs": [],
   "source": [
    "ydf = pd.DataFrame(list(zip(float_y_hat, y_valid)), columns=['y_hat', 'y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zAyKh_mX8Jmu",
    "outputId": "611224b8-f980-47df-d596-9aa3a5811009"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_hat</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.001, 0.0, 0.0, 0.0, 0.0, 0.999]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[0.001, 0.0, 0.0, 0.0, 0.001, 0.998]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  y_hat                               y\n",
       "0    [0.001, 0.0, 0.0, 0.0, 0.0, 0.999]  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0]\n",
       "1        [0.0, 0.0, 1.0, 0.0, 0.0, 0.0]  [0.0, 0.0, 1.0, 0.0, 0.0, 0.0]\n",
       "2        [0.0, 1.0, 0.0, 0.0, 0.0, 0.0]  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0]\n",
       "3        [1.0, 0.0, 0.0, 0.0, 0.0, 0.0]  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
       "4        [0.0, 1.0, 0.0, 0.0, 0.0, 0.0]  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0]\n",
       "5  [0.001, 0.0, 0.0, 0.0, 0.001, 0.998]  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0]\n",
       "6        [0.0, 0.0, 0.0, 1.0, 0.0, 0.0]  [0.0, 0.0, 0.0, 1.0, 0.0, 0.0]\n",
       "7        [0.0, 1.0, 0.0, 0.0, 0.0, 0.0]  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0]\n",
       "8        [1.0, 0.0, 0.0, 0.0, 0.0, 0.0]  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
       "9        [0.0, 1.0, 0.0, 0.0, 0.0, 0.0]  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ydf.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "dense_sentiment_classifier.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
