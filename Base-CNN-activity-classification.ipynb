{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/jonkrohn/DLTFpT/blob/master/notebooks/dense_sentiment_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ahUZuAfz8Jje"
   },
   "source": [
    "# Dense Activity Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Re0ecmVI8Jjk"
   },
   "source": [
    "In this notebook, we build a dense neural net to classify PE activity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ixsGb9tY8Jjm"
   },
   "source": [
    "#### Load dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5At1PKQp8Jjp"
   },
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow.keras.datasets import imdb # new!  # delete later\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences #new!\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, Conv1D, GlobalMaxPooling1D\n",
    "from tensorflow.keras.layers import Embedding # new!\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint # new! \n",
    "import os # new! \n",
    "from sklearn.metrics import roc_auc_score, roc_curve # new!\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt # new!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 12999530604010175751\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 8261215578605472945\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 4022219571\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 2026259895196578640\n",
      "physical_device_desc: \"device: 0, name: Quadro P2000, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 11184852676554901213\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      "]\n",
      "# GPUs Available:  1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.3.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "print(device_lib.list_local_devices())\n",
    "import tensorflow as tf\n",
    "print(\"# GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "tensorflow.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hg5wX2Dd8Jjz"
   },
   "source": [
    "#### Set hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "# encoder = OneHotEncoder()\n",
    "# encoder.fit(label_array)\n",
    "# encoder.categories_\n",
    "\n",
    "# label_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lYLOM99-8Jj2"
   },
   "outputs": [],
   "source": [
    "# output directory name:\n",
    "output_dir = 'model_output/dense'\n",
    "input_dir =  'Z:/Research/dfuller/Walkabilly/studies/smarphone_accel/data/Ethica_Jaeger_Merged/pocket/'\n",
    "input_file_name = 'pocket-NN-data.npz'\n",
    "\n",
    "# from the data preparation section we have:\n",
    "window_size_second = 3\n",
    "frequency = 30\n",
    "lenght_of_each_seq = window_size_second * frequency\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# convolutional layer architecture:\n",
    "n_conv = 64 # filters, a.k.a. kernels\n",
    "k_conv = 3 # kernel length\n",
    "\n",
    "# dense layer architecture: \n",
    "n_dense = 256\n",
    "dropout = 0.2\n",
    "\n",
    "# training:\n",
    "epochs = 30\n",
    "batch_size = 128\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DaLx4yZ48Jj9"
   },
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CD9X0yJg8Jj_"
   },
   "source": [
    "##### For this notebook we use the acceleration data gathered from the pocket location. It was prepared in the DataPrep-Deep notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6r44JKj-8JkA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acceleration_data\n",
      "metadata\n",
      "labels\n"
     ]
    }
   ],
   "source": [
    "# read the raw file and get the keys:\n",
    "raw_data = np.load(file=input_dir+input_file_name,allow_pickle=True)\n",
    "for k in raw_data.keys():\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the data\n",
    "\n",
    "accel_array = raw_data['acceleration_data']\n",
    "meta_array = raw_data['metadata']\n",
    "labels_array = raw_data['labels']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WWq3ipbu8JlG"
   },
   "source": [
    "#### Preprocess data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert the  labels to integer.\n",
    "In the raw data format of the labels is String and there are 6 classes. 'Lying', 'Sitting', 'Self Pace walk', 'Running 3 METs',\n",
    "       'Running 5 METs', 'Running 7 METs' <br>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LyReiequ8Jln"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       ...,\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change from string to integer so keras.to_categorical can consume it\n",
    "\n",
    "# could do with factorize method as well\n",
    "n_class = len(np.unique(labels_array))\n",
    "class_list, labels_array_int = np.unique(labels_array,return_inverse=True)\n",
    "labels_array_int\n",
    "\n",
    "# check if the result is consistant with the original input\n",
    "class_list[labels_array_int].reshape(len(labels_array_int), 1) == labels_array\n",
    "\n",
    "# Note to get the reverse, i.e converting integer array to string use class_list[labels_array_int]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels to categorical\n",
    "\n",
    "y = to_categorical(labels_array_int, num_classes=n_class)\n",
    "input_shape = list(accel_array.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "GscSnCpk8Jlm"
   },
   "source": [
    "\n",
    "#### Design neural network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a conv model!\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(n_conv, k_conv, activation='relu', input_shape=input_shape[1:]))\n",
    "# model.add(Conv1D(n_conv, k_conv, activation='relu'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(n_dense, activation='relu'))\n",
    "model.add(Dropout(dropout))\n",
    "model.add(Dense(n_dense, activation='relu'))\n",
    "model.add(Dropout(dropout))\n",
    "model.add(Dense(n_class, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3nx7eGkg8Jlr",
    "outputId": "76af5145-5c7d-45c1-f292-e9f68a0907a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 88, 64)            640       \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 1542      \n",
      "=================================================================\n",
      "Total params: 84,614\n",
      "Trainable params: 84,614\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "40x3s0KY8Jlv",
    "outputId": "d3ac3e31-3c47-4b01-c2f9-ada0684b31b7"
   },
   "source": [
    "### Splitting and shuffeling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f5grc2H78Jlz",
    "outputId": "3f7eeb55-f851-4796-de4e-0c68eb9df88d"
   },
   "outputs": [],
   "source": [
    "# split and shuffle\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(\n",
    "     accel_array, y, test_size=0.1, random_state=65)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JkbhJMox8Jl9"
   },
   "source": [
    "#### Configure model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QodbQvQh8Jl_"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='nadam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zHjvYe288JmE"
   },
   "outputs": [],
   "source": [
    "modelcheckpoint = ModelCheckpoint(filepath=output_dir+\n",
    "                                  \"/weights.{epoch:02d}.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "esUwodZA8JmI"
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((58278, 90, 3), (58278, 6), (6476, 90, 3), (6476, 6))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.test.gpu_device_name()\n",
    "tf.__version__\n",
    "x_train.shape, y_train.shape, x_valid.shape, y_valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TEYpX7968JmL"
   },
   "source": [
    "#### Train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QaD1W7Ka8JmM",
    "outputId": "f0c30141-0962-48f6-a000-d136af50af79",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "456/456 [==============================] - 2s 4ms/step - loss: 0.4859 - accuracy: 0.8247 - val_loss: 0.4200 - val_accuracy: 0.8515\n",
      "Epoch 2/30\n",
      "456/456 [==============================] - 2s 3ms/step - loss: 0.4488 - accuracy: 0.8395 - val_loss: 0.4335 - val_accuracy: 0.8386\n",
      "Epoch 3/30\n",
      "456/456 [==============================] - 2s 3ms/step - loss: 0.4214 - accuracy: 0.8506 - val_loss: 0.3943 - val_accuracy: 0.8570\n",
      "Epoch 4/30\n",
      "456/456 [==============================] - 2s 4ms/step - loss: 0.3998 - accuracy: 0.8564 - val_loss: 0.3642 - val_accuracy: 0.8743\n",
      "Epoch 5/30\n",
      "456/456 [==============================] - 2s 3ms/step - loss: 0.3829 - accuracy: 0.8621 - val_loss: 0.3283 - val_accuracy: 0.8802\n",
      "Epoch 6/30\n",
      "456/456 [==============================] - 2s 3ms/step - loss: 0.3671 - accuracy: 0.8684 - val_loss: 0.3159 - val_accuracy: 0.8834\n",
      "Epoch 7/30\n",
      "456/456 [==============================] - 2s 3ms/step - loss: 0.3512 - accuracy: 0.8725 - val_loss: 0.3173 - val_accuracy: 0.8894\n",
      "Epoch 8/30\n",
      "456/456 [==============================] - 2s 3ms/step - loss: 0.3438 - accuracy: 0.8753 - val_loss: 0.3066 - val_accuracy: 0.8935\n",
      "Epoch 9/30\n",
      "456/456 [==============================] - 2s 3ms/step - loss: 0.3335 - accuracy: 0.8790 - val_loss: 0.3004 - val_accuracy: 0.8947\n",
      "Epoch 10/30\n",
      "456/456 [==============================] - 2s 4ms/step - loss: 0.3241 - accuracy: 0.8831 - val_loss: 0.2869 - val_accuracy: 0.8942\n",
      "Epoch 11/30\n",
      "456/456 [==============================] - 2s 4ms/step - loss: 0.3134 - accuracy: 0.8864 - val_loss: 0.3102 - val_accuracy: 0.8851\n",
      "Epoch 12/30\n",
      "456/456 [==============================] - 2s 3ms/step - loss: 0.3095 - accuracy: 0.8870 - val_loss: 0.2778 - val_accuracy: 0.8979\n",
      "Epoch 13/30\n",
      "456/456 [==============================] - 2s 3ms/step - loss: 0.2998 - accuracy: 0.8901 - val_loss: 0.2680 - val_accuracy: 0.9016\n",
      "Epoch 14/30\n",
      "456/456 [==============================] - 2s 4ms/step - loss: 0.2955 - accuracy: 0.8933 - val_loss: 0.2712 - val_accuracy: 0.8992\n",
      "Epoch 15/30\n",
      "456/456 [==============================] - 2s 4ms/step - loss: 0.2911 - accuracy: 0.8937 - val_loss: 0.2695 - val_accuracy: 0.9043\n",
      "Epoch 16/30\n",
      "456/456 [==============================] - 2s 3ms/step - loss: 0.2845 - accuracy: 0.8975 - val_loss: 0.2684 - val_accuracy: 0.8990\n",
      "Epoch 17/30\n",
      "456/456 [==============================] - 2s 3ms/step - loss: 0.2817 - accuracy: 0.8972 - val_loss: 0.2574 - val_accuracy: 0.9040\n",
      "Epoch 18/30\n",
      "456/456 [==============================] - 2s 3ms/step - loss: 0.2761 - accuracy: 0.8997 - val_loss: 0.2587 - val_accuracy: 0.9049\n",
      "Epoch 19/30\n",
      "456/456 [==============================] - 2s 3ms/step - loss: 0.2724 - accuracy: 0.9013 - val_loss: 0.2490 - val_accuracy: 0.9083\n",
      "Epoch 20/30\n",
      "456/456 [==============================] - 2s 3ms/step - loss: 0.2681 - accuracy: 0.9024 - val_loss: 0.2464 - val_accuracy: 0.9123\n",
      "Epoch 21/30\n",
      "456/456 [==============================] - 2s 4ms/step - loss: 0.2657 - accuracy: 0.9031 - val_loss: 0.2420 - val_accuracy: 0.9158\n",
      "Epoch 22/30\n",
      "456/456 [==============================] - 2s 3ms/step - loss: 0.2617 - accuracy: 0.9036 - val_loss: 0.2451 - val_accuracy: 0.9084\n",
      "Epoch 23/30\n",
      "456/456 [==============================] - 2s 4ms/step - loss: 0.2569 - accuracy: 0.9057 - val_loss: 0.2379 - val_accuracy: 0.9189\n",
      "Epoch 24/30\n",
      "456/456 [==============================] - 2s 4ms/step - loss: 0.2538 - accuracy: 0.9078 - val_loss: 0.2293 - val_accuracy: 0.9174\n",
      "Epoch 25/30\n",
      "456/456 [==============================] - 2s 3ms/step - loss: 0.2520 - accuracy: 0.9092 - val_loss: 0.2277 - val_accuracy: 0.9185\n",
      "Epoch 26/30\n",
      "456/456 [==============================] - 2s 4ms/step - loss: 0.2461 - accuracy: 0.9097 - val_loss: 0.2320 - val_accuracy: 0.9185\n",
      "Epoch 27/30\n",
      "456/456 [==============================] - 2s 4ms/step - loss: 0.2444 - accuracy: 0.9111 - val_loss: 0.2299 - val_accuracy: 0.9217\n",
      "Epoch 28/30\n",
      "456/456 [==============================] - 2s 4ms/step - loss: 0.2404 - accuracy: 0.9122 - val_loss: 0.2305 - val_accuracy: 0.9216\n",
      "Epoch 29/30\n",
      "456/456 [==============================] - 2s 3ms/step - loss: 0.2403 - accuracy: 0.9129 - val_loss: 0.2237 - val_accuracy: 0.9172\n",
      "Epoch 30/30\n",
      "456/456 [==============================] - 2s 4ms/step - loss: 0.2394 - accuracy: 0.9125 - val_loss: 0.2218 - val_accuracy: 0.9239\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ebdc2b2278>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, \n",
    "         batch_size=batch_size, epochs=epochs, verbose=1, \n",
    "         validation_data=(x_valid, y_valid), \n",
    "         callbacks=[modelcheckpoint])\n",
    "\n",
    "# model.fit(x_train, y_train, \n",
    "#           batch_size=batch_size, epochs=epochs, verbose=1, \n",
    "#           validation_data=(x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7PWlH5SJ8JmP"
   },
   "source": [
    "#### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z8t0nVCw8JmP"
   },
   "outputs": [],
   "source": [
    "# model.load_weights(output_dir+\"/weights.02.hdf5\") # NOT zero-indexed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kZwGk5dR8JmS"
   },
   "outputs": [],
   "source": [
    "y_hat = model.predict(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EPc5_h6K8JmW",
    "outputId": "cad99da9-9f89-437f-854b-a315616ed50f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7040"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E_GNq-R_8JmZ",
    "outputId": "0fc16efe-7739-4394-f1a3-46da92e79584"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.3900741e-01, 2.3661785e-07, 2.7467215e-07, 3.5306093e-05,\n",
       "       1.0925921e-09, 7.6095676e-01], dtype=float32)"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SFqRQ5XB8Jmc",
    "outputId": "a957fbed-92f8-4bdd-d24b-5df3361a8bac"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 1.], dtype=float32)"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FTWf6Cf-8Jme",
    "outputId": "1256b170-33dc-4171-f2ff-7a3d7ddd74e3"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_hat)\n",
    "_ = plt.axvline(x=0.5, color='orange')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RNljSx3v8Jmh"
   },
   "outputs": [],
   "source": [
    "pct_auc = roc_auc_score(y_valid, y_hat)*100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SO_N9lJG8Jmj",
    "outputId": "20968a52-8ca0-44d3-abf6-a1382bba5cde"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'99.40'"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"{:0.2f}\".format(pct_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vU3hnA298Jmo"
   },
   "outputs": [],
   "source": [
    "float_y_hat = []\n",
    "for y in y_hat:\n",
    "    float_y_hat.append(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zrTf-aQl8Jmr"
   },
   "outputs": [],
   "source": [
    "ydf = pd.DataFrame(list(zip(float_y_hat, y_valid)), columns=['y_hat', 'y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zAyKh_mX8Jmu",
    "outputId": "611224b8-f980-47df-d596-9aa3a5811009"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_hat</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.390074e-01</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.455001e-04</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.522904e-03</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.519241e-10</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.942215e-01</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.289968e-03</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.869331e-01</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.000041e-02</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.545678e-01</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6.445088e-01</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          y_hat                               y\n",
       "0  2.390074e-01  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0]\n",
       "1  4.455001e-04  [0.0, 0.0, 1.0, 0.0, 0.0, 0.0]\n",
       "2  6.522904e-03  [0.0, 0.0, 0.0, 0.0, 1.0, 0.0]\n",
       "3  2.519241e-10  [0.0, 0.0, 0.0, 1.0, 0.0, 0.0]\n",
       "4  9.942215e-01  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
       "5  2.289968e-03  [0.0, 0.0, 1.0, 0.0, 0.0, 0.0]\n",
       "6  4.869331e-01  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0]\n",
       "7  1.000041e-02  [0.0, 0.0, 0.0, 1.0, 0.0, 0.0]\n",
       "8  1.545678e-01  [0.0, 0.0, 0.0, 0.0, 1.0, 0.0]\n",
       "9  6.445088e-01  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ydf.head(10)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "dense_sentiment_classifier.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
