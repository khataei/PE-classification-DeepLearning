{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ahUZuAfz8Jje"
   },
   "source": [
    "# Sklearn Tuner for CNN Activity Classifier - V3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Re0ecmVI8Jjk"
   },
   "source": [
    "In this notebook, we use SKlearn  to tune a CNN neural net to classify PE activity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ixsGb9tY8Jjm"
   },
   "source": [
    "#### Load dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5At1PKQp8Jjp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 9231755697673437919\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 4783861506879629581\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 4022219571\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 18018878115323770423\n",
      "physical_device_desc: \"device: 0, name: Quadro P2000, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 16828206419121335104\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      "]\n",
      "# GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import os  \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "import tensorflow\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, Conv1D, GlobalMaxPooling1D\n",
    "from tensorflow.keras.layers import AveragePooling1D, LeakyReLU , MaxPool1D, GlobalAveragePooling1D\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint \n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, roc_curve \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "print(device_lib.list_local_devices())\n",
    "import tensorflow as tf\n",
    "print(\"# GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "import sklearn\n",
    "# bug in sklearn wrapper\n",
    "#https://stackoverflow.com/questions/59746974/cannot-clone-object-tensorflow-python-keras-wrappers-scikit-learn-kerasclassifi\n",
    "if sklearn.__version__ != '0.21.2':\n",
    "    print(\"updating sklearn ...\")\n",
    "    !pip install --user scikit-learn==0.21.2\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hg5wX2Dd8Jjz"
   },
   "source": [
    "#### Set hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lYLOM99-8Jj2"
   },
   "outputs": [],
   "source": [
    "# output directory name:\n",
    "output_dir = 'model_output/tunecnn-sklearn-2'\n",
    "input_dir =  'Z:/Research/dfuller/Walkabilly/studies/smarphone_accel/data/Ethica_Jaeger_Merged/pocket/'\n",
    "input_file_name = 'pocket-NN-data.npz'\n",
    "\n",
    "# from the data preparation section we have:\n",
    "window_size_second = 3\n",
    "frequency = 30\n",
    "lenght_of_each_seq = window_size_second * frequency\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn hyperparams\n",
    "params = {\n",
    "    'n_conv_1':[512, 768], # filters, a.k.a. kernels\n",
    "    'k_conv_1':[2, 3], # kernel length\n",
    "    'n_conv_2':[256, 512], # filters, a.k.a. kernels\n",
    "    'k_conv_2':[2, 3], # kernel length\n",
    "    'n_conv_3':[256, 512], # filters, a.k.a. kernels\n",
    "    'k_conv_3':[2, 3], # kernel length\n",
    "    'maxpooling_pool_size':[3, 5],\n",
    "    'avepooling_pool_size':[3, 5],\n",
    "    'n_dense_1':[256, 384, 512],\n",
    "    'dropout_1':[0.2, 0.3],\n",
    "    'n_dense_2':[256, 384, 512],\n",
    "    'dropout_2':[0.2, 0.3],\n",
    "    'activation_conv':['elu', 'relu', LeakyReLU()],\n",
    "    'activation_dense':['elu', 'relu', LeakyReLU()]\n",
    "}\n",
    "\n",
    "# training:\n",
    "n_tune_iter = 20\n",
    "cv = 3\n",
    "epochs = 60\n",
    "batch_size = 256\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DaLx4yZ48Jj9"
   },
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CD9X0yJg8Jj_"
   },
   "source": [
    "##### For this notebook we use the acceleration data gathered from the pocket location. It was prepared in the DataPrep-Deep notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6r44JKj-8JkA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acceleration_data\n",
      "metadata\n",
      "labels\n"
     ]
    }
   ],
   "source": [
    "# read the raw file and get the keys:\n",
    "raw_data = np.load(file=input_dir+input_file_name,allow_pickle=True)\n",
    "for k in raw_data.keys():\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the data\n",
    "\n",
    "accel_array = raw_data['acceleration_data']\n",
    "meta_array = raw_data['metadata']\n",
    "labels_array = raw_data['labels']\n",
    "input_shape = list(accel_array.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WWq3ipbu8JlG"
   },
   "source": [
    "#### Preprocess data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert the  labels to integer.\n",
    "In the raw data format of the labels is String and there are 6 classes. 'Lying', 'Sitting', 'Self Pace walk', 'Running 3 METs',\n",
    "       'Running 5 METs', 'Running 7 METs' <br>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LyReiequ8Jln"
   },
   "outputs": [],
   "source": [
    "n_class = len(np.unique(labels_array))\n",
    "class_list, labels_array_int = np.unique(labels_array,return_inverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = to_categorical(labels_array_int, num_classes=n_class)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "40x3s0KY8Jlv",
    "outputId": "d3ac3e31-3c47-4b01-c2f9-ada0684b31b7"
   },
   "source": [
    "### Splitting and shuffeling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f5grc2H78Jlz",
    "outputId": "3f7eeb55-f851-4796-de4e-0c68eb9df88d"
   },
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "     accel_array, y, test_size=0.1, random_state=65)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "GscSnCpk8Jlm"
   },
   "source": [
    "\n",
    "#### Design neural network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_conv_1': [512, 768],\n",
       " 'k_conv_1': [2, 3],\n",
       " 'n_conv_2': [256, 512],\n",
       " 'k_conv_2': [2, 3],\n",
       " 'n_conv_3': [256, 512],\n",
       " 'k_conv_3': [2, 3],\n",
       " 'maxpooling_pool_size': [3, 5],\n",
       " 'avepooling_pool_size': [3, 5],\n",
       " 'n_dense_1': [256, 384, 512],\n",
       " 'dropout_1': [0.2, 0.3],\n",
       " 'n_dense_2': [256, 384, 512],\n",
       " 'dropout_2': [0.2, 0.3],\n",
       " 'activation_conv': ['elu',\n",
       "  'relu',\n",
       "  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU at 0x1d5ae3cd8c8>],\n",
       " 'activation_dense': ['elu',\n",
       "  'relu',\n",
       "  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU at 0x1d5b5607388>]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(n_conv_1=256, k_conv_1=3, n_conv_2=256, k_conv_2=3, n_conv_3=256, k_conv_3=3,\n",
    "                 maxpooling_pool_size = 2, avepooling_pool_size = 2, n_dense_1=256, dropout_1=0.2,\n",
    "                 n_dense_2=256, dropout_2=0.2, activation_conv= 'relu', activation_dense= 'elu'\n",
    "                ):\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(n_conv_1, k_conv_1, activation=activation_conv, input_shape=input_shape[1:]))\n",
    "    model.add(MaxPool1D(pool_size = maxpooling_pool_size))\n",
    "    model.add(Conv1D(n_conv_2, k_conv_2, activation=activation_conv))\n",
    "    model.add(AveragePooling1D(pool_size = avepooling_pool_size))\n",
    "    model.add(Conv1D(n_conv_3, k_conv_3, activation=activation_conv))\n",
    "    # model.add(GlobalMaxPooling1D())\n",
    "    model.add(GlobalAveragePooling1D())\n",
    "    model.add(Dense(n_dense_1, activation=activation_dense))\n",
    "    model.add(Dropout(dropout_1))\n",
    "    model.add(Dense(n_dense_2, activation=activation_dense))\n",
    "    model.add(Dropout(dropout_2))\n",
    "    model.add(Dense(n_class, activation='softmax'))\n",
    "    model.summary()\n",
    "    print(f\"\"\"n_conv_1 = {n_conv_1}, k_conv_1 = {k_conv_1},  n_conv_2 = {n_conv_2}, k_conv_2 = {k_conv_2}, \n",
    "          n_conv_3 = {n_conv_3},  k_conv_3 = {k_conv_3},  maxpooling_pool_size = {maxpooling_pool_size},\n",
    "          avepooling_pool_size = {avepooling_pool_size},  n_dense_1 = {n_dense_1}, dropout_1 = {dropout_1},\n",
    "          n_dense_2 = {n_dense_2}, dropout_2 = {dropout_2}, activation_conv=  {activation_conv},\n",
    "          activation_dense=  {activation_dense}\"\"\")\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 88, 256)           2560      \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 44, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 42, 256)           196864    \n",
      "_________________________________________________________________\n",
      "average_pooling1d (AveragePo (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 19, 256)           196864    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 1542      \n",
      "=================================================================\n",
      "Total params: 529,414\n",
      "Trainable params: 529,414\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 256, k_conv_1 = 3,  n_conv_2 = 256, k_conv_2 = 3, \n",
      "          n_conv_3 = 256,  k_conv_3 = 3,  maxpooling_pool_size = 2,\n",
      "          avepooling_pool_size = 2,  n_dense_1 = 256, dropout_1 = 0.2,\n",
      "          n_dense_2 = 256, dropout_2 = 0.2, activation_conv=  relu,\n",
      "          activation_dense=  elu\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 88, 256)           2560      \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 44, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 42, 256)           196864    \n",
      "_________________________________________________________________\n",
      "average_pooling1d (AveragePo (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 19, 256)           196864    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 1542      \n",
      "=================================================================\n",
      "Total params: 529,414\n",
      "Trainable params: 529,414\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_default = create_model()\n",
    "model_default.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasClassifier(build_fn=create_model, epochs=epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_3 (Conv1D)            (None, 88, 512)           5120      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 29, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 28, 512)           524800    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average (None, 5, 512)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 3, 512)            786944    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_1 ( (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 6)                 3078      \n",
      "=================================================================\n",
      "Total params: 1,582,854\n",
      "Trainable params: 1,582,854\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 512, k_conv_1 = 3,  n_conv_2 = 512, k_conv_2 = 2, \n",
      "          n_conv_3 = 512,  k_conv_3 = 3,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 5,  n_dense_1 = 256, dropout_1 = 0.2,\n",
      "          n_dense_2 = 512, dropout_2 = 0.2, activation_conv=  relu,\n",
      "          activation_dense=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001D5B5607388>\n",
      "Epoch 1/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 1.0542 - accuracy: 0.5543\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.6501 - accuracy: 0.7461\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.4977 - accuracy: 0.8120\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.4150 - accuracy: 0.8456\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.3764 - accuracy: 0.8606\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.3439 - accuracy: 0.8711\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.3286 - accuracy: 0.8748\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.3131 - accuracy: 0.8827\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2938 - accuracy: 0.8889\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2770 - accuracy: 0.8959\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2751 - accuracy: 0.8975\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2660 - accuracy: 0.8995\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2553 - accuracy: 0.9031\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2365 - accuracy: 0.9099\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2333 - accuracy: 0.9108\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2259 - accuracy: 0.9149\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2072 - accuracy: 0.9213\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2107 - accuracy: 0.9213\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.1992 - accuracy: 0.9247\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2037 - accuracy: 0.9237\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.1859 - accuracy: 0.9293\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.1868 - accuracy: 0.9304\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.1756 - accuracy: 0.9328\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.1730 - accuracy: 0.9353\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.1697 - accuracy: 0.9348\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.1709 - accuracy: 0.9344\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.1731 - accuracy: 0.9352\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.1630 - accuracy: 0.9381\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.1455 - accuracy: 0.9441\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.1510 - accuracy: 0.9417\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.1460 - accuracy: 0.9432\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.1390 - accuracy: 0.9461\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.1421 - accuracy: 0.9459\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.1383 - accuracy: 0.9457\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.1328 - accuracy: 0.9486\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.1296 - accuracy: 0.9502\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.1303 - accuracy: 0.9498\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.1212 - accuracy: 0.9540\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.1225 - accuracy: 0.9527\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.1169 - accuracy: 0.9550\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.1164 - accuracy: 0.9542\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.1160 - accuracy: 0.9562\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.1068 - accuracy: 0.9595\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.1062 - accuracy: 0.9599\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.1046 - accuracy: 0.9596\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.1062 - accuracy: 0.9587\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.1095 - accuracy: 0.9575\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.1021 - accuracy: 0.9609\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.1013 - accuracy: 0.9613\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.0913 - accuracy: 0.9647\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.0967 - accuracy: 0.9639\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.1011 - accuracy: 0.9619\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.0925 - accuracy: 0.9659\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.0903 - accuracy: 0.9659\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.0923 - accuracy: 0.9650\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.0884 - accuracy: 0.9666\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.0849 - accuracy: 0.9669\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.0890 - accuracy: 0.9677\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.0838 - accuracy: 0.9687\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.0784 - accuracy: 0.9703\n",
      "76/76 [==============================] - 1s 15ms/step - loss: 0.3034 - accuracy: 0.9367\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_6 (Conv1D)            (None, 88, 512)           5120      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 29, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 28, 512)           524800    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_2 (Average (None, 5, 512)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 3, 512)            786944    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_2 ( (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 6)                 3078      \n",
      "=================================================================\n",
      "Total params: 1,582,854\n",
      "Trainable params: 1,582,854\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 512, k_conv_1 = 3,  n_conv_2 = 512, k_conv_2 = 2, \n",
      "          n_conv_3 = 512,  k_conv_3 = 3,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 5,  n_dense_1 = 256, dropout_1 = 0.2,\n",
      "          n_dense_2 = 512, dropout_2 = 0.2, activation_conv=  relu,\n",
      "          activation_dense=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001D5B5607388>\n",
      "Epoch 1/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 1.0699 - accuracy: 0.5485\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.6769 - accuracy: 0.7363\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.4946 - accuracy: 0.8163\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.4189 - accuracy: 0.8431\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.3642 - accuracy: 0.8639\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.3457 - accuracy: 0.8688\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.3235 - accuracy: 0.8781\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.3105 - accuracy: 0.8804\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2899 - accuracy: 0.8885\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2740 - accuracy: 0.8943\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2682 - accuracy: 0.8962\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2641 - accuracy: 0.8991\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2450 - accuracy: 0.9076\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2294 - accuracy: 0.9124\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2361 - accuracy: 0.9092\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2227 - accuracy: 0.9162\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2190 - accuracy: 0.9186\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.1997 - accuracy: 0.9244\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2016 - accuracy: 0.9253\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2020 - accuracy: 0.9237\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.1837 - accuracy: 0.9305\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.1857 - accuracy: 0.9309\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.1757 - accuracy: 0.9346\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.1713 - accuracy: 0.9356\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.1689 - accuracy: 0.9359\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.1628 - accuracy: 0.9381\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.1615 - accuracy: 0.9392\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.1459 - accuracy: 0.9441\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.1503 - accuracy: 0.9435\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.1416 - accuracy: 0.9466\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.1415 - accuracy: 0.9464\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.1388 - accuracy: 0.9469\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.1270 - accuracy: 0.9512\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.1316 - accuracy: 0.9502\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.1278 - accuracy: 0.9519\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.1372 - accuracy: 0.9493\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.1153 - accuracy: 0.9555\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.1107 - accuracy: 0.9582\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.1143 - accuracy: 0.9563\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.1136 - accuracy: 0.9562\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - ETA: 0s - loss: 0.1118 - accuracy: 0.95 - 5s 30ms/step - loss: 0.1116 - accuracy: 0.9584\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.1116 - accuracy: 0.9577\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.1031 - accuracy: 0.9609\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.0967 - accuracy: 0.9629 0s - loss: 0.0966 - accu\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.0984 - accuracy: 0.9641 0s - loss: 0.0984 - accuracy: \n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.1016 - accuracy: 0.9623\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.1039 - accuracy: 0.9602\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.1035 - accuracy: 0.9615\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.0924 - accuracy: 0.9652\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.0980 - accuracy: 0.9617\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.0930 - accuracy: 0.9639 0s - loss: 0.0931 - accuracy: 0.96\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.0894 - accuracy: 0.9659\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.0895 - accuracy: 0.9675\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.0793 - accuracy: 0.9693\n",
      "Epoch 55/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 5s 30ms/step - loss: 0.0879 - accuracy: 0.9664 0s - loss: 0.0887 - accu\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.0931 - accuracy: 0.9658\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.0802 - accuracy: 0.9704\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.0802 - accuracy: 0.9691\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.0758 - accuracy: 0.9711\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.0800 - accuracy: 0.9703\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 0.3421 - accuracy: 0.9294\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_9 (Conv1D)            (None, 88, 512)           5120      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 29, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_10 (Conv1D)           (None, 28, 512)           524800    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_3 (Average (None, 5, 512)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 3, 512)            786944    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_3 ( (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 6)                 3078      \n",
      "=================================================================\n",
      "Total params: 1,582,854\n",
      "Trainable params: 1,582,854\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 512, k_conv_1 = 3,  n_conv_2 = 512, k_conv_2 = 2, \n",
      "          n_conv_3 = 512,  k_conv_3 = 3,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 5,  n_dense_1 = 256, dropout_1 = 0.2,\n",
      "          n_dense_2 = 512, dropout_2 = 0.2, activation_conv=  relu,\n",
      "          activation_dense=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001D5B5607388>\n",
      "Epoch 1/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 1.0599 - accuracy: 0.5507\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.6625 - accuracy: 0.7429\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.4928 - accuracy: 0.8141\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.4218 - accuracy: 0.8423\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.3673 - accuracy: 0.8617\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.3453 - accuracy: 0.8700\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.3181 - accuracy: 0.8783\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.3072 - accuracy: 0.8828\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2846 - accuracy: 0.8922\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2710 - accuracy: 0.8971\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2698 - accuracy: 0.8984\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2552 - accuracy: 0.9041\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2446 - accuracy: 0.9059\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2321 - accuracy: 0.9105\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2355 - accuracy: 0.9116\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2193 - accuracy: 0.9174\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2133 - accuracy: 0.9190\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2077 - accuracy: 0.9204\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2007 - accuracy: 0.9231\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.1917 - accuracy: 0.9282\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.1838 - accuracy: 0.9308\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.1859 - accuracy: 0.9305\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.1768 - accuracy: 0.9329\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.1715 - accuracy: 0.9349\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.1611 - accuracy: 0.9389\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.1615 - accuracy: 0.9383\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.1616 - accuracy: 0.9382\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.1519 - accuracy: 0.9424\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.1453 - accuracy: 0.9447\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.1348 - accuracy: 0.9479\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.1378 - accuracy: 0.9472\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.1424 - accuracy: 0.9478\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.1390 - accuracy: 0.9486\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.1298 - accuracy: 0.9507\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - ETA: 0s - loss: 0.1278 - accuracy: 0.95 - 5s 30ms/step - loss: 0.1278 - accuracy: 0.9515\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.1277 - accuracy: 0.9515\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.1185 - accuracy: 0.9556\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.1276 - accuracy: 0.9516\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.1211 - accuracy: 0.9531\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.1152 - accuracy: 0.9567\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.1200 - accuracy: 0.9550\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.1147 - accuracy: 0.9571\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.1048 - accuracy: 0.9593\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.1066 - accuracy: 0.9589\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.1075 - accuracy: 0.9606\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.1059 - accuracy: 0.9600\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.0955 - accuracy: 0.9643\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.0906 - accuracy: 0.9655\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.0945 - accuracy: 0.9650\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.0985 - accuracy: 0.9628\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.0952 - accuracy: 0.9645\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.0928 - accuracy: 0.9645\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.0885 - accuracy: 0.9677\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.0868 - accuracy: 0.9679\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.0880 - accuracy: 0.9686\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.0833 - accuracy: 0.9687\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.0854 - accuracy: 0.9686\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.0864 - accuracy: 0.9672\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.0823 - accuracy: 0.9695\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.0809 - accuracy: 0.9698\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 0.3065 - accuracy: 0.9391\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_12 (Conv1D)           (None, 88, 512)           5120      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 29, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_13 (Conv1D)           (None, 28, 256)           262400    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_4 (Average (None, 5, 256)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 3, 256)            196864    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_4 ( (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 384)               98688     \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 384)               147840    \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 6)                 2310      \n",
      "=================================================================\n",
      "Total params: 713,222\n",
      "Trainable params: 713,222\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 512, k_conv_1 = 3,  n_conv_2 = 256, k_conv_2 = 2, \n",
      "          n_conv_3 = 256,  k_conv_3 = 3,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 5,  n_dense_1 = 384, dropout_1 = 0.2,\n",
      "          n_dense_2 = 384, dropout_2 = 0.2, activation_conv=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001D5AE3CD8C8>,\n",
      "          activation_dense=  relu\n",
      "Epoch 1/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 1.1174 - accuracy: 0.5272\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.8205 - accuracy: 0.6597\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.6576 - accuracy: 0.7379\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.6062 - accuracy: 0.7616\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.5356 - accuracy: 0.7923\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.5086 - accuracy: 0.8021\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.4853 - accuracy: 0.8106\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.4522 - accuracy: 0.8265\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.4354 - accuracy: 0.8331\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.4272 - accuracy: 0.8358\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.4065 - accuracy: 0.8438\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3992 - accuracy: 0.8459\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3738 - accuracy: 0.8575\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3719 - accuracy: 0.8567\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3855 - accuracy: 0.8516\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3540 - accuracy: 0.8646\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3514 - accuracy: 0.8637\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3463 - accuracy: 0.8660\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3430 - accuracy: 0.8689\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3268 - accuracy: 0.8740\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3296 - accuracy: 0.8706\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3247 - accuracy: 0.8712\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3180 - accuracy: 0.8752\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3260 - accuracy: 0.8730\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3252 - accuracy: 0.8727\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3154 - accuracy: 0.8781\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3048 - accuracy: 0.8814\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3004 - accuracy: 0.8792\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.2973 - accuracy: 0.8834\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.2988 - accuracy: 0.8826\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.2942 - accuracy: 0.8840\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.2873 - accuracy: 0.8874\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.2862 - accuracy: 0.8897\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.2995 - accuracy: 0.8828\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.2782 - accuracy: 0.8889\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.2699 - accuracy: 0.8957\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.2791 - accuracy: 0.8917\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.2691 - accuracy: 0.8948\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.2647 - accuracy: 0.8979\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.2647 - accuracy: 0.8966\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.2666 - accuracy: 0.8963\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.2617 - accuracy: 0.8988\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.2619 - accuracy: 0.8977\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.2488 - accuracy: 0.9035\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.2609 - accuracy: 0.8993\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.2577 - accuracy: 0.9018\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.2495 - accuracy: 0.9024\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.2466 - accuracy: 0.9051\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.2424 - accuracy: 0.9049\n",
      "Epoch 50/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 3s 23ms/step - loss: 0.2408 - accuracy: 0.9077\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.2503 - accuracy: 0.9025\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.2342 - accuracy: 0.9102\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.2443 - accuracy: 0.9063\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.2387 - accuracy: 0.9080\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.2341 - accuracy: 0.9106\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.2262 - accuracy: 0.9114\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.2353 - accuracy: 0.9103\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.2258 - accuracy: 0.9137\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.2314 - accuracy: 0.9115\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.2202 - accuracy: 0.9154\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 0.3136 - accuracy: 0.8963\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_15 (Conv1D)           (None, 88, 512)           5120      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 29, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_16 (Conv1D)           (None, 28, 256)           262400    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_5 (Average (None, 5, 256)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_17 (Conv1D)           (None, 3, 256)            196864    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_5 ( (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 384)               98688     \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 384)               147840    \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 6)                 2310      \n",
      "=================================================================\n",
      "Total params: 713,222\n",
      "Trainable params: 713,222\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 512, k_conv_1 = 3,  n_conv_2 = 256, k_conv_2 = 2, \n",
      "          n_conv_3 = 256,  k_conv_3 = 3,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 5,  n_dense_1 = 384, dropout_1 = 0.2,\n",
      "          n_dense_2 = 384, dropout_2 = 0.2, activation_conv=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001D5AE3CD8C8>,\n",
      "          activation_dense=  relu\n",
      "Epoch 1/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 1.1136 - accuracy: 0.5254\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.8317 - accuracy: 0.6524\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.6703 - accuracy: 0.7322\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.5967 - accuracy: 0.7643\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.5311 - accuracy: 0.7924\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.5035 - accuracy: 0.8035\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.4675 - accuracy: 0.8178\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.4395 - accuracy: 0.8290\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.4229 - accuracy: 0.8372\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3967 - accuracy: 0.8487\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3994 - accuracy: 0.8458\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3830 - accuracy: 0.8527\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3635 - accuracy: 0.8582\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3658 - accuracy: 0.8573\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3552 - accuracy: 0.8608\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3519 - accuracy: 0.8635\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3461 - accuracy: 0.8657\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3357 - accuracy: 0.8698\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3300 - accuracy: 0.8699\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3330 - accuracy: 0.8708\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3241 - accuracy: 0.8730\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3286 - accuracy: 0.8720\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3179 - accuracy: 0.8751\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3228 - accuracy: 0.8738\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3134 - accuracy: 0.8757\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.2988 - accuracy: 0.8804\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.2990 - accuracy: 0.8822\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3093 - accuracy: 0.8798\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.2990 - accuracy: 0.8823\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.2850 - accuracy: 0.8886\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.2860 - accuracy: 0.8871\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.2927 - accuracy: 0.8847\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.2839 - accuracy: 0.8875\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.2799 - accuracy: 0.8916\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.2746 - accuracy: 0.8923\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.2769 - accuracy: 0.8914\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.2686 - accuracy: 0.8956\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.2750 - accuracy: 0.8934\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.2674 - accuracy: 0.8971\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.2734 - accuracy: 0.8939\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.2508 - accuracy: 0.9027\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.2614 - accuracy: 0.8976\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.2539 - accuracy: 0.8999\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.2611 - accuracy: 0.8990\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.2483 - accuracy: 0.9019\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.2523 - accuracy: 0.9026\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.2470 - accuracy: 0.9059\n",
      "Epoch 48/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 3s 23ms/step - loss: 0.2394 - accuracy: 0.9094\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.2409 - accuracy: 0.9061\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.2438 - accuracy: 0.9049\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.2303 - accuracy: 0.9106\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.2399 - accuracy: 0.9082\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.2353 - accuracy: 0.9084\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.2295 - accuracy: 0.9101\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.2251 - accuracy: 0.9141\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.2287 - accuracy: 0.9128\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.2230 - accuracy: 0.9147\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.2213 - accuracy: 0.9161\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.2150 - accuracy: 0.9171\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.2201 - accuracy: 0.9170\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.2593 - accuracy: 0.9152\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_18 (Conv1D)           (None, 88, 512)           5120      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 29, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_19 (Conv1D)           (None, 28, 256)           262400    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_6 (Average (None, 5, 256)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_20 (Conv1D)           (None, 3, 256)            196864    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_6 ( (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 384)               98688     \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 384)               147840    \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 6)                 2310      \n",
      "=================================================================\n",
      "Total params: 713,222\n",
      "Trainable params: 713,222\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 512, k_conv_1 = 3,  n_conv_2 = 256, k_conv_2 = 2, \n",
      "          n_conv_3 = 256,  k_conv_3 = 3,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 5,  n_dense_1 = 384, dropout_1 = 0.2,\n",
      "          n_dense_2 = 384, dropout_2 = 0.2, activation_conv=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001D5AE3CD8C8>,\n",
      "          activation_dense=  relu\n",
      "Epoch 1/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 1.1069 - accuracy: 0.5333\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.8393 - accuracy: 0.6464\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.6655 - accuracy: 0.7327\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.6018 - accuracy: 0.7633\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.5540 - accuracy: 0.7828\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.5002 - accuracy: 0.8044\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.4689 - accuracy: 0.8184\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.4455 - accuracy: 0.8291\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.4440 - accuracy: 0.8282\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.4152 - accuracy: 0.8405\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.4007 - accuracy: 0.8448\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3890 - accuracy: 0.8491\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3877 - accuracy: 0.8505\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3668 - accuracy: 0.8588\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3674 - accuracy: 0.8585\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3544 - accuracy: 0.8645\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3638 - accuracy: 0.8601\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3504 - accuracy: 0.8629\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3342 - accuracy: 0.8697\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3303 - accuracy: 0.8718\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3250 - accuracy: 0.8732\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3301 - accuracy: 0.8719\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3151 - accuracy: 0.8769\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3213 - accuracy: 0.8744\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3194 - accuracy: 0.8764\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3104 - accuracy: 0.8789\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.2985 - accuracy: 0.8848\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3065 - accuracy: 0.8809\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.2962 - accuracy: 0.8853\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.3087 - accuracy: 0.8811\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.2952 - accuracy: 0.8844\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.2898 - accuracy: 0.8886\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.2908 - accuracy: 0.8872\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.2810 - accuracy: 0.8915\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.2791 - accuracy: 0.8933\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.2774 - accuracy: 0.8924\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.2771 - accuracy: 0.8923\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.2748 - accuracy: 0.8948\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.2757 - accuracy: 0.8929\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.2723 - accuracy: 0.8961 0s - loss: 0\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.2634 - accuracy: 0.8979\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.2598 - accuracy: 0.8994\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.2597 - accuracy: 0.8999\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.2566 - accuracy: 0.9023\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.2507 - accuracy: 0.9046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.2565 - accuracy: 0.9013\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.2505 - accuracy: 0.9037\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.2446 - accuracy: 0.9052\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.2553 - accuracy: 0.9022\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.2456 - accuracy: 0.9047\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.2393 - accuracy: 0.9066\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.2358 - accuracy: 0.9098\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.2431 - accuracy: 0.9059\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.2276 - accuracy: 0.9127\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.2283 - accuracy: 0.9117\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.2281 - accuracy: 0.9111\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.2322 - accuracy: 0.9101\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.2330 - accuracy: 0.9096\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.2251 - accuracy: 0.9132\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 0.2223 - accuracy: 0.9135\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.2631 - accuracy: 0.9119\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_21 (Conv1D)           (None, 89, 768)           5376      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 29, 768)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_22 (Conv1D)           (None, 28, 256)           393472    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_7 (Average (None, 9, 256)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_23 (Conv1D)           (None, 7, 256)            196864    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_7 ( (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 384)               98688     \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 6)                 2310      \n",
      "=================================================================\n",
      "Total params: 762,502\n",
      "Trainable params: 762,502\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 768, k_conv_1 = 2,  n_conv_2 = 256, k_conv_2 = 2, \n",
      "          n_conv_3 = 256,  k_conv_3 = 3,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 256, dropout_1 = 0.3,\n",
      "          n_dense_2 = 384, dropout_2 = 0.3, activation_conv=  relu,\n",
      "          activation_dense=  relu\n",
      "Epoch 1/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 1.1293 - accuracy: 0.5181 0s - loss: 1.1459 - \n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.7983 - accuracy: 0.6640\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.6439 - accuracy: 0.7364\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.5355 - accuracy: 0.7903\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.4622 - accuracy: 0.8222\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.4128 - accuracy: 0.8430\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3899 - accuracy: 0.8504\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3549 - accuracy: 0.8659\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3430 - accuracy: 0.8700\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3270 - accuracy: 0.8760\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3124 - accuracy: 0.8815\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.2956 - accuracy: 0.8879\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.2919 - accuracy: 0.8905\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.2726 - accuracy: 0.8982\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.2702 - accuracy: 0.8967\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.2612 - accuracy: 0.9025\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.2536 - accuracy: 0.9037\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.2478 - accuracy: 0.9067\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.2394 - accuracy: 0.9113\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.2348 - accuracy: 0.9127\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.2301 - accuracy: 0.9147\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.2176 - accuracy: 0.9188\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.2165 - accuracy: 0.9192\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.2092 - accuracy: 0.9217 0s - loss: 0.210\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.2106 - accuracy: 0.9198\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.2010 - accuracy: 0.9248\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.1958 - accuracy: 0.9264\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.1913 - accuracy: 0.9283\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.1987 - accuracy: 0.9246\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.1825 - accuracy: 0.9313\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.1813 - accuracy: 0.9325\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.1825 - accuracy: 0.9307\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.1771 - accuracy: 0.9321\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.1770 - accuracy: 0.9325\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.1768 - accuracy: 0.9342\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.1691 - accuracy: 0.9373\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.1739 - accuracy: 0.9350\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.1671 - accuracy: 0.9381\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.1648 - accuracy: 0.9377\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.1555 - accuracy: 0.9408\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.1556 - accuracy: 0.9410\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.1512 - accuracy: 0.9415\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.1484 - accuracy: 0.9423\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.1504 - accuracy: 0.9432\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.1382 - accuracy: 0.9471\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.1393 - accuracy: 0.9470\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.1392 - accuracy: 0.9478\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.1358 - accuracy: 0.9495\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.1379 - accuracy: 0.9480\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.1359 - accuracy: 0.9487\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.1327 - accuracy: 0.9490\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.1233 - accuracy: 0.9524\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.1284 - accuracy: 0.9517\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.1239 - accuracy: 0.9522\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.1252 - accuracy: 0.9517\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.1167 - accuracy: 0.9552\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.1250 - accuracy: 0.9526\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.1213 - accuracy: 0.9542\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.1138 - accuracy: 0.9563\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.1163 - accuracy: 0.9545\n",
      "76/76 [==============================] - 1s 15ms/step - loss: 0.2653 - accuracy: 0.9277\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_24 (Conv1D)           (None, 89, 768)           5376      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 29, 768)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_25 (Conv1D)           (None, 28, 256)           393472    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_8 (Average (None, 9, 256)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_26 (Conv1D)           (None, 7, 256)            196864    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_8 ( (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 384)               98688     \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 6)                 2310      \n",
      "=================================================================\n",
      "Total params: 762,502\n",
      "Trainable params: 762,502\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 768, k_conv_1 = 2,  n_conv_2 = 256, k_conv_2 = 2, \n",
      "          n_conv_3 = 256,  k_conv_3 = 3,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 256, dropout_1 = 0.3,\n",
      "          n_dense_2 = 384, dropout_2 = 0.3, activation_conv=  relu,\n",
      "          activation_dense=  relu\n",
      "Epoch 1/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 1.1153 - accuracy: 0.5264\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.8209 - accuracy: 0.6575\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.6874 - accuracy: 0.7186\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.5632 - accuracy: 0.7785\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.4855 - accuracy: 0.8163\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.4335 - accuracy: 0.8387\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3909 - accuracy: 0.8529\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3728 - accuracy: 0.8598\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3470 - accuracy: 0.8712\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3333 - accuracy: 0.8743\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3186 - accuracy: 0.8793 0s - loss: 0\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3019 - accuracy: 0.8859\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.2930 - accuracy: 0.8887\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.2807 - accuracy: 0.8939\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.2729 - accuracy: 0.8975\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.2618 - accuracy: 0.9006\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.2551 - accuracy: 0.9045\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.2515 - accuracy: 0.9059\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.2413 - accuracy: 0.9110\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.2378 - accuracy: 0.9114\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.2250 - accuracy: 0.9144\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.2192 - accuracy: 0.9185\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.2307 - accuracy: 0.9152 1s - loss: 0.2352  - ETA\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.2159 - accuracy: 0.9198\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.2230 - accuracy: 0.9183\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.2049 - accuracy: 0.9244\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.2068 - accuracy: 0.9225\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.1952 - accuracy: 0.9274\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.1914 - accuracy: 0.9274\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.1978 - accuracy: 0.9263\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.1879 - accuracy: 0.9294\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.1859 - accuracy: 0.9308\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.1794 - accuracy: 0.9335\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.1805 - accuracy: 0.9314\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.1725 - accuracy: 0.9345\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.1653 - accuracy: 0.9389\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.1662 - accuracy: 0.9381\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.1677 - accuracy: 0.9369\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.1632 - accuracy: 0.9382\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.1579 - accuracy: 0.9396\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.1559 - accuracy: 0.9424\n",
      "Epoch 42/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 5s 33ms/step - loss: 0.1572 - accuracy: 0.9415\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.1508 - accuracy: 0.9438\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.1487 - accuracy: 0.9447\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.1443 - accuracy: 0.9457\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.1400 - accuracy: 0.9463\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.1462 - accuracy: 0.9443\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.1323 - accuracy: 0.9496\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.1373 - accuracy: 0.9476\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.1421 - accuracy: 0.9474\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.1353 - accuracy: 0.9489\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.1204 - accuracy: 0.9543\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.1248 - accuracy: 0.9522\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.1226 - accuracy: 0.9543\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.1241 - accuracy: 0.9527\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.1220 - accuracy: 0.9538\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.1161 - accuracy: 0.9559\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.1220 - accuracy: 0.9539\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.1189 - accuracy: 0.9554\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.1199 - accuracy: 0.9541\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 0.2476 - accuracy: 0.9298\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_27 (Conv1D)           (None, 89, 768)           5376      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1 (None, 29, 768)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_28 (Conv1D)           (None, 28, 256)           393472    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_9 (Average (None, 9, 256)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_29 (Conv1D)           (None, 7, 256)            196864    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_9 ( (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 384)               98688     \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 6)                 2310      \n",
      "=================================================================\n",
      "Total params: 762,502\n",
      "Trainable params: 762,502\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 768, k_conv_1 = 2,  n_conv_2 = 256, k_conv_2 = 2, \n",
      "          n_conv_3 = 256,  k_conv_3 = 3,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 256, dropout_1 = 0.3,\n",
      "          n_dense_2 = 384, dropout_2 = 0.3, activation_conv=  relu,\n",
      "          activation_dense=  relu\n",
      "Epoch 1/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 1.1152 - accuracy: 0.5218\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.8107 - accuracy: 0.6641\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.6773 - accuracy: 0.7199\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.5631 - accuracy: 0.7771\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.4785 - accuracy: 0.8166\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.4377 - accuracy: 0.8303\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3924 - accuracy: 0.8489\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3734 - accuracy: 0.8548\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3531 - accuracy: 0.8646\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3266 - accuracy: 0.8750\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3208 - accuracy: 0.8777\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3033 - accuracy: 0.8833\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.2950 - accuracy: 0.8881\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.2825 - accuracy: 0.8936\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.2800 - accuracy: 0.8943\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.2650 - accuracy: 0.9008\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.2676 - accuracy: 0.8993\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.2440 - accuracy: 0.9084\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.2360 - accuracy: 0.9119\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.2307 - accuracy: 0.9153\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.2242 - accuracy: 0.9152\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.2281 - accuracy: 0.9153\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.2175 - accuracy: 0.9179\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.2102 - accuracy: 0.9197\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.2123 - accuracy: 0.9210\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.1998 - accuracy: 0.9254\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.1995 - accuracy: 0.9260\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.2041 - accuracy: 0.9228 0s - loss: 0.2040 - accuracy\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.1957 - accuracy: 0.9283\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.1915 - accuracy: 0.9285\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.1910 - accuracy: 0.9283\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.1752 - accuracy: 0.9354 0s - loss: 0.1748 - accu\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.1782 - accuracy: 0.9341\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.1734 - accuracy: 0.9346\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.1675 - accuracy: 0.9380\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.1736 - accuracy: 0.9361\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.1672 - accuracy: 0.9375\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.1660 - accuracy: 0.9360\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.1592 - accuracy: 0.9401\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.1571 - accuracy: 0.9412\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.1519 - accuracy: 0.9435\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.1470 - accuracy: 0.9444\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.1484 - accuracy: 0.9440\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.1471 - accuracy: 0.9448\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.1443 - accuracy: 0.9455\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.1509 - accuracy: 0.9430\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.1505 - accuracy: 0.9435\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.1345 - accuracy: 0.9495\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.1436 - accuracy: 0.9461\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.1363 - accuracy: 0.9486\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.1292 - accuracy: 0.9495\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.1314 - accuracy: 0.9511\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.1349 - accuracy: 0.9496\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.1231 - accuracy: 0.9525\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.1234 - accuracy: 0.9526\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.1269 - accuracy: 0.9511\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.1230 - accuracy: 0.9530\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.1211 - accuracy: 0.9534\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.1254 - accuracy: 0.9529\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.1221 - accuracy: 0.9529\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 0.2530 - accuracy: 0.9333\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_30 (Conv1D)           (None, 89, 512)           3584      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling (None, 17, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_31 (Conv1D)           (None, 15, 512)           786944    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_10 (Averag (None, 5, 512)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_32 (Conv1D)           (None, 3, 512)            786944    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_10  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 6)                 3078      \n",
      "=================================================================\n",
      "Total params: 1,843,462\n",
      "Trainable params: 1,843,462\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 512, k_conv_1 = 2,  n_conv_2 = 512, k_conv_2 = 3, \n",
      "          n_conv_3 = 512,  k_conv_3 = 3,  maxpooling_pool_size = 5,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 256, dropout_1 = 0.3,\n",
      "          n_dense_2 = 512, dropout_2 = 0.2, activation_conv=  relu,\n",
      "          activation_dense=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001D5B5607388>\n",
      "Epoch 1/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 1.0539 - accuracy: 0.5548\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.6938 - accuracy: 0.7162\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.5360 - accuracy: 0.7906\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.4438 - accuracy: 0.8344\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.3986 - accuracy: 0.8483\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.3675 - accuracy: 0.8621\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.3330 - accuracy: 0.8748\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.3108 - accuracy: 0.8832\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.2960 - accuracy: 0.8872\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.2740 - accuracy: 0.8963\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.2552 - accuracy: 0.9032\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.2494 - accuracy: 0.9043\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.2398 - accuracy: 0.9087\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.2225 - accuracy: 0.9142\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.2248 - accuracy: 0.9127\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.2153 - accuracy: 0.9173\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.1941 - accuracy: 0.9237\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.1901 - accuracy: 0.9263\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.1955 - accuracy: 0.9240\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.1802 - accuracy: 0.9318\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.1723 - accuracy: 0.9349\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.1749 - accuracy: 0.9333\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.1566 - accuracy: 0.9406\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.1585 - accuracy: 0.9400\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.1568 - accuracy: 0.9405\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.1558 - accuracy: 0.9418\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.1439 - accuracy: 0.9459\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.1487 - accuracy: 0.9423\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.1452 - accuracy: 0.9444\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.1329 - accuracy: 0.9499\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.1266 - accuracy: 0.9521\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.1304 - accuracy: 0.9507\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.1224 - accuracy: 0.9540\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.1183 - accuracy: 0.9560\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.1138 - accuracy: 0.9566\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.1181 - accuracy: 0.9552\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.1204 - accuracy: 0.9546\n",
      "Epoch 38/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 4s 29ms/step - loss: 0.1153 - accuracy: 0.9572\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.1027 - accuracy: 0.9606\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.1145 - accuracy: 0.9570\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.0986 - accuracy: 0.9626\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.0981 - accuracy: 0.9624\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.1026 - accuracy: 0.9609\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.1004 - accuracy: 0.9639\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.0998 - accuracy: 0.9627\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.0919 - accuracy: 0.9661\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.1007 - accuracy: 0.9626\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.0931 - accuracy: 0.9651\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.0897 - accuracy: 0.9664\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.0968 - accuracy: 0.9654\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.0889 - accuracy: 0.9677\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.0923 - accuracy: 0.9657\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.0907 - accuracy: 0.9664\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.0856 - accuracy: 0.9674\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.0784 - accuracy: 0.9698\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.0810 - accuracy: 0.9700\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.0817 - accuracy: 0.9694\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.0821 - accuracy: 0.9695\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.0821 - accuracy: 0.9688\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.0826 - accuracy: 0.9690\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 0.3302 - accuracy: 0.9343\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_33 (Conv1D)           (None, 89, 512)           3584      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling (None, 17, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_34 (Conv1D)           (None, 15, 512)           786944    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_11 (Averag (None, 5, 512)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_35 (Conv1D)           (None, 3, 512)            786944    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_11  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 6)                 3078      \n",
      "=================================================================\n",
      "Total params: 1,843,462\n",
      "Trainable params: 1,843,462\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 512, k_conv_1 = 2,  n_conv_2 = 512, k_conv_2 = 3, \n",
      "          n_conv_3 = 512,  k_conv_3 = 3,  maxpooling_pool_size = 5,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 256, dropout_1 = 0.3,\n",
      "          n_dense_2 = 512, dropout_2 = 0.2, activation_conv=  relu,\n",
      "          activation_dense=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001D5B5607388>\n",
      "Epoch 1/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 1.0503 - accuracy: 0.5570\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.7153 - accuracy: 0.7050\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.5645 - accuracy: 0.7803\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.4575 - accuracy: 0.8256\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.4011 - accuracy: 0.8470\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.3566 - accuracy: 0.8663\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.3304 - accuracy: 0.8748\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.3105 - accuracy: 0.8839\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.3002 - accuracy: 0.8864\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.2712 - accuracy: 0.8968\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.2683 - accuracy: 0.8991\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.2463 - accuracy: 0.9065\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.2370 - accuracy: 0.9108\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.2337 - accuracy: 0.9107\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.2310 - accuracy: 0.9132\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.2165 - accuracy: 0.9170\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.2089 - accuracy: 0.9210\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.1963 - accuracy: 0.9253\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.2076 - accuracy: 0.9197\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.1813 - accuracy: 0.9314\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.1771 - accuracy: 0.9319\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.1766 - accuracy: 0.9317\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.1651 - accuracy: 0.9357\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.1671 - accuracy: 0.9366\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.1609 - accuracy: 0.9381\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.1604 - accuracy: 0.9379\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.1515 - accuracy: 0.9422\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.1439 - accuracy: 0.9442\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.1420 - accuracy: 0.9444\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.1392 - accuracy: 0.9454\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.1429 - accuracy: 0.9468\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.1310 - accuracy: 0.9493\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.1269 - accuracy: 0.9513\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.1252 - accuracy: 0.9506\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.1152 - accuracy: 0.9557\n",
      "Epoch 36/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 4s 29ms/step - loss: 0.1200 - accuracy: 0.9539\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.1188 - accuracy: 0.9547\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.1183 - accuracy: 0.9542\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.1232 - accuracy: 0.9528\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.1084 - accuracy: 0.9586\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.1043 - accuracy: 0.9593\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.1175 - accuracy: 0.9562\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.1150 - accuracy: 0.9563\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.1046 - accuracy: 0.9592\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.1041 - accuracy: 0.9599\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - ETA: 0s - loss: 0.1013 - accuracy: 0.96 - 4s 29ms/step - loss: 0.1010 - accuracy: 0.9603\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.0931 - accuracy: 0.9627\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.1023 - accuracy: 0.9598\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.1007 - accuracy: 0.9608\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.0937 - accuracy: 0.9639\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.0897 - accuracy: 0.9654\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.0952 - accuracy: 0.9637\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.0877 - accuracy: 0.9665\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.0900 - accuracy: 0.9651\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.0802 - accuracy: 0.9690\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.0967 - accuracy: 0.9630\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.0914 - accuracy: 0.9656\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.0825 - accuracy: 0.9686\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.0777 - accuracy: 0.9722\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.0767 - accuracy: 0.9719\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 0.3239 - accuracy: 0.9300\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_36 (Conv1D)           (None, 89, 512)           3584      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling (None, 17, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_37 (Conv1D)           (None, 15, 512)           786944    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_12 (Averag (None, 5, 512)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_38 (Conv1D)           (None, 3, 512)            786944    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_12  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 6)                 3078      \n",
      "=================================================================\n",
      "Total params: 1,843,462\n",
      "Trainable params: 1,843,462\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 512, k_conv_1 = 2,  n_conv_2 = 512, k_conv_2 = 3, \n",
      "          n_conv_3 = 512,  k_conv_3 = 3,  maxpooling_pool_size = 5,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 256, dropout_1 = 0.3,\n",
      "          n_dense_2 = 512, dropout_2 = 0.2, activation_conv=  relu,\n",
      "          activation_dense=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001D5B5607388>\n",
      "Epoch 1/60\n",
      "  1/152 [..............................] - ETA: 2s - loss: 1.7892 - accuracy: 0.1562WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0109s vs `on_train_batch_end` time: 0.0184s). Check your callbacks.\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 1.0548 - accuracy: 0.5556\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.7036 - accuracy: 0.7088\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.5541 - accuracy: 0.7784\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.4615 - accuracy: 0.8225\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.4029 - accuracy: 0.8474\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.3634 - accuracy: 0.8612\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.3355 - accuracy: 0.8703\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.3102 - accuracy: 0.8812\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.2917 - accuracy: 0.8899\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.2777 - accuracy: 0.8947\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.2631 - accuracy: 0.8977\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.2491 - accuracy: 0.9053\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.2372 - accuracy: 0.9089\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.2296 - accuracy: 0.9130\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.2196 - accuracy: 0.9157\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.2173 - accuracy: 0.9165\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.1998 - accuracy: 0.9247\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.1961 - accuracy: 0.9251\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.1924 - accuracy: 0.9269\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.1865 - accuracy: 0.9285\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.1786 - accuracy: 0.9323\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.1770 - accuracy: 0.9325\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.1700 - accuracy: 0.9365\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.1658 - accuracy: 0.9363\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.1614 - accuracy: 0.9390\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.1520 - accuracy: 0.9418\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.1489 - accuracy: 0.9408\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.1450 - accuracy: 0.9442\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.1384 - accuracy: 0.9465\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.1405 - accuracy: 0.9462\n",
      "Epoch 31/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 4s 29ms/step - loss: 0.1390 - accuracy: 0.9462\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.1238 - accuracy: 0.9520\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.1371 - accuracy: 0.9492\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.1266 - accuracy: 0.9524\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.1194 - accuracy: 0.9542\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.1154 - accuracy: 0.9567\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.1137 - accuracy: 0.9558\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.1177 - accuracy: 0.9561\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.1144 - accuracy: 0.9570\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.1089 - accuracy: 0.9588\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.1112 - accuracy: 0.9593\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.1039 - accuracy: 0.9598\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.1045 - accuracy: 0.9604\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.0988 - accuracy: 0.9625\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.1000 - accuracy: 0.9622\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.0969 - accuracy: 0.9628\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.0903 - accuracy: 0.9649\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.0945 - accuracy: 0.9644\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.0937 - accuracy: 0.9649\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.0900 - accuracy: 0.9667\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.0894 - accuracy: 0.9657\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.0915 - accuracy: 0.9655\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.0854 - accuracy: 0.9678\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.0895 - accuracy: 0.9658\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.0819 - accuracy: 0.9687\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.0842 - accuracy: 0.9688\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.0870 - accuracy: 0.9658\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.0849 - accuracy: 0.9685\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.0737 - accuracy: 0.9709\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.0745 - accuracy: 0.9712\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 0.3433 - accuracy: 0.9337\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_39 (Conv1D)           (None, 88, 512)           5120      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling (None, 17, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_40 (Conv1D)           (None, 15, 512)           786944    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_13 (Averag (None, 5, 512)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_41 (Conv1D)           (None, 4, 512)            524800    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_13  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 6)                 1542      \n",
      "=================================================================\n",
      "Total params: 1,712,390\n",
      "Trainable params: 1,712,390\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 512, k_conv_1 = 3,  n_conv_2 = 512, k_conv_2 = 3, \n",
      "          n_conv_3 = 512,  k_conv_3 = 2,  maxpooling_pool_size = 5,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 512, dropout_1 = 0.3,\n",
      "          n_dense_2 = 256, dropout_2 = 0.2, activation_conv=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001D5AE3CD8C8>,\n",
      "          activation_dense=  elu\n",
      "Epoch 1/60\n",
      "  1/152 [..............................] - ETA: 2s - loss: 1.7942 - accuracy: 0.1602WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0119s vs `on_train_batch_end` time: 0.0180s). Check your callbacks.\n",
      "152/152 [==============================] - 4s 30ms/step - loss: 1.0823 - accuracy: 0.5358\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.7519 - accuracy: 0.6922\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.6399 - accuracy: 0.7437\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.6002 - accuracy: 0.7610\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.5681 - accuracy: 0.7752\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.5179 - accuracy: 0.7958\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.4971 - accuracy: 0.8073\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.4744 - accuracy: 0.8139\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.4526 - accuracy: 0.8256\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.4378 - accuracy: 0.8298\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.4201 - accuracy: 0.8385\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.4138 - accuracy: 0.8443\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3905 - accuracy: 0.8501\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.4023 - accuracy: 0.8466\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3877 - accuracy: 0.8527\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3842 - accuracy: 0.8507\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3816 - accuracy: 0.8553\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3622 - accuracy: 0.8603\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3710 - accuracy: 0.8579\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3621 - accuracy: 0.8597\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3478 - accuracy: 0.8680\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3488 - accuracy: 0.8664\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3448 - accuracy: 0.8696\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3446 - accuracy: 0.8664\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3335 - accuracy: 0.8744\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3308 - accuracy: 0.8728\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3340 - accuracy: 0.8719\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3190 - accuracy: 0.8769\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3195 - accuracy: 0.8757\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3185 - accuracy: 0.8766\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3128 - accuracy: 0.8789\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3057 - accuracy: 0.8837\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3131 - accuracy: 0.8787\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3115 - accuracy: 0.8785\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3032 - accuracy: 0.8829\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3048 - accuracy: 0.8836\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2961 - accuracy: 0.8853\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2933 - accuracy: 0.8842\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3012 - accuracy: 0.8816\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2817 - accuracy: 0.8903\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2950 - accuracy: 0.8861\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2857 - accuracy: 0.8857\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2875 - accuracy: 0.8869\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2833 - accuracy: 0.8880\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2755 - accuracy: 0.8913\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2719 - accuracy: 0.8917\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2736 - accuracy: 0.8921\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2735 - accuracy: 0.8936\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2573 - accuracy: 0.8983\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2694 - accuracy: 0.8949\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2628 - accuracy: 0.8967\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2664 - accuracy: 0.8941\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2628 - accuracy: 0.8963\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2610 - accuracy: 0.8969\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2521 - accuracy: 0.9014\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2585 - accuracy: 0.8985\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2512 - accuracy: 0.9029\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2482 - accuracy: 0.9018\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2462 - accuracy: 0.9028\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2501 - accuracy: 0.9015\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 0.2899 - accuracy: 0.8965\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_42 (Conv1D)           (None, 88, 512)           5120      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling (None, 17, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_43 (Conv1D)           (None, 15, 512)           786944    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_14 (Averag (None, 5, 512)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_44 (Conv1D)           (None, 4, 512)            524800    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_14  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 6)                 1542      \n",
      "=================================================================\n",
      "Total params: 1,712,390\n",
      "Trainable params: 1,712,390\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 512, k_conv_1 = 3,  n_conv_2 = 512, k_conv_2 = 3, \n",
      "          n_conv_3 = 512,  k_conv_3 = 2,  maxpooling_pool_size = 5,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 512, dropout_1 = 0.3,\n",
      "          n_dense_2 = 256, dropout_2 = 0.2, activation_conv=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001D5AE3CD8C8>,\n",
      "          activation_dense=  elu\n",
      "Epoch 1/60\n",
      "  1/152 [..............................] - ETA: 2s - loss: 1.8014 - accuracy: 0.1836WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0110s vs `on_train_batch_end` time: 0.0178s). Check your callbacks.\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 1.0577 - accuracy: 0.5497\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.7358 - accuracy: 0.7049\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.6460 - accuracy: 0.7404\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.5941 - accuracy: 0.7632\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.5649 - accuracy: 0.7742\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.5135 - accuracy: 0.7987\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.5088 - accuracy: 0.8022\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.4521 - accuracy: 0.8283\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.4563 - accuracy: 0.8260\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.4297 - accuracy: 0.8338\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.4232 - accuracy: 0.8371\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.4184 - accuracy: 0.8405\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.4013 - accuracy: 0.8454\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.4068 - accuracy: 0.8429\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3840 - accuracy: 0.8530\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3838 - accuracy: 0.8546\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3802 - accuracy: 0.8531\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3691 - accuracy: 0.8574\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3522 - accuracy: 0.8657\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3489 - accuracy: 0.8652\n",
      "Epoch 21/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3457 - accuracy: 0.8678\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - ETA: 0s - loss: 0.3572 - accuracy: 0.86 - 4s 28ms/step - loss: 0.3568 - accuracy: 0.8620\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3388 - accuracy: 0.8684\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3345 - accuracy: 0.8697\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3226 - accuracy: 0.8758\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3363 - accuracy: 0.8683\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3356 - accuracy: 0.8702\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3200 - accuracy: 0.8743\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3174 - accuracy: 0.8766\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3204 - accuracy: 0.8734\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3192 - accuracy: 0.8769\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3107 - accuracy: 0.8783\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3187 - accuracy: 0.8753\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3067 - accuracy: 0.8782\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3061 - accuracy: 0.8805\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3062 - accuracy: 0.8784\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2946 - accuracy: 0.8840 0s - loss: 0.2\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2939 - accuracy: 0.8844\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2990 - accuracy: 0.8825\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2858 - accuracy: 0.8873\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2930 - accuracy: 0.8833\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2961 - accuracy: 0.8813\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2868 - accuracy: 0.8867\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2783 - accuracy: 0.8894\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2753 - accuracy: 0.8897\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2715 - accuracy: 0.8917\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2768 - accuracy: 0.8898\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2800 - accuracy: 0.8871\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2638 - accuracy: 0.8958\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2703 - accuracy: 0.8904\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2548 - accuracy: 0.8980\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2656 - accuracy: 0.8924\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2630 - accuracy: 0.8955\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2586 - accuracy: 0.8961\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2544 - accuracy: 0.8966\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2607 - accuracy: 0.8941\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2556 - accuracy: 0.8986\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2533 - accuracy: 0.8980\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2510 - accuracy: 0.8992\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2483 - accuracy: 0.9013\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 0.2915 - accuracy: 0.8929\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_45 (Conv1D)           (None, 88, 512)           5120      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling (None, 17, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_46 (Conv1D)           (None, 15, 512)           786944    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_15 (Averag (None, 5, 512)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_47 (Conv1D)           (None, 4, 512)            524800    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_15  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_31 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 6)                 1542      \n",
      "=================================================================\n",
      "Total params: 1,712,390\n",
      "Trainable params: 1,712,390\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 512, k_conv_1 = 3,  n_conv_2 = 512, k_conv_2 = 3, \n",
      "          n_conv_3 = 512,  k_conv_3 = 2,  maxpooling_pool_size = 5,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 512, dropout_1 = 0.3,\n",
      "          n_dense_2 = 256, dropout_2 = 0.2, activation_conv=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001D5AE3CD8C8>,\n",
      "          activation_dense=  elu\n",
      "Epoch 1/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 1.0600 - accuracy: 0.5508\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.7490 - accuracy: 0.6942\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.6517 - accuracy: 0.7387\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.5920 - accuracy: 0.7648\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.5585 - accuracy: 0.7770\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.5239 - accuracy: 0.7941\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.5040 - accuracy: 0.8048\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.4818 - accuracy: 0.8138\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.4609 - accuracy: 0.8234\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.4400 - accuracy: 0.8311\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.4101 - accuracy: 0.8425\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.4217 - accuracy: 0.8377\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.4014 - accuracy: 0.8465\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3946 - accuracy: 0.8499\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3931 - accuracy: 0.8485\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3796 - accuracy: 0.8536\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3788 - accuracy: 0.8549\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3575 - accuracy: 0.8616\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3700 - accuracy: 0.8558\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3600 - accuracy: 0.8626\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3477 - accuracy: 0.8653\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3488 - accuracy: 0.8658\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3394 - accuracy: 0.8698\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3386 - accuracy: 0.8676\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3267 - accuracy: 0.8734\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3353 - accuracy: 0.8692\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3347 - accuracy: 0.8692\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3246 - accuracy: 0.8729\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3097 - accuracy: 0.8796\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3312 - accuracy: 0.8712\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3100 - accuracy: 0.8803\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3170 - accuracy: 0.8761\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3092 - accuracy: 0.8804\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3127 - accuracy: 0.8758\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3087 - accuracy: 0.8785\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3053 - accuracy: 0.8813\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3016 - accuracy: 0.8813\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.3012 - accuracy: 0.8808\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2907 - accuracy: 0.8858\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2965 - accuracy: 0.8847\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2915 - accuracy: 0.8849\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2832 - accuracy: 0.8882\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2825 - accuracy: 0.8892\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2866 - accuracy: 0.8894\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2878 - accuracy: 0.8867\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2702 - accuracy: 0.8937\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2680 - accuracy: 0.8935\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2702 - accuracy: 0.8942\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2737 - accuracy: 0.8938\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2687 - accuracy: 0.8956\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2734 - accuracy: 0.8936\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2626 - accuracy: 0.8970\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2527 - accuracy: 0.9011\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2618 - accuracy: 0.8974\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2458 - accuracy: 0.9030\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2536 - accuracy: 0.8991\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2552 - accuracy: 0.9007\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2494 - accuracy: 0.9008\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2705 - accuracy: 0.8948\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.2430 - accuracy: 0.9049\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 0.2759 - accuracy: 0.8989\n",
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_48 (Conv1D)           (None, 89, 768)           5376      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_16 (MaxPooling (None, 17, 768)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_49 (Conv1D)           (None, 16, 512)           786944    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_16 (Averag (None, 3, 512)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_50 (Conv1D)           (None, 2, 512)            524800    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_16  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 384)               196992    \n",
      "_________________________________________________________________\n",
      "dropout_32 (Dropout)         (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 384)               147840    \n",
      "_________________________________________________________________\n",
      "dropout_33 (Dropout)         (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 6)                 2310      \n",
      "=================================================================\n",
      "Total params: 1,664,262\n",
      "Trainable params: 1,664,262\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 768, k_conv_1 = 2,  n_conv_2 = 512, k_conv_2 = 2, \n",
      "          n_conv_3 = 512,  k_conv_3 = 2,  maxpooling_pool_size = 5,\n",
      "          avepooling_pool_size = 5,  n_dense_1 = 384, dropout_1 = 0.3,\n",
      "          n_dense_2 = 384, dropout_2 = 0.2, activation_conv=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001D5AE3CD8C8>,\n",
      "          activation_dense=  relu\n",
      "Epoch 1/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 1.1168 - accuracy: 0.5255\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.8856 - accuracy: 0.6255\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.7838 - accuracy: 0.6631\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.7171 - accuracy: 0.6943\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.6731 - accuracy: 0.7146\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.6400 - accuracy: 0.7310\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.5913 - accuracy: 0.7547\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.5790 - accuracy: 0.7624\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.5490 - accuracy: 0.7795\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.5167 - accuracy: 0.7928\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.5082 - accuracy: 0.7943\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.4970 - accuracy: 0.8030\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.4709 - accuracy: 0.8120\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.4634 - accuracy: 0.8157\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.4554 - accuracy: 0.8196\n",
      "Epoch 16/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 5s 35ms/step - loss: 0.4327 - accuracy: 0.8294\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.4274 - accuracy: 0.8306\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.4130 - accuracy: 0.8367\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.4027 - accuracy: 0.8422\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.4041 - accuracy: 0.8419\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3848 - accuracy: 0.8510\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3862 - accuracy: 0.8495\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3736 - accuracy: 0.8521\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3549 - accuracy: 0.8619\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3538 - accuracy: 0.8614\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3483 - accuracy: 0.8646\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3520 - accuracy: 0.8620\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3414 - accuracy: 0.8648\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3447 - accuracy: 0.8666\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3427 - accuracy: 0.8666\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3291 - accuracy: 0.8709\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3406 - accuracy: 0.8677\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3189 - accuracy: 0.8744\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3271 - accuracy: 0.8726\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3233 - accuracy: 0.8722\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3188 - accuracy: 0.8759\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3108 - accuracy: 0.8795\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3151 - accuracy: 0.8771\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3100 - accuracy: 0.8770\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2972 - accuracy: 0.8848\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2981 - accuracy: 0.8837\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2969 - accuracy: 0.8835\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3075 - accuracy: 0.8806\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2954 - accuracy: 0.8848\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2996 - accuracy: 0.8827\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2961 - accuracy: 0.8846\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2936 - accuracy: 0.8853\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2765 - accuracy: 0.8914\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2866 - accuracy: 0.8890\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2838 - accuracy: 0.8887\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2844 - accuracy: 0.8858\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2800 - accuracy: 0.8902\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2623 - accuracy: 0.8995\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2709 - accuracy: 0.8933\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2742 - accuracy: 0.8917\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2773 - accuracy: 0.8921\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2726 - accuracy: 0.8931\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2529 - accuracy: 0.9023\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2576 - accuracy: 0.9005\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2700 - accuracy: 0.8945\n",
      "76/76 [==============================] - 1s 14ms/step - loss: 0.3654 - accuracy: 0.8654\n",
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_51 (Conv1D)           (None, 89, 768)           5376      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_17 (MaxPooling (None, 17, 768)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_52 (Conv1D)           (None, 16, 512)           786944    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_17 (Averag (None, 3, 512)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_53 (Conv1D)           (None, 2, 512)            524800    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_17  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 384)               196992    \n",
      "_________________________________________________________________\n",
      "dropout_34 (Dropout)         (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 384)               147840    \n",
      "_________________________________________________________________\n",
      "dropout_35 (Dropout)         (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 6)                 2310      \n",
      "=================================================================\n",
      "Total params: 1,664,262\n",
      "Trainable params: 1,664,262\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 768, k_conv_1 = 2,  n_conv_2 = 512, k_conv_2 = 2, \n",
      "          n_conv_3 = 512,  k_conv_3 = 2,  maxpooling_pool_size = 5,\n",
      "          avepooling_pool_size = 5,  n_dense_1 = 384, dropout_1 = 0.3,\n",
      "          n_dense_2 = 384, dropout_2 = 0.2, activation_conv=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001D5AE3CD8C8>,\n",
      "          activation_dense=  relu\n",
      "Epoch 1/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 1.1107 - accuracy: 0.5306\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.8936 - accuracy: 0.6212\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.7810 - accuracy: 0.6679\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.7381 - accuracy: 0.6890\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.6739 - accuracy: 0.7150\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.6290 - accuracy: 0.7388\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.5993 - accuracy: 0.7533\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.5730 - accuracy: 0.7666\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.5412 - accuracy: 0.7830\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.5146 - accuracy: 0.7957\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.4917 - accuracy: 0.8062\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.4649 - accuracy: 0.8174\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.4643 - accuracy: 0.8181\n",
      "Epoch 14/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 5s 35ms/step - loss: 0.4474 - accuracy: 0.8250\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.4332 - accuracy: 0.8292\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.4296 - accuracy: 0.8338\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.4158 - accuracy: 0.8363\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.4085 - accuracy: 0.8402\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3943 - accuracy: 0.8462\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3838 - accuracy: 0.8510\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3862 - accuracy: 0.8486\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3674 - accuracy: 0.8558\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3686 - accuracy: 0.8542\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3699 - accuracy: 0.8534\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3636 - accuracy: 0.8573\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3520 - accuracy: 0.8610\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3497 - accuracy: 0.8627\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3416 - accuracy: 0.8651\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3349 - accuracy: 0.8690\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3358 - accuracy: 0.8669\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3326 - accuracy: 0.8694\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3320 - accuracy: 0.8682\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3344 - accuracy: 0.8698\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3157 - accuracy: 0.8766\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3110 - accuracy: 0.8759\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3262 - accuracy: 0.8714\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3092 - accuracy: 0.8787\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3102 - accuracy: 0.8771\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3068 - accuracy: 0.8785\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3046 - accuracy: 0.8798\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2990 - accuracy: 0.8827\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2943 - accuracy: 0.8852\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3033 - accuracy: 0.8793\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2871 - accuracy: 0.8865\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2894 - accuracy: 0.8882\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2946 - accuracy: 0.8838\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2831 - accuracy: 0.8903\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2884 - accuracy: 0.8866\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2729 - accuracy: 0.8933\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2890 - accuracy: 0.8870\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2705 - accuracy: 0.8952\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2682 - accuracy: 0.8930\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2735 - accuracy: 0.8924\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2756 - accuracy: 0.8939\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2695 - accuracy: 0.8949\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2723 - accuracy: 0.8943\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2771 - accuracy: 0.8912\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2583 - accuracy: 0.8984\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2656 - accuracy: 0.8946\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2570 - accuracy: 0.9008\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 0.2797 - accuracy: 0.8988\n",
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_54 (Conv1D)           (None, 89, 768)           5376      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_18 (MaxPooling (None, 17, 768)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_55 (Conv1D)           (None, 16, 512)           786944    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_18 (Averag (None, 3, 512)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_56 (Conv1D)           (None, 2, 512)            524800    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_18  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 384)               196992    \n",
      "_________________________________________________________________\n",
      "dropout_36 (Dropout)         (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 384)               147840    \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 6)                 2310      \n",
      "=================================================================\n",
      "Total params: 1,664,262\n",
      "Trainable params: 1,664,262\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 768, k_conv_1 = 2,  n_conv_2 = 512, k_conv_2 = 2, \n",
      "          n_conv_3 = 512,  k_conv_3 = 2,  maxpooling_pool_size = 5,\n",
      "          avepooling_pool_size = 5,  n_dense_1 = 384, dropout_1 = 0.3,\n",
      "          n_dense_2 = 384, dropout_2 = 0.2, activation_conv=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001D5AE3CD8C8>,\n",
      "          activation_dense=  relu\n",
      "Epoch 1/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 1.1056 - accuracy: 0.5325\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.8917 - accuracy: 0.6231\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.8025 - accuracy: 0.6591\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.7357 - accuracy: 0.6863\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.6813 - accuracy: 0.7138\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.6488 - accuracy: 0.7252\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.6071 - accuracy: 0.7474\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.5745 - accuracy: 0.7642\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.5446 - accuracy: 0.7784\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.5353 - accuracy: 0.7806\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.5039 - accuracy: 0.7970\n",
      "Epoch 12/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 5s 35ms/step - loss: 0.4793 - accuracy: 0.8070\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.4747 - accuracy: 0.8087\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.4626 - accuracy: 0.8148\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.4397 - accuracy: 0.8263\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.4423 - accuracy: 0.8239\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.4234 - accuracy: 0.8315\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.4128 - accuracy: 0.8383\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.4126 - accuracy: 0.8370\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3992 - accuracy: 0.8437\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3915 - accuracy: 0.8450\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3887 - accuracy: 0.8449\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3802 - accuracy: 0.8488\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3561 - accuracy: 0.8602\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3530 - accuracy: 0.8597\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3570 - accuracy: 0.8592\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3517 - accuracy: 0.8617\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3369 - accuracy: 0.8675\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3428 - accuracy: 0.8630\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3467 - accuracy: 0.8639\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3406 - accuracy: 0.8662\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3257 - accuracy: 0.8716\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3364 - accuracy: 0.8685\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3204 - accuracy: 0.8733\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3236 - accuracy: 0.8745\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3130 - accuracy: 0.8806\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3220 - accuracy: 0.8738\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3224 - accuracy: 0.8725\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3034 - accuracy: 0.8802\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3104 - accuracy: 0.8775\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3076 - accuracy: 0.8797\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3037 - accuracy: 0.8824\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2951 - accuracy: 0.8832\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2851 - accuracy: 0.8903\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2903 - accuracy: 0.8856\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2886 - accuracy: 0.8860\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2940 - accuracy: 0.8842\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2851 - accuracy: 0.8889\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2812 - accuracy: 0.8887\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2760 - accuracy: 0.8923\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2801 - accuracy: 0.8908\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2854 - accuracy: 0.8879\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2756 - accuracy: 0.8941\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2654 - accuracy: 0.8966\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2774 - accuracy: 0.8917\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2600 - accuracy: 0.8981\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2756 - accuracy: 0.8915\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2743 - accuracy: 0.8935\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2709 - accuracy: 0.8948\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2542 - accuracy: 0.9005\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 0.2983 - accuracy: 0.8971\n",
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_57 (Conv1D)           (None, 89, 768)           5376      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_19 (MaxPooling (None, 29, 768)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_58 (Conv1D)           (None, 28, 256)           393472    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_19 (Averag (None, 9, 256)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_59 (Conv1D)           (None, 7, 256)            196864    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_19  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_38 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 384)               98688     \n",
      "_________________________________________________________________\n",
      "dropout_39 (Dropout)         (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 6)                 2310      \n",
      "=================================================================\n",
      "Total params: 762,502\n",
      "Trainable params: 762,502\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 768, k_conv_1 = 2,  n_conv_2 = 256, k_conv_2 = 2, \n",
      "          n_conv_3 = 256,  k_conv_3 = 3,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 256, dropout_1 = 0.3,\n",
      "          n_dense_2 = 384, dropout_2 = 0.2, activation_conv=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001D5AE3CD8C8>,\n",
      "          activation_dense=  elu\n",
      "Epoch 1/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 1.1021 - accuracy: 0.5255\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.9108 - accuracy: 0.6008\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.8172 - accuracy: 0.6484\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.7403 - accuracy: 0.6888\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.6778 - accuracy: 0.7234\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.6346 - accuracy: 0.7449\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.5909 - accuracy: 0.7708\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.5663 - accuracy: 0.7779\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.5294 - accuracy: 0.7942\n",
      "Epoch 10/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 5s 33ms/step - loss: 0.5030 - accuracy: 0.8075\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.4945 - accuracy: 0.8085\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.4729 - accuracy: 0.8201\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.4508 - accuracy: 0.8294\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.4365 - accuracy: 0.8343\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.4357 - accuracy: 0.8318\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.4268 - accuracy: 0.8368\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.4115 - accuracy: 0.8433\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3994 - accuracy: 0.8469\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3959 - accuracy: 0.8511\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3985 - accuracy: 0.8479\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3795 - accuracy: 0.8558\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3749 - accuracy: 0.8566\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3751 - accuracy: 0.8573\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3690 - accuracy: 0.8586\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3633 - accuracy: 0.8602\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3602 - accuracy: 0.8604\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3544 - accuracy: 0.8615\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3553 - accuracy: 0.8630\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3503 - accuracy: 0.8648\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3600 - accuracy: 0.8616\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3480 - accuracy: 0.8652\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3446 - accuracy: 0.8674\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3283 - accuracy: 0.8713\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3348 - accuracy: 0.8692\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3222 - accuracy: 0.8748\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3282 - accuracy: 0.8729\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3339 - accuracy: 0.8705\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3229 - accuracy: 0.8753\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3126 - accuracy: 0.8770\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3134 - accuracy: 0.8773\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3138 - accuracy: 0.8780\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3160 - accuracy: 0.8770\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3103 - accuracy: 0.8790\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3092 - accuracy: 0.8790\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.2995 - accuracy: 0.8826\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3047 - accuracy: 0.8795\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.2930 - accuracy: 0.8862\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3062 - accuracy: 0.8792\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.2980 - accuracy: 0.8839\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3110 - accuracy: 0.8763\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.2827 - accuracy: 0.8880\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.2936 - accuracy: 0.8840\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.2931 - accuracy: 0.8830\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.2877 - accuracy: 0.8871\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.2967 - accuracy: 0.8854\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.2813 - accuracy: 0.8894\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.2727 - accuracy: 0.8931\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.2913 - accuracy: 0.8862\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.2747 - accuracy: 0.8906\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.2786 - accuracy: 0.8914\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 0.3006 - accuracy: 0.8876\n",
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_60 (Conv1D)           (None, 89, 768)           5376      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_20 (MaxPooling (None, 29, 768)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_61 (Conv1D)           (None, 28, 256)           393472    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_20 (Averag (None, 9, 256)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_62 (Conv1D)           (None, 7, 256)            196864    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_20  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_40 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 384)               98688     \n",
      "_________________________________________________________________\n",
      "dropout_41 (Dropout)         (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 6)                 2310      \n",
      "=================================================================\n",
      "Total params: 762,502\n",
      "Trainable params: 762,502\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 768, k_conv_1 = 2,  n_conv_2 = 256, k_conv_2 = 2, \n",
      "          n_conv_3 = 256,  k_conv_3 = 3,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 256, dropout_1 = 0.3,\n",
      "          n_dense_2 = 384, dropout_2 = 0.2, activation_conv=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001D5AE3CD8C8>,\n",
      "          activation_dense=  elu\n",
      "Epoch 1/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 1.1080 - accuracy: 0.5179\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.8967 - accuracy: 0.6067\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.8089 - accuracy: 0.6543\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.7569 - accuracy: 0.6825\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.6750 - accuracy: 0.7245\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.6265 - accuracy: 0.7523\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.5973 - accuracy: 0.7661\n",
      "Epoch 8/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 5s 33ms/step - loss: 0.5602 - accuracy: 0.7823\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.5303 - accuracy: 0.7954\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.5092 - accuracy: 0.8034\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.4831 - accuracy: 0.8166\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.4782 - accuracy: 0.8200\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.4624 - accuracy: 0.8247\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.4306 - accuracy: 0.8368\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.4268 - accuracy: 0.8371\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.4280 - accuracy: 0.8347\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.4122 - accuracy: 0.8439\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.4051 - accuracy: 0.8467\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.4038 - accuracy: 0.8457\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.4037 - accuracy: 0.8451\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3891 - accuracy: 0.8492\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3804 - accuracy: 0.8547\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3741 - accuracy: 0.8566\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3811 - accuracy: 0.8529\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3674 - accuracy: 0.8583\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3689 - accuracy: 0.8591\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3565 - accuracy: 0.8618\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3467 - accuracy: 0.8652\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3473 - accuracy: 0.8665\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3489 - accuracy: 0.8658\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3469 - accuracy: 0.8649\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3349 - accuracy: 0.8708\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3372 - accuracy: 0.8699\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3394 - accuracy: 0.8683\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3337 - accuracy: 0.8701\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3200 - accuracy: 0.8744\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3244 - accuracy: 0.8731\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3250 - accuracy: 0.8721\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3271 - accuracy: 0.8733\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3230 - accuracy: 0.8739\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3186 - accuracy: 0.8737 0s - los\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3197 - accuracy: 0.8750\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3079 - accuracy: 0.8792\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.2950 - accuracy: 0.8841\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3242 - accuracy: 0.8733\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3069 - accuracy: 0.8787\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3156 - accuracy: 0.8759\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.2941 - accuracy: 0.8845\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.2983 - accuracy: 0.8826\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3060 - accuracy: 0.8787\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.2917 - accuracy: 0.8842\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.2944 - accuracy: 0.8840\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.2947 - accuracy: 0.8831\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.2786 - accuracy: 0.8895\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.2894 - accuracy: 0.8847\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.2871 - accuracy: 0.8876\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.2806 - accuracy: 0.8886\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.2824 - accuracy: 0.8882\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.2768 - accuracy: 0.8899\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.2745 - accuracy: 0.8899\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 0.3273 - accuracy: 0.8752\n",
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_63 (Conv1D)           (None, 89, 768)           5376      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_21 (MaxPooling (None, 29, 768)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_64 (Conv1D)           (None, 28, 256)           393472    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_21 (Averag (None, 9, 256)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_65 (Conv1D)           (None, 7, 256)            196864    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_21  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_42 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_64 (Dense)             (None, 384)               98688     \n",
      "_________________________________________________________________\n",
      "dropout_43 (Dropout)         (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 6)                 2310      \n",
      "=================================================================\n",
      "Total params: 762,502\n",
      "Trainable params: 762,502\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 768, k_conv_1 = 2,  n_conv_2 = 256, k_conv_2 = 2, \n",
      "          n_conv_3 = 256,  k_conv_3 = 3,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 256, dropout_1 = 0.3,\n",
      "          n_dense_2 = 384, dropout_2 = 0.2, activation_conv=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001D5AE3CD8C8>,\n",
      "          activation_dense=  elu\n",
      "Epoch 1/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 1.1083 - accuracy: 0.5259\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.9142 - accuracy: 0.6011\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.8216 - accuracy: 0.6431\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.7536 - accuracy: 0.6805\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.6866 - accuracy: 0.7220\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.6361 - accuracy: 0.7483\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.6013 - accuracy: 0.7640\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.5602 - accuracy: 0.7845\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.5229 - accuracy: 0.7997\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.5199 - accuracy: 0.7993\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.4787 - accuracy: 0.8186\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.4595 - accuracy: 0.8226\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.4525 - accuracy: 0.8271\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.4455 - accuracy: 0.8299\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.4356 - accuracy: 0.8349\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.4245 - accuracy: 0.8370\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.4168 - accuracy: 0.8413\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.4258 - accuracy: 0.8373\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.4008 - accuracy: 0.8463\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3977 - accuracy: 0.8478\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3922 - accuracy: 0.8500\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3803 - accuracy: 0.8530\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3925 - accuracy: 0.8488\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3904 - accuracy: 0.8493\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3693 - accuracy: 0.8562 0s - loss: 0.3710 - \n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3754 - accuracy: 0.8546\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3650 - accuracy: 0.8561\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3559 - accuracy: 0.8620\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3559 - accuracy: 0.8624\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3387 - accuracy: 0.8672\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3350 - accuracy: 0.8697\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3490 - accuracy: 0.8650\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3337 - accuracy: 0.8691\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3431 - accuracy: 0.8677\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3277 - accuracy: 0.8730\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3314 - accuracy: 0.8703\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3316 - accuracy: 0.8706\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3288 - accuracy: 0.8718\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3440 - accuracy: 0.8643\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3281 - accuracy: 0.8712\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3194 - accuracy: 0.8742\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3330 - accuracy: 0.8706\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3116 - accuracy: 0.8790\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3134 - accuracy: 0.8768\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3115 - accuracy: 0.8751\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3064 - accuracy: 0.8806\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3067 - accuracy: 0.8786 0s - loss: 0.3069 - accuracy: 0.87\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.2987 - accuracy: 0.8815\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.2986 - accuracy: 0.8813\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.2981 - accuracy: 0.8823\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.2997 - accuracy: 0.8812\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.2858 - accuracy: 0.8867\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.2950 - accuracy: 0.8833\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.2893 - accuracy: 0.8830\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.2877 - accuracy: 0.8846\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.2843 - accuracy: 0.8872\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.2926 - accuracy: 0.8847\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.2900 - accuracy: 0.8848\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.2790 - accuracy: 0.8883\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.2846 - accuracy: 0.8875\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 0.3243 - accuracy: 0.8796\n",
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_66 (Conv1D)           (None, 89, 512)           3584      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_22 (MaxPooling (None, 17, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_67 (Conv1D)           (None, 15, 256)           393472    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_22 (Averag (None, 3, 256)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_68 (Conv1D)           (None, 2, 512)            262656    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_22  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             (None, 384)               196992    \n",
      "_________________________________________________________________\n",
      "dropout_44 (Dropout)         (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_67 (Dense)             (None, 256)               98560     \n",
      "_________________________________________________________________\n",
      "dropout_45 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 6)                 1542      \n",
      "=================================================================\n",
      "Total params: 956,806\n",
      "Trainable params: 956,806\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 512, k_conv_1 = 2,  n_conv_2 = 256, k_conv_2 = 3, \n",
      "          n_conv_3 = 512,  k_conv_3 = 2,  maxpooling_pool_size = 5,\n",
      "          avepooling_pool_size = 5,  n_dense_1 = 384, dropout_1 = 0.3,\n",
      "          n_dense_2 = 256, dropout_2 = 0.2, activation_conv=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001D5AE3CD8C8>,\n",
      "          activation_dense=  elu\n",
      "Epoch 1/60\n",
      "  1/152 [..............................] - ETA: 1s - loss: 1.7872 - accuracy: 0.1836WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0099s vs `on_train_batch_end` time: 0.0150s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 4s 25ms/step - loss: 1.1119 - accuracy: 0.5178\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.8769 - accuracy: 0.6202\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.7767 - accuracy: 0.6648\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.7396 - accuracy: 0.6878\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.6732 - accuracy: 0.7238\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.6254 - accuracy: 0.7492\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.5826 - accuracy: 0.7658\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.5561 - accuracy: 0.7794\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.5116 - accuracy: 0.8024\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.4956 - accuracy: 0.8064\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.4881 - accuracy: 0.8100\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.4664 - accuracy: 0.8182\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.4668 - accuracy: 0.8182\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.4211 - accuracy: 0.8392\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.4324 - accuracy: 0.8323\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.4213 - accuracy: 0.8371\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.4038 - accuracy: 0.8440\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.3951 - accuracy: 0.8486\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.3863 - accuracy: 0.8516\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.3938 - accuracy: 0.8481\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.3836 - accuracy: 0.8506\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.3682 - accuracy: 0.8595\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.3672 - accuracy: 0.8579\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.3554 - accuracy: 0.8647\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.3483 - accuracy: 0.8645\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.3534 - accuracy: 0.8650\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.3414 - accuracy: 0.8691\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.3418 - accuracy: 0.8679\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.3431 - accuracy: 0.8675\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.3243 - accuracy: 0.8757\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.3345 - accuracy: 0.8696\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.3075 - accuracy: 0.8814\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.3222 - accuracy: 0.8751\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.3204 - accuracy: 0.8760\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.3245 - accuracy: 0.8743\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.3059 - accuracy: 0.8812\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.3067 - accuracy: 0.8808\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.3035 - accuracy: 0.8818\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2993 - accuracy: 0.8821\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2946 - accuracy: 0.8853\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2950 - accuracy: 0.8861\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2934 - accuracy: 0.8859\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2919 - accuracy: 0.8861\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2833 - accuracy: 0.8889\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2824 - accuracy: 0.8894\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2802 - accuracy: 0.8896\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2693 - accuracy: 0.8949\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2828 - accuracy: 0.8900\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2729 - accuracy: 0.8934 0s - loss: 0\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2624 - accuracy: 0.8959\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2833 - accuracy: 0.8874\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2534 - accuracy: 0.8986\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2747 - accuracy: 0.8925\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2709 - accuracy: 0.8933\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2657 - accuracy: 0.8944\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2596 - accuracy: 0.8967\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2532 - accuracy: 0.8995\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2514 - accuracy: 0.9005\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2451 - accuracy: 0.9022\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2490 - accuracy: 0.9019\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 0.3234 - accuracy: 0.8821\n",
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_69 (Conv1D)           (None, 89, 512)           3584      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_23 (MaxPooling (None, 17, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_70 (Conv1D)           (None, 15, 256)           393472    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_23 (Averag (None, 3, 256)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_71 (Conv1D)           (None, 2, 512)            262656    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_23  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 384)               196992    \n",
      "_________________________________________________________________\n",
      "dropout_46 (Dropout)         (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_70 (Dense)             (None, 256)               98560     \n",
      "_________________________________________________________________\n",
      "dropout_47 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_71 (Dense)             (None, 6)                 1542      \n",
      "=================================================================\n",
      "Total params: 956,806\n",
      "Trainable params: 956,806\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 512, k_conv_1 = 2,  n_conv_2 = 256, k_conv_2 = 3, \n",
      "          n_conv_3 = 512,  k_conv_3 = 2,  maxpooling_pool_size = 5,\n",
      "          avepooling_pool_size = 5,  n_dense_1 = 384, dropout_1 = 0.3,\n",
      "          n_dense_2 = 256, dropout_2 = 0.2, activation_conv=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001D5AE3CD8C8>,\n",
      "          activation_dense=  elu\n",
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 3s 22ms/step - loss: 1.0954 - accuracy: 0.5305\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.8794 - accuracy: 0.6219\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.7830 - accuracy: 0.6656\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.7055 - accuracy: 0.7034\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.6565 - accuracy: 0.7309\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.6188 - accuracy: 0.7524\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.5895 - accuracy: 0.7648\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.5471 - accuracy: 0.7842\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.5166 - accuracy: 0.7972\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.4968 - accuracy: 0.8060\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.4847 - accuracy: 0.8114\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.4501 - accuracy: 0.8269\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.4418 - accuracy: 0.8301\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.4363 - accuracy: 0.8295 1s -\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.4350 - accuracy: 0.8316\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.4080 - accuracy: 0.8447\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.4190 - accuracy: 0.8385\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.4023 - accuracy: 0.8441\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.3973 - accuracy: 0.8470\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.3805 - accuracy: 0.8519\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.3679 - accuracy: 0.8578\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.3651 - accuracy: 0.8583\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.3641 - accuracy: 0.8577\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.3636 - accuracy: 0.8567\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.3678 - accuracy: 0.8573\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.3436 - accuracy: 0.8657\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.3414 - accuracy: 0.8653\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.3359 - accuracy: 0.8674\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.3386 - accuracy: 0.8678\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.3269 - accuracy: 0.8724\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.3270 - accuracy: 0.8711\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.3262 - accuracy: 0.8726\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.3152 - accuracy: 0.8752\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.3329 - accuracy: 0.8694\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.3015 - accuracy: 0.8823\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.3107 - accuracy: 0.8750\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.3046 - accuracy: 0.8789\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.3099 - accuracy: 0.8776\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.3006 - accuracy: 0.8809\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2985 - accuracy: 0.8804\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2985 - accuracy: 0.8828\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2911 - accuracy: 0.8845\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2855 - accuracy: 0.8864\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2886 - accuracy: 0.8868\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2805 - accuracy: 0.8870\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2807 - accuracy: 0.8880\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2749 - accuracy: 0.8895\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2847 - accuracy: 0.8846\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2693 - accuracy: 0.8922\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2792 - accuracy: 0.8873\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2690 - accuracy: 0.8901\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2636 - accuracy: 0.8946\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2752 - accuracy: 0.8889\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2666 - accuracy: 0.8930\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2661 - accuracy: 0.8922\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2536 - accuracy: 0.8975\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2564 - accuracy: 0.8969\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2556 - accuracy: 0.8971\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2523 - accuracy: 0.8978\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2504 - accuracy: 0.8995\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.3397 - accuracy: 0.8787\n",
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_72 (Conv1D)           (None, 89, 512)           3584      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_24 (MaxPooling (None, 17, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_73 (Conv1D)           (None, 15, 256)           393472    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_24 (Averag (None, 3, 256)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_74 (Conv1D)           (None, 2, 512)            262656    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_24  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_72 (Dense)             (None, 384)               196992    \n",
      "_________________________________________________________________\n",
      "dropout_48 (Dropout)         (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_73 (Dense)             (None, 256)               98560     \n",
      "_________________________________________________________________\n",
      "dropout_49 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_74 (Dense)             (None, 6)                 1542      \n",
      "=================================================================\n",
      "Total params: 956,806\n",
      "Trainable params: 956,806\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 512, k_conv_1 = 2,  n_conv_2 = 256, k_conv_2 = 3, \n",
      "          n_conv_3 = 512,  k_conv_3 = 2,  maxpooling_pool_size = 5,\n",
      "          avepooling_pool_size = 5,  n_dense_1 = 384, dropout_1 = 0.3,\n",
      "          n_dense_2 = 256, dropout_2 = 0.2, activation_conv=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001D5AE3CD8C8>,\n",
      "          activation_dense=  elu\n",
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 3s 22ms/step - loss: 1.1067 - accuracy: 0.5262\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.8715 - accuracy: 0.6218\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.7774 - accuracy: 0.6709\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.7085 - accuracy: 0.7062\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.6635 - accuracy: 0.7262\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.6052 - accuracy: 0.7569\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.5882 - accuracy: 0.7674\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.5500 - accuracy: 0.7846\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.5073 - accuracy: 0.8050\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.4963 - accuracy: 0.8085\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.4775 - accuracy: 0.8140\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.4563 - accuracy: 0.8234\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.4399 - accuracy: 0.8306\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.4309 - accuracy: 0.8337\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.4205 - accuracy: 0.8378\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.4108 - accuracy: 0.8422\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.4107 - accuracy: 0.8399\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.3920 - accuracy: 0.8461\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.3945 - accuracy: 0.8485\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.3765 - accuracy: 0.8540\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.3678 - accuracy: 0.8557\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.3729 - accuracy: 0.8553\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.3761 - accuracy: 0.8537\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.3699 - accuracy: 0.8566\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.3447 - accuracy: 0.8644\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.3417 - accuracy: 0.8679\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.3556 - accuracy: 0.8617\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.3345 - accuracy: 0.8692\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.3339 - accuracy: 0.8708\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.3313 - accuracy: 0.8690\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.3350 - accuracy: 0.8683\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.3244 - accuracy: 0.8738\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.3235 - accuracy: 0.8733\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.3203 - accuracy: 0.8754\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.3165 - accuracy: 0.8741\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.3173 - accuracy: 0.8750\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.3021 - accuracy: 0.8805\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2993 - accuracy: 0.8830\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.3108 - accuracy: 0.8773\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2927 - accuracy: 0.8831\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2877 - accuracy: 0.8864\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2816 - accuracy: 0.8890\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2955 - accuracy: 0.8842\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2772 - accuracy: 0.8907\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2775 - accuracy: 0.8911\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2826 - accuracy: 0.8882\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2893 - accuracy: 0.8848\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2702 - accuracy: 0.8919\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2698 - accuracy: 0.8936\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2684 - accuracy: 0.8934\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2665 - accuracy: 0.8942\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2625 - accuracy: 0.8968\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2640 - accuracy: 0.8954\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2674 - accuracy: 0.8938 0s - l\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2528 - accuracy: 0.8991\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2591 - accuracy: 0.8958\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2519 - accuracy: 0.8982\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2622 - accuracy: 0.8961\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2422 - accuracy: 0.9025\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2462 - accuracy: 0.9031\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.3684 - accuracy: 0.8700\n",
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_75 (Conv1D)           (None, 88, 768)           7680      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_25 (MaxPooling (None, 29, 768)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_76 (Conv1D)           (None, 27, 512)           1180160   \n",
      "_________________________________________________________________\n",
      "average_pooling1d_25 (Averag (None, 9, 512)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_77 (Conv1D)           (None, 7, 256)            393472    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_25  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_75 (Dense)             (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_50 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_76 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_51 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_77 (Dense)             (None, 6)                 1542      \n",
      "=================================================================\n",
      "Total params: 1,845,766\n",
      "Trainable params: 1,845,766\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 768, k_conv_1 = 3,  n_conv_2 = 512, k_conv_2 = 3, \n",
      "          n_conv_3 = 256,  k_conv_3 = 3,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 512, dropout_1 = 0.3,\n",
      "          n_dense_2 = 256, dropout_2 = 0.3, activation_conv=  relu,\n",
      "          activation_dense=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001D5B5607388>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "  2/152 [..............................] - ETA: 4s - loss: 1.7843 - accuracy: 0.1523WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0209s vs `on_train_batch_end` time: 0.0314s). Check your callbacks.\n",
      "152/152 [==============================] - 8s 51ms/step - loss: 1.0592 - accuracy: 0.5499\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.6563 - accuracy: 0.7437\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.4818 - accuracy: 0.8192\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.3948 - accuracy: 0.8539\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.3639 - accuracy: 0.8649\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.3379 - accuracy: 0.8733\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.3267 - accuracy: 0.8784\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2967 - accuracy: 0.8894\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2924 - accuracy: 0.8920\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2795 - accuracy: 0.8940\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2684 - accuracy: 0.8999\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2599 - accuracy: 0.9030\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2454 - accuracy: 0.9100\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2393 - accuracy: 0.9119\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2411 - accuracy: 0.9108\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2266 - accuracy: 0.9150\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2186 - accuracy: 0.9170\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2103 - accuracy: 0.9212\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2077 - accuracy: 0.9206\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2032 - accuracy: 0.9242\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2049 - accuracy: 0.9231\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1938 - accuracy: 0.9271\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1877 - accuracy: 0.9283\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1790 - accuracy: 0.9330\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1787 - accuracy: 0.9341\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1753 - accuracy: 0.9328\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1718 - accuracy: 0.9344\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1724 - accuracy: 0.9353\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1583 - accuracy: 0.9401\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1575 - accuracy: 0.9400\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1553 - accuracy: 0.9411\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1561 - accuracy: 0.9410\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1523 - accuracy: 0.9414\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1471 - accuracy: 0.9451\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1387 - accuracy: 0.9466\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1432 - accuracy: 0.9450\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1397 - accuracy: 0.9464\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1308 - accuracy: 0.9508\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1336 - accuracy: 0.9492\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1359 - accuracy: 0.9484\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1239 - accuracy: 0.9511\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1279 - accuracy: 0.9508\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1313 - accuracy: 0.9489\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1174 - accuracy: 0.9561\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1248 - accuracy: 0.9524\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1139 - accuracy: 0.9562\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1142 - accuracy: 0.9554\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1129 - accuracy: 0.9574\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1144 - accuracy: 0.9556\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1099 - accuracy: 0.9565\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1189 - accuracy: 0.9554\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1068 - accuracy: 0.9579\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1030 - accuracy: 0.9605\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.0978 - accuracy: 0.9619\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1055 - accuracy: 0.9596\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1013 - accuracy: 0.9615\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.0973 - accuracy: 0.9622\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1004 - accuracy: 0.9614\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.0960 - accuracy: 0.9618\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.0976 - accuracy: 0.9634\n",
      "76/76 [==============================] - 1s 19ms/step - loss: 0.2737 - accuracy: 0.9344\n",
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_78 (Conv1D)           (None, 88, 768)           7680      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_26 (MaxPooling (None, 29, 768)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_79 (Conv1D)           (None, 27, 512)           1180160   \n",
      "_________________________________________________________________\n",
      "average_pooling1d_26 (Averag (None, 9, 512)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_80 (Conv1D)           (None, 7, 256)            393472    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_26  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_78 (Dense)             (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_52 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_79 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_53 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_80 (Dense)             (None, 6)                 1542      \n",
      "=================================================================\n",
      "Total params: 1,845,766\n",
      "Trainable params: 1,845,766\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 768, k_conv_1 = 3,  n_conv_2 = 512, k_conv_2 = 3, \n",
      "          n_conv_3 = 256,  k_conv_3 = 3,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 512, dropout_1 = 0.3,\n",
      "          n_dense_2 = 256, dropout_2 = 0.3, activation_conv=  relu,\n",
      "          activation_dense=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001D5B5607388>\n",
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/152 [..............................] - ETA: 4s - loss: 1.8009 - accuracy: 0.1562WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0189s vs `on_train_batch_end` time: 0.0289s). Check your callbacks.\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 1.0419 - accuracy: 0.5581\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.6471 - accuracy: 0.7479\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.4752 - accuracy: 0.8231\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.4011 - accuracy: 0.8498\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.3775 - accuracy: 0.8576\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.3299 - accuracy: 0.8759\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.3216 - accuracy: 0.8791\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.3040 - accuracy: 0.8835\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2923 - accuracy: 0.8897\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2779 - accuracy: 0.8943\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2594 - accuracy: 0.9014\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2615 - accuracy: 0.9020\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2443 - accuracy: 0.9080\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2431 - accuracy: 0.9080\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2420 - accuracy: 0.9086\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2252 - accuracy: 0.9151\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2147 - accuracy: 0.9198\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2071 - accuracy: 0.9217\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2029 - accuracy: 0.9234\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2071 - accuracy: 0.9207\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1925 - accuracy: 0.9274\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1821 - accuracy: 0.9306\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1979 - accuracy: 0.9265\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1806 - accuracy: 0.9330\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1807 - accuracy: 0.9316\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1742 - accuracy: 0.9344\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1702 - accuracy: 0.9356\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1594 - accuracy: 0.9394\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1494 - accuracy: 0.9440\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1547 - accuracy: 0.9405\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1524 - accuracy: 0.9419\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1532 - accuracy: 0.9430\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1427 - accuracy: 0.9461\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1453 - accuracy: 0.9439\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1361 - accuracy: 0.9473\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1405 - accuracy: 0.9464\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1388 - accuracy: 0.9480\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1358 - accuracy: 0.9491\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1249 - accuracy: 0.9523\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1279 - accuracy: 0.9508\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1262 - accuracy: 0.9514\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1231 - accuracy: 0.9535\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1216 - accuracy: 0.9536\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1205 - accuracy: 0.9523\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1160 - accuracy: 0.9551\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1175 - accuracy: 0.9545\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1239 - accuracy: 0.9543\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1086 - accuracy: 0.9590\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1038 - accuracy: 0.9606\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1117 - accuracy: 0.9581\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1041 - accuracy: 0.9602\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.0953 - accuracy: 0.9638\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1020 - accuracy: 0.9613\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.0948 - accuracy: 0.9629\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1117 - accuracy: 0.9575\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.0950 - accuracy: 0.9635\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.0999 - accuracy: 0.9628\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.0937 - accuracy: 0.9639\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1017 - accuracy: 0.9631\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.0871 - accuracy: 0.9675\n",
      "76/76 [==============================] - 1s 18ms/step - loss: 0.2875 - accuracy: 0.9362\n",
      "Model: \"sequential_27\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_81 (Conv1D)           (None, 88, 768)           7680      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_27 (MaxPooling (None, 29, 768)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_82 (Conv1D)           (None, 27, 512)           1180160   \n",
      "_________________________________________________________________\n",
      "average_pooling1d_27 (Averag (None, 9, 512)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_83 (Conv1D)           (None, 7, 256)            393472    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_27  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_81 (Dense)             (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_54 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_82 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_55 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_83 (Dense)             (None, 6)                 1542      \n",
      "=================================================================\n",
      "Total params: 1,845,766\n",
      "Trainable params: 1,845,766\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 768, k_conv_1 = 3,  n_conv_2 = 512, k_conv_2 = 3, \n",
      "          n_conv_3 = 256,  k_conv_3 = 3,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 512, dropout_1 = 0.3,\n",
      "          n_dense_2 = 256, dropout_2 = 0.3, activation_conv=  relu,\n",
      "          activation_dense=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001D5B5607388>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "  2/152 [..............................] - ETA: 5s - loss: 1.7753 - accuracy: 0.2266WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0199s vs `on_train_batch_end` time: 0.0309s). Check your callbacks.\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 1.0433 - accuracy: 0.5642\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.6574 - accuracy: 0.7403\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.4789 - accuracy: 0.8203\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.4031 - accuracy: 0.8473\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.3676 - accuracy: 0.8611\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.3444 - accuracy: 0.8716\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.3234 - accuracy: 0.8783\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.3107 - accuracy: 0.8824\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2869 - accuracy: 0.8914\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2780 - accuracy: 0.8956\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2641 - accuracy: 0.9007\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2564 - accuracy: 0.9026\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2483 - accuracy: 0.9047\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2421 - accuracy: 0.9087\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2311 - accuracy: 0.9129\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2302 - accuracy: 0.9133\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2122 - accuracy: 0.9195\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2135 - accuracy: 0.9190\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2083 - accuracy: 0.9220\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1973 - accuracy: 0.9253\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1978 - accuracy: 0.9257\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1952 - accuracy: 0.9252\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1847 - accuracy: 0.9309\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1903 - accuracy: 0.9285\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1797 - accuracy: 0.9325\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1683 - accuracy: 0.9376\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1650 - accuracy: 0.9384\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1693 - accuracy: 0.9377\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1586 - accuracy: 0.9397\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1511 - accuracy: 0.9427\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1534 - accuracy: 0.9418\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1525 - accuracy: 0.9413\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1430 - accuracy: 0.9456\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1431 - accuracy: 0.9465\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1449 - accuracy: 0.9457\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1359 - accuracy: 0.9479\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1381 - accuracy: 0.9479\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1352 - accuracy: 0.9479\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1291 - accuracy: 0.9515\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1353 - accuracy: 0.9490\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1383 - accuracy: 0.9484\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1146 - accuracy: 0.9558\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1187 - accuracy: 0.9544\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1320 - accuracy: 0.9505\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1137 - accuracy: 0.9569\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1279 - accuracy: 0.9527\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1121 - accuracy: 0.9573\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1111 - accuracy: 0.9587\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1162 - accuracy: 0.9574\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1044 - accuracy: 0.9599 0s - loss: 0.1\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1075 - accuracy: 0.9591\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1089 - accuracy: 0.9584\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1025 - accuracy: 0.9602\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1078 - accuracy: 0.9595\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.0992 - accuracy: 0.9632\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.0926 - accuracy: 0.9641\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1125 - accuracy: 0.9595\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.0981 - accuracy: 0.9632\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.0940 - accuracy: 0.9645\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.0956 - accuracy: 0.9644\n",
      "76/76 [==============================] - 1s 18ms/step - loss: 0.2617 - accuracy: 0.9414\n",
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_84 (Conv1D)           (None, 89, 512)           3584      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_28 (MaxPooling (None, 29, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_85 (Conv1D)           (None, 28, 512)           524800    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_28 (Averag (None, 9, 512)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_86 (Conv1D)           (None, 7, 256)            393472    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_28  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_84 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_56 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_85 (Dense)             (None, 384)               98688     \n",
      "_________________________________________________________________\n",
      "dropout_57 (Dropout)         (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_86 (Dense)             (None, 6)                 2310      \n",
      "=================================================================\n",
      "Total params: 1,088,646\n",
      "Trainable params: 1,088,646\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 512, k_conv_1 = 2,  n_conv_2 = 512, k_conv_2 = 2, \n",
      "          n_conv_3 = 256,  k_conv_3 = 3,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 256, dropout_1 = 0.3,\n",
      "          n_dense_2 = 384, dropout_2 = 0.2, activation_conv=  elu,\n",
      "          activation_dense=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001D5B5607388>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 1.1595 - accuracy: 0.5094\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 1.0367 - accuracy: 0.5586\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.9624 - accuracy: 0.5914\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.9077 - accuracy: 0.6165\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.8533 - accuracy: 0.6463\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.8087 - accuracy: 0.6641\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.7648 - accuracy: 0.6823\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.7389 - accuracy: 0.6933 0s - loss: 0.7424 \n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.6962 - accuracy: 0.7165\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.6537 - accuracy: 0.7368\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.6187 - accuracy: 0.7510\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.5861 - accuracy: 0.7665\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.5741 - accuracy: 0.7739\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.5308 - accuracy: 0.7935\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.5192 - accuracy: 0.7980\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.5133 - accuracy: 0.8001\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4961 - accuracy: 0.8104\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4776 - accuracy: 0.8169\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4676 - accuracy: 0.8187\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4715 - accuracy: 0.8195\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4517 - accuracy: 0.8270\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4403 - accuracy: 0.8321\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4328 - accuracy: 0.8342 0s - loss: 0.4321 - accura\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4331 - accuracy: 0.8322\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4122 - accuracy: 0.8395\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4115 - accuracy: 0.8417\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4048 - accuracy: 0.8439\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3891 - accuracy: 0.8499\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3907 - accuracy: 0.8502\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3798 - accuracy: 0.8539\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3785 - accuracy: 0.8519\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3732 - accuracy: 0.8571\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3677 - accuracy: 0.8573 0s - loss: 0.3\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3560 - accuracy: 0.8620\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3518 - accuracy: 0.8638\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3527 - accuracy: 0.8643\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3492 - accuracy: 0.8633\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3322 - accuracy: 0.8705\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3304 - accuracy: 0.8711\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3364 - accuracy: 0.8689\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3275 - accuracy: 0.8740\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3221 - accuracy: 0.8739\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3207 - accuracy: 0.8756\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3180 - accuracy: 0.8773\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3044 - accuracy: 0.8804\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3134 - accuracy: 0.8785\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2997 - accuracy: 0.8822\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3017 - accuracy: 0.8828\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2934 - accuracy: 0.8855\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2896 - accuracy: 0.8856\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2880 - accuracy: 0.8869\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2946 - accuracy: 0.8853\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2771 - accuracy: 0.8899\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2800 - accuracy: 0.8909 0s -\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2751 - accuracy: 0.8913\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2786 - accuracy: 0.8905\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2658 - accuracy: 0.8957\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2630 - accuracy: 0.8975\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2681 - accuracy: 0.8950\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2621 - accuracy: 0.8978\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 0.3044 - accuracy: 0.8924\n",
      "Model: \"sequential_29\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_87 (Conv1D)           (None, 89, 512)           3584      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_29 (MaxPooling (None, 29, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_88 (Conv1D)           (None, 28, 512)           524800    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_29 (Averag (None, 9, 512)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_89 (Conv1D)           (None, 7, 256)            393472    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_29  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_87 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_58 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_88 (Dense)             (None, 384)               98688     \n",
      "_________________________________________________________________\n",
      "dropout_59 (Dropout)         (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_89 (Dense)             (None, 6)                 2310      \n",
      "=================================================================\n",
      "Total params: 1,088,646\n",
      "Trainable params: 1,088,646\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 512, k_conv_1 = 2,  n_conv_2 = 512, k_conv_2 = 2, \n",
      "          n_conv_3 = 256,  k_conv_3 = 3,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 256, dropout_1 = 0.3,\n",
      "          n_dense_2 = 384, dropout_2 = 0.2, activation_conv=  elu,\n",
      "          activation_dense=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001D5B5607388>\n",
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 5s 31ms/step - loss: 1.1604 - accuracy: 0.5086\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 1.0312 - accuracy: 0.5632\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.9593 - accuracy: 0.5906\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.9069 - accuracy: 0.6185\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.8371 - accuracy: 0.6519\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.7961 - accuracy: 0.6663\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.7498 - accuracy: 0.6893\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.7084 - accuracy: 0.7067\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.6763 - accuracy: 0.7226\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.6662 - accuracy: 0.7280\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.6132 - accuracy: 0.7536\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.5881 - accuracy: 0.7657\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.5635 - accuracy: 0.7769\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.5320 - accuracy: 0.7907\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.5225 - accuracy: 0.7942\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4973 - accuracy: 0.8067\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4868 - accuracy: 0.8101\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4727 - accuracy: 0.8170\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4592 - accuracy: 0.8220\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4488 - accuracy: 0.8281\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4395 - accuracy: 0.8313\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4360 - accuracy: 0.8320\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4298 - accuracy: 0.8343\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4130 - accuracy: 0.8411\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4107 - accuracy: 0.8427\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4148 - accuracy: 0.8419\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3888 - accuracy: 0.8513\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3818 - accuracy: 0.8531\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3845 - accuracy: 0.8527\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3724 - accuracy: 0.8580\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3676 - accuracy: 0.8578\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3685 - accuracy: 0.8594\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3637 - accuracy: 0.8586\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3584 - accuracy: 0.8621\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3507 - accuracy: 0.8647\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3508 - accuracy: 0.8645\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3467 - accuracy: 0.8655\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3420 - accuracy: 0.8676\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3338 - accuracy: 0.8698\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3333 - accuracy: 0.8701\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3320 - accuracy: 0.8712\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3227 - accuracy: 0.8743\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3194 - accuracy: 0.8755\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3187 - accuracy: 0.8744\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3120 - accuracy: 0.8755\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3084 - accuracy: 0.8795\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3071 - accuracy: 0.8807 0s - loss: 0.3055 - accura\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2926 - accuracy: 0.8843 0s - loss: 0.2\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2990 - accuracy: 0.8822\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2999 - accuracy: 0.8803\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2906 - accuracy: 0.8830\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2914 - accuracy: 0.8849\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2858 - accuracy: 0.8872\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2793 - accuracy: 0.8881\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2798 - accuracy: 0.8895\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2783 - accuracy: 0.8896\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2701 - accuracy: 0.8932\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2744 - accuracy: 0.8922\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2677 - accuracy: 0.8934\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2685 - accuracy: 0.8946\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 0.3098 - accuracy: 0.8934\n",
      "Model: \"sequential_30\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_90 (Conv1D)           (None, 89, 512)           3584      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_30 (MaxPooling (None, 29, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_91 (Conv1D)           (None, 28, 512)           524800    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_30 (Averag (None, 9, 512)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_92 (Conv1D)           (None, 7, 256)            393472    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_30  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_90 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_60 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_91 (Dense)             (None, 384)               98688     \n",
      "_________________________________________________________________\n",
      "dropout_61 (Dropout)         (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_92 (Dense)             (None, 6)                 2310      \n",
      "=================================================================\n",
      "Total params: 1,088,646\n",
      "Trainable params: 1,088,646\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 512, k_conv_1 = 2,  n_conv_2 = 512, k_conv_2 = 2, \n",
      "          n_conv_3 = 256,  k_conv_3 = 3,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 256, dropout_1 = 0.3,\n",
      "          n_dense_2 = 384, dropout_2 = 0.2, activation_conv=  elu,\n",
      "          activation_dense=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001D5B5607388>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 1.1641 - accuracy: 0.5124\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 1.0323 - accuracy: 0.5637\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.9671 - accuracy: 0.5897\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.9145 - accuracy: 0.6118\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.8725 - accuracy: 0.6358\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.8147 - accuracy: 0.6598\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.7735 - accuracy: 0.6781\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.7390 - accuracy: 0.6938\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.7093 - accuracy: 0.7100\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.6691 - accuracy: 0.7282\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.6314 - accuracy: 0.7474\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.6040 - accuracy: 0.7585\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.5632 - accuracy: 0.7785\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.5420 - accuracy: 0.7847 0s - loss: 0.5426 \n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.5332 - accuracy: 0.7889\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.5112 - accuracy: 0.8003\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4898 - accuracy: 0.8073\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4812 - accuracy: 0.8115\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4568 - accuracy: 0.8221\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4671 - accuracy: 0.8154\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4456 - accuracy: 0.8265\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4355 - accuracy: 0.8290\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4298 - accuracy: 0.8330\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4198 - accuracy: 0.8347\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4219 - accuracy: 0.8362\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4047 - accuracy: 0.8418\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4045 - accuracy: 0.8399 0s - loss: - ETA: 0s - loss: 0.4053 - accuracy: 0.\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3940 - accuracy: 0.8480\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3915 - accuracy: 0.8472\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3839 - accuracy: 0.8497\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3664 - accuracy: 0.8559\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3802 - accuracy: 0.8519\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3644 - accuracy: 0.8588\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3612 - accuracy: 0.8581\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3495 - accuracy: 0.8631\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3532 - accuracy: 0.8613\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3441 - accuracy: 0.8645\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3453 - accuracy: 0.8649\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3311 - accuracy: 0.8697\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3324 - accuracy: 0.8695\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3238 - accuracy: 0.8746\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3218 - accuracy: 0.8723\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3159 - accuracy: 0.8787\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3139 - accuracy: 0.8780\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3119 - accuracy: 0.8790\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3091 - accuracy: 0.8779\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3022 - accuracy: 0.8810\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2907 - accuracy: 0.8862\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3011 - accuracy: 0.8837\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2958 - accuracy: 0.8858\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2881 - accuracy: 0.8868\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2850 - accuracy: 0.8893\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2824 - accuracy: 0.8895\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2911 - accuracy: 0.8870\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2796 - accuracy: 0.8900\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2704 - accuracy: 0.8947\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2744 - accuracy: 0.8939\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2653 - accuracy: 0.8955\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2693 - accuracy: 0.8941\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2602 - accuracy: 0.8976\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 0.2926 - accuracy: 0.8969\n",
      "Model: \"sequential_31\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_93 (Conv1D)           (None, 88, 768)           7680      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_31 (MaxPooling (None, 17, 768)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_94 (Conv1D)           (None, 15, 256)           590080    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_31 (Averag (None, 5, 256)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_95 (Conv1D)           (None, 4, 512)            262656    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_31  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_93 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_62 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_94 (Dense)             (None, 384)               196992    \n",
      "_________________________________________________________________\n",
      "dropout_63 (Dropout)         (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_95 (Dense)             (None, 6)                 2310      \n",
      "=================================================================\n",
      "Total params: 1,322,374\n",
      "Trainable params: 1,322,374\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 768, k_conv_1 = 3,  n_conv_2 = 256, k_conv_2 = 3, \n",
      "          n_conv_3 = 512,  k_conv_3 = 2,  maxpooling_pool_size = 5,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 512, dropout_1 = 0.3,\n",
      "          n_dense_2 = 384, dropout_2 = 0.3, activation_conv=  elu,\n",
      "          activation_dense=  elu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "  1/152 [..............................] - ETA: 2s - loss: 1.7968 - accuracy: 0.1914WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0129s vs `on_train_batch_end` time: 0.0200s). Check your callbacks.\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 1.1583 - accuracy: 0.5167\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.8919 - accuracy: 0.6441\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.8224 - accuracy: 0.6711\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.7791 - accuracy: 0.6894\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.7553 - accuracy: 0.6983\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.7089 - accuracy: 0.7177\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.7040 - accuracy: 0.7193\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.6702 - accuracy: 0.7310\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.6388 - accuracy: 0.7437\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.6068 - accuracy: 0.7576\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.5883 - accuracy: 0.7651\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.5811 - accuracy: 0.7708\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.5498 - accuracy: 0.7825\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.5410 - accuracy: 0.7876\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.5080 - accuracy: 0.8024\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.5035 - accuracy: 0.8056\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4910 - accuracy: 0.8090\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.4599 - accuracy: 0.8247\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4542 - accuracy: 0.8268\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4555 - accuracy: 0.8253\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4277 - accuracy: 0.8351\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4286 - accuracy: 0.8355\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4145 - accuracy: 0.8426\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4018 - accuracy: 0.8468\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.3911 - accuracy: 0.8504\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.3901 - accuracy: 0.8515\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3804 - accuracy: 0.8551\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.3697 - accuracy: 0.8612\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3557 - accuracy: 0.8646\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3559 - accuracy: 0.8651\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.3450 - accuracy: 0.8686\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3341 - accuracy: 0.8729\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.3352 - accuracy: 0.8698\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3410 - accuracy: 0.8681\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.3210 - accuracy: 0.8760\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.3160 - accuracy: 0.8762\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.3112 - accuracy: 0.8801\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3082 - accuracy: 0.8825\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3016 - accuracy: 0.8835\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.3119 - accuracy: 0.8808\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3049 - accuracy: 0.8849\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2849 - accuracy: 0.8914\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2826 - accuracy: 0.8927\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2754 - accuracy: 0.8954\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2849 - accuracy: 0.8909\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2754 - accuracy: 0.8938\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2742 - accuracy: 0.8958\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2701 - accuracy: 0.8949\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2646 - accuracy: 0.8988\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2689 - accuracy: 0.8962\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2508 - accuracy: 0.9022\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2625 - accuracy: 0.8999\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2539 - accuracy: 0.9029\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2560 - accuracy: 0.9018\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2453 - accuracy: 0.9050\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2483 - accuracy: 0.9045\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2486 - accuracy: 0.9025\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2400 - accuracy: 0.9080\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2320 - accuracy: 0.9094\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2347 - accuracy: 0.9102\n",
      "76/76 [==============================] - 1s 14ms/step - loss: 0.2766 - accuracy: 0.9072\n",
      "Model: \"sequential_32\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_96 (Conv1D)           (None, 88, 768)           7680      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_32 (MaxPooling (None, 17, 768)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_97 (Conv1D)           (None, 15, 256)           590080    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_32 (Averag (None, 5, 256)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_98 (Conv1D)           (None, 4, 512)            262656    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_32  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_96 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_64 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_97 (Dense)             (None, 384)               196992    \n",
      "_________________________________________________________________\n",
      "dropout_65 (Dropout)         (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_98 (Dense)             (None, 6)                 2310      \n",
      "=================================================================\n",
      "Total params: 1,322,374\n",
      "Trainable params: 1,322,374\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 768, k_conv_1 = 3,  n_conv_2 = 256, k_conv_2 = 3, \n",
      "          n_conv_3 = 512,  k_conv_3 = 2,  maxpooling_pool_size = 5,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 512, dropout_1 = 0.3,\n",
      "          n_dense_2 = 384, dropout_2 = 0.3, activation_conv=  elu,\n",
      "          activation_dense=  elu\n",
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/152 [..............................] - ETA: 2s - loss: 1.8011 - accuracy: 0.1602WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0120s vs `on_train_batch_end` time: 0.0199s). Check your callbacks.\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 1.1481 - accuracy: 0.5227\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.8775 - accuracy: 0.6503\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.8201 - accuracy: 0.6745 0s - loss:\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.7676 - accuracy: 0.6955\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.7655 - accuracy: 0.6939\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.7222 - accuracy: 0.7127\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.6991 - accuracy: 0.7209\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.6688 - accuracy: 0.7308\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.6538 - accuracy: 0.7357\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.6138 - accuracy: 0.7552\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.5938 - accuracy: 0.7608\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.5688 - accuracy: 0.7740\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.5584 - accuracy: 0.7804\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.5299 - accuracy: 0.7931\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.5180 - accuracy: 0.7982\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.4956 - accuracy: 0.8057\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4778 - accuracy: 0.8124\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.4717 - accuracy: 0.8162\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.4525 - accuracy: 0.8262\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4441 - accuracy: 0.8291\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4257 - accuracy: 0.8349\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4212 - accuracy: 0.8375\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.4137 - accuracy: 0.8410\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.4005 - accuracy: 0.8465\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.3891 - accuracy: 0.8491\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.3886 - accuracy: 0.8496\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.3888 - accuracy: 0.8514\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3685 - accuracy: 0.8594\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.3511 - accuracy: 0.8668\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.3467 - accuracy: 0.8651\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.3471 - accuracy: 0.8677\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3495 - accuracy: 0.8658\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.3290 - accuracy: 0.8714\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.3322 - accuracy: 0.8725\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3244 - accuracy: 0.8749\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.3164 - accuracy: 0.8781\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.3214 - accuracy: 0.8763\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.3151 - accuracy: 0.8786\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.3034 - accuracy: 0.8840\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.3051 - accuracy: 0.8845\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2917 - accuracy: 0.8869\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2889 - accuracy: 0.8869\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2906 - accuracy: 0.8871\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2873 - accuracy: 0.8875\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2821 - accuracy: 0.8916\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2862 - accuracy: 0.8896\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2693 - accuracy: 0.8963\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2731 - accuracy: 0.8947\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2672 - accuracy: 0.8952\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2589 - accuracy: 0.8978\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2584 - accuracy: 0.8983\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2579 - accuracy: 0.8996\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2483 - accuracy: 0.9044\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2514 - accuracy: 0.9026\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2449 - accuracy: 0.9052\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2477 - accuracy: 0.9036\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2463 - accuracy: 0.9051\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2338 - accuracy: 0.9103\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2326 - accuracy: 0.9098\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2472 - accuracy: 0.9051\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 0.2863 - accuracy: 0.8997\n",
      "Model: \"sequential_33\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_99 (Conv1D)           (None, 88, 768)           7680      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_33 (MaxPooling (None, 17, 768)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_100 (Conv1D)          (None, 15, 256)           590080    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_33 (Averag (None, 5, 256)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_101 (Conv1D)          (None, 4, 512)            262656    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_33  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_99 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_66 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_100 (Dense)            (None, 384)               196992    \n",
      "_________________________________________________________________\n",
      "dropout_67 (Dropout)         (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_101 (Dense)            (None, 6)                 2310      \n",
      "=================================================================\n",
      "Total params: 1,322,374\n",
      "Trainable params: 1,322,374\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 768, k_conv_1 = 3,  n_conv_2 = 256, k_conv_2 = 3, \n",
      "          n_conv_3 = 512,  k_conv_3 = 2,  maxpooling_pool_size = 5,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 512, dropout_1 = 0.3,\n",
      "          n_dense_2 = 384, dropout_2 = 0.3, activation_conv=  elu,\n",
      "          activation_dense=  elu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 1.1684 - accuracy: 0.5115\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.9048 - accuracy: 0.6355\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.8150 - accuracy: 0.6748\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.7987 - accuracy: 0.6849\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.7557 - accuracy: 0.7004\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.7509 - accuracy: 0.6985\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.7260 - accuracy: 0.7100\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.6888 - accuracy: 0.7246\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.6679 - accuracy: 0.7347\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.6371 - accuracy: 0.7438\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.6157 - accuracy: 0.7546\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.5944 - accuracy: 0.7617\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.5766 - accuracy: 0.7692\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.5428 - accuracy: 0.7882\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.5414 - accuracy: 0.7891\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.5150 - accuracy: 0.8022\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4852 - accuracy: 0.8135\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.4834 - accuracy: 0.8150\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.4580 - accuracy: 0.8249\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4354 - accuracy: 0.8355\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4331 - accuracy: 0.8347\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.4120 - accuracy: 0.8440\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.4006 - accuracy: 0.8469 0s - loss: 0.4009 - accuracy: \n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.4139 - accuracy: 0.8430\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3969 - accuracy: 0.8482\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.3722 - accuracy: 0.8573\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.3791 - accuracy: 0.8553\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.3607 - accuracy: 0.8613\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.3585 - accuracy: 0.8636\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.3473 - accuracy: 0.8664\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.3464 - accuracy: 0.8680\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.3317 - accuracy: 0.8737\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.3204 - accuracy: 0.8773\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.3335 - accuracy: 0.8730\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3135 - accuracy: 0.8808\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3076 - accuracy: 0.8828\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2992 - accuracy: 0.8844\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3173 - accuracy: 0.8818\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2973 - accuracy: 0.8880\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2917 - accuracy: 0.8904\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2810 - accuracy: 0.8924\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2843 - accuracy: 0.8922\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2835 - accuracy: 0.8930 0s -\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2768 - accuracy: 0.8931\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2659 - accuracy: 0.9004\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2773 - accuracy: 0.8951\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2663 - accuracy: 0.8972\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2887 - accuracy: 0.8911 0s - loss: 0.2894 - accu\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2527 - accuracy: 0.9028\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2689 - accuracy: 0.8979\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2474 - accuracy: 0.9048\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2457 - accuracy: 0.9060\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2460 - accuracy: 0.9053\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2397 - accuracy: 0.9084\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2504 - accuracy: 0.9056\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2302 - accuracy: 0.9101\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2343 - accuracy: 0.9118\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2342 - accuracy: 0.9092\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2342 - accuracy: 0.9087\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2278 - accuracy: 0.9117\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 0.3059 - accuracy: 0.8978\n",
      "Model: \"sequential_34\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_102 (Conv1D)          (None, 88, 768)           7680      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_34 (MaxPooling (None, 17, 768)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_103 (Conv1D)          (None, 15, 256)           590080    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_34 (Averag (None, 3, 256)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_104 (Conv1D)          (None, 2, 512)            262656    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_34  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_102 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_68 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_103 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_69 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_104 (Dense)            (None, 6)                 3078      \n",
      "=================================================================\n",
      "Total params: 1,388,806\n",
      "Trainable params: 1,388,806\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 768, k_conv_1 = 3,  n_conv_2 = 256, k_conv_2 = 3, \n",
      "          n_conv_3 = 512,  k_conv_3 = 2,  maxpooling_pool_size = 5,\n",
      "          avepooling_pool_size = 5,  n_dense_1 = 512, dropout_1 = 0.2,\n",
      "          n_dense_2 = 512, dropout_2 = 0.3, activation_conv=  elu,\n",
      "          activation_dense=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001D5B5607388>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 1.0861 - accuracy: 0.5420\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.8460 - accuracy: 0.6600 0s - loss: 0.8\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.7529 - accuracy: 0.6991\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.7114 - accuracy: 0.7184\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.6851 - accuracy: 0.7246\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.6477 - accuracy: 0.7398\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.6418 - accuracy: 0.7436\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.6101 - accuracy: 0.7537\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.5908 - accuracy: 0.7638\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.5778 - accuracy: 0.7704\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.5470 - accuracy: 0.7815\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.5288 - accuracy: 0.7875\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.5313 - accuracy: 0.7874\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.5109 - accuracy: 0.7983\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4943 - accuracy: 0.8045\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4754 - accuracy: 0.8125\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4737 - accuracy: 0.8129\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4735 - accuracy: 0.8124\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4621 - accuracy: 0.8205\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4516 - accuracy: 0.8259\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4455 - accuracy: 0.8275\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4250 - accuracy: 0.8344\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4331 - accuracy: 0.8326\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4231 - accuracy: 0.8357\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4137 - accuracy: 0.8389\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4036 - accuracy: 0.8437\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3976 - accuracy: 0.8463\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3985 - accuracy: 0.8460\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3851 - accuracy: 0.8539\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3871 - accuracy: 0.8515\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3809 - accuracy: 0.8537\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3782 - accuracy: 0.8551\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3737 - accuracy: 0.8562\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3726 - accuracy: 0.8564\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3630 - accuracy: 0.8600\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3526 - accuracy: 0.8627\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3581 - accuracy: 0.8628\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3521 - accuracy: 0.8651 1s\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3540 - accuracy: 0.8628 0s - loss: 0.3562 - accuracy\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3446 - accuracy: 0.8678\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3376 - accuracy: 0.8708\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3317 - accuracy: 0.8716\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3369 - accuracy: 0.8708\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3303 - accuracy: 0.8726\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3227 - accuracy: 0.8754\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3296 - accuracy: 0.8726\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3206 - accuracy: 0.8761\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3140 - accuracy: 0.8777\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3042 - accuracy: 0.8816\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3050 - accuracy: 0.8821\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3102 - accuracy: 0.8811\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3035 - accuracy: 0.8817\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3067 - accuracy: 0.8823\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2990 - accuracy: 0.8839\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2929 - accuracy: 0.8856\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2922 - accuracy: 0.8866\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2886 - accuracy: 0.8873\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2824 - accuracy: 0.8906\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2980 - accuracy: 0.8862\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2776 - accuracy: 0.8931\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 0.3234 - accuracy: 0.8904\n",
      "Model: \"sequential_35\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_105 (Conv1D)          (None, 88, 768)           7680      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_35 (MaxPooling (None, 17, 768)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_106 (Conv1D)          (None, 15, 256)           590080    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_35 (Averag (None, 3, 256)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_107 (Conv1D)          (None, 2, 512)            262656    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_35  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_105 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_70 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_106 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_71 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_107 (Dense)            (None, 6)                 3078      \n",
      "=================================================================\n",
      "Total params: 1,388,806\n",
      "Trainable params: 1,388,806\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 768, k_conv_1 = 3,  n_conv_2 = 256, k_conv_2 = 3, \n",
      "          n_conv_3 = 512,  k_conv_3 = 2,  maxpooling_pool_size = 5,\n",
      "          avepooling_pool_size = 5,  n_dense_1 = 512, dropout_1 = 0.2,\n",
      "          n_dense_2 = 512, dropout_2 = 0.3, activation_conv=  elu,\n",
      "          activation_dense=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001D5B5607388>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 1.1063 - accuracy: 0.5353\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.8476 - accuracy: 0.6591\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.7614 - accuracy: 0.6990\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.7143 - accuracy: 0.7156\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.6956 - accuracy: 0.7221\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.6695 - accuracy: 0.7322\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.6354 - accuracy: 0.7436\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.6079 - accuracy: 0.7571\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.5761 - accuracy: 0.7673\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.5748 - accuracy: 0.7712\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.5405 - accuracy: 0.7855\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.5337 - accuracy: 0.7861\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.5144 - accuracy: 0.7927\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4980 - accuracy: 0.8003\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4925 - accuracy: 0.8076\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4799 - accuracy: 0.8106\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4548 - accuracy: 0.8225\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4518 - accuracy: 0.8214\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4461 - accuracy: 0.8239\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4507 - accuracy: 0.8247\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4350 - accuracy: 0.8297\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4252 - accuracy: 0.8345\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4151 - accuracy: 0.8367\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4087 - accuracy: 0.8408\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4074 - accuracy: 0.8418\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4099 - accuracy: 0.8412\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3904 - accuracy: 0.8484\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3867 - accuracy: 0.8501\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3829 - accuracy: 0.8501\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3744 - accuracy: 0.8573\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3718 - accuracy: 0.8576\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3622 - accuracy: 0.8607\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3570 - accuracy: 0.8622\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3668 - accuracy: 0.8591\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3500 - accuracy: 0.8660\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3590 - accuracy: 0.8616\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3467 - accuracy: 0.8658\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3473 - accuracy: 0.8664\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3386 - accuracy: 0.8701\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3303 - accuracy: 0.8727\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3281 - accuracy: 0.8737\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3208 - accuracy: 0.8774\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3243 - accuracy: 0.8759\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3207 - accuracy: 0.8776\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3228 - accuracy: 0.8758\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3095 - accuracy: 0.8804\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3085 - accuracy: 0.8809\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3100 - accuracy: 0.8817\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2991 - accuracy: 0.8860\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2997 - accuracy: 0.8847\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2902 - accuracy: 0.8898\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2798 - accuracy: 0.8919\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2791 - accuracy: 0.8919\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2865 - accuracy: 0.8892\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2805 - accuracy: 0.8952 0s - loss: 0.2796 - accura\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2811 - accuracy: 0.8934\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2743 - accuracy: 0.8955\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2618 - accuracy: 0.8995\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2605 - accuracy: 0.9006\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2627 - accuracy: 0.8997\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 0.3639 - accuracy: 0.8848\n",
      "Model: \"sequential_36\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_108 (Conv1D)          (None, 88, 768)           7680      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_36 (MaxPooling (None, 17, 768)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_109 (Conv1D)          (None, 15, 256)           590080    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_36 (Averag (None, 3, 256)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_110 (Conv1D)          (None, 2, 512)            262656    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_36  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_108 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_72 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_109 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_73 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_110 (Dense)            (None, 6)                 3078      \n",
      "=================================================================\n",
      "Total params: 1,388,806\n",
      "Trainable params: 1,388,806\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 768, k_conv_1 = 3,  n_conv_2 = 256, k_conv_2 = 3, \n",
      "          n_conv_3 = 512,  k_conv_3 = 2,  maxpooling_pool_size = 5,\n",
      "          avepooling_pool_size = 5,  n_dense_1 = 512, dropout_1 = 0.2,\n",
      "          n_dense_2 = 512, dropout_2 = 0.3, activation_conv=  elu,\n",
      "          activation_dense=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001D5B5607388>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 1.0952 - accuracy: 0.5401\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.8427 - accuracy: 0.6608 0s - loss: 0.8478 \n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.7667 - accuracy: 0.6947\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.7201 - accuracy: 0.7108\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.6872 - accuracy: 0.7277\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.6643 - accuracy: 0.7351\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.6288 - accuracy: 0.7501\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.6088 - accuracy: 0.7564\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.5935 - accuracy: 0.7642\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.5575 - accuracy: 0.7789\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.5539 - accuracy: 0.7792\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.5446 - accuracy: 0.7813\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.5269 - accuracy: 0.7899\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.5015 - accuracy: 0.8046\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.5021 - accuracy: 0.8031\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4722 - accuracy: 0.8140\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4746 - accuracy: 0.8141\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4600 - accuracy: 0.8202\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4487 - accuracy: 0.8251\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4438 - accuracy: 0.8255\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4421 - accuracy: 0.8282\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4322 - accuracy: 0.8346\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4257 - accuracy: 0.8324\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4154 - accuracy: 0.8391\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4096 - accuracy: 0.8427\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4036 - accuracy: 0.8430\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4004 - accuracy: 0.8456\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3948 - accuracy: 0.8494\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3863 - accuracy: 0.8506\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3879 - accuracy: 0.8494\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3882 - accuracy: 0.8497\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3700 - accuracy: 0.8576\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3751 - accuracy: 0.8533\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3706 - accuracy: 0.8553\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3609 - accuracy: 0.8612\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3632 - accuracy: 0.8595\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3483 - accuracy: 0.8666\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3437 - accuracy: 0.8683\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3523 - accuracy: 0.8646\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3381 - accuracy: 0.8680\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3418 - accuracy: 0.8683\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3369 - accuracy: 0.8694\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3366 - accuracy: 0.8700\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3330 - accuracy: 0.8716\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3275 - accuracy: 0.8725\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3236 - accuracy: 0.8763\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3089 - accuracy: 0.8791\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3101 - accuracy: 0.8796\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3026 - accuracy: 0.8831\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3060 - accuracy: 0.8812\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2971 - accuracy: 0.8840\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3028 - accuracy: 0.8844\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2932 - accuracy: 0.8868\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2874 - accuracy: 0.8898\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2942 - accuracy: 0.8860\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2864 - accuracy: 0.8889\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2810 - accuracy: 0.8926\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2807 - accuracy: 0.8923\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2648 - accuracy: 0.8977\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2709 - accuracy: 0.8959\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 0.3038 - accuracy: 0.8931\n",
      "Model: \"sequential_37\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_111 (Conv1D)          (None, 89, 512)           3584      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_37 (MaxPooling (None, 17, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_112 (Conv1D)          (None, 16, 256)           262400    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_37 (Averag (None, 5, 256)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_113 (Conv1D)          (None, 4, 512)            262656    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_37  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_111 (Dense)            (None, 384)               196992    \n",
      "_________________________________________________________________\n",
      "dropout_74 (Dropout)         (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_112 (Dense)            (None, 384)               147840    \n",
      "_________________________________________________________________\n",
      "dropout_75 (Dropout)         (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_113 (Dense)            (None, 6)                 2310      \n",
      "=================================================================\n",
      "Total params: 875,782\n",
      "Trainable params: 875,782\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 512, k_conv_1 = 2,  n_conv_2 = 256, k_conv_2 = 2, \n",
      "          n_conv_3 = 512,  k_conv_3 = 2,  maxpooling_pool_size = 5,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 384, dropout_1 = 0.3,\n",
      "          n_dense_2 = 384, dropout_2 = 0.3, activation_conv=  relu,\n",
      "          activation_dense=  elu\n",
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/152 [..............................] - ETA: 1s - loss: 1.7935 - accuracy: 0.1602WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0089s vs `on_train_batch_end` time: 0.0140s). Check your callbacks.\n",
      "152/152 [==============================] - 3s 23ms/step - loss: 1.0384 - accuracy: 0.5591\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.7388 - accuracy: 0.6922\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.6013 - accuracy: 0.7545\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.5156 - accuracy: 0.7958\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.4438 - accuracy: 0.8321\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.4050 - accuracy: 0.8481\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.3783 - accuracy: 0.8603\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.3476 - accuracy: 0.8714\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.3178 - accuracy: 0.8833\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.3060 - accuracy: 0.8872\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.2891 - accuracy: 0.8945\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.2713 - accuracy: 0.9011\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.2596 - accuracy: 0.9064\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.2482 - accuracy: 0.9087\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.2485 - accuracy: 0.9091\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.2327 - accuracy: 0.9153\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.2368 - accuracy: 0.9119\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.2268 - accuracy: 0.9172 0s - loss: 0.2261 - accuracy\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.2089 - accuracy: 0.9236\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.2096 - accuracy: 0.9228\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.1919 - accuracy: 0.9307\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.1908 - accuracy: 0.9283\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.1983 - accuracy: 0.9280\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.1806 - accuracy: 0.9347\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.1845 - accuracy: 0.9318\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.1752 - accuracy: 0.9353\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.1797 - accuracy: 0.9341\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.1680 - accuracy: 0.9362\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.1611 - accuracy: 0.9403\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.1614 - accuracy: 0.9413\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.1461 - accuracy: 0.9457\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.1559 - accuracy: 0.9422\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.1438 - accuracy: 0.9462\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.1371 - accuracy: 0.9497\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.1433 - accuracy: 0.9477\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.1362 - accuracy: 0.9499\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.1364 - accuracy: 0.9491\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.1320 - accuracy: 0.9520\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.1299 - accuracy: 0.9514\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.1312 - accuracy: 0.9510\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.1243 - accuracy: 0.9549 0s - loss: 0.1\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.1270 - accuracy: 0.9536\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.1247 - accuracy: 0.9538\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.1156 - accuracy: 0.9567\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.1192 - accuracy: 0.9573\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.1091 - accuracy: 0.9594\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.1104 - accuracy: 0.9593\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.1125 - accuracy: 0.9578\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.1131 - accuracy: 0.9579\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.1060 - accuracy: 0.9618\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.1061 - accuracy: 0.9621\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.1000 - accuracy: 0.9630\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.0994 - accuracy: 0.9633\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.1068 - accuracy: 0.9612\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.0964 - accuracy: 0.9653\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.0907 - accuracy: 0.9673\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.1039 - accuracy: 0.9622\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.1053 - accuracy: 0.9620\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.0940 - accuracy: 0.9647\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.0889 - accuracy: 0.9663\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 0.2689 - accuracy: 0.9376\n",
      "Model: \"sequential_38\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_114 (Conv1D)          (None, 89, 512)           3584      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_38 (MaxPooling (None, 17, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_115 (Conv1D)          (None, 16, 256)           262400    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_38 (Averag (None, 5, 256)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_116 (Conv1D)          (None, 4, 512)            262656    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_38  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_114 (Dense)            (None, 384)               196992    \n",
      "_________________________________________________________________\n",
      "dropout_76 (Dropout)         (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_115 (Dense)            (None, 384)               147840    \n",
      "_________________________________________________________________\n",
      "dropout_77 (Dropout)         (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_116 (Dense)            (None, 6)                 2310      \n",
      "=================================================================\n",
      "Total params: 875,782\n",
      "Trainable params: 875,782\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 512, k_conv_1 = 2,  n_conv_2 = 256, k_conv_2 = 2, \n",
      "          n_conv_3 = 512,  k_conv_3 = 2,  maxpooling_pool_size = 5,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 384, dropout_1 = 0.3,\n",
      "          n_dense_2 = 384, dropout_2 = 0.3, activation_conv=  relu,\n",
      "          activation_dense=  elu\n",
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 3s 21ms/step - loss: 1.0413 - accuracy: 0.5559\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.7243 - accuracy: 0.6970 0s - loss: 0.7\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.5834 - accuracy: 0.7631 0s - los\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.5006 - accuracy: 0.8044\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.4348 - accuracy: 0.8353\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.3912 - accuracy: 0.8546\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.3614 - accuracy: 0.8665\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.3320 - accuracy: 0.8763\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.3079 - accuracy: 0.8880\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.2915 - accuracy: 0.8937\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.2827 - accuracy: 0.8978\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.2645 - accuracy: 0.9035\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.2472 - accuracy: 0.9110\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.2394 - accuracy: 0.9123\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.2367 - accuracy: 0.9137\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.2321 - accuracy: 0.9143\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.2128 - accuracy: 0.9232\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.2142 - accuracy: 0.9221\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.2110 - accuracy: 0.9234\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.1998 - accuracy: 0.9265\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.1905 - accuracy: 0.9295\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.1821 - accuracy: 0.9328\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.1745 - accuracy: 0.9349\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.1793 - accuracy: 0.9329\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.1688 - accuracy: 0.9384\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.1695 - accuracy: 0.9393\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.1625 - accuracy: 0.9396\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.1497 - accuracy: 0.9455\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.1603 - accuracy: 0.9414\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.1639 - accuracy: 0.9394\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.1470 - accuracy: 0.9444\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.1465 - accuracy: 0.9463\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.1453 - accuracy: 0.9463\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.1333 - accuracy: 0.9499\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.1300 - accuracy: 0.9527\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.1326 - accuracy: 0.9516\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.1244 - accuracy: 0.9535\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.1274 - accuracy: 0.9522\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.1227 - accuracy: 0.9550\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.1191 - accuracy: 0.9572\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.1178 - accuracy: 0.9564\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.1113 - accuracy: 0.9590\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.1145 - accuracy: 0.9581\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.1112 - accuracy: 0.9588\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.1077 - accuracy: 0.9606\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.1217 - accuracy: 0.9557\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.1046 - accuracy: 0.9618\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.1010 - accuracy: 0.9628\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.1093 - accuracy: 0.9601\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.0979 - accuracy: 0.9632\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.0972 - accuracy: 0.9635\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.0962 - accuracy: 0.9664\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.0951 - accuracy: 0.9657\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.0928 - accuracy: 0.9668\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.0938 - accuracy: 0.9648\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.0922 - accuracy: 0.9668\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.0927 - accuracy: 0.9671\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.0935 - accuracy: 0.9662\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.0834 - accuracy: 0.9693\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.0923 - accuracy: 0.9659\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.2847 - accuracy: 0.9319\n",
      "Model: \"sequential_39\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_117 (Conv1D)          (None, 89, 512)           3584      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_39 (MaxPooling (None, 17, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_118 (Conv1D)          (None, 16, 256)           262400    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_39 (Averag (None, 5, 256)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_119 (Conv1D)          (None, 4, 512)            262656    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_39  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_117 (Dense)            (None, 384)               196992    \n",
      "_________________________________________________________________\n",
      "dropout_78 (Dropout)         (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_118 (Dense)            (None, 384)               147840    \n",
      "_________________________________________________________________\n",
      "dropout_79 (Dropout)         (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_119 (Dense)            (None, 6)                 2310      \n",
      "=================================================================\n",
      "Total params: 875,782\n",
      "Trainable params: 875,782\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 512, k_conv_1 = 2,  n_conv_2 = 256, k_conv_2 = 2, \n",
      "          n_conv_3 = 512,  k_conv_3 = 2,  maxpooling_pool_size = 5,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 384, dropout_1 = 0.3,\n",
      "          n_dense_2 = 384, dropout_2 = 0.3, activation_conv=  relu,\n",
      "          activation_dense=  elu\n",
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 3s 21ms/step - loss: 1.0501 - accuracy: 0.5547\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.7201 - accuracy: 0.6933\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.5880 - accuracy: 0.7617\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.5029 - accuracy: 0.8046\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.4443 - accuracy: 0.8302\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.3883 - accuracy: 0.8552\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.3620 - accuracy: 0.8654\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.3478 - accuracy: 0.8697\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.3275 - accuracy: 0.8789\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.3040 - accuracy: 0.8871\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.2932 - accuracy: 0.8909\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.2793 - accuracy: 0.8971\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.2770 - accuracy: 0.8979\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.2496 - accuracy: 0.9091\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.2485 - accuracy: 0.9067\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.2368 - accuracy: 0.9123\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.2272 - accuracy: 0.9154\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.2168 - accuracy: 0.9177\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.2165 - accuracy: 0.9214\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.2110 - accuracy: 0.9243\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.2015 - accuracy: 0.9254\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.1893 - accuracy: 0.9310\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.1914 - accuracy: 0.9295 0s - loss: 0.1\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.1763 - accuracy: 0.9349\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.1750 - accuracy: 0.9351\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.1757 - accuracy: 0.9366\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.1741 - accuracy: 0.9363\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.1661 - accuracy: 0.9389\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.1616 - accuracy: 0.9396\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.1561 - accuracy: 0.9425\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.1554 - accuracy: 0.9440\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.1575 - accuracy: 0.9427\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.1454 - accuracy: 0.9477\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.1493 - accuracy: 0.9457\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.1387 - accuracy: 0.9508\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.1391 - accuracy: 0.9475\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.1291 - accuracy: 0.9520\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.1293 - accuracy: 0.9511\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.1372 - accuracy: 0.9487\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.1278 - accuracy: 0.9526\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.1254 - accuracy: 0.9536\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.1192 - accuracy: 0.9560\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.1254 - accuracy: 0.9529\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.1187 - accuracy: 0.9551\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.1150 - accuracy: 0.9561\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.1094 - accuracy: 0.9594\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.1208 - accuracy: 0.9558\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.1088 - accuracy: 0.9596\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.1096 - accuracy: 0.9597\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.1143 - accuracy: 0.9581\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.1013 - accuracy: 0.9625\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.1033 - accuracy: 0.9619\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.1034 - accuracy: 0.9624\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.0986 - accuracy: 0.9637\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.0955 - accuracy: 0.9651\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.0957 - accuracy: 0.9638\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.1000 - accuracy: 0.9635\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.0893 - accuracy: 0.9667\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.0962 - accuracy: 0.9645\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 3s 21ms/step - loss: 0.0909 - accuracy: 0.9665\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.2600 - accuracy: 0.9362\n",
      "Model: \"sequential_40\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_120 (Conv1D)          (None, 89, 768)           5376      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_40 (MaxPooling (None, 29, 768)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_121 (Conv1D)          (None, 27, 256)           590080    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_40 (Averag (None, 5, 256)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_122 (Conv1D)          (None, 4, 512)            262656    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_40  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_120 (Dense)            (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_80 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_121 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_81 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_122 (Dense)            (None, 6)                 1542      \n",
      "=================================================================\n",
      "Total params: 1,056,774\n",
      "Trainable params: 1,056,774\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 768, k_conv_1 = 2,  n_conv_2 = 256, k_conv_2 = 3, \n",
      "          n_conv_3 = 512,  k_conv_3 = 2,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 5,  n_dense_1 = 256, dropout_1 = 0.3,\n",
      "          n_dense_2 = 256, dropout_2 = 0.3, activation_conv=  relu,\n",
      "          activation_dense=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001D5B5607388>\n",
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 6s 38ms/step - loss: 1.0927 - accuracy: 0.5400\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.7730 - accuracy: 0.6794\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.5990 - accuracy: 0.7577\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.4955 - accuracy: 0.8080\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.4274 - accuracy: 0.8389\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.3838 - accuracy: 0.8564\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.3545 - accuracy: 0.8661\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.3374 - accuracy: 0.8737\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.3102 - accuracy: 0.8831\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.2973 - accuracy: 0.8873\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.2908 - accuracy: 0.8908\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.2767 - accuracy: 0.8936\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.2534 - accuracy: 0.9026\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.2574 - accuracy: 0.9019\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.2558 - accuracy: 0.9037\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.2395 - accuracy: 0.9104\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2329 - accuracy: 0.9116\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.2234 - accuracy: 0.9156\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.2139 - accuracy: 0.9177\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.2097 - accuracy: 0.9200\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.2062 - accuracy: 0.9216\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.1942 - accuracy: 0.9252\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.1924 - accuracy: 0.9264\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.1901 - accuracy: 0.9265\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.1878 - accuracy: 0.9278\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.1808 - accuracy: 0.9316\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.1750 - accuracy: 0.9329\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.1713 - accuracy: 0.9339\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.1604 - accuracy: 0.9390\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.1681 - accuracy: 0.9357\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.1672 - accuracy: 0.9363\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.1540 - accuracy: 0.9414\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.1564 - accuracy: 0.9403\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.1434 - accuracy: 0.9463\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.1551 - accuracy: 0.9405\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.1522 - accuracy: 0.9413\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.1411 - accuracy: 0.9452\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.1459 - accuracy: 0.9445\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.1326 - accuracy: 0.9498\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.1329 - accuracy: 0.9492\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.1315 - accuracy: 0.9481\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.1305 - accuracy: 0.9500\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.1307 - accuracy: 0.9492\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.1247 - accuracy: 0.9519\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.1196 - accuracy: 0.9549\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.1248 - accuracy: 0.9514\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.1160 - accuracy: 0.9551\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.1185 - accuracy: 0.9544\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.1183 - accuracy: 0.9547\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.1046 - accuracy: 0.9599\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.1146 - accuracy: 0.9560\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.1029 - accuracy: 0.9603\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.1106 - accuracy: 0.9591\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.1026 - accuracy: 0.9606\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.1066 - accuracy: 0.9595\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.1013 - accuracy: 0.9605\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.1001 - accuracy: 0.9626\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.0995 - accuracy: 0.9624\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.1016 - accuracy: 0.9613\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.0942 - accuracy: 0.9634\n",
      "76/76 [==============================] - 1s 15ms/step - loss: 0.2943 - accuracy: 0.9278\n",
      "Model: \"sequential_41\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_123 (Conv1D)          (None, 89, 768)           5376      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_41 (MaxPooling (None, 29, 768)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_124 (Conv1D)          (None, 27, 256)           590080    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_41 (Averag (None, 5, 256)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_125 (Conv1D)          (None, 4, 512)            262656    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_41  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_123 (Dense)            (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_82 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_124 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_83 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_125 (Dense)            (None, 6)                 1542      \n",
      "=================================================================\n",
      "Total params: 1,056,774\n",
      "Trainable params: 1,056,774\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 768, k_conv_1 = 2,  n_conv_2 = 256, k_conv_2 = 3, \n",
      "          n_conv_3 = 512,  k_conv_3 = 2,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 5,  n_dense_1 = 256, dropout_1 = 0.3,\n",
      "          n_dense_2 = 256, dropout_2 = 0.3, activation_conv=  relu,\n",
      "          activation_dense=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001D5B5607388>\n",
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/152 [..............................] - ETA: 3s - loss: 1.8000 - accuracy: 0.1602WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0160s vs `on_train_batch_end` time: 0.0240s). Check your callbacks.\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 1.0911 - accuracy: 0.5403\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.7526 - accuracy: 0.6931\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.6011 - accuracy: 0.7586\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.5115 - accuracy: 0.7997\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.4323 - accuracy: 0.8330\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.3861 - accuracy: 0.8547\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.3604 - accuracy: 0.8642\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.3431 - accuracy: 0.8702\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.3203 - accuracy: 0.8796\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.2969 - accuracy: 0.8896\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.2904 - accuracy: 0.8900\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.2754 - accuracy: 0.8961\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.2683 - accuracy: 0.8989\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.2572 - accuracy: 0.9036\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.2499 - accuracy: 0.9048\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.2347 - accuracy: 0.9109\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.2351 - accuracy: 0.9124\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.2280 - accuracy: 0.9145\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.2184 - accuracy: 0.9173\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.2186 - accuracy: 0.9166\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.2084 - accuracy: 0.9204\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.2072 - accuracy: 0.9215\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.1937 - accuracy: 0.9248\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.1861 - accuracy: 0.9294\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.1839 - accuracy: 0.9288\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.1855 - accuracy: 0.9303\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.1768 - accuracy: 0.9340\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.1763 - accuracy: 0.9334\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.1769 - accuracy: 0.9332\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.1711 - accuracy: 0.9341\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.1601 - accuracy: 0.9374\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.1658 - accuracy: 0.9362\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.1478 - accuracy: 0.9428\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.1569 - accuracy: 0.9404\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.1462 - accuracy: 0.9431\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.1469 - accuracy: 0.9423\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.1474 - accuracy: 0.9419\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.1323 - accuracy: 0.9488\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.1451 - accuracy: 0.9438\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.1347 - accuracy: 0.9471\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.1365 - accuracy: 0.9462\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.1302 - accuracy: 0.9492\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.1265 - accuracy: 0.9510\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.1291 - accuracy: 0.9508\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.1317 - accuracy: 0.9494\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.1248 - accuracy: 0.9505\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.1255 - accuracy: 0.9516\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.1186 - accuracy: 0.9542\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.1208 - accuracy: 0.9529\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.1110 - accuracy: 0.9580\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.1198 - accuracy: 0.9536\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.1174 - accuracy: 0.9551\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.1051 - accuracy: 0.9596\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.1106 - accuracy: 0.9557\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.1172 - accuracy: 0.9563\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.1070 - accuracy: 0.9590\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.1002 - accuracy: 0.9600\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.0965 - accuracy: 0.9616\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.1119 - accuracy: 0.9572\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.0986 - accuracy: 0.9622\n",
      "76/76 [==============================] - 1s 14ms/step - loss: 0.2798 - accuracy: 0.9269\n",
      "Model: \"sequential_42\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_126 (Conv1D)          (None, 89, 768)           5376      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_42 (MaxPooling (None, 29, 768)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_127 (Conv1D)          (None, 27, 256)           590080    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_42 (Averag (None, 5, 256)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_128 (Conv1D)          (None, 4, 512)            262656    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_42  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_126 (Dense)            (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_84 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_127 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_85 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_128 (Dense)            (None, 6)                 1542      \n",
      "=================================================================\n",
      "Total params: 1,056,774\n",
      "Trainable params: 1,056,774\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 768, k_conv_1 = 2,  n_conv_2 = 256, k_conv_2 = 3, \n",
      "          n_conv_3 = 512,  k_conv_3 = 2,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 5,  n_dense_1 = 256, dropout_1 = 0.3,\n",
      "          n_dense_2 = 256, dropout_2 = 0.3, activation_conv=  relu,\n",
      "          activation_dense=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001D5B5607388>\n",
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/152 [..............................] - ETA: 3s - loss: 1.7913 - accuracy: 0.2109WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0139s vs `on_train_batch_end` time: 0.0210s). Check your callbacks.\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 1.0996 - accuracy: 0.5360\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.7799 - accuracy: 0.6732\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.6203 - accuracy: 0.7473\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.5262 - accuracy: 0.7891\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.4533 - accuracy: 0.8233\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.3989 - accuracy: 0.8483\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.3658 - accuracy: 0.8626\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.3328 - accuracy: 0.8735\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.3134 - accuracy: 0.8821\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.3008 - accuracy: 0.8861\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.2890 - accuracy: 0.8913\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.2732 - accuracy: 0.8965\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.2652 - accuracy: 0.9013\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.2584 - accuracy: 0.9042\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.2438 - accuracy: 0.9080\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.2366 - accuracy: 0.9114\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.2315 - accuracy: 0.9133\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.2269 - accuracy: 0.9151\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.2166 - accuracy: 0.9186\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.2146 - accuracy: 0.9200\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.2051 - accuracy: 0.9238\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.2002 - accuracy: 0.9249\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.2031 - accuracy: 0.9255\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.1849 - accuracy: 0.9308\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.1879 - accuracy: 0.9275\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.1816 - accuracy: 0.9329\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.1802 - accuracy: 0.9328\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.1679 - accuracy: 0.9367\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.1671 - accuracy: 0.9377\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.1661 - accuracy: 0.9362\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.1722 - accuracy: 0.9364\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.1592 - accuracy: 0.9395\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.1588 - accuracy: 0.9411\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.1530 - accuracy: 0.9435\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.1460 - accuracy: 0.9445\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.1438 - accuracy: 0.9459\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.1374 - accuracy: 0.9486\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.1491 - accuracy: 0.9448\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.1338 - accuracy: 0.9505\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.1260 - accuracy: 0.9524\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.1335 - accuracy: 0.9509\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.1355 - accuracy: 0.9501\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.1389 - accuracy: 0.9505\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.1176 - accuracy: 0.9550\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.1193 - accuracy: 0.9544\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.1165 - accuracy: 0.9568\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.1191 - accuracy: 0.9545\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.1177 - accuracy: 0.9554\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.1196 - accuracy: 0.9543\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.1091 - accuracy: 0.9592\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.1034 - accuracy: 0.9613\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.1120 - accuracy: 0.9579\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.1096 - accuracy: 0.9588\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.0996 - accuracy: 0.9624\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.1018 - accuracy: 0.9609\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.1006 - accuracy: 0.9618\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.1008 - accuracy: 0.9625\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.1050 - accuracy: 0.9618\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.0905 - accuracy: 0.9650\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.0945 - accuracy: 0.9645\n",
      "76/76 [==============================] - 1s 14ms/step - loss: 0.2922 - accuracy: 0.9322\n",
      "Model: \"sequential_43\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_129 (Conv1D)          (None, 89, 512)           3584      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_43 (MaxPooling (None, 29, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_130 (Conv1D)          (None, 27, 512)           786944    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_43 (Averag (None, 5, 512)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_131 (Conv1D)          (None, 3, 256)            393472    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_43  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_129 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_86 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_130 (Dense)            (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_87 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_131 (Dense)            (None, 6)                 3078      \n",
      "=================================================================\n",
      "Total params: 1,384,454\n",
      "Trainable params: 1,384,454\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 512, k_conv_1 = 2,  n_conv_2 = 512, k_conv_2 = 3, \n",
      "          n_conv_3 = 256,  k_conv_3 = 3,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 5,  n_dense_1 = 256, dropout_1 = 0.2,\n",
      "          n_dense_2 = 512, dropout_2 = 0.2, activation_conv=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001D5AE3CD8C8>,\n",
      "          activation_dense=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001D5B5607388>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 1.1249 - accuracy: 0.5194\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.9137 - accuracy: 0.6144\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.7958 - accuracy: 0.6608\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.7228 - accuracy: 0.6982\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.6485 - accuracy: 0.7389\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.5965 - accuracy: 0.7618\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.5576 - accuracy: 0.7792\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.5237 - accuracy: 0.7945\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.4839 - accuracy: 0.8125\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.4770 - accuracy: 0.8127\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.4632 - accuracy: 0.8184\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.4422 - accuracy: 0.8274\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.4200 - accuracy: 0.8354\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.4240 - accuracy: 0.8355\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.4007 - accuracy: 0.8468\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.4045 - accuracy: 0.8433\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3932 - accuracy: 0.8484\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3783 - accuracy: 0.8520\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3763 - accuracy: 0.8542\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3647 - accuracy: 0.8568\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3715 - accuracy: 0.8544\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3517 - accuracy: 0.8614\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3664 - accuracy: 0.8596\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3477 - accuracy: 0.8651\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3557 - accuracy: 0.8583\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3391 - accuracy: 0.8670\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3444 - accuracy: 0.8672\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3231 - accuracy: 0.8731\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3379 - accuracy: 0.8669\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3163 - accuracy: 0.8744\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3242 - accuracy: 0.8723 0s - loss: 0.3244 - accuracy: 0.87\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3263 - accuracy: 0.8731\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3200 - accuracy: 0.8747\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3182 - accuracy: 0.8761\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3102 - accuracy: 0.8774\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3014 - accuracy: 0.8813\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3106 - accuracy: 0.8783\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3032 - accuracy: 0.8799\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2945 - accuracy: 0.8846\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2915 - accuracy: 0.8854\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2926 - accuracy: 0.8848\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3159 - accuracy: 0.8765\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2883 - accuracy: 0.8858\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2880 - accuracy: 0.8841\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2812 - accuracy: 0.8890\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3053 - accuracy: 0.8839\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2828 - accuracy: 0.8872\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2771 - accuracy: 0.8911\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2671 - accuracy: 0.8936\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2717 - accuracy: 0.8929\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2609 - accuracy: 0.8978\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2589 - accuracy: 0.8986\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2674 - accuracy: 0.8956\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2737 - accuracy: 0.8942\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2581 - accuracy: 0.8993\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2635 - accuracy: 0.8969\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2504 - accuracy: 0.9010\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2539 - accuracy: 0.9010\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2500 - accuracy: 0.9030\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2483 - accuracy: 0.9009\n",
      "76/76 [==============================] - 1s 16ms/step - loss: 0.2942 - accuracy: 0.8986\n",
      "Model: \"sequential_44\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_132 (Conv1D)          (None, 89, 512)           3584      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_44 (MaxPooling (None, 29, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_133 (Conv1D)          (None, 27, 512)           786944    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_44 (Averag (None, 5, 512)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_134 (Conv1D)          (None, 3, 256)            393472    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_44  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_132 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_88 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_133 (Dense)            (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_89 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_134 (Dense)            (None, 6)                 3078      \n",
      "=================================================================\n",
      "Total params: 1,384,454\n",
      "Trainable params: 1,384,454\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 512, k_conv_1 = 2,  n_conv_2 = 512, k_conv_2 = 3, \n",
      "          n_conv_3 = 256,  k_conv_3 = 3,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 5,  n_dense_1 = 256, dropout_1 = 0.2,\n",
      "          n_dense_2 = 512, dropout_2 = 0.2, activation_conv=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001D5AE3CD8C8>,\n",
      "          activation_dense=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001D5B5607388>\n",
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 5s 34ms/step - loss: 1.1212 - accuracy: 0.5206\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.9080 - accuracy: 0.6135\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.7919 - accuracy: 0.6612\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.7101 - accuracy: 0.7043\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.6380 - accuracy: 0.7431\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.5806 - accuracy: 0.7674\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.5533 - accuracy: 0.7844\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.5142 - accuracy: 0.7981\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.4872 - accuracy: 0.8106\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.4701 - accuracy: 0.8176\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.4414 - accuracy: 0.8266\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.4480 - accuracy: 0.8248\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.4261 - accuracy: 0.8352\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.4182 - accuracy: 0.8366\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.4029 - accuracy: 0.8420\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.4002 - accuracy: 0.8421\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3941 - accuracy: 0.8466\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3843 - accuracy: 0.8484\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3705 - accuracy: 0.8565\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3592 - accuracy: 0.8598\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3825 - accuracy: 0.8505\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3630 - accuracy: 0.8556\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3474 - accuracy: 0.8656\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3630 - accuracy: 0.8581\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3527 - accuracy: 0.8594\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3419 - accuracy: 0.8664\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3506 - accuracy: 0.8601\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3279 - accuracy: 0.8682\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3341 - accuracy: 0.8711\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3293 - accuracy: 0.8692\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3187 - accuracy: 0.8745\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3295 - accuracy: 0.8699\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3141 - accuracy: 0.8750\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3139 - accuracy: 0.8747\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3234 - accuracy: 0.8714\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3079 - accuracy: 0.8764\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3131 - accuracy: 0.8756\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3022 - accuracy: 0.8787\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3043 - accuracy: 0.8786\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3098 - accuracy: 0.8760\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2852 - accuracy: 0.8847\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2838 - accuracy: 0.8868\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2880 - accuracy: 0.8849\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2964 - accuracy: 0.8819\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2844 - accuracy: 0.8878\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2893 - accuracy: 0.8837\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2798 - accuracy: 0.8892\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2775 - accuracy: 0.8896\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2899 - accuracy: 0.8829\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2695 - accuracy: 0.8924\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2853 - accuracy: 0.8879\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2740 - accuracy: 0.8913\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2717 - accuracy: 0.8919\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2609 - accuracy: 0.8954\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2743 - accuracy: 0.8908\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2481 - accuracy: 0.9004\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2556 - accuracy: 0.8979\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2515 - accuracy: 0.9005\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2584 - accuracy: 0.8962\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2487 - accuracy: 0.9004\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 0.3395 - accuracy: 0.8841\n",
      "Model: \"sequential_45\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_135 (Conv1D)          (None, 89, 512)           3584      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_45 (MaxPooling (None, 29, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_136 (Conv1D)          (None, 27, 512)           786944    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_45 (Averag (None, 5, 512)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_137 (Conv1D)          (None, 3, 256)            393472    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_45  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_135 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_90 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_136 (Dense)            (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_91 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_137 (Dense)            (None, 6)                 3078      \n",
      "=================================================================\n",
      "Total params: 1,384,454\n",
      "Trainable params: 1,384,454\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 512, k_conv_1 = 2,  n_conv_2 = 512, k_conv_2 = 3, \n",
      "          n_conv_3 = 256,  k_conv_3 = 3,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 5,  n_dense_1 = 256, dropout_1 = 0.2,\n",
      "          n_dense_2 = 512, dropout_2 = 0.2, activation_conv=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001D5AE3CD8C8>,\n",
      "          activation_dense=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001D5B5607388>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 1.1084 - accuracy: 0.5315\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.8910 - accuracy: 0.6257\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.7988 - accuracy: 0.6614\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.7244 - accuracy: 0.6979\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.6704 - accuracy: 0.7268\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.5958 - accuracy: 0.7608\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.5642 - accuracy: 0.7748\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.5344 - accuracy: 0.7886\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.4975 - accuracy: 0.8053\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.4955 - accuracy: 0.8050\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.4649 - accuracy: 0.8203\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.4332 - accuracy: 0.8310\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.4362 - accuracy: 0.8299\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.4233 - accuracy: 0.8344\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.4135 - accuracy: 0.8403\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.4000 - accuracy: 0.8427\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3941 - accuracy: 0.8465\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3836 - accuracy: 0.8499\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3608 - accuracy: 0.8600\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3886 - accuracy: 0.8486\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3665 - accuracy: 0.8598\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3665 - accuracy: 0.8578\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3493 - accuracy: 0.8638\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3496 - accuracy: 0.8635\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3496 - accuracy: 0.8629\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3334 - accuracy: 0.8698\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3286 - accuracy: 0.8701\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3480 - accuracy: 0.8658\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3302 - accuracy: 0.8711\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3316 - accuracy: 0.8697\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3328 - accuracy: 0.8697\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3261 - accuracy: 0.8737\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3155 - accuracy: 0.8756\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3140 - accuracy: 0.8752\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2999 - accuracy: 0.8808\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3044 - accuracy: 0.8795\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3182 - accuracy: 0.8757\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2934 - accuracy: 0.8853\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3127 - accuracy: 0.8760\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2842 - accuracy: 0.8883\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2802 - accuracy: 0.8904\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2976 - accuracy: 0.8820\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2855 - accuracy: 0.8874\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2886 - accuracy: 0.8868\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2898 - accuracy: 0.8856\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2758 - accuracy: 0.8893\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2845 - accuracy: 0.8886\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2782 - accuracy: 0.8921\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2754 - accuracy: 0.8900\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2680 - accuracy: 0.8934\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2629 - accuracy: 0.8961\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2616 - accuracy: 0.8960\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2725 - accuracy: 0.8921\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2615 - accuracy: 0.8961\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2594 - accuracy: 0.8962\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2582 - accuracy: 0.8987\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2586 - accuracy: 0.8980\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2771 - accuracy: 0.8916\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2523 - accuracy: 0.8982\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2480 - accuracy: 0.9023\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 0.3528 - accuracy: 0.8843\n",
      "Model: \"sequential_46\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_138 (Conv1D)          (None, 89, 768)           5376      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_46 (MaxPooling (None, 17, 768)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_139 (Conv1D)          (None, 16, 256)           393472    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_46 (Averag (None, 5, 256)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_140 (Conv1D)          (None, 3, 256)            196864    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_46  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_138 (Dense)            (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_92 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_139 (Dense)            (None, 384)               196992    \n",
      "_________________________________________________________________\n",
      "dropout_93 (Dropout)         (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_140 (Dense)            (None, 6)                 2310      \n",
      "=================================================================\n",
      "Total params: 926,598\n",
      "Trainable params: 926,598\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 768, k_conv_1 = 2,  n_conv_2 = 256, k_conv_2 = 2, \n",
      "          n_conv_3 = 256,  k_conv_3 = 3,  maxpooling_pool_size = 5,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 512, dropout_1 = 0.2,\n",
      "          n_dense_2 = 384, dropout_2 = 0.3, activation_conv=  elu,\n",
      "          activation_dense=  elu\n",
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/152 [..............................] - ETA: 2s - loss: 1.8024 - accuracy: 0.1680WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0120s vs `on_train_batch_end` time: 0.0189s). Check your callbacks.\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 1.1802 - accuracy: 0.5002\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 1.0398 - accuracy: 0.5571\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.9884 - accuracy: 0.5828\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.9423 - accuracy: 0.6008 0s - loss: 0.9423 - accuracy: 0.60\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 4s 30ms/step - loss: 0.9045 - accuracy: 0.6180\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.8579 - accuracy: 0.6368\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.7969 - accuracy: 0.6665\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.7424 - accuracy: 0.6907\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.7049 - accuracy: 0.7057\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.6542 - accuracy: 0.7293\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.6215 - accuracy: 0.7469\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.5875 - accuracy: 0.7604\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 4s 30ms/step - loss: 0.5627 - accuracy: 0.7728\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.5317 - accuracy: 0.7845 0s - loss: 0.5317 - accuracy: 0.78\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.5141 - accuracy: 0.7942 0s - loss: 0.5142 - accu\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.4868 - accuracy: 0.8065\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.4629 - accuracy: 0.8176\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.4486 - accuracy: 0.8225\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.4450 - accuracy: 0.8231\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.4119 - accuracy: 0.8380\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.4041 - accuracy: 0.8419\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.3870 - accuracy: 0.8473\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.3803 - accuracy: 0.8512\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.3751 - accuracy: 0.8510\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.3555 - accuracy: 0.8607\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.3401 - accuracy: 0.8664\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.3353 - accuracy: 0.8687\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.3193 - accuracy: 0.8770\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 4s 30ms/step - loss: 0.3246 - accuracy: 0.8738\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.3093 - accuracy: 0.8787\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2945 - accuracy: 0.8858\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2964 - accuracy: 0.8871 \n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 4s 30ms/step - loss: 0.2859 - accuracy: 0.8893\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2743 - accuracy: 0.8927\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2770 - accuracy: 0.8944\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2653 - accuracy: 0.8967\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2573 - accuracy: 0.9008\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 4s 30ms/step - loss: 0.2546 - accuracy: 0.9016\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2521 - accuracy: 0.9039\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2420 - accuracy: 0.9062\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2463 - accuracy: 0.9035\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2353 - accuracy: 0.9084\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2278 - accuracy: 0.9127\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2319 - accuracy: 0.9110\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2315 - accuracy: 0.9120\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2227 - accuracy: 0.9154\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2093 - accuracy: 0.9193\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2082 - accuracy: 0.9212\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2110 - accuracy: 0.9186\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.1994 - accuracy: 0.9231\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2038 - accuracy: 0.9211\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2022 - accuracy: 0.9224\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.1941 - accuracy: 0.9245\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.1968 - accuracy: 0.9244\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.1956 - accuracy: 0.9245\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.1887 - accuracy: 0.9268\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.1840 - accuracy: 0.9297\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.1783 - accuracy: 0.9317\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.1804 - accuracy: 0.9308\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.1812 - accuracy: 0.9313\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 0.3404 - accuracy: 0.9025\n",
      "Model: \"sequential_47\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_141 (Conv1D)          (None, 89, 768)           5376      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_47 (MaxPooling (None, 17, 768)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_142 (Conv1D)          (None, 16, 256)           393472    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_47 (Averag (None, 5, 256)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_143 (Conv1D)          (None, 3, 256)            196864    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_47  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_141 (Dense)            (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_94 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_142 (Dense)            (None, 384)               196992    \n",
      "_________________________________________________________________\n",
      "dropout_95 (Dropout)         (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_143 (Dense)            (None, 6)                 2310      \n",
      "=================================================================\n",
      "Total params: 926,598\n",
      "Trainable params: 926,598\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 768, k_conv_1 = 2,  n_conv_2 = 256, k_conv_2 = 2, \n",
      "          n_conv_3 = 256,  k_conv_3 = 3,  maxpooling_pool_size = 5,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 512, dropout_1 = 0.2,\n",
      "          n_dense_2 = 384, dropout_2 = 0.3, activation_conv=  elu,\n",
      "          activation_dense=  elu\n",
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/152 [..............................] - ETA: 2s - loss: 1.7784 - accuracy: 0.2188WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0120s vs `on_train_batch_end` time: 0.0199s). Check your callbacks.\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 1.1752 - accuracy: 0.5010\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 4s 30ms/step - loss: 1.0353 - accuracy: 0.5615\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.9816 - accuracy: 0.5884\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.9492 - accuracy: 0.6018\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 4s 30ms/step - loss: 0.9120 - accuracy: 0.6183\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.8702 - accuracy: 0.6357\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.8183 - accuracy: 0.6577\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.7688 - accuracy: 0.6789\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.7123 - accuracy: 0.7012\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.6724 - accuracy: 0.7208\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.6368 - accuracy: 0.7396\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 4s 30ms/step - loss: 0.5988 - accuracy: 0.7540\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.5760 - accuracy: 0.7631\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.5533 - accuracy: 0.7750\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.5264 - accuracy: 0.7883\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 4s 30ms/step - loss: 0.4936 - accuracy: 0.8037\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.4763 - accuracy: 0.8112\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.4622 - accuracy: 0.8169\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 4s 30ms/step - loss: 0.4421 - accuracy: 0.8245\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.4116 - accuracy: 0.8374\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 4s 30ms/step - loss: 0.4225 - accuracy: 0.8338\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.3905 - accuracy: 0.8447\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.3857 - accuracy: 0.8481\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.3791 - accuracy: 0.8518\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.3598 - accuracy: 0.8581\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.3428 - accuracy: 0.8641\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.3488 - accuracy: 0.8611\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.3257 - accuracy: 0.8718\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.3284 - accuracy: 0.8679\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 4s 30ms/step - loss: 0.3196 - accuracy: 0.8725\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.3001 - accuracy: 0.8796\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.3038 - accuracy: 0.8793\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2973 - accuracy: 0.8834\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2866 - accuracy: 0.8866\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2815 - accuracy: 0.8899\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2773 - accuracy: 0.8905\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2742 - accuracy: 0.8914\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 4s 30ms/step - loss: 0.2599 - accuracy: 0.8975\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2549 - accuracy: 0.8985\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2592 - accuracy: 0.8989\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 4s 30ms/step - loss: 0.2462 - accuracy: 0.9042\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2483 - accuracy: 0.9014\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2470 - accuracy: 0.9040\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2228 - accuracy: 0.9124\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2285 - accuracy: 0.9114\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 4s 30ms/step - loss: 0.2275 - accuracy: 0.9107\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2150 - accuracy: 0.9184\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2225 - accuracy: 0.9135\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2113 - accuracy: 0.9178\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2090 - accuracy: 0.9177\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2092 - accuracy: 0.9199\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2100 - accuracy: 0.9201\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.1964 - accuracy: 0.9246\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 4s 30ms/step - loss: 0.1974 - accuracy: 0.9248 0s - loss: 0\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.1927 - accuracy: 0.9250\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 4s 30ms/step - loss: 0.1882 - accuracy: 0.9272\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 4s 30ms/step - loss: 0.1861 - accuracy: 0.9285\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.1821 - accuracy: 0.9295\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 4s 30ms/step - loss: 0.1876 - accuracy: 0.9279\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.1826 - accuracy: 0.9301\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 0.3453 - accuracy: 0.9049\n",
      "Model: \"sequential_48\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_144 (Conv1D)          (None, 89, 768)           5376      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_48 (MaxPooling (None, 17, 768)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_145 (Conv1D)          (None, 16, 256)           393472    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_48 (Averag (None, 5, 256)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_146 (Conv1D)          (None, 3, 256)            196864    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_48  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_144 (Dense)            (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_96 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_145 (Dense)            (None, 384)               196992    \n",
      "_________________________________________________________________\n",
      "dropout_97 (Dropout)         (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_146 (Dense)            (None, 6)                 2310      \n",
      "=================================================================\n",
      "Total params: 926,598\n",
      "Trainable params: 926,598\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 768, k_conv_1 = 2,  n_conv_2 = 256, k_conv_2 = 2, \n",
      "          n_conv_3 = 256,  k_conv_3 = 3,  maxpooling_pool_size = 5,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 512, dropout_1 = 0.2,\n",
      "          n_dense_2 = 384, dropout_2 = 0.3, activation_conv=  elu,\n",
      "          activation_dense=  elu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "  1/152 [..............................] - ETA: 2s - loss: 1.7763 - accuracy: 0.1953WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0110s vs `on_train_batch_end` time: 0.0178s). Check your callbacks.\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 1.1758 - accuracy: 0.4994\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 4s 30ms/step - loss: 1.0381 - accuracy: 0.5577\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.9889 - accuracy: 0.5807\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.9514 - accuracy: 0.6005\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.9146 - accuracy: 0.6194\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.8716 - accuracy: 0.6334\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.8106 - accuracy: 0.6583\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.7606 - accuracy: 0.6816\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.7182 - accuracy: 0.7011\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.6794 - accuracy: 0.7226\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.6349 - accuracy: 0.7410\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.6005 - accuracy: 0.7514\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.5647 - accuracy: 0.7717\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.5424 - accuracy: 0.7825\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.5121 - accuracy: 0.7960\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.4945 - accuracy: 0.8035\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.4768 - accuracy: 0.8110\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.4477 - accuracy: 0.8243\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.4381 - accuracy: 0.8296\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.4148 - accuracy: 0.8356\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.4090 - accuracy: 0.8383\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.3928 - accuracy: 0.8462\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.3811 - accuracy: 0.8523\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.3709 - accuracy: 0.8544\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.3607 - accuracy: 0.8602\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.3487 - accuracy: 0.8627\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.3473 - accuracy: 0.8631\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.3364 - accuracy: 0.8687\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.3219 - accuracy: 0.8748\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.3181 - accuracy: 0.8756\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.3038 - accuracy: 0.8813\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.3017 - accuracy: 0.8823\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2871 - accuracy: 0.8889\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2855 - accuracy: 0.8905\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2746 - accuracy: 0.8945\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2733 - accuracy: 0.8963\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2539 - accuracy: 0.9018\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2552 - accuracy: 0.9023\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2591 - accuracy: 0.9014\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2564 - accuracy: 0.9023\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2405 - accuracy: 0.9080\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2429 - accuracy: 0.9080\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2270 - accuracy: 0.9143\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2253 - accuracy: 0.9139\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2294 - accuracy: 0.9127\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2212 - accuracy: 0.9159\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2176 - accuracy: 0.9169\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2196 - accuracy: 0.9175\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2080 - accuracy: 0.9212\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2126 - accuracy: 0.9201\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2024 - accuracy: 0.9228\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.1951 - accuracy: 0.9265\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.1953 - accuracy: 0.9251\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.1898 - accuracy: 0.9272\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 4s 30ms/step - loss: 0.1852 - accuracy: 0.9301\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.1893 - accuracy: 0.9276\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.1850 - accuracy: 0.9296\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.1865 - accuracy: 0.9300\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.1836 - accuracy: 0.9298\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.1749 - accuracy: 0.9339\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 0.3371 - accuracy: 0.9105\n",
      "Model: \"sequential_49\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_147 (Conv1D)          (None, 88, 768)           7680      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_49 (MaxPooling (None, 17, 768)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_148 (Conv1D)          (None, 15, 512)           1180160   \n",
      "_________________________________________________________________\n",
      "average_pooling1d_49 (Averag (None, 5, 512)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_149 (Conv1D)          (None, 3, 256)            393472    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_49  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_147 (Dense)            (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_98 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_148 (Dense)            (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_99 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_149 (Dense)            (None, 6)                 1542      \n",
      "=================================================================\n",
      "Total params: 1,845,766\n",
      "Trainable params: 1,845,766\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 768, k_conv_1 = 3,  n_conv_2 = 512, k_conv_2 = 3, \n",
      "          n_conv_3 = 256,  k_conv_3 = 3,  maxpooling_pool_size = 5,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 512, dropout_1 = 0.3,\n",
      "          n_dense_2 = 256, dropout_2 = 0.2, activation_conv=  relu,\n",
      "          activation_dense=  elu\n",
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/152 [..............................] - ETA: 2s - loss: 1.7945 - accuracy: 0.2188WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0160s vs `on_train_batch_end` time: 0.0250s). Check your callbacks.\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.9866 - accuracy: 0.5823\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.6079 - accuracy: 0.7644\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.4735 - accuracy: 0.8227\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.4064 - accuracy: 0.8483\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3582 - accuracy: 0.8646\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3322 - accuracy: 0.8749\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3224 - accuracy: 0.8805\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2985 - accuracy: 0.8866\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2943 - accuracy: 0.8897\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2734 - accuracy: 0.8980\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2542 - accuracy: 0.9040\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2562 - accuracy: 0.9057\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2364 - accuracy: 0.9113\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2332 - accuracy: 0.9126\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2213 - accuracy: 0.9184\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2109 - accuracy: 0.9203\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2099 - accuracy: 0.9211\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2124 - accuracy: 0.9201\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.1903 - accuracy: 0.9266\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.1869 - accuracy: 0.9312\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.1857 - accuracy: 0.9315\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.1875 - accuracy: 0.9291\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.1763 - accuracy: 0.9328\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.1737 - accuracy: 0.9362\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.1584 - accuracy: 0.9397\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.1643 - accuracy: 0.9377\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.1543 - accuracy: 0.9416\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.1507 - accuracy: 0.9447\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.1486 - accuracy: 0.9437\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.1451 - accuracy: 0.9440\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.1406 - accuracy: 0.9474\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.1416 - accuracy: 0.9471\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.1325 - accuracy: 0.9497\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.1317 - accuracy: 0.9498\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.1262 - accuracy: 0.9518\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.1260 - accuracy: 0.9515\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.1197 - accuracy: 0.9551\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.1247 - accuracy: 0.9537\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.1140 - accuracy: 0.9568\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.1200 - accuracy: 0.9559\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.1113 - accuracy: 0.9578\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.1140 - accuracy: 0.9560\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.1159 - accuracy: 0.9564\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.1116 - accuracy: 0.9597\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.1022 - accuracy: 0.9605\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.1012 - accuracy: 0.9624\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.0991 - accuracy: 0.9611\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.0968 - accuracy: 0.9640\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.0968 - accuracy: 0.9646\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.1021 - accuracy: 0.9618\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.0889 - accuracy: 0.9664\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.0910 - accuracy: 0.9654\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.0960 - accuracy: 0.9645\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.0972 - accuracy: 0.9638\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.0887 - accuracy: 0.9672\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.1002 - accuracy: 0.9631\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.0904 - accuracy: 0.9669\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.0849 - accuracy: 0.9683\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.0856 - accuracy: 0.9680\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.0909 - accuracy: 0.9667\n",
      "76/76 [==============================] - 1s 14ms/step - loss: 0.2873 - accuracy: 0.9336\n",
      "Model: \"sequential_50\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_150 (Conv1D)          (None, 88, 768)           7680      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_50 (MaxPooling (None, 17, 768)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_151 (Conv1D)          (None, 15, 512)           1180160   \n",
      "_________________________________________________________________\n",
      "average_pooling1d_50 (Averag (None, 5, 512)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_152 (Conv1D)          (None, 3, 256)            393472    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_50  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_150 (Dense)            (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_100 (Dropout)        (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_151 (Dense)            (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_101 (Dropout)        (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_152 (Dense)            (None, 6)                 1542      \n",
      "=================================================================\n",
      "Total params: 1,845,766\n",
      "Trainable params: 1,845,766\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 768, k_conv_1 = 3,  n_conv_2 = 512, k_conv_2 = 3, \n",
      "          n_conv_3 = 256,  k_conv_3 = 3,  maxpooling_pool_size = 5,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 512, dropout_1 = 0.3,\n",
      "          n_dense_2 = 256, dropout_2 = 0.2, activation_conv=  relu,\n",
      "          activation_dense=  elu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 1.0074 - accuracy: 0.5754\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.6094 - accuracy: 0.7692\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.4531 - accuracy: 0.8317\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3972 - accuracy: 0.8519\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3554 - accuracy: 0.8677\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3365 - accuracy: 0.8731\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3136 - accuracy: 0.8807\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3019 - accuracy: 0.8856\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2800 - accuracy: 0.8938\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2600 - accuracy: 0.9009\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2573 - accuracy: 0.9021\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2585 - accuracy: 0.9040\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2314 - accuracy: 0.9141\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2232 - accuracy: 0.9171\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2195 - accuracy: 0.9176\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2094 - accuracy: 0.9211\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2030 - accuracy: 0.9243\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.1921 - accuracy: 0.9279\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.1923 - accuracy: 0.9276\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.1796 - accuracy: 0.9330\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.1756 - accuracy: 0.9344\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.1717 - accuracy: 0.9353\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.1734 - accuracy: 0.9354\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.1643 - accuracy: 0.9384\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.1525 - accuracy: 0.9432\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.1580 - accuracy: 0.9421\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.1402 - accuracy: 0.9476\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.1424 - accuracy: 0.9480\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.1491 - accuracy: 0.9458\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.1402 - accuracy: 0.9478\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.1397 - accuracy: 0.9487\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.1309 - accuracy: 0.9518\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.1277 - accuracy: 0.9525\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.1234 - accuracy: 0.9544\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.1138 - accuracy: 0.9582\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.1185 - accuracy: 0.9558\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.1212 - accuracy: 0.9567\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.1156 - accuracy: 0.9575\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.1094 - accuracy: 0.9595\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.1150 - accuracy: 0.9587\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.1057 - accuracy: 0.9604\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.1048 - accuracy: 0.9613\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.0995 - accuracy: 0.9642\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.0944 - accuracy: 0.9642\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.0999 - accuracy: 0.9640\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.1006 - accuracy: 0.9631\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.0980 - accuracy: 0.9640\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.1015 - accuracy: 0.9638\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.0953 - accuracy: 0.9660\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.0965 - accuracy: 0.9646\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.0865 - accuracy: 0.9680\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.0962 - accuracy: 0.9643\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.0815 - accuracy: 0.9690\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.0773 - accuracy: 0.9714\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.0839 - accuracy: 0.9694\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.0887 - accuracy: 0.9678\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.0862 - accuracy: 0.9693\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.0872 - accuracy: 0.9673\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.0799 - accuracy: 0.9708\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.0753 - accuracy: 0.9722\n",
      "76/76 [==============================] - 1s 14ms/step - loss: 0.3132 - accuracy: 0.9375\n",
      "Model: \"sequential_51\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_153 (Conv1D)          (None, 88, 768)           7680      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_51 (MaxPooling (None, 17, 768)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_154 (Conv1D)          (None, 15, 512)           1180160   \n",
      "_________________________________________________________________\n",
      "average_pooling1d_51 (Averag (None, 5, 512)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_155 (Conv1D)          (None, 3, 256)            393472    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_51  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_153 (Dense)            (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_102 (Dropout)        (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_154 (Dense)            (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_103 (Dropout)        (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_155 (Dense)            (None, 6)                 1542      \n",
      "=================================================================\n",
      "Total params: 1,845,766\n",
      "Trainable params: 1,845,766\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 768, k_conv_1 = 3,  n_conv_2 = 512, k_conv_2 = 3, \n",
      "          n_conv_3 = 256,  k_conv_3 = 3,  maxpooling_pool_size = 5,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 512, dropout_1 = 0.3,\n",
      "          n_dense_2 = 256, dropout_2 = 0.2, activation_conv=  relu,\n",
      "          activation_dense=  elu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "  1/152 [..............................] - ETA: 3s - loss: 1.7943 - accuracy: 0.1641WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0150s vs `on_train_batch_end` time: 0.0239s). Check your callbacks.\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 1.0222 - accuracy: 0.5660\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.6155 - accuracy: 0.7588\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.4695 - accuracy: 0.8248\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.4055 - accuracy: 0.8498\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3538 - accuracy: 0.8677\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3382 - accuracy: 0.8741\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3225 - accuracy: 0.8788\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3034 - accuracy: 0.8864\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2832 - accuracy: 0.8951\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2821 - accuracy: 0.8964\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2583 - accuracy: 0.9034 1s -\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2543 - accuracy: 0.9056\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2532 - accuracy: 0.9063\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2430 - accuracy: 0.9089\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2282 - accuracy: 0.9158\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2171 - accuracy: 0.9200\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2153 - accuracy: 0.9206\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2067 - accuracy: 0.9231\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2028 - accuracy: 0.9255\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.1917 - accuracy: 0.9279\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.1877 - accuracy: 0.9313\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.1985 - accuracy: 0.9280\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.1743 - accuracy: 0.9363\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.1716 - accuracy: 0.9367\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.1690 - accuracy: 0.9383\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.1736 - accuracy: 0.9352\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.1692 - accuracy: 0.9373\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.1562 - accuracy: 0.9437\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.1491 - accuracy: 0.9446\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.1502 - accuracy: 0.9455\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.1435 - accuracy: 0.9477\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.1483 - accuracy: 0.9455\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.1364 - accuracy: 0.9494\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.1395 - accuracy: 0.9491\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.1336 - accuracy: 0.9511\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.1329 - accuracy: 0.9504\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.1306 - accuracy: 0.9526\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.1255 - accuracy: 0.9551\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.1231 - accuracy: 0.9552\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.1237 - accuracy: 0.9542\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.1278 - accuracy: 0.9545\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.1113 - accuracy: 0.9581\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.1106 - accuracy: 0.9583\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.1141 - accuracy: 0.9580\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.1184 - accuracy: 0.9558\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.1115 - accuracy: 0.9589\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.1066 - accuracy: 0.9606\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.1061 - accuracy: 0.9615\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.1026 - accuracy: 0.9615\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.1013 - accuracy: 0.9627\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.1102 - accuracy: 0.9599\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.0966 - accuracy: 0.9647\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.1046 - accuracy: 0.9613\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.0983 - accuracy: 0.9639\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.0876 - accuracy: 0.9673\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.0899 - accuracy: 0.9670\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.0892 - accuracy: 0.9668\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.0931 - accuracy: 0.9658\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.0925 - accuracy: 0.9667\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.0866 - accuracy: 0.9686\n",
      "76/76 [==============================] - 1s 14ms/step - loss: 0.2817 - accuracy: 0.9352\n",
      "Model: \"sequential_52\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_156 (Conv1D)          (None, 88, 768)           7680      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_52 (MaxPooling (None, 29, 768)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_157 (Conv1D)          (None, 28, 256)           393472    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_52 (Averag (None, 9, 256)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_158 (Conv1D)          (None, 8, 512)            262656    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_52  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_156 (Dense)            (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_104 (Dropout)        (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_157 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_105 (Dropout)        (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_158 (Dense)            (None, 6)                 1542      \n",
      "=================================================================\n",
      "Total params: 862,470\n",
      "Trainable params: 862,470\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 768, k_conv_1 = 3,  n_conv_2 = 256, k_conv_2 = 2, \n",
      "          n_conv_3 = 512,  k_conv_3 = 2,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 256, dropout_1 = 0.2,\n",
      "          n_dense_2 = 256, dropout_2 = 0.2, activation_conv=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001D5AE3CD8C8>,\n",
      "          activation_dense=  relu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 1.1175 - accuracy: 0.5258\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.8493 - accuracy: 0.6418\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.6822 - accuracy: 0.7250\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.6103 - accuracy: 0.7564\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.5496 - accuracy: 0.7847\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.4966 - accuracy: 0.8085\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.4733 - accuracy: 0.8161\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.4476 - accuracy: 0.8255\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.4377 - accuracy: 0.8309\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.4352 - accuracy: 0.8311\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.4212 - accuracy: 0.8367\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3876 - accuracy: 0.8502\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3881 - accuracy: 0.8501\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3790 - accuracy: 0.8519\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3758 - accuracy: 0.8546\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3599 - accuracy: 0.8602\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3677 - accuracy: 0.8576\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3614 - accuracy: 0.8601\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3434 - accuracy: 0.8665\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3475 - accuracy: 0.8653\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3293 - accuracy: 0.8709\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3476 - accuracy: 0.8675\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3397 - accuracy: 0.8698\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3336 - accuracy: 0.8700\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3372 - accuracy: 0.8697\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3227 - accuracy: 0.8736\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3172 - accuracy: 0.8762\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3143 - accuracy: 0.8784\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3172 - accuracy: 0.8750\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3114 - accuracy: 0.8783\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2978 - accuracy: 0.8837\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2996 - accuracy: 0.8823\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3006 - accuracy: 0.8830\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3010 - accuracy: 0.8832\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3012 - accuracy: 0.8831\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3093 - accuracy: 0.8797\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2915 - accuracy: 0.8872\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2864 - accuracy: 0.8891\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2889 - accuracy: 0.8886\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2862 - accuracy: 0.8879\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2888 - accuracy: 0.8897\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2911 - accuracy: 0.8887\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2833 - accuracy: 0.8911\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.2790 - accuracy: 0.8913\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2773 - accuracy: 0.8918\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2690 - accuracy: 0.8961\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2735 - accuracy: 0.8939\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2821 - accuracy: 0.8921\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2624 - accuracy: 0.8982\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2612 - accuracy: 0.8989\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2680 - accuracy: 0.8967\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.2596 - accuracy: 0.9001\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2583 - accuracy: 0.9009\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2729 - accuracy: 0.8964\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2755 - accuracy: 0.8948\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2562 - accuracy: 0.9012\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2596 - accuracy: 0.8995\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2497 - accuracy: 0.9022\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.2457 - accuracy: 0.9065\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2484 - accuracy: 0.9052\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 0.2656 - accuracy: 0.9035\n",
      "Model: \"sequential_53\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_159 (Conv1D)          (None, 88, 768)           7680      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_53 (MaxPooling (None, 29, 768)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_160 (Conv1D)          (None, 28, 256)           393472    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_53 (Averag (None, 9, 256)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_161 (Conv1D)          (None, 8, 512)            262656    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_53  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_159 (Dense)            (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_106 (Dropout)        (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_160 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_107 (Dropout)        (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_161 (Dense)            (None, 6)                 1542      \n",
      "=================================================================\n",
      "Total params: 862,470\n",
      "Trainable params: 862,470\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 768, k_conv_1 = 3,  n_conv_2 = 256, k_conv_2 = 2, \n",
      "          n_conv_3 = 512,  k_conv_3 = 2,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 256, dropout_1 = 0.2,\n",
      "          n_dense_2 = 256, dropout_2 = 0.2, activation_conv=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001D5AE3CD8C8>,\n",
      "          activation_dense=  relu\n",
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 5s 34ms/step - loss: 1.1068 - accuracy: 0.5309\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.8254 - accuracy: 0.6554\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.6749 - accuracy: 0.7273\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.6055 - accuracy: 0.7603\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.5522 - accuracy: 0.7813\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.5210 - accuracy: 0.7968\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.4766 - accuracy: 0.8158\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.4579 - accuracy: 0.8224\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.4229 - accuracy: 0.8357\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.4346 - accuracy: 0.8320\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3975 - accuracy: 0.8475\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3865 - accuracy: 0.8512\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3876 - accuracy: 0.8514\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3928 - accuracy: 0.8483\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3716 - accuracy: 0.8556\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3610 - accuracy: 0.8606\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3593 - accuracy: 0.8633\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3380 - accuracy: 0.8680\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3404 - accuracy: 0.8683\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3485 - accuracy: 0.8648\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3279 - accuracy: 0.8735\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3426 - accuracy: 0.8647\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3189 - accuracy: 0.8764\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3251 - accuracy: 0.8757\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3223 - accuracy: 0.8758\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3236 - accuracy: 0.8759\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3180 - accuracy: 0.8767\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3118 - accuracy: 0.8794\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3106 - accuracy: 0.8778\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2976 - accuracy: 0.8852\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3008 - accuracy: 0.8832\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2931 - accuracy: 0.8855\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3043 - accuracy: 0.8824\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2913 - accuracy: 0.8868\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.2904 - accuracy: 0.8877\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2802 - accuracy: 0.8903\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2907 - accuracy: 0.8871\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2788 - accuracy: 0.8938\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2930 - accuracy: 0.8875\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2787 - accuracy: 0.8942\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2799 - accuracy: 0.8913\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2752 - accuracy: 0.8930\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2639 - accuracy: 0.8980\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2777 - accuracy: 0.8926\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2729 - accuracy: 0.8944\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2663 - accuracy: 0.8975\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.2732 - accuracy: 0.8932\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2602 - accuracy: 0.9008\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2667 - accuracy: 0.8975\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2684 - accuracy: 0.8969\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2559 - accuracy: 0.9031\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2502 - accuracy: 0.9027\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2569 - accuracy: 0.9018\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2563 - accuracy: 0.9014\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2491 - accuracy: 0.9047\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2610 - accuracy: 0.8984\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2447 - accuracy: 0.9062\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2474 - accuracy: 0.9043\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2556 - accuracy: 0.9014\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.2384 - accuracy: 0.9073\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 0.2591 - accuracy: 0.9048\n",
      "Model: \"sequential_54\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_162 (Conv1D)          (None, 88, 768)           7680      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_54 (MaxPooling (None, 29, 768)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_163 (Conv1D)          (None, 28, 256)           393472    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_54 (Averag (None, 9, 256)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_164 (Conv1D)          (None, 8, 512)            262656    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_54  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_162 (Dense)            (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_108 (Dropout)        (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_163 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_109 (Dropout)        (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_164 (Dense)            (None, 6)                 1542      \n",
      "=================================================================\n",
      "Total params: 862,470\n",
      "Trainable params: 862,470\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 768, k_conv_1 = 3,  n_conv_2 = 256, k_conv_2 = 2, \n",
      "          n_conv_3 = 512,  k_conv_3 = 2,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 256, dropout_1 = 0.2,\n",
      "          n_dense_2 = 256, dropout_2 = 0.2, activation_conv=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001D5AE3CD8C8>,\n",
      "          activation_dense=  relu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 1.1104 - accuracy: 0.5296\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.8529 - accuracy: 0.6393\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.7020 - accuracy: 0.7165\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.6157 - accuracy: 0.7566\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.5612 - accuracy: 0.7802\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.5218 - accuracy: 0.7963\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.4909 - accuracy: 0.8099\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.4531 - accuracy: 0.8278\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.4477 - accuracy: 0.8253\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.4184 - accuracy: 0.8382\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.4168 - accuracy: 0.8411\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3987 - accuracy: 0.8463\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3951 - accuracy: 0.8484\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3817 - accuracy: 0.8523\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3708 - accuracy: 0.8578\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3608 - accuracy: 0.8616\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3608 - accuracy: 0.8623\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3687 - accuracy: 0.8586\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3493 - accuracy: 0.8646\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3401 - accuracy: 0.8670\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3347 - accuracy: 0.8707\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3409 - accuracy: 0.8685\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3393 - accuracy: 0.8679\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3267 - accuracy: 0.8756\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3235 - accuracy: 0.8769\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3218 - accuracy: 0.8753\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3135 - accuracy: 0.8802\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3121 - accuracy: 0.8809\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3043 - accuracy: 0.8826\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.3142 - accuracy: 0.8797\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3173 - accuracy: 0.8776\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2990 - accuracy: 0.8845 1s\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3110 - accuracy: 0.8814\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2987 - accuracy: 0.8843\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2916 - accuracy: 0.8886\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2836 - accuracy: 0.8919\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.2905 - accuracy: 0.8897\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2786 - accuracy: 0.8950\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2860 - accuracy: 0.8903\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2827 - accuracy: 0.8919\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.2843 - accuracy: 0.8931\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2759 - accuracy: 0.8949\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2807 - accuracy: 0.8936\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2730 - accuracy: 0.8956\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2682 - accuracy: 0.8983\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2706 - accuracy: 0.8981\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2690 - accuracy: 0.8988\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2657 - accuracy: 0.8980\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2662 - accuracy: 0.8970\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2594 - accuracy: 0.9010\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2589 - accuracy: 0.9003\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2613 - accuracy: 0.9004\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2552 - accuracy: 0.9017\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2545 - accuracy: 0.9037\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2579 - accuracy: 0.9011\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2538 - accuracy: 0.9027\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2448 - accuracy: 0.9069\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2541 - accuracy: 0.9031\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2516 - accuracy: 0.9044\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.2459 - accuracy: 0.9063\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 0.2622 - accuracy: 0.9028\n",
      "Model: \"sequential_55\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_165 (Conv1D)          (None, 89, 512)           3584      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_55 (MaxPooling (None, 17, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_166 (Conv1D)          (None, 16, 256)           262400    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_55 (Averag (None, 5, 256)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_167 (Conv1D)          (None, 3, 512)            393728    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_55  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_165 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_110 (Dropout)        (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_166 (Dense)            (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_111 (Dropout)        (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_167 (Dense)            (None, 6)                 1542      \n",
      "=================================================================\n",
      "Total params: 1,055,238\n",
      "Trainable params: 1,055,238\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 512, k_conv_1 = 2,  n_conv_2 = 256, k_conv_2 = 2, \n",
      "          n_conv_3 = 512,  k_conv_3 = 3,  maxpooling_pool_size = 5,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 512, dropout_1 = 0.3,\n",
      "          n_dense_2 = 256, dropout_2 = 0.2, activation_conv=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001D5AE3CD8C8>,\n",
      "          activation_dense=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001D5B5607388>\n",
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 3s 22ms/step - loss: 1.1146 - accuracy: 0.5272\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.8950 - accuracy: 0.6177\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.7999 - accuracy: 0.6561\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.7505 - accuracy: 0.6811\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.6838 - accuracy: 0.7165\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.6121 - accuracy: 0.7531\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.5806 - accuracy: 0.7708\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.5504 - accuracy: 0.7839\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.5212 - accuracy: 0.7961\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.5009 - accuracy: 0.8035\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.4605 - accuracy: 0.8220\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.4682 - accuracy: 0.8184\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.4461 - accuracy: 0.8291\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.4316 - accuracy: 0.8344\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.4136 - accuracy: 0.8390\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.3980 - accuracy: 0.8481\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.4023 - accuracy: 0.8444\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.3838 - accuracy: 0.8536\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.3927 - accuracy: 0.8529\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.3717 - accuracy: 0.8566\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.3675 - accuracy: 0.8595\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.3712 - accuracy: 0.8555\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.3640 - accuracy: 0.8592\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.3475 - accuracy: 0.8642\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.3538 - accuracy: 0.8641\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.3446 - accuracy: 0.8656\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.3413 - accuracy: 0.8671\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.3409 - accuracy: 0.8670\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.3349 - accuracy: 0.8711\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.3280 - accuracy: 0.8724\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.3216 - accuracy: 0.8744\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.3125 - accuracy: 0.8784\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.3229 - accuracy: 0.8729\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.3026 - accuracy: 0.8803\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.3066 - accuracy: 0.8818\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.3041 - accuracy: 0.8812\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.3078 - accuracy: 0.8789\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2988 - accuracy: 0.8829\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2948 - accuracy: 0.8827\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2963 - accuracy: 0.8825\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2967 - accuracy: 0.8831\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2980 - accuracy: 0.8834\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2819 - accuracy: 0.8891\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2993 - accuracy: 0.8827\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2859 - accuracy: 0.8870\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2797 - accuracy: 0.8911\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2739 - accuracy: 0.8921\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2852 - accuracy: 0.8882\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2693 - accuracy: 0.8939\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2595 - accuracy: 0.8973\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2743 - accuracy: 0.8912\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2626 - accuracy: 0.8967\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2593 - accuracy: 0.8973\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2580 - accuracy: 0.8990\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2555 - accuracy: 0.8981\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2464 - accuracy: 0.9018\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2684 - accuracy: 0.8937\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2822 - accuracy: 0.8952\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2445 - accuracy: 0.9051\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2467 - accuracy: 0.9022\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.3291 - accuracy: 0.8879\n",
      "Model: \"sequential_56\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_168 (Conv1D)          (None, 89, 512)           3584      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_56 (MaxPooling (None, 17, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_169 (Conv1D)          (None, 16, 256)           262400    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_56 (Averag (None, 5, 256)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_170 (Conv1D)          (None, 3, 512)            393728    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_56  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_168 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_112 (Dropout)        (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_169 (Dense)            (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_113 (Dropout)        (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_170 (Dense)            (None, 6)                 1542      \n",
      "=================================================================\n",
      "Total params: 1,055,238\n",
      "Trainable params: 1,055,238\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 512, k_conv_1 = 2,  n_conv_2 = 256, k_conv_2 = 2, \n",
      "          n_conv_3 = 512,  k_conv_3 = 3,  maxpooling_pool_size = 5,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 512, dropout_1 = 0.3,\n",
      "          n_dense_2 = 256, dropout_2 = 0.2, activation_conv=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001D5AE3CD8C8>,\n",
      "          activation_dense=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001D5B5607388>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 1.1078 - accuracy: 0.5296\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.9126 - accuracy: 0.6141\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.8082 - accuracy: 0.6527\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.7471 - accuracy: 0.6792\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.6925 - accuracy: 0.7072\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.6363 - accuracy: 0.7345\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.5882 - accuracy: 0.7616\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.5425 - accuracy: 0.7847\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.5254 - accuracy: 0.7931\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.4891 - accuracy: 0.8071\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.4612 - accuracy: 0.8185\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.4477 - accuracy: 0.8242\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.4422 - accuracy: 0.8290\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.4228 - accuracy: 0.8344\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.4139 - accuracy: 0.8373\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.4053 - accuracy: 0.8418\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.4020 - accuracy: 0.8432\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.3818 - accuracy: 0.8497\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.3788 - accuracy: 0.8493\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.3716 - accuracy: 0.8543\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.3580 - accuracy: 0.8589\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.3593 - accuracy: 0.8586\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.3634 - accuracy: 0.8583\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.3579 - accuracy: 0.8602\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.3427 - accuracy: 0.8643\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.3543 - accuracy: 0.8604\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.3368 - accuracy: 0.8674\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.3194 - accuracy: 0.8744\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.3295 - accuracy: 0.8696\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.3175 - accuracy: 0.8750\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.3204 - accuracy: 0.8718\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.3198 - accuracy: 0.8749 0s - loss: 0.3206 - accuracy: \n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.3091 - accuracy: 0.8762\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2991 - accuracy: 0.8817\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.3116 - accuracy: 0.8775\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.3052 - accuracy: 0.8785\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.3194 - accuracy: 0.8735\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2919 - accuracy: 0.8831\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2851 - accuracy: 0.8846\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2987 - accuracy: 0.8818\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2935 - accuracy: 0.8829\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2903 - accuracy: 0.8844\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2800 - accuracy: 0.8886\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2800 - accuracy: 0.8887\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2687 - accuracy: 0.8915\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2858 - accuracy: 0.8840\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2735 - accuracy: 0.8903\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2614 - accuracy: 0.8967\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2701 - accuracy: 0.8923\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2735 - accuracy: 0.8896\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2704 - accuracy: 0.8919\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2635 - accuracy: 0.8950\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2714 - accuracy: 0.8914\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2576 - accuracy: 0.8960\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2539 - accuracy: 0.8983\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2605 - accuracy: 0.8934\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2572 - accuracy: 0.8972\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2429 - accuracy: 0.9000\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2593 - accuracy: 0.8992\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2506 - accuracy: 0.8990\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.3424 - accuracy: 0.8897\n",
      "Model: \"sequential_57\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_171 (Conv1D)          (None, 89, 512)           3584      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_57 (MaxPooling (None, 17, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_172 (Conv1D)          (None, 16, 256)           262400    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_57 (Averag (None, 5, 256)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_173 (Conv1D)          (None, 3, 512)            393728    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_57  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_171 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_114 (Dropout)        (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_172 (Dense)            (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_115 (Dropout)        (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_173 (Dense)            (None, 6)                 1542      \n",
      "=================================================================\n",
      "Total params: 1,055,238\n",
      "Trainable params: 1,055,238\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 512, k_conv_1 = 2,  n_conv_2 = 256, k_conv_2 = 2, \n",
      "          n_conv_3 = 512,  k_conv_3 = 3,  maxpooling_pool_size = 5,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 512, dropout_1 = 0.3,\n",
      "          n_dense_2 = 256, dropout_2 = 0.2, activation_conv=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001D5AE3CD8C8>,\n",
      "          activation_dense=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001D5B5607388>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 1.1032 - accuracy: 0.5321\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.9070 - accuracy: 0.6217\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.8108 - accuracy: 0.6541\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.7310 - accuracy: 0.6900\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.6836 - accuracy: 0.7163\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.6260 - accuracy: 0.7465\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.5855 - accuracy: 0.7642\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.5573 - accuracy: 0.7764\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.5205 - accuracy: 0.7934\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.4983 - accuracy: 0.8053\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.4882 - accuracy: 0.8087\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.4567 - accuracy: 0.8199\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.4418 - accuracy: 0.8279\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.4311 - accuracy: 0.8320\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.4201 - accuracy: 0.8368\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.4079 - accuracy: 0.8420\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.4000 - accuracy: 0.8446 0s - loss: 0.3997 - accuracy: \n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.3968 - accuracy: 0.8478\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.3917 - accuracy: 0.8479\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.3755 - accuracy: 0.8536\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.3712 - accuracy: 0.8552\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.3742 - accuracy: 0.8548\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.3548 - accuracy: 0.8597\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.3599 - accuracy: 0.8594\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.3508 - accuracy: 0.8610\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.3502 - accuracy: 0.8638\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.3325 - accuracy: 0.8697\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.3394 - accuracy: 0.8651\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.3345 - accuracy: 0.8677\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.3195 - accuracy: 0.8742\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.3179 - accuracy: 0.8734\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.3229 - accuracy: 0.8740\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.3216 - accuracy: 0.8719\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.3260 - accuracy: 0.8711\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.3166 - accuracy: 0.8758\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.3221 - accuracy: 0.8737\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2982 - accuracy: 0.8822\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.3076 - accuracy: 0.8786\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2951 - accuracy: 0.8835\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2953 - accuracy: 0.8820\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2941 - accuracy: 0.8847\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2963 - accuracy: 0.8810\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2853 - accuracy: 0.8881\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2811 - accuracy: 0.8877\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.3006 - accuracy: 0.8812\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2790 - accuracy: 0.8908\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2830 - accuracy: 0.8883\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2742 - accuracy: 0.8897\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2647 - accuracy: 0.8949\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2667 - accuracy: 0.8959\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2670 - accuracy: 0.8949\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2695 - accuracy: 0.8925\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2671 - accuracy: 0.8952\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2529 - accuracy: 0.8995\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2574 - accuracy: 0.8990\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2468 - accuracy: 0.9022\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2513 - accuracy: 0.9015\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2485 - accuracy: 0.9014\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2413 - accuracy: 0.9046\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 3s 22ms/step - loss: 0.2504 - accuracy: 0.9012\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.3231 - accuracy: 0.8938\n",
      "Model: \"sequential_58\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_174 (Conv1D)          (None, 88, 768)           7680      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_58 (MaxPooling (None, 29, 768)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_175 (Conv1D)          (None, 27, 512)           1180160   \n",
      "_________________________________________________________________\n",
      "average_pooling1d_58 (Averag (None, 9, 512)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_176 (Conv1D)          (None, 7, 512)            786944    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_58  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_174 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_116 (Dropout)        (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_175 (Dense)            (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_117 (Dropout)        (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_176 (Dense)            (None, 6)                 1542      \n",
      "=================================================================\n",
      "Total params: 2,370,310\n",
      "Trainable params: 2,370,310\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 768, k_conv_1 = 3,  n_conv_2 = 512, k_conv_2 = 3, \n",
      "          n_conv_3 = 512,  k_conv_3 = 3,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 512, dropout_1 = 0.2,\n",
      "          n_dense_2 = 256, dropout_2 = 0.3, activation_conv=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001D5AE3CD8C8>,\n",
      "          activation_dense=  relu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "152/152 [==============================] - 8s 53ms/step - loss: 1.1078 - accuracy: 0.5294\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.7805 - accuracy: 0.6828\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 8s 53ms/step - loss: 0.6430 - accuracy: 0.7435\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.5616 - accuracy: 0.7743\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.5209 - accuracy: 0.7916\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.4858 - accuracy: 0.8088\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.4719 - accuracy: 0.8153\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.4426 - accuracy: 0.8269\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.4276 - accuracy: 0.8330\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.4180 - accuracy: 0.8389\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.4143 - accuracy: 0.8395\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 8s 53ms/step - loss: 0.3900 - accuracy: 0.8485\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 8s 53ms/step - loss: 0.3866 - accuracy: 0.8527\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.3794 - accuracy: 0.8512\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.3508 - accuracy: 0.8657\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.3708 - accuracy: 0.8572\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.3547 - accuracy: 0.8614\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.3463 - accuracy: 0.8645\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 8s 53ms/step - loss: 0.3489 - accuracy: 0.8632\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.3442 - accuracy: 0.8643\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.3267 - accuracy: 0.8716\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.3316 - accuracy: 0.8712\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.3261 - accuracy: 0.8696\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.3264 - accuracy: 0.8704\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.3265 - accuracy: 0.8719\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.3243 - accuracy: 0.8727\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.3117 - accuracy: 0.8787\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.3022 - accuracy: 0.8788\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.3147 - accuracy: 0.8764\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 8s 53ms/step - loss: 0.3010 - accuracy: 0.8799\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.3002 - accuracy: 0.8808\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.2991 - accuracy: 0.8805\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.3122 - accuracy: 0.8771\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.2905 - accuracy: 0.8844\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.2921 - accuracy: 0.8833\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.2807 - accuracy: 0.8872\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.2824 - accuracy: 0.8880\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.2910 - accuracy: 0.8849\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.2752 - accuracy: 0.8901\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.2817 - accuracy: 0.8889\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.2775 - accuracy: 0.8901\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.2711 - accuracy: 0.8917\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.2898 - accuracy: 0.8871\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.2676 - accuracy: 0.8928\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.2646 - accuracy: 0.8951\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.2619 - accuracy: 0.8965\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.2644 - accuracy: 0.8949\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.2584 - accuracy: 0.8967\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.2639 - accuracy: 0.8949\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.2577 - accuracy: 0.8971\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.2588 - accuracy: 0.8972\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.2471 - accuracy: 0.9021\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.2517 - accuracy: 0.9005\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.2563 - accuracy: 0.8986\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.2441 - accuracy: 0.9029\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.2510 - accuracy: 0.9027\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.2495 - accuracy: 0.9012\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.2407 - accuracy: 0.9051\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.2481 - accuracy: 0.9022\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.2374 - accuracy: 0.9061\n",
      "76/76 [==============================] - 1s 20ms/step - loss: 0.3385 - accuracy: 0.8755\n",
      "Model: \"sequential_59\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_177 (Conv1D)          (None, 88, 768)           7680      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_59 (MaxPooling (None, 29, 768)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_178 (Conv1D)          (None, 27, 512)           1180160   \n",
      "_________________________________________________________________\n",
      "average_pooling1d_59 (Averag (None, 9, 512)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_179 (Conv1D)          (None, 7, 512)            786944    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_59  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_177 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_118 (Dropout)        (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_178 (Dense)            (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_119 (Dropout)        (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_179 (Dense)            (None, 6)                 1542      \n",
      "=================================================================\n",
      "Total params: 2,370,310\n",
      "Trainable params: 2,370,310\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 768, k_conv_1 = 3,  n_conv_2 = 512, k_conv_2 = 3, \n",
      "          n_conv_3 = 512,  k_conv_3 = 3,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 512, dropout_1 = 0.2,\n",
      "          n_dense_2 = 256, dropout_2 = 0.3, activation_conv=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001D5AE3CD8C8>,\n",
      "          activation_dense=  relu\n",
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2/152 [..............................] - ETA: 6s - loss: 1.7658 - accuracy: 0.1582WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0209s vs `on_train_batch_end` time: 0.0319s). Check your callbacks.\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 1.1113 - accuracy: 0.5316\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.7799 - accuracy: 0.6790\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.6612 - accuracy: 0.7317\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.5575 - accuracy: 0.7797\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.5225 - accuracy: 0.7949\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - ETA: 0s - loss: 0.4974 - accuracy: 0.80 - 8s 52ms/step - loss: 0.4978 - accuracy: 0.8070\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.4633 - accuracy: 0.8190\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.4487 - accuracy: 0.8268\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.4421 - accuracy: 0.8280\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.4125 - accuracy: 0.8409\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.4096 - accuracy: 0.8415\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.3918 - accuracy: 0.8499\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.3793 - accuracy: 0.8549\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 8s 53ms/step - loss: 0.3706 - accuracy: 0.8587\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 8s 53ms/step - loss: 0.3692 - accuracy: 0.8567\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.3620 - accuracy: 0.8613\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.3514 - accuracy: 0.8646\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.3484 - accuracy: 0.8651\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.3454 - accuracy: 0.8682\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.3330 - accuracy: 0.8706\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.3373 - accuracy: 0.8698\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.3245 - accuracy: 0.8744\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.3220 - accuracy: 0.8743\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.3232 - accuracy: 0.8747\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.3241 - accuracy: 0.8750\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.3241 - accuracy: 0.8739\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.3095 - accuracy: 0.8787\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.3083 - accuracy: 0.8808\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.3030 - accuracy: 0.8822\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.3021 - accuracy: 0.8810\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.3105 - accuracy: 0.8775\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.2945 - accuracy: 0.8850\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.2899 - accuracy: 0.8852\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.2991 - accuracy: 0.8833\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.2872 - accuracy: 0.8853\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.2832 - accuracy: 0.8882\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.2759 - accuracy: 0.8927\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.2789 - accuracy: 0.8898\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.2833 - accuracy: 0.8886\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.2711 - accuracy: 0.8939\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.2711 - accuracy: 0.8926\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.2674 - accuracy: 0.8967\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.2734 - accuracy: 0.8922\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 8s 53ms/step - loss: 0.2594 - accuracy: 0.8971\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.2571 - accuracy: 0.8996\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.2630 - accuracy: 0.8957\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.2490 - accuracy: 0.9035\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.2561 - accuracy: 0.9004\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.2481 - accuracy: 0.9022\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.2676 - accuracy: 0.8942\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.2624 - accuracy: 0.8980\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.2426 - accuracy: 0.9052\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.2448 - accuracy: 0.9046\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.2374 - accuracy: 0.9063\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.2470 - accuracy: 0.9019\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.2369 - accuracy: 0.9067\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.2286 - accuracy: 0.9086\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.2366 - accuracy: 0.9061\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 8s 53ms/step - loss: 0.2516 - accuracy: 0.9032\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.2438 - accuracy: 0.9058\n",
      "76/76 [==============================] - 1s 19ms/step - loss: 0.2772 - accuracy: 0.9057\n",
      "Model: \"sequential_60\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_180 (Conv1D)          (None, 88, 768)           7680      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_60 (MaxPooling (None, 29, 768)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_181 (Conv1D)          (None, 27, 512)           1180160   \n",
      "_________________________________________________________________\n",
      "average_pooling1d_60 (Averag (None, 9, 512)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_182 (Conv1D)          (None, 7, 512)            786944    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_60  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_180 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_120 (Dropout)        (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_181 (Dense)            (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_121 (Dropout)        (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_182 (Dense)            (None, 6)                 1542      \n",
      "=================================================================\n",
      "Total params: 2,370,310\n",
      "Trainable params: 2,370,310\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 768, k_conv_1 = 3,  n_conv_2 = 512, k_conv_2 = 3, \n",
      "          n_conv_3 = 512,  k_conv_3 = 3,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 512, dropout_1 = 0.2,\n",
      "          n_dense_2 = 256, dropout_2 = 0.3, activation_conv=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001D5AE3CD8C8>,\n",
      "          activation_dense=  relu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "  2/152 [..............................] - ETA: 6s - loss: 1.7719 - accuracy: 0.1914WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0199s vs `on_train_batch_end` time: 0.0319s). Check your callbacks.\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 1.0759 - accuracy: 0.5437\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.7525 - accuracy: 0.6977\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 8s 53ms/step - loss: 0.6508 - accuracy: 0.7398\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.5619 - accuracy: 0.7764\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 8s 53ms/step - loss: 0.5238 - accuracy: 0.7948\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.4895 - accuracy: 0.8085\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.4803 - accuracy: 0.8133\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 8s 53ms/step - loss: 0.4424 - accuracy: 0.8268\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.4253 - accuracy: 0.8331\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 8s 53ms/step - loss: 0.4279 - accuracy: 0.8329\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.4066 - accuracy: 0.8432\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.4030 - accuracy: 0.8448\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.3806 - accuracy: 0.8529\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.3736 - accuracy: 0.8554\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.3727 - accuracy: 0.8554\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.3663 - accuracy: 0.8582\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.3684 - accuracy: 0.8588\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.3574 - accuracy: 0.8608\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.3491 - accuracy: 0.8639\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 8s 53ms/step - loss: 0.3523 - accuracy: 0.8633\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.3293 - accuracy: 0.8718\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.3337 - accuracy: 0.8708\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.3330 - accuracy: 0.8691\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.3420 - accuracy: 0.8674\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.3370 - accuracy: 0.8669\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.3249 - accuracy: 0.8743\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.3104 - accuracy: 0.8783\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.3177 - accuracy: 0.8749\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 8s 53ms/step - loss: 0.3111 - accuracy: 0.8794\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.3067 - accuracy: 0.8800\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.3062 - accuracy: 0.8801\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.3103 - accuracy: 0.8770\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.3081 - accuracy: 0.8783\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.2982 - accuracy: 0.8835\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 8s 53ms/step - loss: 0.3027 - accuracy: 0.8796\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.2870 - accuracy: 0.8877\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.2735 - accuracy: 0.8910\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.2951 - accuracy: 0.8845\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.2762 - accuracy: 0.8897\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.2873 - accuracy: 0.8889\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.2754 - accuracy: 0.8906\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.2837 - accuracy: 0.8873\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 8s 53ms/step - loss: 0.2861 - accuracy: 0.8875\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.2653 - accuracy: 0.8955\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.2804 - accuracy: 0.8877\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.2611 - accuracy: 0.8965\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.2598 - accuracy: 0.8980\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.2596 - accuracy: 0.8980\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.2725 - accuracy: 0.8950\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.2506 - accuracy: 0.8994\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.2557 - accuracy: 0.9005\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.2617 - accuracy: 0.8972\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.2541 - accuracy: 0.9001\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.2481 - accuracy: 0.9045\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.2452 - accuracy: 0.9030\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.2513 - accuracy: 0.9007\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.2481 - accuracy: 0.9032\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.2367 - accuracy: 0.9070\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.2415 - accuracy: 0.9057\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.2394 - accuracy: 0.9046\n",
      "76/76 [==============================] - 1s 19ms/step - loss: 0.2781 - accuracy: 0.9019\n",
      "Model: \"sequential_61\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_183 (Conv1D)          (None, 88, 768)           7680      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_61 (MaxPooling (None, 29, 768)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_184 (Conv1D)          (None, 27, 512)           1180160   \n",
      "_________________________________________________________________\n",
      "average_pooling1d_61 (Averag (None, 9, 512)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_185 (Conv1D)          (None, 7, 256)            393472    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_61  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_183 (Dense)            (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_122 (Dropout)        (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_184 (Dense)            (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_123 (Dropout)        (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_185 (Dense)            (None, 6)                 1542      \n",
      "=================================================================\n",
      "Total params: 1,845,766\n",
      "Trainable params: 1,845,766\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 768, k_conv_1 = 3,  n_conv_2 = 512, k_conv_2 = 3, \n",
      "          n_conv_3 = 256,  k_conv_3 = 3,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 512, dropout_1 = 0.3,\n",
      "          n_dense_2 = 256, dropout_2 = 0.3, activation_conv=  relu,\n",
      "          activation_dense=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001D5B5607388>\n",
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/228 [..............................] - ETA: 6s - loss: 1.7912 - accuracy: 0.1719WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0180s vs `on_train_batch_end` time: 0.0299s). Check your callbacks.\n",
      "228/228 [==============================] - 11s 49ms/step - loss: 0.9526 - accuracy: 0.6062\n",
      "Epoch 2/60\n",
      "228/228 [==============================] - 11s 48ms/step - loss: 0.5260 - accuracy: 0.7995\n",
      "Epoch 3/60\n",
      "228/228 [==============================] - 11s 48ms/step - loss: 0.4002 - accuracy: 0.8491\n",
      "Epoch 4/60\n",
      "228/228 [==============================] - 11s 48ms/step - loss: 0.3470 - accuracy: 0.8699\n",
      "Epoch 5/60\n",
      "228/228 [==============================] - 11s 48ms/step - loss: 0.3199 - accuracy: 0.8796\n",
      "Epoch 6/60\n",
      "228/228 [==============================] - 11s 48ms/step - loss: 0.2964 - accuracy: 0.8860\n",
      "Epoch 7/60\n",
      "228/228 [==============================] - 11s 48ms/step - loss: 0.2766 - accuracy: 0.8955\n",
      "Epoch 8/60\n",
      "228/228 [==============================] - 11s 48ms/step - loss: 0.2770 - accuracy: 0.8964\n",
      "Epoch 9/60\n",
      "228/228 [==============================] - 11s 48ms/step - loss: 0.2504 - accuracy: 0.9055\n",
      "Epoch 10/60\n",
      "228/228 [==============================] - 11s 48ms/step - loss: 0.2465 - accuracy: 0.9081\n",
      "Epoch 11/60\n",
      "228/228 [==============================] - 11s 48ms/step - loss: 0.2335 - accuracy: 0.9119\n",
      "Epoch 12/60\n",
      "228/228 [==============================] - 11s 48ms/step - loss: 0.2209 - accuracy: 0.9175\n",
      "Epoch 13/60\n",
      "228/228 [==============================] - 11s 48ms/step - loss: 0.2225 - accuracy: 0.9163\n",
      "Epoch 14/60\n",
      "228/228 [==============================] - 11s 48ms/step - loss: 0.2077 - accuracy: 0.9216\n",
      "Epoch 15/60\n",
      "228/228 [==============================] - 11s 48ms/step - loss: 0.2027 - accuracy: 0.9235\n",
      "Epoch 16/60\n",
      "228/228 [==============================] - 11s 48ms/step - loss: 0.1937 - accuracy: 0.9270\n",
      "Epoch 17/60\n",
      "228/228 [==============================] - 11s 48ms/step - loss: 0.1907 - accuracy: 0.9287\n",
      "Epoch 18/60\n",
      "228/228 [==============================] - 11s 48ms/step - loss: 0.1914 - accuracy: 0.9292\n",
      "Epoch 19/60\n",
      "228/228 [==============================] - 11s 48ms/step - loss: 0.1770 - accuracy: 0.9334\n",
      "Epoch 20/60\n",
      "228/228 [==============================] - 11s 48ms/step - loss: 0.1713 - accuracy: 0.9364\n",
      "Epoch 21/60\n",
      "228/228 [==============================] - 11s 48ms/step - loss: 0.1761 - accuracy: 0.9342\n",
      "Epoch 22/60\n",
      "228/228 [==============================] - 11s 48ms/step - loss: 0.1640 - accuracy: 0.9377\n",
      "Epoch 23/60\n",
      "228/228 [==============================] - 11s 48ms/step - loss: 0.1627 - accuracy: 0.9391\n",
      "Epoch 24/60\n",
      "228/228 [==============================] - 11s 48ms/step - loss: 0.1563 - accuracy: 0.9421\n",
      "Epoch 25/60\n",
      "228/228 [==============================] - 11s 48ms/step - loss: 0.1531 - accuracy: 0.9424\n",
      "Epoch 26/60\n",
      "228/228 [==============================] - 11s 48ms/step - loss: 0.1434 - accuracy: 0.9457\n",
      "Epoch 27/60\n",
      "228/228 [==============================] - 11s 48ms/step - loss: 0.1478 - accuracy: 0.9446\n",
      "Epoch 28/60\n",
      "228/228 [==============================] - 11s 48ms/step - loss: 0.1413 - accuracy: 0.9470\n",
      "Epoch 29/60\n",
      "228/228 [==============================] - 11s 48ms/step - loss: 0.1367 - accuracy: 0.9486\n",
      "Epoch 30/60\n",
      "228/228 [==============================] - 11s 48ms/step - loss: 0.1353 - accuracy: 0.9493\n",
      "Epoch 31/60\n",
      "228/228 [==============================] - 11s 48ms/step - loss: 0.1320 - accuracy: 0.9505\n",
      "Epoch 32/60\n",
      "228/228 [==============================] - 11s 48ms/step - loss: 0.1226 - accuracy: 0.9546\n",
      "Epoch 33/60\n",
      "228/228 [==============================] - 11s 48ms/step - loss: 0.1241 - accuracy: 0.9531\n",
      "Epoch 34/60\n",
      "228/228 [==============================] - 11s 48ms/step - loss: 0.1239 - accuracy: 0.9526\n",
      "Epoch 35/60\n",
      "228/228 [==============================] - 11s 48ms/step - loss: 0.1187 - accuracy: 0.9548\n",
      "Epoch 36/60\n",
      "228/228 [==============================] - 11s 48ms/step - loss: 0.1200 - accuracy: 0.9560\n",
      "Epoch 37/60\n",
      "228/228 [==============================] - 11s 48ms/step - loss: 0.1105 - accuracy: 0.9579\n",
      "Epoch 38/60\n",
      "228/228 [==============================] - 11s 48ms/step - loss: 0.1177 - accuracy: 0.9556\n",
      "Epoch 39/60\n",
      "228/228 [==============================] - 11s 48ms/step - loss: 0.1125 - accuracy: 0.9585\n",
      "Epoch 40/60\n",
      "228/228 [==============================] - 11s 48ms/step - loss: 0.1055 - accuracy: 0.9601\n",
      "Epoch 41/60\n",
      "228/228 [==============================] - 11s 48ms/step - loss: 0.0992 - accuracy: 0.9615\n",
      "Epoch 42/60\n",
      "228/228 [==============================] - 11s 48ms/step - loss: 0.1040 - accuracy: 0.9611\n",
      "Epoch 43/60\n",
      "228/228 [==============================] - 11s 48ms/step - loss: 0.1064 - accuracy: 0.9602\n",
      "Epoch 44/60\n",
      "228/228 [==============================] - 11s 48ms/step - loss: 0.1086 - accuracy: 0.9604\n",
      "Epoch 45/60\n",
      "228/228 [==============================] - 11s 48ms/step - loss: 0.0978 - accuracy: 0.9635\n",
      "Epoch 46/60\n",
      "228/228 [==============================] - 11s 48ms/step - loss: 0.0967 - accuracy: 0.9644\n",
      "Epoch 47/60\n",
      "228/228 [==============================] - 11s 48ms/step - loss: 0.1036 - accuracy: 0.9619\n",
      "Epoch 48/60\n",
      "228/228 [==============================] - 11s 48ms/step - loss: 0.0927 - accuracy: 0.9659\n",
      "Epoch 49/60\n",
      "228/228 [==============================] - 11s 48ms/step - loss: 0.0906 - accuracy: 0.9660\n",
      "Epoch 50/60\n",
      "228/228 [==============================] - 11s 48ms/step - loss: 0.0897 - accuracy: 0.9666\n",
      "Epoch 51/60\n",
      "228/228 [==============================] - 11s 48ms/step - loss: 0.0935 - accuracy: 0.9660\n",
      "Epoch 52/60\n",
      "228/228 [==============================] - 11s 48ms/step - loss: 0.0884 - accuracy: 0.9671\n",
      "Epoch 53/60\n",
      "228/228 [==============================] - 11s 48ms/step - loss: 0.0879 - accuracy: 0.9670\n",
      "Epoch 54/60\n",
      "228/228 [==============================] - 11s 48ms/step - loss: 0.0898 - accuracy: 0.9666\n",
      "Epoch 55/60\n",
      "228/228 [==============================] - 11s 48ms/step - loss: 0.0849 - accuracy: 0.9678\n",
      "Epoch 56/60\n",
      "228/228 [==============================] - 11s 48ms/step - loss: 0.0824 - accuracy: 0.9693\n",
      "Epoch 57/60\n",
      "228/228 [==============================] - 11s 48ms/step - loss: 0.0790 - accuracy: 0.9716\n",
      "Epoch 58/60\n",
      "228/228 [==============================] - 11s 48ms/step - loss: 0.0818 - accuracy: 0.9696\n",
      "Epoch 59/60\n",
      "228/228 [==============================] - 11s 48ms/step - loss: 0.0773 - accuracy: 0.9711\n",
      "Epoch 60/60\n",
      "228/228 [==============================] - 11s 48ms/step - loss: 0.0845 - accuracy: 0.9684\n",
      "Wall time: 5h 5min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rscv = RandomizedSearchCV(model, param_distributions=params, cv=cv, n_iter=n_tune_iter)\n",
    "rscv_results = rscv.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score is: 0.9373348355293274 using {'n_dense_2': 256, 'n_dense_1': 512, 'n_conv_3': 256, 'n_conv_2': 512, 'n_conv_1': 768, 'maxpooling_pool_size': 3, 'k_conv_3': 3, 'k_conv_2': 3, 'k_conv_1': 3, 'dropout_2': 0.3, 'dropout_1': 0.3, 'avepooling_pool_size': 3, 'activation_dense': <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001D5B5607388>, 'activation_conv': 'relu'}\n"
     ]
    }
   ],
   "source": [
    "print('Best score is: {} using {}'.format(rscv_results.best_score_,\n",
    "rscv_results.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = rscv_results.best_estimator_\n",
    "best_param = rscv_results.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JkbhJMox8Jl9"
   },
   "source": [
    "### Test the best model based on the validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kZwGk5dR8JmS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\dfuller\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\wrappers\\scikit_learn.py:241: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
     ]
    }
   ],
   "source": [
    "y_hat = best_model.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E_GNq-R_8JmZ",
    "outputId": "0fc16efe-7739-4394-f1a3-46da92e79584"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 1.], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = to_categorical(y_hat)\n",
    "y_hat[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SFqRQ5XB8Jmc",
    "outputId": "a957fbed-92f8-4bdd-d24b-5df3361a8bac"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 1.], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FTWf6Cf-8Jme",
    "outputId": "1256b170-33dc-4171-f2ff-7a3d7ddd74e3"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_hat)\n",
    "_ = plt.axvline(x=0.5, color='orange')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 1.] [0. 0. 0. 0. 0. 1.] [0. 0. 0. 0. 0. 1.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "94.96602841260037"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import  accuracy_score as score\n",
    "y_pred_classes = y_hat.round()\n",
    "print(y_valid[0], y_hat[0], y_pred_classes[0])\n",
    "acc = score(y_valid, y_pred_classes) * 100\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RNljSx3v8Jmh"
   },
   "outputs": [],
   "source": [
    "pct_auc = roc_auc_score(y_valid, y_hat)*100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SO_N9lJG8Jmj",
    "outputId": "20968a52-8ca0-44d3-abf6-a1382bba5cde"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'96.98'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"{:0.2f}\".format(pct_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vU3hnA298Jmo"
   },
   "outputs": [],
   "source": [
    "float_y_hat = []\n",
    "for y in y_hat:\n",
    "    float_y_hat.append(y[0:6].round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zrTf-aQl8Jmr"
   },
   "outputs": [],
   "source": [
    "ydf = pd.DataFrame(list(zip(float_y_hat, y_valid)), columns=['y_hat', 'y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zAyKh_mX8Jmu",
    "outputId": "611224b8-f980-47df-d596-9aa3a5811009"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_hat</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            y_hat                               y\n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0]  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0]\n",
       "1  [0.0, 0.0, 1.0, 0.0, 0.0, 0.0]  [0.0, 0.0, 1.0, 0.0, 0.0, 0.0]\n",
       "2  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0]  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0]\n",
       "3  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0]  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
       "4  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0]  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0]\n",
       "5  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0]  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0]\n",
       "6  [0.0, 0.0, 0.0, 1.0, 0.0, 0.0]  [0.0, 0.0, 0.0, 1.0, 0.0, 0.0]\n",
       "7  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0]  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0]\n",
       "8  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0]  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
       "9  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0]  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ydf.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_dense_2</th>\n",
       "      <th>n_dense_1</th>\n",
       "      <th>n_conv_3</th>\n",
       "      <th>n_conv_2</th>\n",
       "      <th>n_conv_1</th>\n",
       "      <th>maxpooling_pool_size</th>\n",
       "      <th>k_conv_3</th>\n",
       "      <th>k_conv_2</th>\n",
       "      <th>k_conv_1</th>\n",
       "      <th>dropout_2</th>\n",
       "      <th>dropout_1</th>\n",
       "      <th>avepooling_pool_size</th>\n",
       "      <th>activation_dense</th>\n",
       "      <th>activation_conv</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>256</td>\n",
       "      <td>512</td>\n",
       "      <td>256</td>\n",
       "      <td>512</td>\n",
       "      <td>768</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>&lt;tensorflow.python.keras.layers.advanced_activ...</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.937335</td>\n",
       "      <td>0.002975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>256</td>\n",
       "      <td>512</td>\n",
       "      <td>256</td>\n",
       "      <td>512</td>\n",
       "      <td>768</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>elu</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.935447</td>\n",
       "      <td>0.001562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>384</td>\n",
       "      <td>384</td>\n",
       "      <td>512</td>\n",
       "      <td>256</td>\n",
       "      <td>512</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>elu</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.935224</td>\n",
       "      <td>0.002426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>512</td>\n",
       "      <td>256</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>&lt;tensorflow.python.keras.layers.advanced_activ...</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.935070</td>\n",
       "      <td>0.004143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>512</td>\n",
       "      <td>256</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>&lt;tensorflow.python.keras.layers.advanced_activ...</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.932668</td>\n",
       "      <td>0.001910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>384</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>768</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>relu</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.930265</td>\n",
       "      <td>0.002295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>512</td>\n",
       "      <td>256</td>\n",
       "      <td>768</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>5</td>\n",
       "      <td>&lt;tensorflow.python.keras.layers.advanced_activ...</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.928944</td>\n",
       "      <td>0.002297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>384</td>\n",
       "      <td>384</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>512</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>relu</td>\n",
       "      <td>&lt;tensorflow.python.keras.layers.advanced_activ...</td>\n",
       "      <td>0.907787</td>\n",
       "      <td>0.008216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>384</td>\n",
       "      <td>512</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>768</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>elu</td>\n",
       "      <td>elu</td>\n",
       "      <td>0.905968</td>\n",
       "      <td>0.003381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>512</td>\n",
       "      <td>256</td>\n",
       "      <td>768</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>relu</td>\n",
       "      <td>&lt;tensorflow.python.keras.layers.advanced_activ...</td>\n",
       "      <td>0.903720</td>\n",
       "      <td>0.000830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>384</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>256</td>\n",
       "      <td>768</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>elu</td>\n",
       "      <td>elu</td>\n",
       "      <td>0.901541</td>\n",
       "      <td>0.004067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>256</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>elu</td>\n",
       "      <td>&lt;tensorflow.python.keras.layers.advanced_activ...</td>\n",
       "      <td>0.896119</td>\n",
       "      <td>0.002472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>256</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>768</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>relu</td>\n",
       "      <td>&lt;tensorflow.python.keras.layers.advanced_activ...</td>\n",
       "      <td>0.894386</td>\n",
       "      <td>0.013423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>384</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>&lt;tensorflow.python.keras.layers.advanced_activ...</td>\n",
       "      <td>elu</td>\n",
       "      <td>0.894231</td>\n",
       "      <td>0.001923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>256</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>256</td>\n",
       "      <td>512</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>&lt;tensorflow.python.keras.layers.advanced_activ...</td>\n",
       "      <td>&lt;tensorflow.python.keras.layers.advanced_activ...</td>\n",
       "      <td>0.890456</td>\n",
       "      <td>0.002449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>256</td>\n",
       "      <td>768</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>&lt;tensorflow.python.keras.layers.advanced_activ...</td>\n",
       "      <td>elu</td>\n",
       "      <td>0.889409</td>\n",
       "      <td>0.003449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>512</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>&lt;tensorflow.python.keras.layers.advanced_activ...</td>\n",
       "      <td>&lt;tensorflow.python.keras.layers.advanced_activ...</td>\n",
       "      <td>0.888998</td>\n",
       "      <td>0.006783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>384</td>\n",
       "      <td>384</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>768</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>5</td>\n",
       "      <td>relu</td>\n",
       "      <td>&lt;tensorflow.python.keras.layers.advanced_activ...</td>\n",
       "      <td>0.887110</td>\n",
       "      <td>0.015376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>384</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>768</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>elu</td>\n",
       "      <td>&lt;tensorflow.python.keras.layers.advanced_activ...</td>\n",
       "      <td>0.880830</td>\n",
       "      <td>0.005133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>256</td>\n",
       "      <td>384</td>\n",
       "      <td>512</td>\n",
       "      <td>256</td>\n",
       "      <td>512</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>5</td>\n",
       "      <td>elu</td>\n",
       "      <td>&lt;tensorflow.python.keras.layers.advanced_activ...</td>\n",
       "      <td>0.876935</td>\n",
       "      <td>0.005118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    n_dense_2  n_dense_1  n_conv_3  n_conv_2  n_conv_1  maxpooling_pool_size  \\\n",
       "8         256        512       256       512       768                     3   \n",
       "16        256        512       256       512       768                     5   \n",
       "12        384        384       512       256       512                     5   \n",
       "0         512        256       512       512       512                     3   \n",
       "3         512        256       512       512       512                     5   \n",
       "2         384        256       256       256       768                     3   \n",
       "13        256        256       512       256       768                     3   \n",
       "1         384        384       256       256       512                     3   \n",
       "15        384        512       256       256       768                     5   \n",
       "17        256        256       512       256       768                     3   \n",
       "10        384        512       512       256       768                     5   \n",
       "4         256        512       512       512       512                     5   \n",
       "19        256        512       512       512       768                     3   \n",
       "9         384        256       256       512       512                     3   \n",
       "18        256        512       512       256       512                     5   \n",
       "11        512        512       512       256       768                     5   \n",
       "14        512        256       256       512       512                     3   \n",
       "5         384        384       512       512       768                     5   \n",
       "6         384        256       256       256       768                     3   \n",
       "7         256        384       512       256       512                     5   \n",
       "\n",
       "    k_conv_3  k_conv_2  k_conv_1  dropout_2  dropout_1  avepooling_pool_size  \\\n",
       "8          3         3         3        0.3        0.3                     3   \n",
       "16         3         3         3        0.2        0.3                     3   \n",
       "12         2         2         2        0.3        0.3                     3   \n",
       "0          3         2         3        0.2        0.2                     5   \n",
       "3          3         3         2        0.2        0.3                     3   \n",
       "2          3         2         2        0.3        0.3                     3   \n",
       "13         2         3         2        0.3        0.3                     5   \n",
       "1          3         2         3        0.2        0.2                     5   \n",
       "15         3         2         2        0.3        0.2                     3   \n",
       "17         2         2         3        0.2        0.2                     3   \n",
       "10         2         3         3        0.3        0.3                     3   \n",
       "4          2         3         3        0.2        0.3                     3   \n",
       "19         3         3         3        0.3        0.2                     3   \n",
       "9          3         2         2        0.2        0.3                     3   \n",
       "18         3         2         2        0.2        0.3                     3   \n",
       "11         2         3         3        0.3        0.2                     5   \n",
       "14         3         3         2        0.2        0.2                     5   \n",
       "5          2         2         2        0.2        0.3                     5   \n",
       "6          3         2         2        0.2        0.3                     3   \n",
       "7          2         3         2        0.2        0.3                     5   \n",
       "\n",
       "                                     activation_dense  \\\n",
       "8   <tensorflow.python.keras.layers.advanced_activ...   \n",
       "16                                                elu   \n",
       "12                                                elu   \n",
       "0   <tensorflow.python.keras.layers.advanced_activ...   \n",
       "3   <tensorflow.python.keras.layers.advanced_activ...   \n",
       "2                                                relu   \n",
       "13  <tensorflow.python.keras.layers.advanced_activ...   \n",
       "1                                                relu   \n",
       "15                                                elu   \n",
       "17                                               relu   \n",
       "10                                                elu   \n",
       "4                                                 elu   \n",
       "19                                               relu   \n",
       "9   <tensorflow.python.keras.layers.advanced_activ...   \n",
       "18  <tensorflow.python.keras.layers.advanced_activ...   \n",
       "11  <tensorflow.python.keras.layers.advanced_activ...   \n",
       "14  <tensorflow.python.keras.layers.advanced_activ...   \n",
       "5                                                relu   \n",
       "6                                                 elu   \n",
       "7                                                 elu   \n",
       "\n",
       "                                      activation_conv      mean       std  \n",
       "8                                                relu  0.937335  0.002975  \n",
       "16                                               relu  0.935447  0.001562  \n",
       "12                                               relu  0.935224  0.002426  \n",
       "0                                                relu  0.935070  0.004143  \n",
       "3                                                relu  0.932668  0.001910  \n",
       "2                                                relu  0.930265  0.002295  \n",
       "13                                               relu  0.928944  0.002297  \n",
       "1   <tensorflow.python.keras.layers.advanced_activ...  0.907787  0.008216  \n",
       "15                                                elu  0.905968  0.003381  \n",
       "17  <tensorflow.python.keras.layers.advanced_activ...  0.903720  0.000830  \n",
       "10                                                elu  0.901541  0.004067  \n",
       "4   <tensorflow.python.keras.layers.advanced_activ...  0.896119  0.002472  \n",
       "19  <tensorflow.python.keras.layers.advanced_activ...  0.894386  0.013423  \n",
       "9                                                 elu  0.894231  0.001923  \n",
       "18  <tensorflow.python.keras.layers.advanced_activ...  0.890456  0.002449  \n",
       "11                                                elu  0.889409  0.003449  \n",
       "14  <tensorflow.python.keras.layers.advanced_activ...  0.888998  0.006783  \n",
       "5   <tensorflow.python.keras.layers.advanced_activ...  0.887110  0.015376  \n",
       "6   <tensorflow.python.keras.layers.advanced_activ...  0.880830  0.005133  \n",
       "7   <tensorflow.python.keras.layers.advanced_activ...  0.876935  0.005118  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame(rscv_results.cv_results_['params'])\n",
    "results_df['mean'] = rscv_results.cv_results_['mean_test_score']\n",
    "results_df['std'] = rscv_results.cv_results_['std_test_score']\n",
    "results_df.sort_values('mean', ascending=False, ignore_index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating best model from the best param and train it for 60 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_dense_2= 256\n",
    "n_dense_1= 512\n",
    "n_conv_3= 256\n",
    "n_conv_2= 512\n",
    "n_conv_1= 768\n",
    "maxpooling_pool_size= 2\n",
    "k_conv_3= 3\n",
    "k_conv_2= 3\n",
    "k_conv_1= 3\n",
    "dropout_2= 0.3\n",
    "dropout_1= 0.25\n",
    "avepooling_pool_size= 2\n",
    "activation_dense = LeakyReLU()\n",
    "activation_conv = 'relu'\n",
    "model = Sequential()\n",
    "model.add(Conv1D(n_conv_1, k_conv_1, activation=activation_conv, input_shape=input_shape[1:]))\n",
    "model.add(MaxPool1D(pool_size = maxpooling_pool_size))\n",
    "model.add(Conv1D(n_conv_2, k_conv_2, activation=activation_conv))\n",
    "model.add(AveragePooling1D(pool_size = avepooling_pool_size))\n",
    "model.add(Conv1D(n_conv_3, k_conv_3, activation=activation_conv))\n",
    "# model.add(GlobalMaxPooling1D())\n",
    "model.add(GlobalAveragePooling1D())\n",
    "model.add(Dense(n_dense_1, activation=activation_dense))\n",
    "model.add(Dropout(dropout_1))\n",
    "model.add(Dense(n_dense_2, activation=activation_dense))\n",
    "model.add(Dropout(dropout_2))\n",
    "model.add(Dense(n_class, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir= 'model_ouput/tune-sklearn-2'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "modelcheckpoint = ModelCheckpoint(filepath=output_dir+\n",
    "                                  \"/weights.{epoch:02d}.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "  2/228 [..............................] - ETA: 10s - loss: 1.7767 - accuracy: 0.1758WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0259s vs `on_train_batch_end` time: 0.0459s). Check your callbacks.\n",
      "228/228 [==============================] - 16s 71ms/step - loss: 0.9513 - accuracy: 0.6021 - val_loss: 0.6159 - val_accuracy: 0.7543\n",
      "Epoch 2/120\n",
      "228/228 [==============================] - 16s 69ms/step - loss: 0.5042 - accuracy: 0.8076 - val_loss: 0.3957 - val_accuracy: 0.8524\n",
      "Epoch 3/120\n",
      "228/228 [==============================] - 16s 69ms/step - loss: 0.3865 - accuracy: 0.8542 - val_loss: 0.3783 - val_accuracy: 0.8618\n",
      "Epoch 4/120\n",
      "228/228 [==============================] - 16s 69ms/step - loss: 0.3469 - accuracy: 0.8701 - val_loss: 0.3243 - val_accuracy: 0.8796\n",
      "Epoch 5/120\n",
      "228/228 [==============================] - 16s 69ms/step - loss: 0.3160 - accuracy: 0.8803 - val_loss: 0.3090 - val_accuracy: 0.8789\n",
      "Epoch 6/120\n",
      "228/228 [==============================] - 16s 69ms/step - loss: 0.2946 - accuracy: 0.8896 - val_loss: 0.2957 - val_accuracy: 0.8851\n",
      "Epoch 7/120\n",
      "228/228 [==============================] - 16s 69ms/step - loss: 0.2789 - accuracy: 0.8966 - val_loss: 0.2774 - val_accuracy: 0.8927\n",
      "Epoch 8/120\n",
      "228/228 [==============================] - 16s 69ms/step - loss: 0.2605 - accuracy: 0.9025 - val_loss: 0.2535 - val_accuracy: 0.9100\n",
      "Epoch 9/120\n",
      "228/228 [==============================] - 16s 69ms/step - loss: 0.2549 - accuracy: 0.9035 - val_loss: 0.2398 - val_accuracy: 0.9104\n",
      "Epoch 10/120\n",
      "228/228 [==============================] - 16s 69ms/step - loss: 0.2387 - accuracy: 0.9115 - val_loss: 0.2443 - val_accuracy: 0.9103\n",
      "Epoch 11/120\n",
      "228/228 [==============================] - 16s 69ms/step - loss: 0.2316 - accuracy: 0.9127 - val_loss: 0.2241 - val_accuracy: 0.9179\n",
      "Epoch 12/120\n",
      "228/228 [==============================] - 16s 69ms/step - loss: 0.2219 - accuracy: 0.9160 - val_loss: 0.2411 - val_accuracy: 0.9106\n",
      "Epoch 13/120\n",
      "228/228 [==============================] - 16s 69ms/step - loss: 0.2188 - accuracy: 0.9182 - val_loss: 0.2198 - val_accuracy: 0.9174\n",
      "Epoch 14/120\n",
      "228/228 [==============================] - 16s 69ms/step - loss: 0.2045 - accuracy: 0.9233 - val_loss: 0.2196 - val_accuracy: 0.9219\n",
      "Epoch 15/120\n",
      "228/228 [==============================] - 16s 69ms/step - loss: 0.1987 - accuracy: 0.9255 - val_loss: 0.1920 - val_accuracy: 0.9290\n",
      "Epoch 16/120\n",
      "228/228 [==============================] - 16s 69ms/step - loss: 0.2000 - accuracy: 0.9254 - val_loss: 0.1990 - val_accuracy: 0.9268\n",
      "Epoch 17/120\n",
      "228/228 [==============================] - 16s 69ms/step - loss: 0.1905 - accuracy: 0.9287 - val_loss: 0.1956 - val_accuracy: 0.9274\n",
      "Epoch 18/120\n",
      "228/228 [==============================] - 16s 69ms/step - loss: 0.1816 - accuracy: 0.9312 - val_loss: 0.1908 - val_accuracy: 0.9365\n",
      "Epoch 19/120\n",
      "228/228 [==============================] - 16s 69ms/step - loss: 0.1825 - accuracy: 0.9302 - val_loss: 0.1970 - val_accuracy: 0.9302\n",
      "Epoch 20/120\n",
      "228/228 [==============================] - 16s 69ms/step - loss: 0.1711 - accuracy: 0.9351 - val_loss: 0.1996 - val_accuracy: 0.9317\n",
      "Epoch 21/120\n",
      "228/228 [==============================] - 16s 69ms/step - loss: 0.1713 - accuracy: 0.9362 - val_loss: 0.1954 - val_accuracy: 0.9372\n",
      "Epoch 22/120\n",
      "228/228 [==============================] - 16s 69ms/step - loss: 0.1673 - accuracy: 0.9371 - val_loss: 0.1906 - val_accuracy: 0.9322\n",
      "Epoch 23/120\n",
      "228/228 [==============================] - 16s 69ms/step - loss: 0.1625 - accuracy: 0.9387 - val_loss: 0.1672 - val_accuracy: 0.9443\n",
      "Epoch 24/120\n",
      "228/228 [==============================] - 16s 69ms/step - loss: 0.1521 - accuracy: 0.9424 - val_loss: 0.1763 - val_accuracy: 0.9396\n",
      "Epoch 25/120\n",
      "228/228 [==============================] - 16s 69ms/step - loss: 0.1525 - accuracy: 0.9424 - val_loss: 0.1772 - val_accuracy: 0.9372\n",
      "Epoch 26/120\n",
      "228/228 [==============================] - 16s 69ms/step - loss: 0.1475 - accuracy: 0.9437 - val_loss: 0.1736 - val_accuracy: 0.9356\n",
      "Epoch 27/120\n",
      "228/228 [==============================] - 16s 69ms/step - loss: 0.1476 - accuracy: 0.9439 - val_loss: 0.1676 - val_accuracy: 0.9405\n",
      "Epoch 28/120\n",
      "228/228 [==============================] - 16s 69ms/step - loss: 0.1428 - accuracy: 0.9462 - val_loss: 0.1691 - val_accuracy: 0.9438\n",
      "Epoch 29/120\n",
      "228/228 [==============================] - 16s 69ms/step - loss: 0.1408 - accuracy: 0.9475 - val_loss: 0.1838 - val_accuracy: 0.9387\n",
      "Epoch 30/120\n",
      "228/228 [==============================] - 16s 69ms/step - loss: 0.1427 - accuracy: 0.9451 - val_loss: 0.1753 - val_accuracy: 0.9385\n",
      "Epoch 31/120\n",
      "228/228 [==============================] - 16s 69ms/step - loss: 0.1305 - accuracy: 0.9505 - val_loss: 0.1572 - val_accuracy: 0.9466\n",
      "Epoch 32/120\n",
      "228/228 [==============================] - 16s 69ms/step - loss: 0.1315 - accuracy: 0.9505 - val_loss: 0.1670 - val_accuracy: 0.9438\n",
      "Epoch 33/120\n",
      "228/228 [==============================] - 16s 69ms/step - loss: 0.1302 - accuracy: 0.9511 - val_loss: 0.1681 - val_accuracy: 0.9439\n",
      "Epoch 34/120\n",
      "228/228 [==============================] - 16s 69ms/step - loss: 0.1277 - accuracy: 0.9524 - val_loss: 0.1656 - val_accuracy: 0.9453\n",
      "Epoch 35/120\n",
      "228/228 [==============================] - 16s 69ms/step - loss: 0.1240 - accuracy: 0.9544 - val_loss: 0.2492 - val_accuracy: 0.9307\n",
      "Epoch 36/120\n",
      "228/228 [==============================] - 16s 69ms/step - loss: 0.1288 - accuracy: 0.9522 - val_loss: 0.1602 - val_accuracy: 0.9478\n",
      "Epoch 37/120\n",
      "228/228 [==============================] - 16s 69ms/step - loss: 0.1154 - accuracy: 0.9568 - val_loss: 0.1963 - val_accuracy: 0.9382\n",
      "Epoch 38/120\n",
      "228/228 [==============================] - 16s 69ms/step - loss: 0.1267 - accuracy: 0.9522 - val_loss: 0.1603 - val_accuracy: 0.9494\n",
      "Epoch 39/120\n",
      "228/228 [==============================] - 16s 69ms/step - loss: 0.1120 - accuracy: 0.9574 - val_loss: 0.1636 - val_accuracy: 0.9467\n",
      "Epoch 40/120\n",
      "228/228 [==============================] - 16s 69ms/step - loss: 0.1120 - accuracy: 0.9582 - val_loss: 0.1494 - val_accuracy: 0.9506\n",
      "Epoch 41/120\n",
      "228/228 [==============================] - 16s 69ms/step - loss: 0.1087 - accuracy: 0.9589 - val_loss: 0.1730 - val_accuracy: 0.9486\n",
      "Epoch 42/120\n",
      "228/228 [==============================] - 16s 69ms/step - loss: 0.1120 - accuracy: 0.9589 - val_loss: 0.1649 - val_accuracy: 0.9501\n",
      "Epoch 43/120\n",
      "228/228 [==============================] - 16s 69ms/step - loss: 0.1042 - accuracy: 0.9606 - val_loss: 0.1817 - val_accuracy: 0.9469\n",
      "Epoch 44/120\n",
      "228/228 [==============================] - 16s 69ms/step - loss: 0.1049 - accuracy: 0.9611 - val_loss: 0.1675 - val_accuracy: 0.9487\n",
      "Epoch 45/120\n",
      "228/228 [==============================] - 16s 69ms/step - loss: 0.1063 - accuracy: 0.9603 - val_loss: 0.1546 - val_accuracy: 0.9509\n",
      "Epoch 46/120\n",
      "228/228 [==============================] - 16s 69ms/step - loss: 0.1046 - accuracy: 0.9612 - val_loss: 0.1704 - val_accuracy: 0.9469\n",
      "Epoch 47/120\n",
      "228/228 [==============================] - 16s 69ms/step - loss: 0.1017 - accuracy: 0.9615 - val_loss: 0.1714 - val_accuracy: 0.9452\n",
      "Epoch 48/120\n",
      "228/228 [==============================] - 16s 69ms/step - loss: 0.1006 - accuracy: 0.9620 - val_loss: 0.1778 - val_accuracy: 0.9460\n",
      "Epoch 49/120\n",
      "228/228 [==============================] - 16s 69ms/step - loss: 0.0958 - accuracy: 0.9645 - val_loss: 0.1638 - val_accuracy: 0.9532\n",
      "Epoch 50/120\n",
      "228/228 [==============================] - 16s 69ms/step - loss: 0.0991 - accuracy: 0.9629 - val_loss: 0.1663 - val_accuracy: 0.9511\n",
      "Epoch 51/120\n",
      "228/228 [==============================] - 16s 69ms/step - loss: 0.0986 - accuracy: 0.9642 - val_loss: 0.1595 - val_accuracy: 0.9591\n",
      "Epoch 52/120\n",
      "228/228 [==============================] - 16s 69ms/step - loss: 0.0951 - accuracy: 0.9641 - val_loss: 0.1519 - val_accuracy: 0.9572\n",
      "Epoch 53/120\n",
      "228/228 [==============================] - 16s 69ms/step - loss: 0.0870 - accuracy: 0.9679 - val_loss: 0.1645 - val_accuracy: 0.9554\n",
      "Epoch 54/120\n",
      "228/228 [==============================] - 16s 69ms/step - loss: 0.0864 - accuracy: 0.9675 - val_loss: 0.1708 - val_accuracy: 0.9537\n",
      "Epoch 55/120\n",
      "228/228 [==============================] - 16s 68ms/step - loss: 0.0900 - accuracy: 0.9672 - val_loss: 0.1864 - val_accuracy: 0.9511\n",
      "Epoch 56/120\n",
      "228/228 [==============================] - 16s 69ms/step - loss: 0.0895 - accuracy: 0.9665 - val_loss: 0.1831 - val_accuracy: 0.9511\n",
      "Epoch 57/120\n",
      "228/228 [==============================] - 16s 69ms/step - loss: 0.0915 - accuracy: 0.9667 - val_loss: 0.1592 - val_accuracy: 0.9526\n",
      "Epoch 58/120\n",
      "228/228 [==============================] - 16s 69ms/step - loss: 0.0848 - accuracy: 0.9686 - val_loss: 0.1779 - val_accuracy: 0.9498\n",
      "Epoch 59/120\n",
      "228/228 [==============================] - 16s 69ms/step - loss: 0.0894 - accuracy: 0.9679 - val_loss: 0.1544 - val_accuracy: 0.9578\n",
      "Epoch 60/120\n",
      "228/228 [==============================] - 16s 68ms/step - loss: 0.0822 - accuracy: 0.9698 - val_loss: 0.1859 - val_accuracy: 0.9531\n",
      "Epoch 61/120\n",
      "228/228 [==============================] - 16s 69ms/step - loss: 0.0801 - accuracy: 0.9701 - val_loss: 0.1818 - val_accuracy: 0.9565\n",
      "Epoch 62/120\n",
      "228/228 [==============================] - 16s 69ms/step - loss: 0.0837 - accuracy: 0.9693 - val_loss: 0.1827 - val_accuracy: 0.9555\n",
      "Epoch 63/120\n",
      "228/228 [==============================] - 16s 69ms/step - loss: 0.0900 - accuracy: 0.9679 - val_loss: 0.1620 - val_accuracy: 0.9588\n",
      "Epoch 64/120\n",
      "228/228 [==============================] - 16s 69ms/step - loss: 0.0765 - accuracy: 0.9718 - val_loss: 0.1807 - val_accuracy: 0.9507\n",
      "Epoch 65/120\n",
      "228/228 [==============================] - 16s 69ms/step - loss: 0.0809 - accuracy: 0.9697 - val_loss: 0.1736 - val_accuracy: 0.9529\n",
      "Epoch 66/120\n",
      "228/228 [==============================] - 16s 69ms/step - loss: 0.0812 - accuracy: 0.9701 - val_loss: 0.1745 - val_accuracy: 0.9568\n",
      "Epoch 67/120\n",
      "228/228 [==============================] - 16s 69ms/step - loss: 0.0789 - accuracy: 0.9699 - val_loss: 0.1789 - val_accuracy: 0.9526\n",
      "Epoch 68/120\n",
      "228/228 [==============================] - 16s 68ms/step - loss: 0.0785 - accuracy: 0.9700 - val_loss: 0.1707 - val_accuracy: 0.9566\n",
      "Epoch 69/120\n",
      "228/228 [==============================] - 16s 69ms/step - loss: 0.0742 - accuracy: 0.9727 - val_loss: 0.2128 - val_accuracy: 0.9501\n",
      "Epoch 70/120\n",
      "228/228 [==============================] - 16s 68ms/step - loss: 0.0784 - accuracy: 0.9706 - val_loss: 0.1720 - val_accuracy: 0.9543\n",
      "Epoch 71/120\n",
      "228/228 [==============================] - 16s 69ms/step - loss: 0.0732 - accuracy: 0.9733 - val_loss: 0.1751 - val_accuracy: 0.9535\n",
      "Epoch 72/120\n",
      "228/228 [==============================] - 16s 69ms/step - loss: 0.0743 - accuracy: 0.9724 - val_loss: 0.2141 - val_accuracy: 0.9486\n",
      "Epoch 73/120\n",
      "228/228 [==============================] - 16s 69ms/step - loss: 0.0772 - accuracy: 0.9722 - val_loss: 0.1854 - val_accuracy: 0.9558\n",
      "Epoch 74/120\n",
      "228/228 [==============================] - 16s 69ms/step - loss: 0.0709 - accuracy: 0.9732 - val_loss: 0.1718 - val_accuracy: 0.9575\n",
      "Epoch 75/120\n",
      "228/228 [==============================] - 16s 69ms/step - loss: 0.0662 - accuracy: 0.9751 - val_loss: 0.2023 - val_accuracy: 0.9538\n",
      "Epoch 76/120\n",
      "228/228 [==============================] - 16s 69ms/step - loss: 0.0729 - accuracy: 0.9724 - val_loss: 0.1763 - val_accuracy: 0.9568\n",
      "Epoch 77/120\n",
      "228/228 [==============================] - 16s 69ms/step - loss: 0.0736 - accuracy: 0.9729 - val_loss: 0.1800 - val_accuracy: 0.9561\n",
      "Epoch 78/120\n",
      "228/228 [==============================] - 16s 69ms/step - loss: 0.0718 - accuracy: 0.9734 - val_loss: 0.1770 - val_accuracy: 0.9534\n",
      "Epoch 79/120\n",
      "228/228 [==============================] - 16s 69ms/step - loss: 0.0703 - accuracy: 0.9741 - val_loss: 0.1957 - val_accuracy: 0.9531\n",
      "Epoch 80/120\n",
      "228/228 [==============================] - 16s 69ms/step - loss: 0.0667 - accuracy: 0.9746 - val_loss: 0.1933 - val_accuracy: 0.9527\n",
      "Epoch 81/120\n",
      "228/228 [==============================] - 16s 68ms/step - loss: 0.0646 - accuracy: 0.9761 - val_loss: 0.1887 - val_accuracy: 0.9577\n",
      "Epoch 82/120\n",
      "228/228 [==============================] - 16s 69ms/step - loss: 0.0637 - accuracy: 0.9764 - val_loss: 0.1808 - val_accuracy: 0.9586\n",
      "Epoch 83/120\n",
      "228/228 [==============================] - 16s 69ms/step - loss: 0.0704 - accuracy: 0.9746 - val_loss: 0.1822 - val_accuracy: 0.9585\n",
      "Epoch 84/120\n",
      "228/228 [==============================] - 16s 68ms/step - loss: 0.0663 - accuracy: 0.9756 - val_loss: 0.1719 - val_accuracy: 0.9634\n",
      "Epoch 85/120\n",
      "228/228 [==============================] - 16s 69ms/step - loss: 0.0618 - accuracy: 0.9771 - val_loss: 0.1938 - val_accuracy: 0.9597\n",
      "Epoch 86/120\n",
      "228/228 [==============================] - 16s 68ms/step - loss: 0.0670 - accuracy: 0.9757 - val_loss: 0.2012 - val_accuracy: 0.9541\n",
      "Epoch 87/120\n",
      "228/228 [==============================] - 16s 68ms/step - loss: 0.0687 - accuracy: 0.9748 - val_loss: 0.1873 - val_accuracy: 0.9540\n",
      "Epoch 88/120\n",
      "228/228 [==============================] - 16s 69ms/step - loss: 0.0614 - accuracy: 0.9774 - val_loss: 0.1827 - val_accuracy: 0.9595\n",
      "Epoch 89/120\n",
      "228/228 [==============================] - 16s 68ms/step - loss: 0.0629 - accuracy: 0.9766 - val_loss: 0.1816 - val_accuracy: 0.9592\n",
      "Epoch 90/120\n",
      "228/228 [==============================] - 16s 68ms/step - loss: 0.0681 - accuracy: 0.9753 - val_loss: 0.1844 - val_accuracy: 0.9551\n",
      "Epoch 91/120\n",
      "228/228 [==============================] - 16s 68ms/step - loss: 0.0664 - accuracy: 0.9761 - val_loss: 0.1955 - val_accuracy: 0.9555\n",
      "Epoch 92/120\n",
      "228/228 [==============================] - 16s 68ms/step - loss: 0.0608 - accuracy: 0.9781 - val_loss: 0.1955 - val_accuracy: 0.9591\n",
      "Epoch 93/120\n",
      "228/228 [==============================] - 16s 68ms/step - loss: 0.0600 - accuracy: 0.9773 - val_loss: 0.1814 - val_accuracy: 0.9591\n",
      "Epoch 94/120\n",
      "228/228 [==============================] - 16s 68ms/step - loss: 0.0568 - accuracy: 0.9784 - val_loss: 0.2158 - val_accuracy: 0.9544\n",
      "Epoch 95/120\n",
      "228/228 [==============================] - 16s 69ms/step - loss: 0.0633 - accuracy: 0.9769 - val_loss: 0.2051 - val_accuracy: 0.9552\n",
      "Epoch 96/120\n",
      "228/228 [==============================] - 16s 68ms/step - loss: 0.0578 - accuracy: 0.9783 - val_loss: 0.1992 - val_accuracy: 0.9537\n",
      "Epoch 97/120\n",
      "228/228 [==============================] - 16s 68ms/step - loss: 0.0613 - accuracy: 0.9780 - val_loss: 0.1823 - val_accuracy: 0.9571\n",
      "Epoch 98/120\n",
      "228/228 [==============================] - 16s 68ms/step - loss: 0.0603 - accuracy: 0.9783 - val_loss: 0.2001 - val_accuracy: 0.9592\n",
      "Epoch 99/120\n",
      "228/228 [==============================] - 16s 69ms/step - loss: 0.0616 - accuracy: 0.9770 - val_loss: 0.2013 - val_accuracy: 0.9566\n",
      "Epoch 100/120\n",
      "228/228 [==============================] - 16s 68ms/step - loss: 0.0609 - accuracy: 0.9777 - val_loss: 0.1882 - val_accuracy: 0.9591\n",
      "Epoch 101/120\n",
      "228/228 [==============================] - 16s 69ms/step - loss: 0.0599 - accuracy: 0.9778 - val_loss: 0.1760 - val_accuracy: 0.9600\n",
      "Epoch 102/120\n",
      "228/228 [==============================] - 16s 68ms/step - loss: 0.0574 - accuracy: 0.9794 - val_loss: 0.1811 - val_accuracy: 0.9606\n",
      "Epoch 103/120\n",
      "228/228 [==============================] - 16s 69ms/step - loss: 0.0552 - accuracy: 0.9793 - val_loss: 0.1873 - val_accuracy: 0.9599\n",
      "Epoch 104/120\n",
      "228/228 [==============================] - 16s 68ms/step - loss: 0.0582 - accuracy: 0.9792 - val_loss: 0.1870 - val_accuracy: 0.9634\n",
      "Epoch 105/120\n",
      "228/228 [==============================] - 16s 68ms/step - loss: 0.0604 - accuracy: 0.9781 - val_loss: 0.2140 - val_accuracy: 0.9566\n",
      "Epoch 106/120\n",
      "228/228 [==============================] - 16s 68ms/step - loss: 0.0585 - accuracy: 0.9780 - val_loss: 0.1769 - val_accuracy: 0.9629\n",
      "Epoch 107/120\n",
      "228/228 [==============================] - 16s 68ms/step - loss: 0.0566 - accuracy: 0.9790 - val_loss: 0.2022 - val_accuracy: 0.9565\n",
      "Epoch 108/120\n",
      "228/228 [==============================] - 16s 68ms/step - loss: 0.0533 - accuracy: 0.9800 - val_loss: 0.1904 - val_accuracy: 0.9631\n",
      "Epoch 109/120\n",
      "228/228 [==============================] - 16s 69ms/step - loss: 0.0581 - accuracy: 0.9785 - val_loss: 0.1840 - val_accuracy: 0.9597\n",
      "Epoch 110/120\n",
      "228/228 [==============================] - 16s 68ms/step - loss: 0.0525 - accuracy: 0.9800 - val_loss: 0.1965 - val_accuracy: 0.9592\n",
      "Epoch 111/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "228/228 [==============================] - 16s 69ms/step - loss: 0.0591 - accuracy: 0.9789 - val_loss: 0.1911 - val_accuracy: 0.9591\n",
      "Epoch 112/120\n",
      "228/228 [==============================] - 16s 68ms/step - loss: 0.0516 - accuracy: 0.9807 - val_loss: 0.1887 - val_accuracy: 0.9616\n",
      "Epoch 113/120\n",
      "228/228 [==============================] - 16s 68ms/step - loss: 0.0736 - accuracy: 0.9752 - val_loss: 0.1666 - val_accuracy: 0.9608\n",
      "Epoch 114/120\n",
      "228/228 [==============================] - 16s 68ms/step - loss: 0.0500 - accuracy: 0.9814 - val_loss: 0.1874 - val_accuracy: 0.9588\n",
      "Epoch 115/120\n",
      "228/228 [==============================] - 16s 68ms/step - loss: 0.0480 - accuracy: 0.9819 - val_loss: 0.1879 - val_accuracy: 0.9614\n",
      "Epoch 116/120\n",
      "228/228 [==============================] - 16s 68ms/step - loss: 0.0480 - accuracy: 0.9820 - val_loss: 0.1901 - val_accuracy: 0.9642\n",
      "Epoch 117/120\n",
      "228/228 [==============================] - 16s 68ms/step - loss: 0.0515 - accuracy: 0.9806 - val_loss: 0.2009 - val_accuracy: 0.9582\n",
      "Epoch 118/120\n",
      "228/228 [==============================] - 16s 69ms/step - loss: 0.0523 - accuracy: 0.9809 - val_loss: 0.2170 - val_accuracy: 0.9597\n",
      "Epoch 119/120\n",
      "228/228 [==============================] - 16s 69ms/step - loss: 0.0601 - accuracy: 0.9787 - val_loss: 0.1901 - val_accuracy: 0.9582\n",
      "Epoch 120/120\n",
      "228/228 [==============================] - 16s 68ms/step - loss: 0.0491 - accuracy: 0.9827 - val_loss: 0.1906 - val_accuracy: 0.9602\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1d6e9d86ec8>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 120\n",
    "model.fit(X_train, y_train, \n",
    "         batch_size=batch_size, epochs=epochs, verbose=1, \n",
    "         validation_data=(X_valid, y_valid), \n",
    "         callbacks=[modelcheckpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z8t0nVCw8JmP"
   },
   "outputs": [],
   "source": [
    "model.load_weights(output_dir+\"/weights.116.hdf5\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kZwGk5dR8JmS"
   },
   "outputs": [],
   "source": [
    "y_hat = model.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EPc5_h6K8JmW",
    "outputId": "cad99da9-9f89-437f-854b-a315616ed50f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6476"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E_GNq-R_8JmZ",
    "outputId": "0fc16efe-7739-4394-f1a3-46da92e79584"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.8225738e-05, 1.9944432e-07, 2.4306075e-08, 8.1681016e-08,\n",
       "       1.1624115e-05, 9.9991977e-01], dtype=float32)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SFqRQ5XB8Jmc",
    "outputId": "a957fbed-92f8-4bdd-d24b-5df3361a8bac"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 1.], dtype=float32)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FTWf6Cf-8Jme",
    "outputId": "1256b170-33dc-4171-f2ff-7a3d7ddd74e3"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_hat)\n",
    "_ = plt.axvline(x=0.5, color='orange')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RNljSx3v8Jmh"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'99.75'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pct_auc = roc_auc_score(y_valid, y_hat)*100.0\n",
    "\"{:0.2f}\".format(pct_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SO_N9lJG8Jmj",
    "outputId": "20968a52-8ca0-44d3-abf6-a1382bba5cde"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'96.32'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_classes = y_hat.round()\n",
    "acc = score(y_valid, y_pred_classes) * 100\n",
    "\"{:0.2f}\".format(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vU3hnA298Jmo"
   },
   "outputs": [],
   "source": [
    "float_y_hat = []\n",
    "for y in y_hat:\n",
    "    float_y_hat.append(y[0:6].round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zrTf-aQl8Jmr"
   },
   "outputs": [],
   "source": [
    "ydf = pd.DataFrame(list(zip(float_y_hat, y_valid)), columns=['y_hat', 'y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zAyKh_mX8Jmu",
    "outputId": "611224b8-f980-47df-d596-9aa3a5811009"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_hat</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            y_hat                               y\n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0]  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0]\n",
       "1  [0.0, 0.0, 1.0, 0.0, 0.0, 0.0]  [0.0, 0.0, 1.0, 0.0, 0.0, 0.0]\n",
       "2  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0]  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0]\n",
       "3  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0]  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
       "4  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0]  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0]\n",
       "5  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0]  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0]\n",
       "6  [0.0, 0.0, 0.0, 1.0, 0.0, 0.0]  [0.0, 0.0, 0.0, 1.0, 0.0, 0.0]\n",
       "7  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0]  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0]\n",
       "8  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0]  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
       "9  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0]  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ydf.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "dense_sentiment_classifier.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
