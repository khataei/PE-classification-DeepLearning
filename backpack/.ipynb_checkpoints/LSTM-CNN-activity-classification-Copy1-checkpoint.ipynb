{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/khataei/PE-classification-DeepLearning/blob/master/LSTM-activity-classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ahUZuAfz8Jje"
   },
   "source": [
    "# LSTM then CNN Activity Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Re0ecmVI8Jjk"
   },
   "source": [
    "In this notebook, we modify use LSTM then CNN layers to classify PE activity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ixsGb9tY8Jjm"
   },
   "source": [
    "#### Load dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5At1PKQp8Jjp"
   },
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Embedding, SpatialDropout1D, LSTM\n",
    "from tensorflow.keras.layers import Bidirectional, LeakyReLU, Flatten\n",
    "from tensorflow.keras.layers import Conv1D, GlobalMaxPooling1D, MaxPool1D, GlobalAveragePooling1D, AveragePooling1D\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint \n",
    "import os \n",
    "from sklearn.metrics import roc_auc_score, roc_curve \n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt # new!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hg5wX2Dd8Jjz"
   },
   "source": [
    "#### Set hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lYLOM99-8Jj2"
   },
   "outputs": [],
   "source": [
    "# output directory name:\n",
    "output_dir = 'model_output/lstm2'\n",
    "input_dir =  'Z:/Research/dfuller/Walkabilly/studies/smarphone_accel/data/Ethica_Jaeger_Merged/pocket/'\n",
    "input_file_name = 'pocket-NN-data.npz'\n",
    "\n",
    "# from the data preparation section we have:\n",
    "window_size_second = 3\n",
    "frequency = 30\n",
    "lenght_of_each_seq = window_size_second * frequency\n",
    "\n",
    "\n",
    "\n",
    "# pooling layer parameters\n",
    "maxpooling_pool_size = 2\n",
    "avepooling_pool_size = 2\n",
    "\n",
    "\n",
    "# convolutional layer architecture:\n",
    "n_conv_1 = 512 # filters, a.k.a. kernels\n",
    "k_conv_1 = 3 # kernel length\n",
    "strides_1 = 1\n",
    "n_conv_2 = 256\n",
    "k_conv_2 = 3 # kernel length\n",
    "n_conv_3 = 256 # filters, a.k.a. kernels\n",
    "k_conv_3 = 2 # kernel length\n",
    "\n",
    "\n",
    "# LSTM layer architecture:\n",
    "n_lstm_1 = 128 \n",
    "n_lstm_2 = 128 \n",
    "n_lstm_3 = 64\n",
    "drop_lstm_1 = 0.0\n",
    "drop_lstm_2 = 0.02\n",
    "drop_lstm_3 = 0.05\n",
    "\n",
    "\n",
    "# dense layer architecture: \n",
    "n_dense_1 = 256\n",
    "dropout_1 = 0.2\n",
    "n_dense_2 = 256\n",
    "dropout_2 = 0.3\n",
    "n_dense_3 = 128\n",
    "dropout_3 = 0.3\n",
    "\n",
    "# training:\n",
    "epochs = 60\n",
    "batch_size = 256\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DaLx4yZ48Jj9"
   },
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CD9X0yJg8Jj_"
   },
   "source": [
    "##### For this notebook we use the acceleration data gathered from the pocket location. It was prepared in the DataPrep-Deep notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6r44JKj-8JkA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acceleration_data\n",
      "metadata\n",
      "labels\n"
     ]
    }
   ],
   "source": [
    "# read the raw file and get the keys:\n",
    "raw_data = np.load(file=input_dir+input_file_name,allow_pickle=True)\n",
    "for k in raw_data.keys():\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the data\n",
    "\n",
    "accel_array = raw_data['acceleration_data']\n",
    "meta_array = raw_data['metadata']\n",
    "labels_array = raw_data['labels']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WWq3ipbu8JlG"
   },
   "source": [
    "#### Preprocess data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert the  labels to integer.\n",
    "In the raw data format of the labels is String and there are 6 classes. 'Lying', 'Sitting', 'Self Pace walk', 'Running 3 METs',\n",
    "       'Running 5 METs', 'Running 7 METs' <br>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LyReiequ8Jln"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       ...,\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change from string to integer so keras.to_categorical can consume it\n",
    "\n",
    "# could do with factorize method as well\n",
    "n_class = len(np.unique(labels_array))\n",
    "class_list, labels_array_int = np.unique(labels_array,return_inverse=True)\n",
    "labels_array_int\n",
    "\n",
    "# check if the result is consistant with the original input\n",
    "class_list[labels_array_int].reshape(len(labels_array_int), 1) == labels_array\n",
    "\n",
    "# Note: to get the reverse, i.e converting integer array to string use class_list[labels_array_int]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64754, 6)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# labels to categorical\n",
    "\n",
    "y = to_categorical(labels_array_int, num_classes=n_class)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[64754, 90, 3]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape = list(accel_array.shape)\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "GscSnCpk8Jlm"
   },
   "source": [
    "\n",
    "#### Design neural network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_5 (LSTM)                (None, 90, 128)           67584     \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 88, 512)           197120    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 44, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 42, 256)           393472    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_3 (Average (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 20, 256)           131328    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_4 (Average (None, 10, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_10 (Conv1D)           (None, 9, 256)            131328    \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 256)               590080    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 6)                 774       \n",
      "=================================================================\n",
      "Total params: 1,544,582\n",
      "Trainable params: 1,544,582\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "# model.add(MaxPool1D(pool_size = avepooling_pool_size, input_shape=input_shape[1:]))\n",
    "\n",
    "# model.add(GlobalMaxPooling1D())\n",
    "# model.add(GlobalAveragePooling1D())\n",
    "model.add(LSTM(n_lstm_1, dropout=drop_lstm_1, \n",
    "                             return_sequences=True, input_shape=input_shape[1:])) \n",
    "# model.add(LSTM(n_lstm_2, dropout=drop_lstm_2, \n",
    "#                              return_sequences=True))\n",
    "# model.add(LSTM(n_lstm_3, dropout=drop_lstm_3, \n",
    "#                              return_sequences=True)) \n",
    "\n",
    "# model.add(Bidirectional(LSTM(n_lstm_2, dropout=drop_lstm_2)))\n",
    "\n",
    "model.add(Conv1D(n_conv_1, k_conv_1, activation='relu', strides= strides_1))\n",
    "model.add(MaxPool1D(pool_size = maxpooling_pool_size))\n",
    "model.add(Conv1D(n_conv_2, k_conv_2, activation='relu'))\n",
    "model.add(AveragePooling1D(pool_size = avepooling_pool_size))\n",
    "model.add(Conv1D(n_conv_3, k_conv_3, activation='relu'))\n",
    "model.add(AveragePooling1D(pool_size = avepooling_pool_size))\n",
    "model.add(Conv1D(n_conv_3, k_conv_3, activation='relu'))# new layer 4\n",
    "# model.add(GlobalMaxPooling1D())\n",
    "# model.add(GlobalAveragePooling1D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(n_dense_1, activation=LeakyReLU(alpha=0.1)))\n",
    "model.add(Dropout(dropout_1))\n",
    "# model.add(Dense(n_dense_2, activation=LeakyReLU(alpha=0.1)))\n",
    "# model.add(Dropout(dropout_2))\n",
    "model.add(Dense(n_dense_3, activation=LeakyReLU(alpha=0.1)))\n",
    "model.add(Dropout(dropout_3))\n",
    "model.add(Dense(n_class, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "40x3s0KY8Jlv",
    "outputId": "d3ac3e31-3c47-4b01-c2f9-ada0684b31b7"
   },
   "source": [
    "### Splitting and shuffeling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f5grc2H78Jlz",
    "outputId": "3f7eeb55-f851-4796-de4e-0c68eb9df88d"
   },
   "outputs": [],
   "source": [
    "# split and shuffle\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(\n",
    "     accel_array, y, test_size=0.1, random_state=65)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JkbhJMox8Jl9"
   },
   "source": [
    "#### Configure model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QodbQvQh8Jl_"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='nadam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zHjvYe288JmE"
   },
   "outputs": [],
   "source": [
    "modelcheckpoint = ModelCheckpoint(filepath=output_dir+\n",
    "                                  \"/weights.{epoch:02d}.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "esUwodZA8JmI"
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TEYpX7968JmL"
   },
   "source": [
    "#### Train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QaD1W7Ka8JmM",
    "outputId": "f0c30141-0962-48f6-a000-d136af50af79"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "228/228 [==============================] - 14s 62ms/step - loss: 1.1015 - accuracy: 0.5372 - val_loss: 0.7696 - val_accuracy: 0.6881\n",
      "Epoch 2/60\n",
      "228/228 [==============================] - 14s 61ms/step - loss: 0.6397 - accuracy: 0.7499 - val_loss: 0.5749 - val_accuracy: 0.7951\n",
      "Epoch 3/60\n",
      "228/228 [==============================] - 14s 61ms/step - loss: 0.4793 - accuracy: 0.8172 - val_loss: 0.4268 - val_accuracy: 0.8328\n",
      "Epoch 4/60\n",
      "228/228 [==============================] - 14s 61ms/step - loss: 0.3950 - accuracy: 0.8489 - val_loss: 0.3450 - val_accuracy: 0.8678\n",
      "Epoch 5/60\n",
      "228/228 [==============================] - 14s 61ms/step - loss: 0.3465 - accuracy: 0.8673 - val_loss: 0.3318 - val_accuracy: 0.8743\n",
      "Epoch 6/60\n",
      "228/228 [==============================] - 14s 61ms/step - loss: 0.3211 - accuracy: 0.8761 - val_loss: 0.3471 - val_accuracy: 0.8623\n",
      "Epoch 7/60\n",
      "228/228 [==============================] - 14s 61ms/step - loss: 0.2833 - accuracy: 0.8905 - val_loss: 0.2839 - val_accuracy: 0.8907\n",
      "Epoch 8/60\n",
      "228/228 [==============================] - 14s 61ms/step - loss: 0.3633 - accuracy: 0.8683 - val_loss: 0.2993 - val_accuracy: 0.8840\n",
      "Epoch 9/60\n",
      "228/228 [==============================] - 14s 62ms/step - loss: 0.2593 - accuracy: 0.9019 - val_loss: 0.2870 - val_accuracy: 0.8918\n",
      "Epoch 10/60\n",
      "228/228 [==============================] - 14s 62ms/step - loss: 0.2315 - accuracy: 0.9103 - val_loss: 0.2459 - val_accuracy: 0.9069\n",
      "Epoch 11/60\n",
      "228/228 [==============================] - 14s 62ms/step - loss: 0.2217 - accuracy: 0.9159 - val_loss: 0.2438 - val_accuracy: 0.9151\n",
      "Epoch 12/60\n",
      "228/228 [==============================] - 14s 62ms/step - loss: 0.2052 - accuracy: 0.9214 - val_loss: 0.2315 - val_accuracy: 0.9199\n",
      "Epoch 13/60\n",
      "228/228 [==============================] - 14s 62ms/step - loss: 0.2008 - accuracy: 0.9231 - val_loss: 0.2742 - val_accuracy: 0.9060\n",
      "Epoch 14/60\n",
      "228/228 [==============================] - 14s 62ms/step - loss: 0.1914 - accuracy: 0.9272 - val_loss: 0.2283 - val_accuracy: 0.9206\n",
      "Epoch 15/60\n",
      "228/228 [==============================] - 14s 62ms/step - loss: 0.1798 - accuracy: 0.9317 - val_loss: 0.2494 - val_accuracy: 0.9192\n",
      "Epoch 16/60\n",
      "228/228 [==============================] - 14s 62ms/step - loss: 0.1687 - accuracy: 0.9367 - val_loss: 0.2357 - val_accuracy: 0.9219\n",
      "Epoch 17/60\n",
      "228/228 [==============================] - 14s 62ms/step - loss: 0.1618 - accuracy: 0.9391 - val_loss: 0.2260 - val_accuracy: 0.9237\n",
      "Epoch 18/60\n",
      "228/228 [==============================] - 14s 63ms/step - loss: 0.1525 - accuracy: 0.9424 - val_loss: 0.2297 - val_accuracy: 0.9239\n",
      "Epoch 19/60\n",
      "228/228 [==============================] - 14s 62ms/step - loss: 0.1476 - accuracy: 0.9440 - val_loss: 0.2323 - val_accuracy: 0.9280\n",
      "Epoch 20/60\n",
      "228/228 [==============================] - 14s 62ms/step - loss: 0.1438 - accuracy: 0.9456 - val_loss: 0.2467 - val_accuracy: 0.9217\n",
      "Epoch 21/60\n",
      "228/228 [==============================] - 14s 62ms/step - loss: 0.1377 - accuracy: 0.9483 - val_loss: 0.2529 - val_accuracy: 0.9243\n",
      "Epoch 22/60\n",
      "228/228 [==============================] - 14s 62ms/step - loss: 0.1401 - accuracy: 0.9475 - val_loss: 0.2241 - val_accuracy: 0.9287\n",
      "Epoch 23/60\n",
      "228/228 [==============================] - 14s 62ms/step - loss: 0.1258 - accuracy: 0.9518 - val_loss: 0.2484 - val_accuracy: 0.9199\n",
      "Epoch 24/60\n",
      "228/228 [==============================] - 14s 63ms/step - loss: 0.1219 - accuracy: 0.9523 - val_loss: 0.2355 - val_accuracy: 0.9336\n",
      "Epoch 25/60\n",
      "228/228 [==============================] - 14s 62ms/step - loss: 0.1239 - accuracy: 0.9526 - val_loss: 0.2380 - val_accuracy: 0.9263\n",
      "Epoch 26/60\n",
      "228/228 [==============================] - 14s 63ms/step - loss: 0.1206 - accuracy: 0.9537 - val_loss: 0.2375 - val_accuracy: 0.9355\n",
      "Epoch 27/60\n",
      "228/228 [==============================] - 14s 62ms/step - loss: 0.1164 - accuracy: 0.9547 - val_loss: 0.2392 - val_accuracy: 0.9245\n",
      "Epoch 28/60\n",
      "228/228 [==============================] - 14s 62ms/step - loss: 0.1136 - accuracy: 0.9558 - val_loss: 0.2604 - val_accuracy: 0.9246\n",
      "Epoch 29/60\n",
      "228/228 [==============================] - 14s 62ms/step - loss: 0.1145 - accuracy: 0.9561 - val_loss: 0.2307 - val_accuracy: 0.9384\n",
      "Epoch 30/60\n",
      "228/228 [==============================] - 14s 62ms/step - loss: 0.1069 - accuracy: 0.9588 - val_loss: 0.2647 - val_accuracy: 0.9325\n",
      "Epoch 31/60\n",
      "228/228 [==============================] - 14s 63ms/step - loss: 0.1088 - accuracy: 0.9582 - val_loss: 0.2740 - val_accuracy: 0.9291\n",
      "Epoch 32/60\n",
      "228/228 [==============================] - 14s 62ms/step - loss: 0.1155 - accuracy: 0.9567 - val_loss: 0.2696 - val_accuracy: 0.9338\n",
      "Epoch 33/60\n",
      "228/228 [==============================] - 14s 63ms/step - loss: 0.1043 - accuracy: 0.9606 - val_loss: 0.2436 - val_accuracy: 0.9291\n",
      "Epoch 34/60\n",
      "228/228 [==============================] - 14s 63ms/step - loss: 0.1064 - accuracy: 0.9599 - val_loss: 0.2577 - val_accuracy: 0.9313\n",
      "Epoch 35/60\n",
      "228/228 [==============================] - 14s 63ms/step - loss: 0.0935 - accuracy: 0.9648 - val_loss: 0.2571 - val_accuracy: 0.9364\n",
      "Epoch 36/60\n",
      "228/228 [==============================] - 14s 63ms/step - loss: 0.0985 - accuracy: 0.9630 - val_loss: 0.2367 - val_accuracy: 0.9345\n",
      "Epoch 37/60\n",
      "228/228 [==============================] - 14s 63ms/step - loss: 0.1006 - accuracy: 0.9617 - val_loss: 0.2594 - val_accuracy: 0.9341\n",
      "Epoch 38/60\n",
      "228/228 [==============================] - 14s 63ms/step - loss: 0.0912 - accuracy: 0.9637 - val_loss: 0.2582 - val_accuracy: 0.9372\n",
      "Epoch 39/60\n",
      "228/228 [==============================] - 14s 63ms/step - loss: 0.0913 - accuracy: 0.9659 - val_loss: 0.2537 - val_accuracy: 0.9381\n",
      "Epoch 40/60\n",
      "228/228 [==============================] - 14s 63ms/step - loss: 0.0932 - accuracy: 0.9644 - val_loss: 0.2507 - val_accuracy: 0.9419\n",
      "Epoch 41/60\n",
      "228/228 [==============================] - 14s 63ms/step - loss: 0.0890 - accuracy: 0.9654 - val_loss: 0.2450 - val_accuracy: 0.9402\n",
      "Epoch 42/60\n",
      "228/228 [==============================] - 14s 63ms/step - loss: 0.0901 - accuracy: 0.9651 - val_loss: 0.2699 - val_accuracy: 0.9304\n",
      "Epoch 43/60\n",
      "228/228 [==============================] - 14s 63ms/step - loss: 0.0865 - accuracy: 0.9674 - val_loss: 0.2529 - val_accuracy: 0.9376\n",
      "Epoch 44/60\n",
      "228/228 [==============================] - 14s 63ms/step - loss: 0.0793 - accuracy: 0.9696 - val_loss: 0.2988 - val_accuracy: 0.9355\n",
      "Epoch 45/60\n",
      "228/228 [==============================] - 14s 63ms/step - loss: 0.0859 - accuracy: 0.9678 - val_loss: 0.2737 - val_accuracy: 0.9350\n",
      "Epoch 46/60\n",
      "228/228 [==============================] - 14s 63ms/step - loss: 0.0830 - accuracy: 0.9680 - val_loss: 0.2896 - val_accuracy: 0.9410\n",
      "Epoch 47/60\n",
      "228/228 [==============================] - 14s 63ms/step - loss: 0.0838 - accuracy: 0.9682 - val_loss: 0.2707 - val_accuracy: 0.9429\n",
      "Epoch 48/60\n",
      "228/228 [==============================] - 14s 63ms/step - loss: 0.0777 - accuracy: 0.9702 - val_loss: 0.2826 - val_accuracy: 0.9393\n",
      "Epoch 49/60\n",
      "228/228 [==============================] - 14s 63ms/step - loss: 0.0803 - accuracy: 0.9690 - val_loss: 0.2721 - val_accuracy: 0.9449\n",
      "Epoch 50/60\n",
      "228/228 [==============================] - 14s 63ms/step - loss: 0.0774 - accuracy: 0.9707 - val_loss: 0.3251 - val_accuracy: 0.9348\n",
      "Epoch 51/60\n",
      "228/228 [==============================] - 14s 63ms/step - loss: 0.0755 - accuracy: 0.9721 - val_loss: 0.2753 - val_accuracy: 0.9447\n",
      "Epoch 52/60\n",
      "228/228 [==============================] - 14s 63ms/step - loss: 0.0749 - accuracy: 0.9716 - val_loss: 0.2709 - val_accuracy: 0.9405\n",
      "Epoch 53/60\n",
      "228/228 [==============================] - 14s 63ms/step - loss: 0.0817 - accuracy: 0.9709 - val_loss: 0.2877 - val_accuracy: 0.9424\n",
      "Epoch 54/60\n",
      "228/228 [==============================] - 14s 63ms/step - loss: 0.0720 - accuracy: 0.9734 - val_loss: 0.2726 - val_accuracy: 0.9463\n",
      "Epoch 55/60\n",
      "228/228 [==============================] - 14s 63ms/step - loss: 0.0766 - accuracy: 0.9719 - val_loss: 0.2696 - val_accuracy: 0.9409\n",
      "Epoch 56/60\n",
      "228/228 [==============================] - 14s 63ms/step - loss: 0.0696 - accuracy: 0.9745 - val_loss: 0.2726 - val_accuracy: 0.9432\n",
      "Epoch 57/60\n",
      "228/228 [==============================] - 14s 62ms/step - loss: 0.0704 - accuracy: 0.9734 - val_loss: 0.2938 - val_accuracy: 0.9373\n",
      "Epoch 58/60\n",
      "228/228 [==============================] - 14s 63ms/step - loss: 0.0696 - accuracy: 0.9741 - val_loss: 0.3201 - val_accuracy: 0.9338\n",
      "Epoch 59/60\n",
      "228/228 [==============================] - 14s 63ms/step - loss: 0.0721 - accuracy: 0.9733 - val_loss: 0.2881 - val_accuracy: 0.9387\n",
      "Epoch 60/60\n",
      "228/228 [==============================] - 14s 63ms/step - loss: 0.0682 - accuracy: 0.9749 - val_loss: 0.2909 - val_accuracy: 0.9413\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1d8b6bff9e8>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, \n",
    "         batch_size=batch_size, epochs=epochs, verbose=1, \n",
    "         validation_data=(x_valid, y_valid), \n",
    "         callbacks=[modelcheckpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7PWlH5SJ8JmP"
   },
   "source": [
    "#### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z8t0nVCw8JmP"
   },
   "outputs": [],
   "source": [
    "# model.load_weights(output_dir+\"/weights.49.hdf5\") #??? val accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kZwGk5dR8JmS"
   },
   "outputs": [],
   "source": [
    "y_hat = model.predict(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EPc5_h6K8JmW",
    "outputId": "cad99da9-9f89-437f-854b-a315616ed50f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6476"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E_GNq-R_8JmZ",
    "outputId": "0fc16efe-7739-4394-f1a3-46da92e79584"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.96524119e-04, 1.13680684e-07, 5.38404549e-07, 2.49315212e-06,\n",
       "       1.73458429e-05, 9.99582946e-01], dtype=float32)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SFqRQ5XB8Jmc",
    "outputId": "a957fbed-92f8-4bdd-d24b-5df3361a8bac"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 1.], dtype=float32)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FTWf6Cf-8Jme",
    "outputId": "1256b170-33dc-4171-f2ff-7a3d7ddd74e3"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_hat)\n",
    "_ = plt.axvline(x=0.5, color='orange')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RNljSx3v8Jmh"
   },
   "outputs": [],
   "source": [
    "pct_auc = roc_auc_score(y_valid, y_hat)*100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SO_N9lJG8Jmj",
    "outputId": "20968a52-8ca0-44d3-abf6-a1382bba5cde"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'99.70'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"{:0.2f}\".format(pct_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vU3hnA298Jmo"
   },
   "outputs": [],
   "source": [
    "float_y_hat = []\n",
    "for y in y_hat:\n",
    "    float_y_hat.append(y[0:6].round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zrTf-aQl8Jmr"
   },
   "outputs": [],
   "source": [
    "ydf = pd.DataFrame(list(zip(float_y_hat, y_valid)), columns=['y_hat', 'y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zAyKh_mX8Jmu",
    "outputId": "611224b8-f980-47df-d596-9aa3a5811009"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_hat</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[0.012, 0.0, 0.0, 0.0, 0.0, 0.988]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                y_hat                               y\n",
       "0      [0.0, 0.0, 0.0, 0.0, 0.0, 1.0]  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0]\n",
       "1      [0.0, 0.0, 1.0, 0.0, 0.0, 0.0]  [0.0, 0.0, 1.0, 0.0, 0.0, 0.0]\n",
       "2      [0.0, 1.0, 0.0, 0.0, 0.0, 0.0]  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0]\n",
       "3      [1.0, 0.0, 0.0, 0.0, 0.0, 0.0]  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
       "4      [0.0, 1.0, 0.0, 0.0, 0.0, 0.0]  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0]\n",
       "5  [0.012, 0.0, 0.0, 0.0, 0.0, 0.988]  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0]\n",
       "6      [0.0, 0.0, 0.0, 1.0, 0.0, 0.0]  [0.0, 0.0, 0.0, 1.0, 0.0, 0.0]\n",
       "7      [0.0, 1.0, 0.0, 0.0, 0.0, 0.0]  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0]\n",
       "8      [1.0, 0.0, 0.0, 0.0, 0.0, 0.0]  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
       "9      [0.0, 1.0, 0.0, 0.0, 0.0, 0.0]  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ydf.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "dense_sentiment_classifier.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
