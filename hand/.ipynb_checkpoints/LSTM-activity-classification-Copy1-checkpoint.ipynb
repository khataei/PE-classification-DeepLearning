{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/jonkrohn/DLTFpT/blob/master/notebooks/dense_sentiment_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ahUZuAfz8Jje"
   },
   "source": [
    "# LSTM Activity Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Re0ecmVI8Jjk"
   },
   "source": [
    "In this notebook, we build an LSTM neural net to classify PE activity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ixsGb9tY8Jjm"
   },
   "source": [
    "#### Load dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5At1PKQp8Jjp"
   },
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Embedding, SpatialDropout1D, LSTM\n",
    "from tensorflow.keras.layers import Bidirectional, LeakyReLU, Flatten\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint \n",
    "import os \n",
    "from sklearn.metrics import roc_auc_score, roc_curve \n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt # new!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hg5wX2Dd8Jjz"
   },
   "source": [
    "#### Set hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lYLOM99-8Jj2"
   },
   "outputs": [],
   "source": [
    "# output directory name:\n",
    "output_dir = 'model_output/lstm1'\n",
    "input_dir =  'Z:/Research/dfuller/Walkabilly/studies/smarphone_accel/data/Ethica_Jaeger_Merged/pocket/'\n",
    "input_file_name = 'pocket-NN-data.npz'\n",
    "\n",
    "# from the data preparation section we have:\n",
    "window_size_second = 3\n",
    "frequency = 30\n",
    "lenght_of_each_seq = window_size_second * frequency\n",
    "\n",
    "# LSTM layer architecture:\n",
    "n_lstm_1 = 64 # lower\n",
    "n_lstm_2 = 64 # new!\n",
    "n_lstm_3 = 64\n",
    "drop_lstm_1 = 0.05\n",
    "drop_lstm_2 = 0.05\n",
    "drop_lstm_3 = 0.05\n",
    "\n",
    "\n",
    "# dense layer architecture: \n",
    "n_dense_1 = 256\n",
    "dropout_1 = 0.2\n",
    "n_dense_2 = 256\n",
    "dropout_2 = 0.2\n",
    "n_dense_3 = 128\n",
    "dropout_3 = 0.2\n",
    "\n",
    "# training:\n",
    "epochs = 60\n",
    "batch_size = 256\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DaLx4yZ48Jj9"
   },
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CD9X0yJg8Jj_"
   },
   "source": [
    "##### For this notebook we use the acceleration data gathered from the pocket location. It was prepared in the DataPrep-Deep notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6r44JKj-8JkA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acceleration_data\n",
      "metadata\n",
      "labels\n"
     ]
    }
   ],
   "source": [
    "# read the raw file and get the keys:\n",
    "raw_data = np.load(file=input_dir+input_file_name,allow_pickle=True)\n",
    "for k in raw_data.keys():\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the data\n",
    "\n",
    "accel_array = raw_data['acceleration_data']\n",
    "meta_array = raw_data['metadata']\n",
    "labels_array = raw_data['labels']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WWq3ipbu8JlG"
   },
   "source": [
    "#### Preprocess data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert the  labels to integer.\n",
    "In the raw data format of the labels is String and there are 6 classes. 'Lying', 'Sitting', 'Self Pace walk', 'Running 3 METs',\n",
    "       'Running 5 METs', 'Running 7 METs' <br>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LyReiequ8Jln"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       ...,\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True]])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change from string to integer so keras.to_categorical can consume it\n",
    "\n",
    "# could do with factorize method as well\n",
    "n_class = len(np.unique(labels_array))\n",
    "class_list, labels_array_int = np.unique(labels_array,return_inverse=True)\n",
    "labels_array_int\n",
    "\n",
    "# check if the result is consistant with the original input\n",
    "class_list[labels_array_int].reshape(len(labels_array_int), 1) == labels_array\n",
    "\n",
    "# Note: to get the reverse, i.e converting integer array to string use class_list[labels_array_int]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64754, 6)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# labels to categorical\n",
    "\n",
    "y = to_categorical(labels_array_int, num_classes=n_class)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[64754, 90, 3]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape = list(accel_array.shape)\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "GscSnCpk8Jlm"
   },
   "source": [
    "\n",
    "#### Design neural network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_36 (LSTM)               (None, 90, 64)            17408     \n",
      "_________________________________________________________________\n",
      "lstm_37 (LSTM)               (None, 90, 64)            33024     \n",
      "_________________________________________________________________\n",
      "lstm_38 (LSTM)               (None, 90, 64)            33024     \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 5760)              0         \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 256)               1474816   \n",
      "_________________________________________________________________\n",
      "dropout_39 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_40 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_41 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 6)                 774       \n",
      "=================================================================\n",
      "Total params: 1,657,734\n",
      "Trainable params: 1,657,734\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "# model.add(Flatten(input_shape=input_shape[1:]))\n",
    "model.add(LSTM(n_lstm_1, dropout=drop_lstm_1, \n",
    "                             return_sequences=True, input_shape=input_shape[1:])) \n",
    "model.add(LSTM(n_lstm_2, dropout=drop_lstm_2, \n",
    "                             return_sequences=True))\n",
    "model.add(LSTM(n_lstm_3, dropout=drop_lstm_3, \n",
    "                             return_sequences=True)) \n",
    "# model.add(Bidirectional(LSTM(n_lstm_2, dropout=drop_lstm_2)))\n",
    "# model.add(GlobalMaxPooling1D())\n",
    "# model.add(GlobalAveragePooling1D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(n_dense_1, activation=LeakyReLU(alpha=0.1)))\n",
    "model.add(Dropout(dropout_1))\n",
    "model.add(Dense(n_dense_2, activation='relu'))\n",
    "model.add(Dropout(dropout_2))\n",
    "model.add(Dense(n_dense_3, activation=LeakyReLU(alpha=0.1)))\n",
    "model.add(Dropout(dropout_3))\n",
    "model.add(Dense(n_class, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "40x3s0KY8Jlv",
    "outputId": "d3ac3e31-3c47-4b01-c2f9-ada0684b31b7"
   },
   "source": [
    "### Splitting and shuffeling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f5grc2H78Jlz",
    "outputId": "3f7eeb55-f851-4796-de4e-0c68eb9df88d"
   },
   "outputs": [],
   "source": [
    "# split and shuffle\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(\n",
    "     accel_array, y, test_size=0.1, random_state=65)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JkbhJMox8Jl9"
   },
   "source": [
    "#### Configure model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QodbQvQh8Jl_"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='nadam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zHjvYe288JmE"
   },
   "outputs": [],
   "source": [
    "modelcheckpoint = ModelCheckpoint(filepath=output_dir+\n",
    "                                  \"/weights.{epoch:02d}.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "esUwodZA8JmI"
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TEYpX7968JmL"
   },
   "source": [
    "#### Train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QaD1W7Ka8JmM",
    "outputId": "f0c30141-0962-48f6-a000-d136af50af79"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "228/228 [==============================] - 8s 36ms/step - loss: 1.2854 - accuracy: 0.4481 - val_loss: 0.9678 - val_accuracy: 0.5976\n",
      "Epoch 2/60\n",
      "228/228 [==============================] - 7s 31ms/step - loss: 0.9448 - accuracy: 0.5892 - val_loss: 0.7768 - val_accuracy: 0.6688\n",
      "Epoch 3/60\n",
      "228/228 [==============================] - 7s 31ms/step - loss: 0.7795 - accuracy: 0.6671 - val_loss: 0.7123 - val_accuracy: 0.6961\n",
      "Epoch 4/60\n",
      "228/228 [==============================] - 7s 31ms/step - loss: 0.6569 - accuracy: 0.7268 - val_loss: 0.5552 - val_accuracy: 0.7861\n",
      "Epoch 5/60\n",
      "228/228 [==============================] - 7s 31ms/step - loss: 0.5708 - accuracy: 0.7705 - val_loss: 0.4596 - val_accuracy: 0.8184\n",
      "Epoch 6/60\n",
      "228/228 [==============================] - 7s 31ms/step - loss: 0.5038 - accuracy: 0.8013 - val_loss: 0.4125 - val_accuracy: 0.8396\n",
      "Epoch 7/60\n",
      "228/228 [==============================] - 7s 31ms/step - loss: 0.4544 - accuracy: 0.8214 - val_loss: 0.3742 - val_accuracy: 0.8590\n",
      "Epoch 8/60\n",
      "228/228 [==============================] - 7s 31ms/step - loss: 0.4205 - accuracy: 0.8363 - val_loss: 0.3456 - val_accuracy: 0.8623\n",
      "Epoch 9/60\n",
      "228/228 [==============================] - 7s 31ms/step - loss: 0.3934 - accuracy: 0.8474 - val_loss: 0.3628 - val_accuracy: 0.8646\n",
      "Epoch 10/60\n",
      "228/228 [==============================] - 7s 31ms/step - loss: 0.3726 - accuracy: 0.8561 - val_loss: 0.3452 - val_accuracy: 0.8708\n",
      "Epoch 11/60\n",
      "228/228 [==============================] - 7s 31ms/step - loss: 0.3602 - accuracy: 0.8590 - val_loss: 0.3239 - val_accuracy: 0.8751\n",
      "Epoch 12/60\n",
      "228/228 [==============================] - 7s 31ms/step - loss: 0.3389 - accuracy: 0.8686 - val_loss: 0.3100 - val_accuracy: 0.8831\n",
      "Epoch 13/60\n",
      "228/228 [==============================] - 7s 31ms/step - loss: 0.3265 - accuracy: 0.8744 - val_loss: 0.3114 - val_accuracy: 0.8820\n",
      "Epoch 14/60\n",
      "228/228 [==============================] - 7s 31ms/step - loss: 0.3143 - accuracy: 0.8788 - val_loss: 0.2869 - val_accuracy: 0.8950\n",
      "Epoch 15/60\n",
      "228/228 [==============================] - 7s 31ms/step - loss: 0.3047 - accuracy: 0.8828 - val_loss: 0.2830 - val_accuracy: 0.8998\n",
      "Epoch 16/60\n",
      "228/228 [==============================] - 7s 31ms/step - loss: 0.2897 - accuracy: 0.8880 - val_loss: 0.2670 - val_accuracy: 0.8959\n",
      "Epoch 17/60\n",
      "228/228 [==============================] - 7s 31ms/step - loss: 0.2784 - accuracy: 0.8909 - val_loss: 0.2794 - val_accuracy: 0.8948\n",
      "Epoch 18/60\n",
      "228/228 [==============================] - 7s 31ms/step - loss: 0.2842 - accuracy: 0.8882 - val_loss: 0.2630 - val_accuracy: 0.8964\n",
      "Epoch 19/60\n",
      "228/228 [==============================] - 7s 31ms/step - loss: 0.2695 - accuracy: 0.8963 - val_loss: 0.2625 - val_accuracy: 0.9010\n",
      "Epoch 20/60\n",
      "228/228 [==============================] - 7s 31ms/step - loss: 0.2676 - accuracy: 0.8959 - val_loss: 0.2791 - val_accuracy: 0.9002\n",
      "Epoch 21/60\n",
      "228/228 [==============================] - 7s 32ms/step - loss: 0.2572 - accuracy: 0.9001 - val_loss: 0.2564 - val_accuracy: 0.9007\n",
      "Epoch 22/60\n",
      "228/228 [==============================] - 7s 31ms/step - loss: 0.2498 - accuracy: 0.9026 - val_loss: 0.2617 - val_accuracy: 0.9030\n",
      "Epoch 23/60\n",
      "228/228 [==============================] - 7s 31ms/step - loss: 0.2484 - accuracy: 0.9041 - val_loss: 0.2715 - val_accuracy: 0.9024\n",
      "Epoch 24/60\n",
      "228/228 [==============================] - 7s 31ms/step - loss: 0.2395 - accuracy: 0.9071 - val_loss: 0.2484 - val_accuracy: 0.9078\n",
      "Epoch 25/60\n",
      "228/228 [==============================] - 7s 31ms/step - loss: 0.2324 - accuracy: 0.9095 - val_loss: 0.2491 - val_accuracy: 0.9121\n",
      "Epoch 26/60\n",
      "228/228 [==============================] - 7s 31ms/step - loss: 0.2312 - accuracy: 0.9111 - val_loss: 0.3211 - val_accuracy: 0.8916\n",
      "Epoch 27/60\n",
      "228/228 [==============================] - 7s 31ms/step - loss: 0.2251 - accuracy: 0.9118 - val_loss: 0.2473 - val_accuracy: 0.9109\n",
      "Epoch 28/60\n",
      "228/228 [==============================] - 7s 31ms/step - loss: 0.2177 - accuracy: 0.9155 - val_loss: 0.2627 - val_accuracy: 0.9107\n",
      "Epoch 29/60\n",
      "228/228 [==============================] - 7s 31ms/step - loss: 0.2137 - accuracy: 0.9153 - val_loss: 0.2505 - val_accuracy: 0.9145\n",
      "Epoch 30/60\n",
      "228/228 [==============================] - 7s 31ms/step - loss: 0.2122 - accuracy: 0.9167 - val_loss: 0.2758 - val_accuracy: 0.8947\n",
      "Epoch 31/60\n",
      "228/228 [==============================] - 7s 31ms/step - loss: 0.2056 - accuracy: 0.9197 - val_loss: 0.2562 - val_accuracy: 0.9148\n",
      "Epoch 32/60\n",
      "228/228 [==============================] - 7s 32ms/step - loss: 0.2031 - accuracy: 0.9206 - val_loss: 0.2529 - val_accuracy: 0.9148\n",
      "Epoch 33/60\n",
      "228/228 [==============================] - 7s 32ms/step - loss: 0.1970 - accuracy: 0.9237 - val_loss: 0.2717 - val_accuracy: 0.9095\n",
      "Epoch 34/60\n",
      "228/228 [==============================] - 7s 31ms/step - loss: 0.1948 - accuracy: 0.9243 - val_loss: 0.2382 - val_accuracy: 0.9141\n",
      "Epoch 35/60\n",
      "228/228 [==============================] - 7s 32ms/step - loss: 0.1933 - accuracy: 0.9243 - val_loss: 0.2414 - val_accuracy: 0.9182\n",
      "Epoch 36/60\n",
      "228/228 [==============================] - 7s 31ms/step - loss: 0.1930 - accuracy: 0.9246 - val_loss: 0.2555 - val_accuracy: 0.9141\n",
      "Epoch 37/60\n",
      "228/228 [==============================] - 7s 31ms/step - loss: 0.1866 - accuracy: 0.9283 - val_loss: 0.2445 - val_accuracy: 0.9192\n",
      "Epoch 38/60\n",
      "228/228 [==============================] - 7s 30ms/step - loss: 0.1829 - accuracy: 0.9293 - val_loss: 0.2951 - val_accuracy: 0.9030\n",
      "Epoch 39/60\n",
      "228/228 [==============================] - 7s 30ms/step - loss: 0.1804 - accuracy: 0.9294 - val_loss: 0.2393 - val_accuracy: 0.9214\n",
      "Epoch 40/60\n",
      "228/228 [==============================] - 7s 30ms/step - loss: 0.1788 - accuracy: 0.9302 - val_loss: 0.2508 - val_accuracy: 0.9157\n",
      "Epoch 41/60\n",
      "228/228 [==============================] - 7s 31ms/step - loss: 0.1773 - accuracy: 0.9313 - val_loss: 0.2388 - val_accuracy: 0.9212\n",
      "Epoch 42/60\n",
      "228/228 [==============================] - 7s 30ms/step - loss: 0.1711 - accuracy: 0.9328 - val_loss: 0.2457 - val_accuracy: 0.9192\n",
      "Epoch 43/60\n",
      "228/228 [==============================] - 7s 31ms/step - loss: 0.1712 - accuracy: 0.9338 - val_loss: 0.2389 - val_accuracy: 0.9226\n",
      "Epoch 44/60\n",
      "228/228 [==============================] - 7s 30ms/step - loss: 0.1680 - accuracy: 0.9343 - val_loss: 0.2620 - val_accuracy: 0.9106\n",
      "Epoch 45/60\n",
      "228/228 [==============================] - 7s 32ms/step - loss: 0.1740 - accuracy: 0.9319 - val_loss: 0.2332 - val_accuracy: 0.9256\n",
      "Epoch 46/60\n",
      "228/228 [==============================] - 7s 32ms/step - loss: 0.1679 - accuracy: 0.9340 - val_loss: 0.2696 - val_accuracy: 0.9077\n",
      "Epoch 47/60\n",
      "228/228 [==============================] - 7s 31ms/step - loss: 0.1613 - accuracy: 0.9370 - val_loss: 0.2694 - val_accuracy: 0.9100\n",
      "Epoch 48/60\n",
      "228/228 [==============================] - 7s 31ms/step - loss: 0.1624 - accuracy: 0.9370 - val_loss: 0.3034 - val_accuracy: 0.8970\n",
      "Epoch 49/60\n",
      "228/228 [==============================] - 7s 32ms/step - loss: 0.1655 - accuracy: 0.9349 - val_loss: 0.2529 - val_accuracy: 0.9183\n",
      "Epoch 50/60\n",
      "228/228 [==============================] - 7s 31ms/step - loss: 0.1562 - accuracy: 0.9389 - val_loss: 0.2461 - val_accuracy: 0.9229\n",
      "Epoch 51/60\n",
      "228/228 [==============================] - 7s 31ms/step - loss: 0.1561 - accuracy: 0.9391 - val_loss: 0.2471 - val_accuracy: 0.9194\n",
      "Epoch 52/60\n",
      "228/228 [==============================] - 7s 31ms/step - loss: 0.1503 - accuracy: 0.9414 - val_loss: 0.2351 - val_accuracy: 0.9276\n",
      "Epoch 53/60\n",
      "228/228 [==============================] - 7s 31ms/step - loss: 0.1509 - accuracy: 0.9404 - val_loss: 0.2410 - val_accuracy: 0.9222\n",
      "Epoch 54/60\n",
      "228/228 [==============================] - 7s 31ms/step - loss: 0.1522 - accuracy: 0.9410 - val_loss: 0.2480 - val_accuracy: 0.9165\n",
      "Epoch 55/60\n",
      "228/228 [==============================] - 7s 31ms/step - loss: 0.1493 - accuracy: 0.9402 - val_loss: 0.2367 - val_accuracy: 0.9260\n",
      "Epoch 56/60\n",
      "228/228 [==============================] - 7s 31ms/step - loss: 0.1462 - accuracy: 0.9424 - val_loss: 0.2375 - val_accuracy: 0.9274\n",
      "Epoch 57/60\n",
      "228/228 [==============================] - 7s 31ms/step - loss: 0.1498 - accuracy: 0.9418 - val_loss: 0.2805 - val_accuracy: 0.9030\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/60\n",
      "228/228 [==============================] - 7s 32ms/step - loss: 0.1468 - accuracy: 0.9431 - val_loss: 0.2644 - val_accuracy: 0.9219\n",
      "Epoch 59/60\n",
      "228/228 [==============================] - 7s 32ms/step - loss: 0.1438 - accuracy: 0.9436 - val_loss: 0.2628 - val_accuracy: 0.9172\n",
      "Epoch 60/60\n",
      "228/228 [==============================] - 7s 32ms/step - loss: 0.1398 - accuracy: 0.9453 - val_loss: 0.2376 - val_accuracy: 0.9361\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2975d419188>"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, \n",
    "         batch_size=batch_size, epochs=epochs, verbose=1, \n",
    "         validation_data=(x_valid, y_valid), \n",
    "         callbacks=[modelcheckpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7PWlH5SJ8JmP"
   },
   "source": [
    "#### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z8t0nVCw8JmP"
   },
   "outputs": [],
   "source": [
    "model.load_weights(output_dir+\"/weights.60.hdf5\") # 93.61 val accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kZwGk5dR8JmS"
   },
   "outputs": [],
   "source": [
    "y_hat = model.predict(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EPc5_h6K8JmW",
    "outputId": "cad99da9-9f89-437f-854b-a315616ed50f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6476"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E_GNq-R_8JmZ",
    "outputId": "0fc16efe-7739-4394-f1a3-46da92e79584"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.3374137e-04, 6.5218779e-07, 2.9682074e-06, 4.7973078e-08,\n",
       "       5.7489134e-04, 9.9908769e-01], dtype=float32)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SFqRQ5XB8Jmc",
    "outputId": "a957fbed-92f8-4bdd-d24b-5df3361a8bac"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 1.], dtype=float32)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FTWf6Cf-8Jme",
    "outputId": "1256b170-33dc-4171-f2ff-7a3d7ddd74e3"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_hat)\n",
    "_ = plt.axvline(x=0.5, color='orange')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RNljSx3v8Jmh"
   },
   "outputs": [],
   "source": [
    "pct_auc = roc_auc_score(y_valid, y_hat)*100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SO_N9lJG8Jmj",
    "outputId": "20968a52-8ca0-44d3-abf6-a1382bba5cde"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'99.47'"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"{:0.2f}\".format(pct_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vU3hnA298Jmo"
   },
   "outputs": [],
   "source": [
    "float_y_hat = []\n",
    "for y in y_hat:\n",
    "    float_y_hat.append(y[0:6].round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zrTf-aQl8Jmr"
   },
   "outputs": [],
   "source": [
    "ydf = pd.DataFrame(list(zip(float_y_hat, y_valid)), columns=['y_hat', 'y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zAyKh_mX8Jmu",
    "outputId": "611224b8-f980-47df-d596-9aa3a5811009"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_hat</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.001, 0.999]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[0.256, 0.002, 0.0, 0.0, 0.002, 0.74]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[0.043, 0.826, 0.012, 0.012, 0.098, 0.01]</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       y_hat                               y\n",
       "0         [0.0, 0.0, 0.0, 0.0, 0.001, 0.999]  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0]\n",
       "1             [0.0, 0.0, 1.0, 0.0, 0.0, 0.0]  [0.0, 0.0, 1.0, 0.0, 0.0, 0.0]\n",
       "2             [0.0, 1.0, 0.0, 0.0, 0.0, 0.0]  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0]\n",
       "3             [1.0, 0.0, 0.0, 0.0, 0.0, 0.0]  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
       "4             [0.0, 1.0, 0.0, 0.0, 0.0, 0.0]  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0]\n",
       "5      [0.256, 0.002, 0.0, 0.0, 0.002, 0.74]  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0]\n",
       "6             [0.0, 0.0, 0.0, 1.0, 0.0, 0.0]  [0.0, 0.0, 0.0, 1.0, 0.0, 0.0]\n",
       "7             [0.0, 1.0, 0.0, 0.0, 0.0, 0.0]  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0]\n",
       "8             [1.0, 0.0, 0.0, 0.0, 0.0, 0.0]  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
       "9  [0.043, 0.826, 0.012, 0.012, 0.098, 0.01]  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ydf.head(10)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "dense_sentiment_classifier.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
