{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/jonkrohn/DLTFpT/blob/master/notebooks/dense_sentiment_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ahUZuAfz8Jje"
   },
   "source": [
    "# Modified LSTM Activity Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Re0ecmVI8Jjk"
   },
   "source": [
    "In this notebook, we modify the baseLSTM neural net to classify PE activity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ixsGb9tY8Jjm"
   },
   "source": [
    "#### Load dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5At1PKQp8Jjp"
   },
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Embedding, SpatialDropout1D, LSTM\n",
    "from tensorflow.keras.layers import Bidirectional, LeakyReLU, Flatten\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint \n",
    "import os \n",
    "from sklearn.metrics import roc_auc_score, roc_curve \n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt # new!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hg5wX2Dd8Jjz"
   },
   "source": [
    "#### Set hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lYLOM99-8Jj2"
   },
   "outputs": [],
   "source": [
    "# output directory name:\n",
    "output_dir = 'model_output/lstm2'\n",
    "input_dir =  'Z:/Research/dfuller/Walkabilly/studies/smarphone_accel/data/Ethica_Jaeger_Merged/pocket/'\n",
    "input_file_name = 'pocket-NN-data.npz'\n",
    "\n",
    "# from the data preparation section we have:\n",
    "window_size_second = 3\n",
    "frequency = 30\n",
    "lenght_of_each_seq = window_size_second * frequency\n",
    "\n",
    "# LSTM layer architecture:\n",
    "n_lstm_1 = 128 \n",
    "n_lstm_2 = 128 \n",
    "n_lstm_3 = 64\n",
    "drop_lstm_1 = 0.0\n",
    "drop_lstm_2 = 0.05\n",
    "drop_lstm_3 = 0.05\n",
    "\n",
    "\n",
    "# dense layer architecture: \n",
    "n_dense_1 = 256\n",
    "dropout_1 = 0.2\n",
    "n_dense_2 = 256\n",
    "dropout_2 = 0.2\n",
    "n_dense_3 = 128\n",
    "dropout_3 = 0.25\n",
    "\n",
    "# training:\n",
    "epochs = 60\n",
    "batch_size = 256\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DaLx4yZ48Jj9"
   },
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CD9X0yJg8Jj_"
   },
   "source": [
    "##### For this notebook we use the acceleration data gathered from the pocket location. It was prepared in the DataPrep-Deep notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6r44JKj-8JkA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acceleration_data\n",
      "metadata\n",
      "labels\n"
     ]
    }
   ],
   "source": [
    "# read the raw file and get the keys:\n",
    "raw_data = np.load(file=input_dir+input_file_name,allow_pickle=True)\n",
    "for k in raw_data.keys():\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the data\n",
    "\n",
    "accel_array = raw_data['acceleration_data']\n",
    "meta_array = raw_data['metadata']\n",
    "labels_array = raw_data['labels']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WWq3ipbu8JlG"
   },
   "source": [
    "#### Preprocess data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert the  labels to integer.\n",
    "In the raw data format of the labels is String and there are 6 classes. 'Lying', 'Sitting', 'Self Pace walk', 'Running 3 METs',\n",
    "       'Running 5 METs', 'Running 7 METs' <br>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LyReiequ8Jln"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       ...,\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change from string to integer so keras.to_categorical can consume it\n",
    "\n",
    "# could do with factorize method as well\n",
    "n_class = len(np.unique(labels_array))\n",
    "class_list, labels_array_int = np.unique(labels_array,return_inverse=True)\n",
    "labels_array_int\n",
    "\n",
    "# check if the result is consistant with the original input\n",
    "class_list[labels_array_int].reshape(len(labels_array_int), 1) == labels_array\n",
    "\n",
    "# Note: to get the reverse, i.e converting integer array to string use class_list[labels_array_int]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64754, 6)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# labels to categorical\n",
    "\n",
    "y = to_categorical(labels_array_int, num_classes=n_class)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[64754, 90, 3]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape = list(accel_array.shape)\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "GscSnCpk8Jlm"
   },
   "source": [
    "\n",
    "#### Design neural network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_6 (LSTM)                (None, 90, 128)           67584     \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 90, 128)           131584    \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 90, 64)            49408     \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 5760)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 256)               1474816   \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 6)                 774       \n",
      "=================================================================\n",
      "Total params: 1,822,854\n",
      "Trainable params: 1,822,854\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "# model.add(Flatten(input_shape=input_shape[1:]))\n",
    "model.add(LSTM(n_lstm_1, dropout=drop_lstm_1, \n",
    "                             return_sequences=True, input_shape=input_shape[1:])) \n",
    "model.add(LSTM(n_lstm_2, dropout=drop_lstm_2, \n",
    "                             return_sequences=True))\n",
    "model.add(LSTM(n_lstm_3, dropout=drop_lstm_3, \n",
    "                             return_sequences=True)) \n",
    "# model.add(Bidirectional(LSTM(n_lstm_2, dropout=drop_lstm_2)))\n",
    "# model.add(GlobalMaxPooling1D())\n",
    "# model.add(GlobalAveragePooling1D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(n_dense_1, activation=LeakyReLU(alpha=0.1)))\n",
    "model.add(Dropout(dropout_1))\n",
    "model.add(Dense(n_dense_2, activation='relu'))\n",
    "model.add(Dropout(dropout_2))\n",
    "model.add(Dense(n_dense_3, activation=LeakyReLU(alpha=0.1)))\n",
    "model.add(Dropout(dropout_3))\n",
    "model.add(Dense(n_class, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "40x3s0KY8Jlv",
    "outputId": "d3ac3e31-3c47-4b01-c2f9-ada0684b31b7"
   },
   "source": [
    "### Splitting and shuffeling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f5grc2H78Jlz",
    "outputId": "3f7eeb55-f851-4796-de4e-0c68eb9df88d"
   },
   "outputs": [],
   "source": [
    "# split and shuffle\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(\n",
    "     accel_array, y, test_size=0.1, random_state=65)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JkbhJMox8Jl9"
   },
   "source": [
    "#### Configure model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QodbQvQh8Jl_"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='nadam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zHjvYe288JmE"
   },
   "outputs": [],
   "source": [
    "modelcheckpoint = ModelCheckpoint(filepath=output_dir+\n",
    "                                  \"/weights.{epoch:02d}.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "esUwodZA8JmI"
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TEYpX7968JmL"
   },
   "source": [
    "#### Train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QaD1W7Ka8JmM",
    "outputId": "f0c30141-0962-48f6-a000-d136af50af79"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "228/228 [==============================] - 12s 51ms/step - loss: 1.2473 - accuracy: 0.4668 - val_loss: 0.9157 - val_accuracy: 0.6106\n",
      "Epoch 2/60\n",
      "228/228 [==============================] - 11s 49ms/step - loss: 0.8015 - accuracy: 0.6646 - val_loss: 0.6063 - val_accuracy: 0.7563\n",
      "Epoch 3/60\n",
      "228/228 [==============================] - 11s 49ms/step - loss: 0.6044 - accuracy: 0.7536 - val_loss: 0.5374 - val_accuracy: 0.7857\n",
      "Epoch 4/60\n",
      "228/228 [==============================] - 11s 49ms/step - loss: 0.5074 - accuracy: 0.7983 - val_loss: 0.4794 - val_accuracy: 0.8107\n",
      "Epoch 5/60\n",
      "228/228 [==============================] - 11s 49ms/step - loss: 0.4412 - accuracy: 0.8272 - val_loss: 0.4149 - val_accuracy: 0.8485\n",
      "Epoch 6/60\n",
      "228/228 [==============================] - 11s 49ms/step - loss: 0.3935 - accuracy: 0.8480 - val_loss: 0.4552 - val_accuracy: 0.8300\n",
      "Epoch 7/60\n",
      "228/228 [==============================] - 11s 49ms/step - loss: 0.3670 - accuracy: 0.8582 - val_loss: 0.3487 - val_accuracy: 0.8698\n",
      "Epoch 8/60\n",
      "228/228 [==============================] - 11s 50ms/step - loss: 0.3416 - accuracy: 0.8666 - val_loss: 0.3905 - val_accuracy: 0.8504\n",
      "Epoch 9/60\n",
      "228/228 [==============================] - 11s 49ms/step - loss: 0.3147 - accuracy: 0.8763 - val_loss: 0.3256 - val_accuracy: 0.8746\n",
      "Epoch 10/60\n",
      "228/228 [==============================] - 11s 49ms/step - loss: 0.3060 - accuracy: 0.8791 - val_loss: 0.3185 - val_accuracy: 0.8779\n",
      "Epoch 11/60\n",
      "228/228 [==============================] - 11s 49ms/step - loss: 0.2906 - accuracy: 0.8864 - val_loss: 0.2776 - val_accuracy: 0.8975\n",
      "Epoch 12/60\n",
      "228/228 [==============================] - 11s 49ms/step - loss: 0.2763 - accuracy: 0.8911 - val_loss: 0.3006 - val_accuracy: 0.8879\n",
      "Epoch 13/60\n",
      "228/228 [==============================] - 11s 49ms/step - loss: 0.2622 - accuracy: 0.8976 - val_loss: 0.2892 - val_accuracy: 0.8894\n",
      "Epoch 14/60\n",
      "228/228 [==============================] - 11s 49ms/step - loss: 0.2600 - accuracy: 0.8975 - val_loss: 0.3174 - val_accuracy: 0.8839\n",
      "Epoch 15/60\n",
      "228/228 [==============================] - 11s 49ms/step - loss: 0.2418 - accuracy: 0.9039 - val_loss: 0.2968 - val_accuracy: 0.8919\n",
      "Epoch 16/60\n",
      "228/228 [==============================] - 11s 49ms/step - loss: 0.2460 - accuracy: 0.9043 - val_loss: 0.2860 - val_accuracy: 0.8996\n",
      "Epoch 17/60\n",
      "228/228 [==============================] - 11s 49ms/step - loss: 0.2322 - accuracy: 0.9092 - val_loss: 0.2732 - val_accuracy: 0.9007\n",
      "Epoch 18/60\n",
      "228/228 [==============================] - 11s 49ms/step - loss: 0.2236 - accuracy: 0.9112 - val_loss: 0.2629 - val_accuracy: 0.9112\n",
      "Epoch 19/60\n",
      "228/228 [==============================] - 11s 50ms/step - loss: 0.2095 - accuracy: 0.9183 - val_loss: 0.2817 - val_accuracy: 0.8989\n",
      "Epoch 20/60\n",
      "228/228 [==============================] - 11s 50ms/step - loss: 0.2107 - accuracy: 0.9190 - val_loss: 0.2805 - val_accuracy: 0.8985\n",
      "Epoch 21/60\n",
      "228/228 [==============================] - 11s 49ms/step - loss: 0.1939 - accuracy: 0.9244 - val_loss: 0.2626 - val_accuracy: 0.9188\n",
      "Epoch 22/60\n",
      "228/228 [==============================] - 11s 49ms/step - loss: 0.1964 - accuracy: 0.9240 - val_loss: 0.2572 - val_accuracy: 0.9186\n",
      "Epoch 23/60\n",
      "228/228 [==============================] - 11s 50ms/step - loss: 0.1890 - accuracy: 0.9265 - val_loss: 0.2753 - val_accuracy: 0.9094\n",
      "Epoch 24/60\n",
      "228/228 [==============================] - 11s 50ms/step - loss: 0.1830 - accuracy: 0.9285 - val_loss: 0.2815 - val_accuracy: 0.9064\n",
      "Epoch 25/60\n",
      "228/228 [==============================] - 11s 50ms/step - loss: 0.1836 - accuracy: 0.9285 - val_loss: 0.2713 - val_accuracy: 0.9123\n",
      "Epoch 26/60\n",
      "228/228 [==============================] - 11s 50ms/step - loss: 0.1730 - accuracy: 0.9313 - val_loss: 0.3182 - val_accuracy: 0.8989\n",
      "Epoch 27/60\n",
      "228/228 [==============================] - 11s 50ms/step - loss: 0.1699 - accuracy: 0.9347 - val_loss: 0.2631 - val_accuracy: 0.9172\n",
      "Epoch 28/60\n",
      "228/228 [==============================] - 11s 50ms/step - loss: 0.1686 - accuracy: 0.9347 - val_loss: 0.2685 - val_accuracy: 0.9146\n",
      "Epoch 29/60\n",
      "228/228 [==============================] - 11s 50ms/step - loss: 0.1661 - accuracy: 0.9357 - val_loss: 0.2465 - val_accuracy: 0.9217\n",
      "Epoch 30/60\n",
      "228/228 [==============================] - 11s 50ms/step - loss: 0.1594 - accuracy: 0.9394 - val_loss: 0.2956 - val_accuracy: 0.9143\n",
      "Epoch 31/60\n",
      "228/228 [==============================] - 11s 50ms/step - loss: 0.1576 - accuracy: 0.9388 - val_loss: 0.2488 - val_accuracy: 0.9240\n",
      "Epoch 32/60\n",
      "228/228 [==============================] - 11s 50ms/step - loss: 0.1450 - accuracy: 0.9444 - val_loss: 0.2557 - val_accuracy: 0.9263\n",
      "Epoch 33/60\n",
      "228/228 [==============================] - 11s 50ms/step - loss: 0.1466 - accuracy: 0.9438 - val_loss: 0.2767 - val_accuracy: 0.9233\n",
      "Epoch 34/60\n",
      "228/228 [==============================] - 11s 50ms/step - loss: 0.1475 - accuracy: 0.9440 - val_loss: 0.2498 - val_accuracy: 0.9285\n",
      "Epoch 35/60\n",
      "228/228 [==============================] - 11s 50ms/step - loss: 0.1443 - accuracy: 0.9432 - val_loss: 0.2645 - val_accuracy: 0.9279\n",
      "Epoch 36/60\n",
      "228/228 [==============================] - 11s 50ms/step - loss: 0.1418 - accuracy: 0.9458 - val_loss: 0.2660 - val_accuracy: 0.9299\n",
      "Epoch 37/60\n",
      "228/228 [==============================] - 11s 50ms/step - loss: 0.1339 - accuracy: 0.9488 - val_loss: 0.2737 - val_accuracy: 0.9231\n",
      "Epoch 38/60\n",
      "228/228 [==============================] - 11s 50ms/step - loss: 0.1377 - accuracy: 0.9467 - val_loss: 0.2506 - val_accuracy: 0.9305\n",
      "Epoch 39/60\n",
      "228/228 [==============================] - 11s 50ms/step - loss: 0.1351 - accuracy: 0.9477 - val_loss: 0.2591 - val_accuracy: 0.9280\n",
      "Epoch 40/60\n",
      "228/228 [==============================] - 11s 50ms/step - loss: 0.1305 - accuracy: 0.9510 - val_loss: 0.2695 - val_accuracy: 0.9288\n",
      "Epoch 41/60\n",
      "228/228 [==============================] - 11s 50ms/step - loss: 0.1288 - accuracy: 0.9512 - val_loss: 0.2735 - val_accuracy: 0.9242\n",
      "Epoch 42/60\n",
      "228/228 [==============================] - 11s 50ms/step - loss: 0.1360 - accuracy: 0.9481 - val_loss: 0.2690 - val_accuracy: 0.9282\n",
      "Epoch 43/60\n",
      "228/228 [==============================] - 11s 50ms/step - loss: 0.1210 - accuracy: 0.9535 - val_loss: 0.2620 - val_accuracy: 0.9319\n",
      "Epoch 44/60\n",
      "228/228 [==============================] - 11s 50ms/step - loss: 0.1275 - accuracy: 0.9513 - val_loss: 0.2538 - val_accuracy: 0.9305\n",
      "Epoch 45/60\n",
      "228/228 [==============================] - 11s 50ms/step - loss: 0.1203 - accuracy: 0.9542 - val_loss: 0.2780 - val_accuracy: 0.9372\n",
      "Epoch 46/60\n",
      "228/228 [==============================] - 11s 50ms/step - loss: 0.1175 - accuracy: 0.9554 - val_loss: 0.2712 - val_accuracy: 0.9327\n",
      "Epoch 47/60\n",
      "228/228 [==============================] - 11s 50ms/step - loss: 0.1193 - accuracy: 0.9550 - val_loss: 0.2789 - val_accuracy: 0.9316\n",
      "Epoch 48/60\n",
      "228/228 [==============================] - 11s 50ms/step - loss: 0.1150 - accuracy: 0.9565 - val_loss: 0.2675 - val_accuracy: 0.9327\n",
      "Epoch 49/60\n",
      "228/228 [==============================] - 11s 50ms/step - loss: 0.1178 - accuracy: 0.9556 - val_loss: 0.2420 - val_accuracy: 0.9422\n",
      "Epoch 50/60\n",
      "228/228 [==============================] - 11s 50ms/step - loss: 0.1116 - accuracy: 0.9576 - val_loss: 0.2529 - val_accuracy: 0.9405\n",
      "Epoch 51/60\n",
      "228/228 [==============================] - 11s 50ms/step - loss: 0.1114 - accuracy: 0.9579 - val_loss: 0.2654 - val_accuracy: 0.9385\n",
      "Epoch 52/60\n",
      "228/228 [==============================] - 11s 50ms/step - loss: 0.1130 - accuracy: 0.9571 - val_loss: 0.2564 - val_accuracy: 0.9370\n",
      "Epoch 53/60\n",
      "228/228 [==============================] - 11s 50ms/step - loss: 0.1052 - accuracy: 0.9605 - val_loss: 0.2692 - val_accuracy: 0.9378\n",
      "Epoch 54/60\n",
      "228/228 [==============================] - 11s 50ms/step - loss: 0.1076 - accuracy: 0.9601 - val_loss: 0.2531 - val_accuracy: 0.9376\n",
      "Epoch 55/60\n",
      "228/228 [==============================] - 11s 50ms/step - loss: 0.1067 - accuracy: 0.9593 - val_loss: 0.2542 - val_accuracy: 0.9347\n",
      "Epoch 56/60\n",
      "228/228 [==============================] - 11s 50ms/step - loss: 0.0952 - accuracy: 0.9640 - val_loss: 0.2594 - val_accuracy: 0.9415\n",
      "Epoch 57/60\n",
      "228/228 [==============================] - 11s 50ms/step - loss: 0.1015 - accuracy: 0.9609 - val_loss: 0.2563 - val_accuracy: 0.9393\n",
      "Epoch 58/60\n",
      "228/228 [==============================] - 11s 50ms/step - loss: 0.1014 - accuracy: 0.9616 - val_loss: 0.2679 - val_accuracy: 0.9379\n",
      "Epoch 59/60\n",
      "228/228 [==============================] - 11s 50ms/step - loss: 0.1028 - accuracy: 0.9612 - val_loss: 0.2695 - val_accuracy: 0.9398\n",
      "Epoch 60/60\n",
      "228/228 [==============================] - 11s 50ms/step - loss: 0.0995 - accuracy: 0.9625 - val_loss: 0.2805 - val_accuracy: 0.9300\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1594b851d48>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, \n",
    "         batch_size=batch_size, epochs=epochs, verbose=1, \n",
    "         validation_data=(x_valid, y_valid), \n",
    "         callbacks=[modelcheckpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7PWlH5SJ8JmP"
   },
   "source": [
    "#### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z8t0nVCw8JmP"
   },
   "outputs": [],
   "source": [
    "model.load_weights(output_dir+\"/weights.49.hdf5\") # 94.22 val accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kZwGk5dR8JmS"
   },
   "outputs": [],
   "source": [
    "y_hat = model.predict(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EPc5_h6K8JmW",
    "outputId": "cad99da9-9f89-437f-854b-a315616ed50f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6476"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E_GNq-R_8JmZ",
    "outputId": "0fc16efe-7739-4394-f1a3-46da92e79584"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.5183621e-03, 1.2306287e-09, 1.9398967e-11, 8.6664807e-11,\n",
       "       1.1307324e-09, 9.9848169e-01], dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SFqRQ5XB8Jmc",
    "outputId": "a957fbed-92f8-4bdd-d24b-5df3361a8bac"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 1.], dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FTWf6Cf-8Jme",
    "outputId": "1256b170-33dc-4171-f2ff-7a3d7ddd74e3"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_hat)\n",
    "_ = plt.axvline(x=0.5, color='orange')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RNljSx3v8Jmh"
   },
   "outputs": [],
   "source": [
    "pct_auc = roc_auc_score(y_valid, y_hat)*100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SO_N9lJG8Jmj",
    "outputId": "20968a52-8ca0-44d3-abf6-a1382bba5cde"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'99.52'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"{:0.2f}\".format(pct_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vU3hnA298Jmo"
   },
   "outputs": [],
   "source": [
    "float_y_hat = []\n",
    "for y in y_hat:\n",
    "    float_y_hat.append(y[0:6].round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zrTf-aQl8Jmr"
   },
   "outputs": [],
   "source": [
    "ydf = pd.DataFrame(list(zip(float_y_hat, y_valid)), columns=['y_hat', 'y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zAyKh_mX8Jmu",
    "outputId": "611224b8-f980-47df-d596-9aa3a5811009"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_hat</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.002, 0.0, 0.0, 0.0, 0.0, 0.998]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[0.0, 0.958, 0.0, 0.0, 0.042, 0.0]</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[0.004, 0.994, 0.0, 0.0, 0.002, 0.0]</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  y_hat                               y\n",
       "0    [0.002, 0.0, 0.0, 0.0, 0.0, 0.998]  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0]\n",
       "1        [0.0, 0.0, 1.0, 0.0, 0.0, 0.0]  [0.0, 0.0, 1.0, 0.0, 0.0, 0.0]\n",
       "2        [0.0, 1.0, 0.0, 0.0, 0.0, 0.0]  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0]\n",
       "3        [1.0, 0.0, 0.0, 0.0, 0.0, 0.0]  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
       "4        [0.0, 1.0, 0.0, 0.0, 0.0, 0.0]  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0]\n",
       "5        [0.0, 0.0, 0.0, 0.0, 0.0, 1.0]  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0]\n",
       "6        [0.0, 0.0, 0.0, 1.0, 0.0, 0.0]  [0.0, 0.0, 0.0, 1.0, 0.0, 0.0]\n",
       "7    [0.0, 0.958, 0.0, 0.0, 0.042, 0.0]  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0]\n",
       "8        [1.0, 0.0, 0.0, 0.0, 0.0, 0.0]  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
       "9  [0.004, 0.994, 0.0, 0.0, 0.002, 0.0]  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ydf.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "dense_sentiment_classifier.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
