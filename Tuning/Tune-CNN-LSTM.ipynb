{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ahUZuAfz8Jje"
   },
   "source": [
    "# Sklearn Tuner for CNN Activity Classifier - V3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Re0ecmVI8Jjk"
   },
   "source": [
    "In this notebook, we use SKlearn  to tune a CNN neural net to classify PE activity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ixsGb9tY8Jjm"
   },
   "source": [
    "#### Load dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5At1PKQp8Jjp"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-5c41473e50aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import os  \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "import tensorflow\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, Conv1D, GlobalMaxPooling1D\n",
    "from tensorflow.keras.layers import AveragePooling1D, LeakyReLU , MaxPool1D, GlobalAveragePooling1D\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint \n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, roc_curve \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "print(device_lib.list_local_devices())\n",
    "import tensorflow as tf\n",
    "print(\"# GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "import sklearn\n",
    "# bug in sklearn wrapper\n",
    "#https://stackoverflow.com/questions/59746974/cannot-clone-object-tensorflow-python-keras-wrappers-scikit-learn-kerasclassifi\n",
    "if sklearn.__version__ != '0.21.2':\n",
    "    print(\"updating sklearn ...\")\n",
    "    !pip install --user scikit-learn==0.21.2\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hg5wX2Dd8Jjz"
   },
   "source": [
    "#### Set hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lYLOM99-8Jj2"
   },
   "outputs": [],
   "source": [
    "# output directory name:\n",
    "output_dir = 'model_output/tune-cnn-lstm'\n",
    "input_dir =  'Z:/Research/dfuller/Walkabilly/studies/smarphone_accel/data/Ethica_Jaeger_Merged/pocket/'\n",
    "input_file_name = 'pocket-NN-data.npz'\n",
    "\n",
    "# from the data preparation section we have:\n",
    "window_size_second = 3\n",
    "frequency = 30\n",
    "lenght_of_each_seq = window_size_second * frequency\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LeakyReLU' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-a1229faf19df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;34m'n_dense_2'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m384\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;34m'dropout_2'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0;34m'activation_conv'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'elu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLeakyReLU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0;34m'activation_dense'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'elu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLeakyReLU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m }\n",
      "\u001b[0;31mNameError\u001b[0m: name 'LeakyReLU' is not defined"
     ]
    }
   ],
   "source": [
    "# sklearn hyperparams\n",
    "params = {\n",
    "    \n",
    "    # Conv layers\n",
    "    'n_conv_1':[512, 768], # filters, a.k.a. kernels\n",
    "    'k_conv_1':[2, 3], # kernel length\n",
    "    'n_conv_2':[256, 512], # filters, a.k.a. kernels\n",
    "    'k_conv_2':[2, 3], # kernel length\n",
    "    'n_conv_3':[256, 512], # filters, a.k.a. kernels\n",
    "    'k_conv_3':[2, 3], # kernel length\n",
    "    'maxpooling_pool_size':[2, 3],\n",
    "    'avepooling_pool_size':[2, 3],\n",
    "    \n",
    "    # LSTM layers\n",
    "    'n_lstm_1' : [128, 256],\n",
    "    'n_lstm_2' : [128, 256],\n",
    "    'drop_lstm_1' : [0.02,0.1],\n",
    "    'drop_lstm_2' : [0.02,0.1],\n",
    "\n",
    "    \n",
    "    # Dense layers\n",
    "    'n_dense_1':[256, 384, 512],\n",
    "    'dropout_1':[0.2, 0.3],\n",
    "    'n_dense_2':[256, 384, 512],\n",
    "    'dropout_2':[0.2, 0.3],\n",
    "    'activation_conv':['elu', 'relu', LeakyReLU()],\n",
    "    'activation_dense':['elu', 'relu', LeakyReLU()]\n",
    "}\n",
    "\n",
    "# training:\n",
    "n_tune_iter = 20\n",
    "cv = 3\n",
    "epochs = 60\n",
    "batch_size = 256\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DaLx4yZ48Jj9"
   },
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CD9X0yJg8Jj_"
   },
   "source": [
    "##### For this notebook we use the acceleration data gathered from the pocket location. It was prepared in the DataPrep-Deep notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6r44JKj-8JkA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acceleration_data\n",
      "metadata\n",
      "labels\n"
     ]
    }
   ],
   "source": [
    "# read the raw file and get the keys:\n",
    "raw_data = np.load(file=input_dir+input_file_name,allow_pickle=True)\n",
    "for k in raw_data.keys():\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the data\n",
    "\n",
    "accel_array = raw_data['acceleration_data']\n",
    "meta_array = raw_data['metadata']\n",
    "labels_array = raw_data['labels']\n",
    "input_shape = list(accel_array.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WWq3ipbu8JlG"
   },
   "source": [
    "#### Preprocess data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert the  labels to integer.\n",
    "In the raw data format of the labels is String and there are 6 classes. 'Lying', 'Sitting', 'Self Pace walk', 'Running 3 METs',\n",
    "       'Running 5 METs', 'Running 7 METs' <br>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LyReiequ8Jln"
   },
   "outputs": [],
   "source": [
    "n_class = len(np.unique(labels_array))\n",
    "class_list, labels_array_int = np.unique(labels_array,return_inverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = to_categorical(labels_array_int, num_classes=n_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "40x3s0KY8Jlv",
    "outputId": "d3ac3e31-3c47-4b01-c2f9-ada0684b31b7"
   },
   "source": [
    "### Splitting and shuffeling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f5grc2H78Jlz",
    "outputId": "3f7eeb55-f851-4796-de4e-0c68eb9df88d"
   },
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "     accel_array, y, test_size=0.1, random_state=65)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "GscSnCpk8Jlm"
   },
   "source": [
    "\n",
    "#### Design neural network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'params' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-bfd368200e6b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mparams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'params' is not defined"
     ]
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(n_conv_1=256, k_conv_1=3, n_conv_2=256, k_conv_2=3, n_conv_3=256, k_conv_3=3,\n",
    "                 maxpooling_pool_size = 2, avepooling_pool_size = 2, n_lstm_1=128, n_lstm_2=128,\n",
    "                 drop_lstm_1=0.02,drop_lstm_2=0.02, n_dense_1=256, dropout_1=0.2,\n",
    "                 n_dense_2=256, dropout_2=0.2, activation_conv= 'relu', activation_dense= 'elu'\n",
    "                ):\n",
    "    model = Sequential()\n",
    "    # Conv layers\n",
    "    model.add(Conv1D(n_conv_1, k_conv_1, activation=activation_conv, input_shape=input_shape[1:]))\n",
    "    model.add(MaxPool1D(pool_size = maxpooling_pool_size))\n",
    "    model.add(Conv1D(n_conv_2, k_conv_2, activation=activation_conv))\n",
    "    model.add(AveragePooling1D(pool_size = avepooling_pool_size))\n",
    "    model.add(Conv1D(n_conv_3, k_conv_3, activation=activation_conv))\n",
    "    model.add(GlobalAveragePooling1D())\n",
    "\n",
    "    # LSTM layers\n",
    "    model.add(LSTM(n_lstm_1, dropout=drop_lstm_1, \n",
    "                             return_sequences=True)) \n",
    "    model.add(LSTM(n_lstm_2, dropout=drop_lstm_2, \n",
    "                             return_sequences=True))\n",
    "    \n",
    "    # Dense layers\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(n_dense_1, activation=activation_dense))\n",
    "    model.add(Dropout(dropout_1))\n",
    "    model.add(Dense(n_dense_2, activation=activation_dense))\n",
    "    model.add(Dropout(dropout_2))\n",
    "    model.add(Dense(n_class, activation='softmax'))\n",
    "    model.summary()\n",
    "    print(f\"\"\"n_conv_1 = {n_conv_1}, k_conv_1 = {k_conv_1},  n_conv_2 = {n_conv_2}, k_conv_2 = {k_conv_2}, \n",
    "          n_conv_3 = {n_conv_3},  k_conv_3 = {k_conv_3},  maxpooling_pool_size = {maxpooling_pool_size},\n",
    "          avepooling_pool_size = {avepooling_pool_size},\n",
    "          n_lstm_1 = {n_lstm_1}, n_lstm_2 = {n_lstm_2},\n",
    "          drop_lstm_1 = {drop_lstm_1}, drop_lstm_2 = {drop_lstm_2},\n",
    "          n_dense_1 = {n_dense_1}, dropout_1 = {dropout_1},\n",
    "          n_dense_2 = {n_dense_2}, dropout_2 = {dropout_2}, activation_conv=  {activation_conv},\n",
    "          activation_dense=  {activation_dense}\"\"\")\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 88, 256)           2560      \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 44, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 42, 256)           196864    \n",
      "_________________________________________________________________\n",
      "average_pooling1d (AveragePo (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 19, 256)           196864    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 1542      \n",
      "=================================================================\n",
      "Total params: 529,414\n",
      "Trainable params: 529,414\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 256, k_conv_1 = 3,  n_conv_2 = 256, k_conv_2 = 3, \n",
      "          n_conv_3 = 256,  k_conv_3 = 3,  maxpooling_pool_size = 2,\n",
      "          avepooling_pool_size = 2,  n_dense_1 = 256, dropout_1 = 0.2,\n",
      "          n_dense_2 = 256, dropout_2 = 0.2, activation_conv=  relu,\n",
      "          activation_dense=  elu\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 88, 256)           2560      \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 44, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 42, 256)           196864    \n",
      "_________________________________________________________________\n",
      "average_pooling1d (AveragePo (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 19, 256)           196864    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 1542      \n",
      "=================================================================\n",
      "Total params: 529,414\n",
      "Trainable params: 529,414\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_default = create_model()\n",
    "model_default.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasClassifier(build_fn=create_model, epochs=epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_3 (Conv1D)            (None, 88, 512)           5120      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 29, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 28, 256)           262400    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average (None, 9, 256)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 7, 512)            393728    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_1 ( (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 6)                 1542      \n",
      "=================================================================\n",
      "Total params: 859,910\n",
      "Trainable params: 859,910\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 512, k_conv_1 = 3,  n_conv_2 = 256, k_conv_2 = 2, \n",
      "          n_conv_3 = 512,  k_conv_3 = 3,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 256, dropout_1 = 0.2,\n",
      "          n_dense_2 = 256, dropout_2 = 0.3, activation_conv=  relu,\n",
      "          activation_dense=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001F691236408>\n",
      "Epoch 1/60\n",
      "152/152 [==============================] - 4s 27ms/step - loss: 1.0798 - accuracy: 0.5409\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.6847 - accuracy: 0.7333\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.5272 - accuracy: 0.8031\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.4369 - accuracy: 0.8367\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3945 - accuracy: 0.8534\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3553 - accuracy: 0.8680\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3239 - accuracy: 0.8787\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.3169 - accuracy: 0.8815\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.3009 - accuracy: 0.8883\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.2953 - accuracy: 0.8888\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.2870 - accuracy: 0.8935\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.2699 - accuracy: 0.8982\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.2707 - accuracy: 0.8989\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.2518 - accuracy: 0.9055\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.2416 - accuracy: 0.9107\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.2379 - accuracy: 0.9115\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.2332 - accuracy: 0.9135\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.2238 - accuracy: 0.9171\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.2275 - accuracy: 0.9165\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.2065 - accuracy: 0.9240\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.2056 - accuracy: 0.9231\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.2053 - accuracy: 0.9246\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.2009 - accuracy: 0.9249 0s - loss: 0.2015 - accura\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1959 - accuracy: 0.9259\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1922 - accuracy: 0.9283\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1866 - accuracy: 0.9289\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1781 - accuracy: 0.9324\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1791 - accuracy: 0.9320\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1747 - accuracy: 0.9325\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1692 - accuracy: 0.9360\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1573 - accuracy: 0.9395\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1657 - accuracy: 0.9369\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1629 - accuracy: 0.9385\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1550 - accuracy: 0.9396\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1528 - accuracy: 0.9419\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1444 - accuracy: 0.9441\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1427 - accuracy: 0.9454\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1408 - accuracy: 0.9454\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1441 - accuracy: 0.9452\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1343 - accuracy: 0.9479\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1279 - accuracy: 0.9504\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1314 - accuracy: 0.9490\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1292 - accuracy: 0.9506\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1234 - accuracy: 0.9533\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1219 - accuracy: 0.9527\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1267 - accuracy: 0.9514\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1204 - accuracy: 0.9523\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 4s 27ms/step - loss: 0.1159 - accuracy: 0.9548\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.1269 - accuracy: 0.9523\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1142 - accuracy: 0.9558\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1061 - accuracy: 0.9576\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1133 - accuracy: 0.9564\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1119 - accuracy: 0.9566\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1100 - accuracy: 0.9573\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.0964 - accuracy: 0.9633\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1029 - accuracy: 0.9600\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1035 - accuracy: 0.9604\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1006 - accuracy: 0.9614\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1054 - accuracy: 0.9591\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.0906 - accuracy: 0.9642\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 0.3115 - accuracy: 0.9303\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_6 (Conv1D)            (None, 88, 512)           5120      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 29, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 28, 256)           262400    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_2 (Average (None, 9, 256)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 7, 512)            393728    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_2 ( (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 6)                 1542      \n",
      "=================================================================\n",
      "Total params: 859,910\n",
      "Trainable params: 859,910\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 512, k_conv_1 = 3,  n_conv_2 = 256, k_conv_2 = 2, \n",
      "          n_conv_3 = 512,  k_conv_3 = 3,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 256, dropout_1 = 0.2,\n",
      "          n_dense_2 = 256, dropout_2 = 0.3, activation_conv=  relu,\n",
      "          activation_dense=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001F691236408>\n",
      "Epoch 1/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 1.0790 - accuracy: 0.5405\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.6874 - accuracy: 0.7293\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.5094 - accuracy: 0.8079\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.4150 - accuracy: 0.8445\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.3781 - accuracy: 0.8583\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.3466 - accuracy: 0.8699\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.3300 - accuracy: 0.8752\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.3083 - accuracy: 0.8852\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.2978 - accuracy: 0.8878\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.2824 - accuracy: 0.8959\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.2763 - accuracy: 0.8960\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.2668 - accuracy: 0.8995\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.2560 - accuracy: 0.9063\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.2498 - accuracy: 0.9054\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.2355 - accuracy: 0.9110\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.2342 - accuracy: 0.9123\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.2298 - accuracy: 0.9149\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.2222 - accuracy: 0.9167\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.2131 - accuracy: 0.9197\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.2104 - accuracy: 0.9217\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1978 - accuracy: 0.9248\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.2069 - accuracy: 0.9234\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1911 - accuracy: 0.9276\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1888 - accuracy: 0.9277\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1821 - accuracy: 0.9319\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1829 - accuracy: 0.9312\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1775 - accuracy: 0.9333\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1762 - accuracy: 0.9327\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1605 - accuracy: 0.9393\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1639 - accuracy: 0.9364\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1652 - accuracy: 0.9367\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1524 - accuracy: 0.9415\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1634 - accuracy: 0.9386\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1502 - accuracy: 0.9429\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1464 - accuracy: 0.9433\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1461 - accuracy: 0.9433\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1358 - accuracy: 0.9472\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1480 - accuracy: 0.9450\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1294 - accuracy: 0.9507\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1297 - accuracy: 0.9503\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1254 - accuracy: 0.9513\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1359 - accuracy: 0.9480\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1320 - accuracy: 0.9497\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1174 - accuracy: 0.9545\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1351 - accuracy: 0.9501\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1205 - accuracy: 0.9533\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1256 - accuracy: 0.9523\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1268 - accuracy: 0.9510\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1178 - accuracy: 0.9563\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1123 - accuracy: 0.9571\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1082 - accuracy: 0.9582\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1132 - accuracy: 0.9575\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1078 - accuracy: 0.9587\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1081 - accuracy: 0.9579\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1011 - accuracy: 0.9609\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1073 - accuracy: 0.9591\n",
      "Epoch 57/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 4s 24ms/step - loss: 0.0954 - accuracy: 0.9639\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1007 - accuracy: 0.9618\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.0994 - accuracy: 0.9633\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.0935 - accuracy: 0.9636\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 0.2855 - accuracy: 0.9349\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_9 (Conv1D)            (None, 88, 512)           5120      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 29, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_10 (Conv1D)           (None, 28, 256)           262400    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_3 (Average (None, 9, 256)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 7, 512)            393728    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_3 ( (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 6)                 1542      \n",
      "=================================================================\n",
      "Total params: 859,910\n",
      "Trainable params: 859,910\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 512, k_conv_1 = 3,  n_conv_2 = 256, k_conv_2 = 2, \n",
      "          n_conv_3 = 512,  k_conv_3 = 3,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 256, dropout_1 = 0.2,\n",
      "          n_dense_2 = 256, dropout_2 = 0.3, activation_conv=  relu,\n",
      "          activation_dense=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001F691236408>\n",
      "Epoch 1/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 1.0793 - accuracy: 0.5430\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.7108 - accuracy: 0.7163\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.5242 - accuracy: 0.8010\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.4171 - accuracy: 0.8440\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.3839 - accuracy: 0.8561\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.3447 - accuracy: 0.8701\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.3359 - accuracy: 0.8738\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.3185 - accuracy: 0.8805\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.2988 - accuracy: 0.8868\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.2896 - accuracy: 0.8917\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.2817 - accuracy: 0.8958\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.2657 - accuracy: 0.9012\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.2646 - accuracy: 0.9020\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.2529 - accuracy: 0.9061\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.2399 - accuracy: 0.9094\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.2315 - accuracy: 0.9130\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.2368 - accuracy: 0.9119\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.2173 - accuracy: 0.9188\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.2219 - accuracy: 0.9167\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.2115 - accuracy: 0.9219\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.2032 - accuracy: 0.9247\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1957 - accuracy: 0.9271\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.2033 - accuracy: 0.9254\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1856 - accuracy: 0.9325\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1853 - accuracy: 0.9317\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1773 - accuracy: 0.9329\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1746 - accuracy: 0.9353\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1689 - accuracy: 0.9377\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.1655 - accuracy: 0.9373\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1691 - accuracy: 0.9368\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1609 - accuracy: 0.9400\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1554 - accuracy: 0.9420\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1573 - accuracy: 0.9417\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1511 - accuracy: 0.9431\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1544 - accuracy: 0.9412\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1441 - accuracy: 0.9454\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1412 - accuracy: 0.9461\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1351 - accuracy: 0.9483\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1431 - accuracy: 0.9452\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1371 - accuracy: 0.9485\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1300 - accuracy: 0.9499\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1197 - accuracy: 0.9543\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1231 - accuracy: 0.9521\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1279 - accuracy: 0.9518\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1267 - accuracy: 0.9517\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1285 - accuracy: 0.9516\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1147 - accuracy: 0.9567\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1149 - accuracy: 0.9565\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1230 - accuracy: 0.9532\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1031 - accuracy: 0.9609\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1206 - accuracy: 0.9551\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1113 - accuracy: 0.9566\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1070 - accuracy: 0.9594\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1040 - accuracy: 0.9602\n",
      "Epoch 55/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 4s 24ms/step - loss: 0.0979 - accuracy: 0.9627\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.0984 - accuracy: 0.9629\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.0956 - accuracy: 0.9631\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1040 - accuracy: 0.9605\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1065 - accuracy: 0.9603\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1018 - accuracy: 0.9614\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 0.2669 - accuracy: 0.9292\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_12 (Conv1D)           (None, 88, 768)           7680      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 44, 768)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_13 (Conv1D)           (None, 42, 256)           590080    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_4 (Average (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 20, 256)           131328    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_4 ( (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 384)               98688     \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 384)               147840    \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 6)                 2310      \n",
      "=================================================================\n",
      "Total params: 977,926\n",
      "Trainable params: 977,926\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 768, k_conv_1 = 3,  n_conv_2 = 256, k_conv_2 = 3, \n",
      "          n_conv_3 = 256,  k_conv_3 = 2,  maxpooling_pool_size = 2,\n",
      "          avepooling_pool_size = 2,  n_dense_1 = 384, dropout_1 = 0.3,\n",
      "          n_dense_2 = 384, dropout_2 = 0.2, activation_conv=  elu,\n",
      "          activation_dense=  elu\n",
      "Epoch 1/60\n",
      "152/152 [==============================] - 7s 47ms/step - loss: 1.2110 - accuracy: 0.4815\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 1.0724 - accuracy: 0.5422\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.9688 - accuracy: 0.5982\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.8412 - accuracy: 0.6597\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.7561 - accuracy: 0.6989\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.7061 - accuracy: 0.7209\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.6550 - accuracy: 0.7359\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.6187 - accuracy: 0.7508\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.5839 - accuracy: 0.7639\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.5646 - accuracy: 0.7721\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.5378 - accuracy: 0.7836\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.5317 - accuracy: 0.7855\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.5022 - accuracy: 0.7975\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.4884 - accuracy: 0.8056\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.4789 - accuracy: 0.8132\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.4537 - accuracy: 0.8217\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.4452 - accuracy: 0.8244\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.4335 - accuracy: 0.8331\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.4212 - accuracy: 0.8374\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.4066 - accuracy: 0.8436\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.4077 - accuracy: 0.8423\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.3873 - accuracy: 0.8512\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.3868 - accuracy: 0.8507\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.3796 - accuracy: 0.8543\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.3714 - accuracy: 0.8552\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.3602 - accuracy: 0.8600\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.3536 - accuracy: 0.8623\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.3477 - accuracy: 0.8643\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.3419 - accuracy: 0.8672\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.3394 - accuracy: 0.8670\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.3250 - accuracy: 0.8739\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.3188 - accuracy: 0.8758\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.3178 - accuracy: 0.8783\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.3111 - accuracy: 0.8783\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.3108 - accuracy: 0.8798\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.2997 - accuracy: 0.8856\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.3028 - accuracy: 0.8855\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.2911 - accuracy: 0.8875\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.2914 - accuracy: 0.8861\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.2866 - accuracy: 0.8879\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.2755 - accuracy: 0.8930\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.2711 - accuracy: 0.8963\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.2697 - accuracy: 0.8965\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.2646 - accuracy: 0.8958\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.2722 - accuracy: 0.8950\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.2624 - accuracy: 0.8979\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.2663 - accuracy: 0.8949\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.2553 - accuracy: 0.9012\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.2533 - accuracy: 0.9013\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.2477 - accuracy: 0.9028\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.2466 - accuracy: 0.9040\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.2447 - accuracy: 0.9037\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.2447 - accuracy: 0.9036\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.2362 - accuracy: 0.9082\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.2336 - accuracy: 0.9094\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.2339 - accuracy: 0.9084\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.2344 - accuracy: 0.9106\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.2341 - accuracy: 0.9093\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.2242 - accuracy: 0.9134\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.2181 - accuracy: 0.9148\n",
      "76/76 [==============================] - 1s 18ms/step - loss: 0.2432 - accuracy: 0.9094\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_15 (Conv1D)           (None, 88, 768)           7680      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 44, 768)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_16 (Conv1D)           (None, 42, 256)           590080    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_5 (Average (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_17 (Conv1D)           (None, 20, 256)           131328    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_5 ( (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 384)               98688     \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 384)               147840    \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 6)                 2310      \n",
      "=================================================================\n",
      "Total params: 977,926\n",
      "Trainable params: 977,926\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 768, k_conv_1 = 3,  n_conv_2 = 256, k_conv_2 = 3, \n",
      "          n_conv_3 = 256,  k_conv_3 = 2,  maxpooling_pool_size = 2,\n",
      "          avepooling_pool_size = 2,  n_dense_1 = 384, dropout_1 = 0.3,\n",
      "          n_dense_2 = 384, dropout_2 = 0.2, activation_conv=  elu,\n",
      "          activation_dense=  elu\n",
      "Epoch 1/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 1.2055 - accuracy: 0.4815\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 1.0723 - accuracy: 0.5413\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.9295 - accuracy: 0.6178\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.8154 - accuracy: 0.6782\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.7574 - accuracy: 0.7054\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.7047 - accuracy: 0.7235\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.6593 - accuracy: 0.7373\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.6203 - accuracy: 0.7514\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.6001 - accuracy: 0.7590\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.5787 - accuracy: 0.7687\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.5455 - accuracy: 0.7810\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.5171 - accuracy: 0.7938\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.5028 - accuracy: 0.7995\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.4882 - accuracy: 0.8068\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.4651 - accuracy: 0.8182\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.4498 - accuracy: 0.8268\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.4396 - accuracy: 0.8313\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.4302 - accuracy: 0.8338\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.4135 - accuracy: 0.8423\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.4057 - accuracy: 0.8432\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.3961 - accuracy: 0.8474\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.3870 - accuracy: 0.8522\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.3750 - accuracy: 0.8566\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.3740 - accuracy: 0.8556\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.3610 - accuracy: 0.8616\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.3607 - accuracy: 0.8605\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.3557 - accuracy: 0.8623\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.3425 - accuracy: 0.8675\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.3369 - accuracy: 0.8697\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.3241 - accuracy: 0.8755\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.3235 - accuracy: 0.8743\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.3217 - accuracy: 0.8743\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.3147 - accuracy: 0.8761\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.3123 - accuracy: 0.8782\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.3041 - accuracy: 0.8820\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.3035 - accuracy: 0.8806\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.2905 - accuracy: 0.8866\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.2964 - accuracy: 0.8838\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.2880 - accuracy: 0.8860\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.2814 - accuracy: 0.8900\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.2804 - accuracy: 0.8883\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.2813 - accuracy: 0.8897\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.2752 - accuracy: 0.8926\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.2765 - accuracy: 0.8904\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.2662 - accuracy: 0.8961\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.2605 - accuracy: 0.8972\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.2625 - accuracy: 0.8964\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.2539 - accuracy: 0.8993\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.2537 - accuracy: 0.9017\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.2556 - accuracy: 0.8990\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.2488 - accuracy: 0.9016\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.2462 - accuracy: 0.9038\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.2411 - accuracy: 0.9046\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.2389 - accuracy: 0.9058\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.2376 - accuracy: 0.9074\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.2389 - accuracy: 0.9060\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.2317 - accuracy: 0.9098\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.2323 - accuracy: 0.9106\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.2321 - accuracy: 0.9079\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.2294 - accuracy: 0.9098\n",
      "76/76 [==============================] - 1s 17ms/step - loss: 0.2473 - accuracy: 0.9103\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_18 (Conv1D)           (None, 88, 768)           7680      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 44, 768)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_19 (Conv1D)           (None, 42, 256)           590080    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_6 (Average (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_20 (Conv1D)           (None, 20, 256)           131328    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_6 ( (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 384)               98688     \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 384)               147840    \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 6)                 2310      \n",
      "=================================================================\n",
      "Total params: 977,926\n",
      "Trainable params: 977,926\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 768, k_conv_1 = 3,  n_conv_2 = 256, k_conv_2 = 3, \n",
      "          n_conv_3 = 256,  k_conv_3 = 2,  maxpooling_pool_size = 2,\n",
      "          avepooling_pool_size = 2,  n_dense_1 = 384, dropout_1 = 0.3,\n",
      "          n_dense_2 = 384, dropout_2 = 0.2, activation_conv=  elu,\n",
      "          activation_dense=  elu\n",
      "Epoch 1/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 1.2074 - accuracy: 0.4825\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 1.0760 - accuracy: 0.5386\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.9525 - accuracy: 0.6078\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.8509 - accuracy: 0.6561\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.7512 - accuracy: 0.7046\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.7010 - accuracy: 0.7198\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.6520 - accuracy: 0.7376\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.6303 - accuracy: 0.7478\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.6004 - accuracy: 0.7547\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.5617 - accuracy: 0.7746\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.5459 - accuracy: 0.7809\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.5206 - accuracy: 0.7928\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.5127 - accuracy: 0.7974\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.4914 - accuracy: 0.8080\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.4684 - accuracy: 0.8180\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.4602 - accuracy: 0.8208\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.4480 - accuracy: 0.8275\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.4353 - accuracy: 0.8311\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.4185 - accuracy: 0.8378\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.4079 - accuracy: 0.8423\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.4108 - accuracy: 0.8432\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.3978 - accuracy: 0.8440\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.3920 - accuracy: 0.8500\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.3698 - accuracy: 0.8573\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.3677 - accuracy: 0.8560\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.3614 - accuracy: 0.8603\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.3589 - accuracy: 0.8598\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.3580 - accuracy: 0.8641\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.3465 - accuracy: 0.8649\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.3405 - accuracy: 0.8685\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.3291 - accuracy: 0.8730\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.3364 - accuracy: 0.8706\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.3206 - accuracy: 0.8764\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.3084 - accuracy: 0.8800\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.3108 - accuracy: 0.8804\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.3035 - accuracy: 0.8819\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.2994 - accuracy: 0.8851\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.3011 - accuracy: 0.8841\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.2932 - accuracy: 0.8863\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.2921 - accuracy: 0.8877\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.2935 - accuracy: 0.8867\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.2764 - accuracy: 0.8946\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.2716 - accuracy: 0.8965\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.2760 - accuracy: 0.8956\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.2713 - accuracy: 0.8947\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.2666 - accuracy: 0.8981\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.2682 - accuracy: 0.8965\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.2649 - accuracy: 0.8986\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.2516 - accuracy: 0.9040\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.2542 - accuracy: 0.9029\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.2531 - accuracy: 0.9014\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.2489 - accuracy: 0.9031\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.2418 - accuracy: 0.9054\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.2494 - accuracy: 0.9053\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.2416 - accuracy: 0.9062\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.2330 - accuracy: 0.9110\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.2304 - accuracy: 0.9097\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.2377 - accuracy: 0.9068\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.2283 - accuracy: 0.9122\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.2307 - accuracy: 0.9116\n",
      "76/76 [==============================] - 1s 17ms/step - loss: 0.2671 - accuracy: 0.8962\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_21 (Conv1D)           (None, 88, 768)           7680      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 44, 768)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_22 (Conv1D)           (None, 42, 512)           1180160   \n",
      "_________________________________________________________________\n",
      "average_pooling1d_7 (Average (None, 14, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_23 (Conv1D)           (None, 13, 512)           524800    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_7 ( (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 384)               196992    \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 6)                 2310      \n",
      "=================================================================\n",
      "Total params: 2,174,598\n",
      "Trainable params: 2,174,598\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 768, k_conv_1 = 3,  n_conv_2 = 512, k_conv_2 = 3, \n",
      "          n_conv_3 = 512,  k_conv_3 = 2,  maxpooling_pool_size = 2,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 512, dropout_1 = 0.2,\n",
      "          n_dense_2 = 384, dropout_2 = 0.2, activation_conv=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001F6FFADDA48>,\n",
      "          activation_dense=  relu\n",
      "Epoch 1/60\n",
      "152/152 [==============================] - 10s 69ms/step - loss: 1.0858 - accuracy: 0.5351\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.8107 - accuracy: 0.6616\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.6494 - accuracy: 0.7418\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.5537 - accuracy: 0.7807\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.5139 - accuracy: 0.7958\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.4769 - accuracy: 0.8133\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.4392 - accuracy: 0.8280\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.4341 - accuracy: 0.8312\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.3942 - accuracy: 0.8477\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.4003 - accuracy: 0.8455\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.3705 - accuracy: 0.8578\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.3768 - accuracy: 0.8544\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.3593 - accuracy: 0.8605\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.3671 - accuracy: 0.8567\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.3380 - accuracy: 0.8676\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.3370 - accuracy: 0.8680\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.3346 - accuracy: 0.8674\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.3228 - accuracy: 0.8724\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.3228 - accuracy: 0.8723\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.3085 - accuracy: 0.8779\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.3202 - accuracy: 0.8746\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.3043 - accuracy: 0.8795\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.3080 - accuracy: 0.8793\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.2959 - accuracy: 0.8840\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.2962 - accuracy: 0.8846\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.2983 - accuracy: 0.8830\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.2880 - accuracy: 0.8862\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.2854 - accuracy: 0.8899\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.2853 - accuracy: 0.8879\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.2671 - accuracy: 0.8927\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.2780 - accuracy: 0.8915\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.2856 - accuracy: 0.8866\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.2742 - accuracy: 0.8924\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.2690 - accuracy: 0.8949\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.2699 - accuracy: 0.8950\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.2780 - accuracy: 0.8913\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.2618 - accuracy: 0.8962\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.2518 - accuracy: 0.8995\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.2521 - accuracy: 0.9006\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.2516 - accuracy: 0.9001\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.2490 - accuracy: 0.9015\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.2501 - accuracy: 0.9024\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.2438 - accuracy: 0.9035\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.2512 - accuracy: 0.9029\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.2306 - accuracy: 0.9099\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.2434 - accuracy: 0.9040\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.2488 - accuracy: 0.9015\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.2412 - accuracy: 0.9062\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.2369 - accuracy: 0.9068\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.2282 - accuracy: 0.9116\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.2297 - accuracy: 0.9103\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.2265 - accuracy: 0.9102\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.2266 - accuracy: 0.9123\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.2258 - accuracy: 0.9127\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.2144 - accuracy: 0.9153\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.2286 - accuracy: 0.9100\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.2226 - accuracy: 0.9116\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.2296 - accuracy: 0.9123\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.2154 - accuracy: 0.9186\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.2279 - accuracy: 0.9102\n",
      "76/76 [==============================] - 2s 26ms/step - loss: 0.2496 - accuracy: 0.9132\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_24 (Conv1D)           (None, 88, 768)           7680      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 44, 768)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_25 (Conv1D)           (None, 42, 512)           1180160   \n",
      "_________________________________________________________________\n",
      "average_pooling1d_8 (Average (None, 14, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_26 (Conv1D)           (None, 13, 512)           524800    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_8 ( (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 384)               196992    \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 6)                 2310      \n",
      "=================================================================\n",
      "Total params: 2,174,598\n",
      "Trainable params: 2,174,598\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 768, k_conv_1 = 3,  n_conv_2 = 512, k_conv_2 = 3, \n",
      "          n_conv_3 = 512,  k_conv_3 = 2,  maxpooling_pool_size = 2,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 512, dropout_1 = 0.2,\n",
      "          n_dense_2 = 384, dropout_2 = 0.2, activation_conv=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001F6FFADDA48>,\n",
      "          activation_dense=  relu\n",
      "Epoch 1/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 1.1089 - accuracy: 0.5240\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.8351 - accuracy: 0.6488\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.6417 - accuracy: 0.7422\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.5485 - accuracy: 0.7820\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.5033 - accuracy: 0.8016\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.4528 - accuracy: 0.8228\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.4257 - accuracy: 0.8332\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.4247 - accuracy: 0.8345\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.4037 - accuracy: 0.8420\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.3901 - accuracy: 0.8459\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.3894 - accuracy: 0.8486\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.3635 - accuracy: 0.8584\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.3591 - accuracy: 0.8610\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.3577 - accuracy: 0.8620\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.3330 - accuracy: 0.8719\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.3378 - accuracy: 0.8695\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.3313 - accuracy: 0.8690\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.3366 - accuracy: 0.8684\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.3152 - accuracy: 0.8777\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.3156 - accuracy: 0.8772\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.3157 - accuracy: 0.8773\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.2972 - accuracy: 0.8845\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.3034 - accuracy: 0.8821\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.3015 - accuracy: 0.8812\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.2937 - accuracy: 0.8847\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.2924 - accuracy: 0.8842\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.2871 - accuracy: 0.8877\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.2892 - accuracy: 0.8861\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.2849 - accuracy: 0.8873\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.2928 - accuracy: 0.8849\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.2801 - accuracy: 0.8903\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.2659 - accuracy: 0.8924\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.2711 - accuracy: 0.8923\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.2653 - accuracy: 0.8952\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.2685 - accuracy: 0.8951\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.2618 - accuracy: 0.8976\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.2669 - accuracy: 0.8956\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.2532 - accuracy: 0.9006\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.2577 - accuracy: 0.8982\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.2600 - accuracy: 0.8992\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.2539 - accuracy: 0.8997\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.2528 - accuracy: 0.9021\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.2460 - accuracy: 0.9032\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.2483 - accuracy: 0.9030\n",
      "Epoch 45/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 10s 67ms/step - loss: 0.2413 - accuracy: 0.9075\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.2340 - accuracy: 0.9082\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.2309 - accuracy: 0.9099\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.2410 - accuracy: 0.9060\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.2390 - accuracy: 0.9075\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.2304 - accuracy: 0.9098\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.2310 - accuracy: 0.9110\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.2282 - accuracy: 0.9096\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.2253 - accuracy: 0.9103\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.2264 - accuracy: 0.9109\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.2282 - accuracy: 0.9114\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.2336 - accuracy: 0.9102\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.2250 - accuracy: 0.9128\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.2126 - accuracy: 0.9158\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.2065 - accuracy: 0.9195\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.2082 - accuracy: 0.9189\n",
      "76/76 [==============================] - 2s 24ms/step - loss: 0.2681 - accuracy: 0.9152\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_27 (Conv1D)           (None, 88, 768)           7680      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1 (None, 44, 768)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_28 (Conv1D)           (None, 42, 512)           1180160   \n",
      "_________________________________________________________________\n",
      "average_pooling1d_9 (Average (None, 14, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_29 (Conv1D)           (None, 13, 512)           524800    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_9 ( (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 384)               196992    \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 6)                 2310      \n",
      "=================================================================\n",
      "Total params: 2,174,598\n",
      "Trainable params: 2,174,598\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 768, k_conv_1 = 3,  n_conv_2 = 512, k_conv_2 = 3, \n",
      "          n_conv_3 = 512,  k_conv_3 = 2,  maxpooling_pool_size = 2,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 512, dropout_1 = 0.2,\n",
      "          n_dense_2 = 384, dropout_2 = 0.2, activation_conv=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001F6FFADDA48>,\n",
      "          activation_dense=  relu\n",
      "Epoch 1/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 1.0718 - accuracy: 0.5411\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.8119 - accuracy: 0.6625\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.6376 - accuracy: 0.7456\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.5545 - accuracy: 0.7779\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.5073 - accuracy: 0.8004\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.4607 - accuracy: 0.8179\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.4451 - accuracy: 0.8244\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.4256 - accuracy: 0.8355\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.4140 - accuracy: 0.8384\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.3879 - accuracy: 0.8497\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.3874 - accuracy: 0.8507\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.3619 - accuracy: 0.8590\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.3726 - accuracy: 0.8567\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.3546 - accuracy: 0.8621\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.3427 - accuracy: 0.8668\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.3453 - accuracy: 0.8656\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.3313 - accuracy: 0.8688\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.3288 - accuracy: 0.8708\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.3271 - accuracy: 0.8724\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.3196 - accuracy: 0.8756\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.3278 - accuracy: 0.8715\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.3072 - accuracy: 0.8792\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.3137 - accuracy: 0.8766\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.3034 - accuracy: 0.8806\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.3076 - accuracy: 0.8804\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.2979 - accuracy: 0.8824\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.3010 - accuracy: 0.8798\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.2953 - accuracy: 0.8852\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.2877 - accuracy: 0.8876\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.2860 - accuracy: 0.8879\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.2885 - accuracy: 0.88760s - loss: 0\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.2796 - accuracy: 0.8883\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.2814 - accuracy: 0.8890\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.2783 - accuracy: 0.8913\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.2674 - accuracy: 0.8954\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.2797 - accuracy: 0.8922\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.2624 - accuracy: 0.8977\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.2601 - accuracy: 0.8994\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.2515 - accuracy: 0.9036\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.2636 - accuracy: 0.8964\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.2552 - accuracy: 0.8997\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.2558 - accuracy: 0.9011\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.2563 - accuracy: 0.8987\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.2455 - accuracy: 0.9046\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.2588 - accuracy: 0.9017\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.2420 - accuracy: 0.9039\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.2383 - accuracy: 0.9062\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.2442 - accuracy: 0.9046\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.2391 - accuracy: 0.9054\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.2286 - accuracy: 0.9102\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 11s 70ms/step - loss: 0.2332 - accuracy: 0.9090\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 11s 70ms/step - loss: 0.2297 - accuracy: 0.9098\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 11s 69ms/step - loss: 0.2301 - accuracy: 0.9105\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.2192 - accuracy: 0.9150\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.2289 - accuracy: 0.9102\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.2229 - accuracy: 0.9133\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.2233 - accuracy: 0.9134\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.2177 - accuracy: 0.9130\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.2189 - accuracy: 0.9141\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.2235 - accuracy: 0.9127\n",
      "76/76 [==============================] - 2s 24ms/step - loss: 0.2519 - accuracy: 0.9123\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_30 (Conv1D)           (None, 89, 768)           5376      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling (None, 44, 768)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_31 (Conv1D)           (None, 43, 256)           393472    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_10 (Averag (None, 14, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_32 (Conv1D)           (None, 12, 256)           196864    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_10  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 6)                 3078      \n",
      "=================================================================\n",
      "Total params: 993,030\n",
      "Trainable params: 993,030\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 768, k_conv_1 = 2,  n_conv_2 = 256, k_conv_2 = 2, \n",
      "          n_conv_3 = 256,  k_conv_3 = 3,  maxpooling_pool_size = 2,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 512, dropout_1 = 0.2,\n",
      "          n_dense_2 = 512, dropout_2 = 0.3, activation_conv=  elu,\n",
      "          activation_dense=  elu\n",
      "Epoch 1/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 1.2287 - accuracy: 0.4798\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 1.0964 - accuracy: 0.5334\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 1.0144 - accuracy: 0.5720\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.9643 - accuracy: 0.5952\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.9066 - accuracy: 0.6217\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.8461 - accuracy: 0.6489\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.7814 - accuracy: 0.6766 0s - loss: 0\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.7384 - accuracy: 0.6951\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.6939 - accuracy: 0.7151\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.6648 - accuracy: 0.7247\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.6309 - accuracy: 0.7385\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.6024 - accuracy: 0.7516\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.5711 - accuracy: 0.7688\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.5441 - accuracy: 0.7811\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.5205 - accuracy: 0.7902\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.5019 - accuracy: 0.8002\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.4717 - accuracy: 0.8157\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.4659 - accuracy: 0.8186\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.4510 - accuracy: 0.8230\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.4438 - accuracy: 0.8269\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.4382 - accuracy: 0.8277\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.4210 - accuracy: 0.8364\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3977 - accuracy: 0.8457\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3894 - accuracy: 0.8480\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3964 - accuracy: 0.8456\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3662 - accuracy: 0.8585\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3677 - accuracy: 0.8567\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3519 - accuracy: 0.8628\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3423 - accuracy: 0.8683\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3384 - accuracy: 0.8678\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3362 - accuracy: 0.8673\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3278 - accuracy: 0.8702\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3194 - accuracy: 0.8772\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3153 - accuracy: 0.8771\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3052 - accuracy: 0.8810\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3031 - accuracy: 0.8788\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3059 - accuracy: 0.8787\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2976 - accuracy: 0.8837\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2845 - accuracy: 0.8869\n",
      "Epoch 40/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2838 - accuracy: 0.8894\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2771 - accuracy: 0.8926\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2829 - accuracy: 0.8881\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2757 - accuracy: 0.8920\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2670 - accuracy: 0.8956\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2671 - accuracy: 0.8966\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2614 - accuracy: 0.8974\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2548 - accuracy: 0.9012\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2545 - accuracy: 0.9020\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2417 - accuracy: 0.9037\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2498 - accuracy: 0.9023\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2358 - accuracy: 0.9087\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2405 - accuracy: 0.9075\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2348 - accuracy: 0.9084\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2351 - accuracy: 0.9102\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2325 - accuracy: 0.9085\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2290 - accuracy: 0.9112\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2175 - accuracy: 0.9159\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2285 - accuracy: 0.9132\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2192 - accuracy: 0.9150\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2173 - accuracy: 0.9171\n",
      "76/76 [==============================] - 1s 16ms/step - loss: 0.2619 - accuracy: 0.9115\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_33 (Conv1D)           (None, 89, 768)           5376      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling (None, 44, 768)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_34 (Conv1D)           (None, 43, 256)           393472    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_11 (Averag (None, 14, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_35 (Conv1D)           (None, 12, 256)           196864    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_11  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 6)                 3078      \n",
      "=================================================================\n",
      "Total params: 993,030\n",
      "Trainable params: 993,030\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 768, k_conv_1 = 2,  n_conv_2 = 256, k_conv_2 = 2, \n",
      "          n_conv_3 = 256,  k_conv_3 = 3,  maxpooling_pool_size = 2,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 512, dropout_1 = 0.2,\n",
      "          n_dense_2 = 512, dropout_2 = 0.3, activation_conv=  elu,\n",
      "          activation_dense=  elu\n",
      "Epoch 1/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 1.2212 - accuracy: 0.4807\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 1.0958 - accuracy: 0.5282\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 1.0289 - accuracy: 0.5593\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.9766 - accuracy: 0.5893\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.9177 - accuracy: 0.6163\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.8642 - accuracy: 0.6357\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.7842 - accuracy: 0.6764\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - ETA: 0s - loss: 0.7440 - accuracy: 0.69 - 6s 40ms/step - loss: 0.7442 - accuracy: 0.6925\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.7007 - accuracy: 0.7103\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.6581 - accuracy: 0.7286\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.6277 - accuracy: 0.7448\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.5936 - accuracy: 0.7599\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.5652 - accuracy: 0.7726\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.5437 - accuracy: 0.7818\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.5199 - accuracy: 0.7933\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.4977 - accuracy: 0.8039\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.4753 - accuracy: 0.8155\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.4635 - accuracy: 0.8198\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.4455 - accuracy: 0.8264\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.4367 - accuracy: 0.8311\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.4229 - accuracy: 0.8375\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.4085 - accuracy: 0.8399\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3944 - accuracy: 0.8491\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3880 - accuracy: 0.8488\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3825 - accuracy: 0.8500\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3703 - accuracy: 0.8564\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3662 - accuracy: 0.8572\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3584 - accuracy: 0.8599\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3551 - accuracy: 0.8594\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3407 - accuracy: 0.8665\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3331 - accuracy: 0.8684\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3271 - accuracy: 0.8733\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3230 - accuracy: 0.8743\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3223 - accuracy: 0.8726\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3099 - accuracy: 0.8759\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3062 - accuracy: 0.8768\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3107 - accuracy: 0.8774\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2967 - accuracy: 0.8824\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2904 - accuracy: 0.8848\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2954 - accuracy: 0.8838\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2798 - accuracy: 0.8892\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2882 - accuracy: 0.8838\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2788 - accuracy: 0.8888\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2747 - accuracy: 0.8916\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2653 - accuracy: 0.8938\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2560 - accuracy: 0.8980\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2620 - accuracy: 0.8958\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2560 - accuracy: 0.8982\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2530 - accuracy: 0.8975\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2501 - accuracy: 0.8996\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2511 - accuracy: 0.8984\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2406 - accuracy: 0.9032\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.2497 - accuracy: 0.8987\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2349 - accuracy: 0.9046\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2354 - accuracy: 0.9065\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2402 - accuracy: 0.9040\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2334 - accuracy: 0.9065\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2316 - accuracy: 0.9070\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2229 - accuracy: 0.9109\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2274 - accuracy: 0.9091\n",
      "76/76 [==============================] - 1s 16ms/step - loss: 0.2708 - accuracy: 0.9028\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_36 (Conv1D)           (None, 89, 768)           5376      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling (None, 44, 768)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_37 (Conv1D)           (None, 43, 256)           393472    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_12 (Averag (None, 14, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_38 (Conv1D)           (None, 12, 256)           196864    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_12  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 6)                 3078      \n",
      "=================================================================\n",
      "Total params: 993,030\n",
      "Trainable params: 993,030\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 768, k_conv_1 = 2,  n_conv_2 = 256, k_conv_2 = 2, \n",
      "          n_conv_3 = 256,  k_conv_3 = 3,  maxpooling_pool_size = 2,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 512, dropout_1 = 0.2,\n",
      "          n_dense_2 = 512, dropout_2 = 0.3, activation_conv=  elu,\n",
      "          activation_dense=  elu\n",
      "Epoch 1/60\n",
      "  1/152 [..............................] - ETA: 4s - loss: 1.8005 - accuracy: 0.1914WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0051s vs `on_train_batch_end` time: 0.0345s). Check your callbacks.\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 1.2072 - accuracy: 0.4867\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 1.0945 - accuracy: 0.5267\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 1.0208 - accuracy: 0.5678\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.9798 - accuracy: 0.5889\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.9243 - accuracy: 0.6141\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.8618 - accuracy: 0.6414\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.7871 - accuracy: 0.6726\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.7536 - accuracy: 0.6840\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.6914 - accuracy: 0.7127\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.6616 - accuracy: 0.7283\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.6315 - accuracy: 0.7407\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.5963 - accuracy: 0.7597\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.5713 - accuracy: 0.7682\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.5421 - accuracy: 0.7821\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.5223 - accuracy: 0.7934\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.4918 - accuracy: 0.8053 0s - loss: 0.488\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.4859 - accuracy: 0.8097\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.4669 - accuracy: 0.8172\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.4420 - accuracy: 0.8294\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.4238 - accuracy: 0.8338\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.4257 - accuracy: 0.8367\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.4113 - accuracy: 0.8412\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3979 - accuracy: 0.8441\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3899 - accuracy: 0.8466\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3752 - accuracy: 0.8531\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3684 - accuracy: 0.8558\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3618 - accuracy: 0.8572\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3587 - accuracy: 0.8607 0s - los\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3454 - accuracy: 0.8656\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3422 - accuracy: 0.8671\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3324 - accuracy: 0.8695\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3212 - accuracy: 0.8753\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3212 - accuracy: 0.8751\n",
      "Epoch 34/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3168 - accuracy: 0.8776\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3161 - accuracy: 0.8778\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3095 - accuracy: 0.8793\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3004 - accuracy: 0.8836\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2860 - accuracy: 0.8872\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2938 - accuracy: 0.8853\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2909 - accuracy: 0.8867\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2760 - accuracy: 0.8917\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2793 - accuracy: 0.8914\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2677 - accuracy: 0.8957\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2691 - accuracy: 0.8962\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2715 - accuracy: 0.8935\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2643 - accuracy: 0.8986\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2587 - accuracy: 0.8995\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2533 - accuracy: 0.9015\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2473 - accuracy: 0.9041\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2632 - accuracy: 0.8982\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2369 - accuracy: 0.9070\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2470 - accuracy: 0.9054\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2284 - accuracy: 0.9113\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2392 - accuracy: 0.9063\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2342 - accuracy: 0.9093\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2322 - accuracy: 0.9090\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2245 - accuracy: 0.9119\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2245 - accuracy: 0.9135\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2273 - accuracy: 0.9129\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2202 - accuracy: 0.9160\n",
      "76/76 [==============================] - 1s 15ms/step - loss: 0.2593 - accuracy: 0.9145\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_39 (Conv1D)           (None, 88, 512)           5120      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling (None, 29, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_40 (Conv1D)           (None, 28, 256)           262400    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_13 (Averag (None, 14, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_41 (Conv1D)           (None, 13, 256)           131328    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_13  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 384)               98688     \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 256)               98560     \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 6)                 1542      \n",
      "=================================================================\n",
      "Total params: 597,638\n",
      "Trainable params: 597,638\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 512, k_conv_1 = 3,  n_conv_2 = 256, k_conv_2 = 2, \n",
      "          n_conv_3 = 256,  k_conv_3 = 2,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 2,  n_dense_1 = 384, dropout_1 = 0.3,\n",
      "          n_dense_2 = 256, dropout_2 = 0.3, activation_conv=  relu,\n",
      "          activation_dense=  relu\n",
      "Epoch 1/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 1.1082 - accuracy: 0.5316\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.7330 - accuracy: 0.7038\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.5665 - accuracy: 0.7828\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.4948 - accuracy: 0.8108\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.4114 - accuracy: 0.8486\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.3869 - accuracy: 0.8548\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.3549 - accuracy: 0.8677\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.3321 - accuracy: 0.8777\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.3191 - accuracy: 0.8826\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.3069 - accuracy: 0.8871\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.2947 - accuracy: 0.8915\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.2875 - accuracy: 0.8928\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.2822 - accuracy: 0.8973\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.2700 - accuracy: 0.8999\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.2592 - accuracy: 0.9041\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.2616 - accuracy: 0.9044\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.2510 - accuracy: 0.9064\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.2396 - accuracy: 0.9114\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.2425 - accuracy: 0.9107\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.2287 - accuracy: 0.9166\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.2258 - accuracy: 0.9172\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.2145 - accuracy: 0.9209\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.2171 - accuracy: 0.9203\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.2118 - accuracy: 0.9225\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.2100 - accuracy: 0.9230\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.2125 - accuracy: 0.9203\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.2066 - accuracy: 0.9226\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.1964 - accuracy: 0.9270\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.1898 - accuracy: 0.9276\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.1827 - accuracy: 0.9304\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.1871 - accuracy: 0.9303\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.1837 - accuracy: 0.9316\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.1692 - accuracy: 0.9374\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.1731 - accuracy: 0.9342\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.1707 - accuracy: 0.9351\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1659 - accuracy: 0.9379\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1660 - accuracy: 0.9374\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1608 - accuracy: 0.9380\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.1720 - accuracy: 0.9355\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1542 - accuracy: 0.9421\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.1584 - accuracy: 0.9407\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1482 - accuracy: 0.9433\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.1538 - accuracy: 0.9434\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.1484 - accuracy: 0.9439\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1478 - accuracy: 0.9449\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.1446 - accuracy: 0.9452\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1430 - accuracy: 0.9444\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1384 - accuracy: 0.9480\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.1362 - accuracy: 0.9500\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.1371 - accuracy: 0.9476\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1288 - accuracy: 0.9511\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1262 - accuracy: 0.9536\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1394 - accuracy: 0.9480 0s - loss: 0.1401 - accu\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1375 - accuracy: 0.9498\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1216 - accuracy: 0.9538\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1160 - accuracy: 0.9559\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.1221 - accuracy: 0.9524\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.1251 - accuracy: 0.9533\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.1171 - accuracy: 0.9556\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1110 - accuracy: 0.9578\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 0.2057 - accuracy: 0.9399\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_42 (Conv1D)           (None, 88, 512)           5120      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling (None, 29, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_43 (Conv1D)           (None, 28, 256)           262400    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_14 (Averag (None, 14, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_44 (Conv1D)           (None, 13, 256)           131328    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_14  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 384)               98688     \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 256)               98560     \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 6)                 1542      \n",
      "=================================================================\n",
      "Total params: 597,638\n",
      "Trainable params: 597,638\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 512, k_conv_1 = 3,  n_conv_2 = 256, k_conv_2 = 2, \n",
      "          n_conv_3 = 256,  k_conv_3 = 2,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 2,  n_dense_1 = 384, dropout_1 = 0.3,\n",
      "          n_dense_2 = 256, dropout_2 = 0.3, activation_conv=  relu,\n",
      "          activation_dense=  relu\n",
      "Epoch 1/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 1.1006 - accuracy: 0.5377\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.7507 - accuracy: 0.6998\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.5617 - accuracy: 0.7891\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.4554 - accuracy: 0.8279\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.4163 - accuracy: 0.8425\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.3662 - accuracy: 0.8626\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.3516 - accuracy: 0.8670\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.3236 - accuracy: 0.8788\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.3111 - accuracy: 0.8830\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.2975 - accuracy: 0.8884\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.2874 - accuracy: 0.8919\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.2849 - accuracy: 0.8928\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.2721 - accuracy: 0.8960\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.2603 - accuracy: 0.9006\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.2523 - accuracy: 0.9055\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.2542 - accuracy: 0.9039\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.2433 - accuracy: 0.9093\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.2369 - accuracy: 0.9126\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.2327 - accuracy: 0.9132\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.2263 - accuracy: 0.9163\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.2200 - accuracy: 0.9189\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.2147 - accuracy: 0.9208\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.2051 - accuracy: 0.9257\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.2122 - accuracy: 0.9211\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1950 - accuracy: 0.9277\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.2016 - accuracy: 0.9267\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1913 - accuracy: 0.9293\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.1866 - accuracy: 0.9319\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.1938 - accuracy: 0.9287\n",
      "Epoch 30/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1802 - accuracy: 0.9348\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.1844 - accuracy: 0.9311\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.1728 - accuracy: 0.9371\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1678 - accuracy: 0.9382\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1731 - accuracy: 0.9354\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1694 - accuracy: 0.9381\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.1655 - accuracy: 0.9381\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1589 - accuracy: 0.9412\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1583 - accuracy: 0.9421\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.1576 - accuracy: 0.9418\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1496 - accuracy: 0.9443\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1474 - accuracy: 0.9458\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1546 - accuracy: 0.9420\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.1479 - accuracy: 0.9448\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1392 - accuracy: 0.9482\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.1405 - accuracy: 0.9477\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.1412 - accuracy: 0.9484\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1341 - accuracy: 0.9495\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1320 - accuracy: 0.9499\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.1389 - accuracy: 0.9486\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1351 - accuracy: 0.9496\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1305 - accuracy: 0.9510\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1243 - accuracy: 0.9542\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.1235 - accuracy: 0.9544\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.1237 - accuracy: 0.9541\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1160 - accuracy: 0.9572\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1193 - accuracy: 0.9563\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1197 - accuracy: 0.9549\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.1119 - accuracy: 0.9583\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.1143 - accuracy: 0.9574\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1077 - accuracy: 0.9606\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 0.2300 - accuracy: 0.9364\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_45 (Conv1D)           (None, 88, 512)           5120      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling (None, 29, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_46 (Conv1D)           (None, 28, 256)           262400    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_15 (Averag (None, 14, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_47 (Conv1D)           (None, 13, 256)           131328    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_15  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 384)               98688     \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 256)               98560     \n",
      "_________________________________________________________________\n",
      "dropout_31 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 6)                 1542      \n",
      "=================================================================\n",
      "Total params: 597,638\n",
      "Trainable params: 597,638\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 512, k_conv_1 = 3,  n_conv_2 = 256, k_conv_2 = 2, \n",
      "          n_conv_3 = 256,  k_conv_3 = 2,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 2,  n_dense_1 = 384, dropout_1 = 0.3,\n",
      "          n_dense_2 = 256, dropout_2 = 0.3, activation_conv=  relu,\n",
      "          activation_dense=  relu\n",
      "Epoch 1/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 1.1055 - accuracy: 0.5319\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.7553 - accuracy: 0.6937\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.5781 - accuracy: 0.7792\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.4808 - accuracy: 0.8207\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.4310 - accuracy: 0.8382\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.3865 - accuracy: 0.8563\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.3481 - accuracy: 0.8699\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.3402 - accuracy: 0.8735\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.3119 - accuracy: 0.8829\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.3086 - accuracy: 0.8839\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.3067 - accuracy: 0.8859\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.2847 - accuracy: 0.8933\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.2758 - accuracy: 0.8971\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.2743 - accuracy: 0.8981\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.2669 - accuracy: 0.9001\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.2567 - accuracy: 0.9038\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.2489 - accuracy: 0.9067\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.2514 - accuracy: 0.9072\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.2384 - accuracy: 0.9116\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.2317 - accuracy: 0.9165\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.2252 - accuracy: 0.9162\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.2183 - accuracy: 0.9192\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.2218 - accuracy: 0.9181\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.2138 - accuracy: 0.9209\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.2071 - accuracy: 0.9227\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.2061 - accuracy: 0.9241\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.2007 - accuracy: 0.9261\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.1946 - accuracy: 0.9284\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1925 - accuracy: 0.9285\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1919 - accuracy: 0.9282\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.1838 - accuracy: 0.9320\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1762 - accuracy: 0.9349\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1769 - accuracy: 0.9359\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.1755 - accuracy: 0.9353\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1745 - accuracy: 0.9353\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.1718 - accuracy: 0.9369\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1629 - accuracy: 0.9397\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.1606 - accuracy: 0.9404\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1657 - accuracy: 0.9373\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1542 - accuracy: 0.9419\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.1555 - accuracy: 0.9423\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.1584 - accuracy: 0.9409\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1562 - accuracy: 0.9418 \n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1463 - accuracy: 0.9458\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.1421 - accuracy: 0.9476\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.1546 - accuracy: 0.9433\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.1387 - accuracy: 0.9483\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1413 - accuracy: 0.9481\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.1390 - accuracy: 0.9486\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1369 - accuracy: 0.9481\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.1250 - accuracy: 0.9528\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1290 - accuracy: 0.9516\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1305 - accuracy: 0.9501\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.1215 - accuracy: 0.9546 0s -\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.1310 - accuracy: 0.9516\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.1274 - accuracy: 0.9516\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.1222 - accuracy: 0.9544\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1235 - accuracy: 0.9540\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 4s 24ms/step - loss: 0.1241 - accuracy: 0.9533\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 4s 23ms/step - loss: 0.1149 - accuracy: 0.9570\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 0.2247 - accuracy: 0.9350\n",
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_48 (Conv1D)           (None, 89, 512)           3584      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_16 (MaxPooling (None, 44, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_49 (Conv1D)           (None, 43, 256)           262400    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_16 (Averag (None, 14, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_50 (Conv1D)           (None, 13, 512)           262656    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_16  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 384)               196992    \n",
      "_________________________________________________________________\n",
      "dropout_32 (Dropout)         (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 384)               147840    \n",
      "_________________________________________________________________\n",
      "dropout_33 (Dropout)         (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 6)                 2310      \n",
      "=================================================================\n",
      "Total params: 875,782\n",
      "Trainable params: 875,782\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 512, k_conv_1 = 2,  n_conv_2 = 256, k_conv_2 = 2, \n",
      "          n_conv_3 = 512,  k_conv_3 = 2,  maxpooling_pool_size = 2,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 384, dropout_1 = 0.2,\n",
      "          n_dense_2 = 384, dropout_2 = 0.3, activation_conv=  elu,\n",
      "          activation_dense=  elu\n",
      "Epoch 1/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 1.2381 - accuracy: 0.4763\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 4s 30ms/step - loss: 1.1099 - accuracy: 0.5225\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 1.0407 - accuracy: 0.5573\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 4s 30ms/step - loss: 0.9878 - accuracy: 0.5828\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.9398 - accuracy: 0.6104\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.8944 - accuracy: 0.6276\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 4s 30ms/step - loss: 0.8528 - accuracy: 0.6487\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.8234 - accuracy: 0.6572\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 4s 30ms/step - loss: 0.7636 - accuracy: 0.6857\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.7094 - accuracy: 0.7122\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 4s 30ms/step - loss: 0.6855 - accuracy: 0.7194\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.6508 - accuracy: 0.7334\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.6083 - accuracy: 0.7553\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.5772 - accuracy: 0.7669\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.5700 - accuracy: 0.7704\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.5496 - accuracy: 0.7811\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.5230 - accuracy: 0.7932\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.4988 - accuracy: 0.8058\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.4883 - accuracy: 0.8088\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 4s 30ms/step - loss: 0.4713 - accuracy: 0.8160\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 4s 30ms/step - loss: 0.4616 - accuracy: 0.8180\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.4517 - accuracy: 0.8256\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.4258 - accuracy: 0.8350\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 4s 30ms/step - loss: 0.4229 - accuracy: 0.8363\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.4072 - accuracy: 0.8427\n",
      "Epoch 26/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 5s 30ms/step - loss: 0.3880 - accuracy: 0.8479\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.3902 - accuracy: 0.8491\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.3757 - accuracy: 0.8544\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.3705 - accuracy: 0.8571\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.3703 - accuracy: 0.8583\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.3627 - accuracy: 0.8600\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.3500 - accuracy: 0.8645\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 4s 30ms/step - loss: 0.3466 - accuracy: 0.8663\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.3464 - accuracy: 0.8670\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.3284 - accuracy: 0.8741\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 4s 30ms/step - loss: 0.3314 - accuracy: 0.8715\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.3259 - accuracy: 0.8748\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 4s 30ms/step - loss: 0.3147 - accuracy: 0.8798\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.3172 - accuracy: 0.8770\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.3105 - accuracy: 0.8799\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 4s 30ms/step - loss: 0.3123 - accuracy: 0.8787 1s\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.3059 - accuracy: 0.8827\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2986 - accuracy: 0.8844\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2964 - accuracy: 0.8858\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2925 - accuracy: 0.8865\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2865 - accuracy: 0.8883\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2840 - accuracy: 0.8894\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 4s 30ms/step - loss: 0.2780 - accuracy: 0.8937\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2784 - accuracy: 0.8924\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2759 - accuracy: 0.8926\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2842 - accuracy: 0.8893\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2682 - accuracy: 0.8950\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2715 - accuracy: 0.8955\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2601 - accuracy: 0.8993\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2566 - accuracy: 0.8991\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2488 - accuracy: 0.9026\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2569 - accuracy: 0.9007\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2554 - accuracy: 0.9037\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2442 - accuracy: 0.9058\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 4s 30ms/step - loss: 0.2525 - accuracy: 0.9016\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 0.2528 - accuracy: 0.9084\n",
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_51 (Conv1D)           (None, 89, 512)           3584      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_17 (MaxPooling (None, 44, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_52 (Conv1D)           (None, 43, 256)           262400    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_17 (Averag (None, 14, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_53 (Conv1D)           (None, 13, 512)           262656    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_17  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 384)               196992    \n",
      "_________________________________________________________________\n",
      "dropout_34 (Dropout)         (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 384)               147840    \n",
      "_________________________________________________________________\n",
      "dropout_35 (Dropout)         (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 6)                 2310      \n",
      "=================================================================\n",
      "Total params: 875,782\n",
      "Trainable params: 875,782\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 512, k_conv_1 = 2,  n_conv_2 = 256, k_conv_2 = 2, \n",
      "          n_conv_3 = 512,  k_conv_3 = 2,  maxpooling_pool_size = 2,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 384, dropout_1 = 0.2,\n",
      "          n_dense_2 = 384, dropout_2 = 0.3, activation_conv=  elu,\n",
      "          activation_dense=  elu\n",
      "Epoch 1/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 1.2239 - accuracy: 0.4807\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 4s 30ms/step - loss: 1.0952 - accuracy: 0.5296\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 1.0233 - accuracy: 0.5679\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 4s 30ms/step - loss: 0.9738 - accuracy: 0.5953\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.9242 - accuracy: 0.6180\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 4s 30ms/step - loss: 0.9048 - accuracy: 0.6233\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 4s 30ms/step - loss: 0.8549 - accuracy: 0.6415\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 4s 30ms/step - loss: 0.8192 - accuracy: 0.6549\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.7836 - accuracy: 0.6743\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.7489 - accuracy: 0.6873\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.7141 - accuracy: 0.7033\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 4s 30ms/step - loss: 0.6731 - accuracy: 0.7218\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.6436 - accuracy: 0.7354\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.6182 - accuracy: 0.7490\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.5807 - accuracy: 0.7698\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.5472 - accuracy: 0.7838\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.5510 - accuracy: 0.7815\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 4s 30ms/step - loss: 0.5200 - accuracy: 0.7957\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.4862 - accuracy: 0.8113\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.4859 - accuracy: 0.8105\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.4707 - accuracy: 0.8181\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.4477 - accuracy: 0.8258\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.4384 - accuracy: 0.8304\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.4240 - accuracy: 0.8381\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.4192 - accuracy: 0.8380\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.4118 - accuracy: 0.8402\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 4s 30ms/step - loss: 0.4046 - accuracy: 0.8412\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.3958 - accuracy: 0.8467\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 4s 30ms/step - loss: 0.3834 - accuracy: 0.8523\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 4s 30ms/step - loss: 0.3756 - accuracy: 0.8534\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.3767 - accuracy: 0.8532\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.3643 - accuracy: 0.8584\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.3612 - accuracy: 0.8592\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 4s 30ms/step - loss: 0.3460 - accuracy: 0.8653\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.3474 - accuracy: 0.8638\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.3306 - accuracy: 0.8723\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.3335 - accuracy: 0.8703\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.3224 - accuracy: 0.8738\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.3157 - accuracy: 0.8774\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.3184 - accuracy: 0.8756\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.3125 - accuracy: 0.8780\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.3007 - accuracy: 0.8824 0s - loss: 0.2\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.3091 - accuracy: 0.8776\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2996 - accuracy: 0.8819\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2945 - accuracy: 0.8834\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.2908 - accuracy: 0.8876\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2788 - accuracy: 0.8905\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2823 - accuracy: 0.8887\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 4s 30ms/step - loss: 0.2831 - accuracy: 0.8895\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2716 - accuracy: 0.8937\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2730 - accuracy: 0.8933\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2729 - accuracy: 0.8924\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2710 - accuracy: 0.8928\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2700 - accuracy: 0.8936\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2622 - accuracy: 0.8983\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2646 - accuracy: 0.8962\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2565 - accuracy: 0.9003\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2486 - accuracy: 0.9021\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2514 - accuracy: 0.9014\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2466 - accuracy: 0.9026\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 0.2706 - accuracy: 0.9037\n",
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_54 (Conv1D)           (None, 89, 512)           3584      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_18 (MaxPooling (None, 44, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_55 (Conv1D)           (None, 43, 256)           262400    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_18 (Averag (None, 14, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_56 (Conv1D)           (None, 13, 512)           262656    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_18  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 384)               196992    \n",
      "_________________________________________________________________\n",
      "dropout_36 (Dropout)         (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 384)               147840    \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 6)                 2310      \n",
      "=================================================================\n",
      "Total params: 875,782\n",
      "Trainable params: 875,782\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 512, k_conv_1 = 2,  n_conv_2 = 256, k_conv_2 = 2, \n",
      "          n_conv_3 = 512,  k_conv_3 = 2,  maxpooling_pool_size = 2,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 384, dropout_1 = 0.2,\n",
      "          n_dense_2 = 384, dropout_2 = 0.3, activation_conv=  elu,\n",
      "          activation_dense=  elu\n",
      "Epoch 1/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 1.2210 - accuracy: 0.4788\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 1.1114 - accuracy: 0.5278\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 4s 30ms/step - loss: 1.0629 - accuracy: 0.5466\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.9852 - accuracy: 0.5865\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.9409 - accuracy: 0.6068\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.8882 - accuracy: 0.6325\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.8552 - accuracy: 0.6457\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.8036 - accuracy: 0.6653\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.7520 - accuracy: 0.6879\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.7116 - accuracy: 0.7039\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.6740 - accuracy: 0.7233\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.6438 - accuracy: 0.7374\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.6142 - accuracy: 0.7479\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.5921 - accuracy: 0.7575\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.5577 - accuracy: 0.7774\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.5436 - accuracy: 0.7807\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 4s 30ms/step - loss: 0.5328 - accuracy: 0.7886\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.5061 - accuracy: 0.7991\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.4861 - accuracy: 0.8096\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.4635 - accuracy: 0.8188\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.4542 - accuracy: 0.8219\n",
      "Epoch 22/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 5s 30ms/step - loss: 0.4502 - accuracy: 0.8224\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.4322 - accuracy: 0.8326\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.4203 - accuracy: 0.8375\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.4081 - accuracy: 0.8408\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.4009 - accuracy: 0.8421\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.3866 - accuracy: 0.8507\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.3862 - accuracy: 0.8489\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.3775 - accuracy: 0.8531\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.3743 - accuracy: 0.8544\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.3640 - accuracy: 0.8580\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.3547 - accuracy: 0.8635\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.3544 - accuracy: 0.8626\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.3409 - accuracy: 0.8689\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.3386 - accuracy: 0.8675\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.3387 - accuracy: 0.8688\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.3254 - accuracy: 0.8737\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.3236 - accuracy: 0.8749\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.3119 - accuracy: 0.8791\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.3156 - accuracy: 0.8790\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.3139 - accuracy: 0.8794\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2951 - accuracy: 0.8855\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.3078 - accuracy: 0.8802 1s\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2927 - accuracy: 0.8877\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2907 - accuracy: 0.8876\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2975 - accuracy: 0.8837\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2845 - accuracy: 0.8909\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2823 - accuracy: 0.8901\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2778 - accuracy: 0.8912\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2823 - accuracy: 0.8916\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2743 - accuracy: 0.8937\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2697 - accuracy: 0.8965\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2623 - accuracy: 0.8975\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2709 - accuracy: 0.8964\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2727 - accuracy: 0.8953\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2690 - accuracy: 0.8968\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2570 - accuracy: 0.8985\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2584 - accuracy: 0.8993\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2550 - accuracy: 0.9004\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.2490 - accuracy: 0.9035\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 0.2558 - accuracy: 0.9099\n",
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_57 (Conv1D)           (None, 88, 512)           5120      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_19 (MaxPooling (None, 44, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_58 (Conv1D)           (None, 43, 512)           524800    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_19 (Averag (None, 21, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_59 (Conv1D)           (None, 20, 256)           262400    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_19  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 384)               98688     \n",
      "_________________________________________________________________\n",
      "dropout_38 (Dropout)         (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 512)               197120    \n",
      "_________________________________________________________________\n",
      "dropout_39 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 6)                 3078      \n",
      "=================================================================\n",
      "Total params: 1,091,206\n",
      "Trainable params: 1,091,206\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 512, k_conv_1 = 3,  n_conv_2 = 512, k_conv_2 = 2, \n",
      "          n_conv_3 = 256,  k_conv_3 = 2,  maxpooling_pool_size = 2,\n",
      "          avepooling_pool_size = 2,  n_dense_1 = 384, dropout_1 = 0.2,\n",
      "          n_dense_2 = 512, dropout_2 = 0.2, activation_conv=  relu,\n",
      "          activation_dense=  relu\n",
      "Epoch 1/60\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 1.1134 - accuracy: 0.5295\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.7460 - accuracy: 0.6943 0s - loss: 0.7491 - accuracy: \n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.5338 - accuracy: 0.7942\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.4232 - accuracy: 0.8421\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.3776 - accuracy: 0.8578\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.3491 - accuracy: 0.8685\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.3310 - accuracy: 0.8751\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.3128 - accuracy: 0.8821\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.2971 - accuracy: 0.8865\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.2904 - accuracy: 0.8900\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.2792 - accuracy: 0.8957\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.2611 - accuracy: 0.9022\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.2527 - accuracy: 0.9046\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.2495 - accuracy: 0.9065\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.2497 - accuracy: 0.9057\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.2360 - accuracy: 0.9123\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.2280 - accuracy: 0.9140\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.2200 - accuracy: 0.9182\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.2112 - accuracy: 0.9219\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.2033 - accuracy: 0.9246\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.2118 - accuracy: 0.9222\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.1893 - accuracy: 0.9297\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.1961 - accuracy: 0.9279\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.1839 - accuracy: 0.9308\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.1881 - accuracy: 0.9298\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.1731 - accuracy: 0.9358\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.1806 - accuracy: 0.9336\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.1753 - accuracy: 0.9356\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.1784 - accuracy: 0.9339\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.1621 - accuracy: 0.9395\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.1636 - accuracy: 0.9395\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.1578 - accuracy: 0.9415\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.1621 - accuracy: 0.9390\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.1501 - accuracy: 0.9450\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.1519 - accuracy: 0.9425\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.1489 - accuracy: 0.9444\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.1451 - accuracy: 0.9438\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.1399 - accuracy: 0.9479\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.1355 - accuracy: 0.9496\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.1351 - accuracy: 0.9492\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.1331 - accuracy: 0.9499\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.1284 - accuracy: 0.9512\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.1296 - accuracy: 0.9500\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.1271 - accuracy: 0.9523\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.1215 - accuracy: 0.9537\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.1228 - accuracy: 0.9529\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.1204 - accuracy: 0.9562\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.1124 - accuracy: 0.9568\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.1170 - accuracy: 0.9559\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.1097 - accuracy: 0.9585\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.1167 - accuracy: 0.9557\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.1107 - accuracy: 0.9568\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.1054 - accuracy: 0.9596\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.1027 - accuracy: 0.9614\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.1092 - accuracy: 0.9593\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.1065 - accuracy: 0.9598\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.1001 - accuracy: 0.9613\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.0974 - accuracy: 0.9615\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.0929 - accuracy: 0.9641\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.1036 - accuracy: 0.9606\n",
      "76/76 [==============================] - 1s 17ms/step - loss: 0.2054 - accuracy: 0.9427\n",
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_60 (Conv1D)           (None, 88, 512)           5120      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_20 (MaxPooling (None, 44, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_61 (Conv1D)           (None, 43, 512)           524800    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_20 (Averag (None, 21, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_62 (Conv1D)           (None, 20, 256)           262400    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_20  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 384)               98688     \n",
      "_________________________________________________________________\n",
      "dropout_40 (Dropout)         (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 512)               197120    \n",
      "_________________________________________________________________\n",
      "dropout_41 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 6)                 3078      \n",
      "=================================================================\n",
      "Total params: 1,091,206\n",
      "Trainable params: 1,091,206\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 512, k_conv_1 = 3,  n_conv_2 = 512, k_conv_2 = 2, \n",
      "          n_conv_3 = 256,  k_conv_3 = 2,  maxpooling_pool_size = 2,\n",
      "          avepooling_pool_size = 2,  n_dense_1 = 384, dropout_1 = 0.2,\n",
      "          n_dense_2 = 512, dropout_2 = 0.2, activation_conv=  relu,\n",
      "          activation_dense=  relu\n",
      "Epoch 1/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 1.0783 - accuracy: 0.5425\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.7301 - accuracy: 0.7030\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.5377 - accuracy: 0.7947\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.4380 - accuracy: 0.8337\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.3878 - accuracy: 0.8532\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.3565 - accuracy: 0.8651\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.3258 - accuracy: 0.8772\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.3098 - accuracy: 0.8819\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.3019 - accuracy: 0.8857\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.2862 - accuracy: 0.8928\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.2853 - accuracy: 0.8926\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.2609 - accuracy: 0.9008\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.2556 - accuracy: 0.9034\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.2579 - accuracy: 0.9030\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.2372 - accuracy: 0.9118\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.2375 - accuracy: 0.9096\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.2313 - accuracy: 0.9119\n",
      "Epoch 18/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 6s 39ms/step - loss: 0.2239 - accuracy: 0.9157\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.2180 - accuracy: 0.9194\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.2115 - accuracy: 0.9212\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.2093 - accuracy: 0.9216\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.1984 - accuracy: 0.9267\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.1991 - accuracy: 0.9259\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.1971 - accuracy: 0.9247\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.1897 - accuracy: 0.9275\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.1828 - accuracy: 0.9320\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.1789 - accuracy: 0.9324\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.1802 - accuracy: 0.9335\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.1783 - accuracy: 0.9324\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.1703 - accuracy: 0.9367\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.1667 - accuracy: 0.9390\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.1627 - accuracy: 0.9398\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.1669 - accuracy: 0.9388\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.1581 - accuracy: 0.9415\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.1525 - accuracy: 0.9426\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.1538 - accuracy: 0.9417 1s - l\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - ETA: 0s - loss: 0.1438 - accuracy: 0.94 - 6s 39ms/step - loss: 0.1441 - accuracy: 0.9453\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.1520 - accuracy: 0.9426\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.1465 - accuracy: 0.9442\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.1349 - accuracy: 0.9477\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.1473 - accuracy: 0.9444\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.1294 - accuracy: 0.9516\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.1316 - accuracy: 0.9498\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.1287 - accuracy: 0.9510\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.1312 - accuracy: 0.9504\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.1228 - accuracy: 0.9544\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.1248 - accuracy: 0.9531\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.1180 - accuracy: 0.9557\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.1219 - accuracy: 0.9538\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.1167 - accuracy: 0.9555\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.1131 - accuracy: 0.9560\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.1182 - accuracy: 0.9557\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.1125 - accuracy: 0.9579 0s - loss: 0.1120 - accura\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.1075 - accuracy: 0.9592\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.1036 - accuracy: 0.9599\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.1083 - accuracy: 0.9596\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.1015 - accuracy: 0.9610\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.0991 - accuracy: 0.9611\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.1001 - accuracy: 0.9624\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.1010 - accuracy: 0.9624 0s - loss:\n",
      "76/76 [==============================] - 1s 15ms/step - loss: 0.2114 - accuracy: 0.9372\n",
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_63 (Conv1D)           (None, 88, 512)           5120      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_21 (MaxPooling (None, 44, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_64 (Conv1D)           (None, 43, 512)           524800    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_21 (Averag (None, 21, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_65 (Conv1D)           (None, 20, 256)           262400    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_21  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (None, 384)               98688     \n",
      "_________________________________________________________________\n",
      "dropout_42 (Dropout)         (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_64 (Dense)             (None, 512)               197120    \n",
      "_________________________________________________________________\n",
      "dropout_43 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 6)                 3078      \n",
      "=================================================================\n",
      "Total params: 1,091,206\n",
      "Trainable params: 1,091,206\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 512, k_conv_1 = 3,  n_conv_2 = 512, k_conv_2 = 2, \n",
      "          n_conv_3 = 256,  k_conv_3 = 2,  maxpooling_pool_size = 2,\n",
      "          avepooling_pool_size = 2,  n_dense_1 = 384, dropout_1 = 0.2,\n",
      "          n_dense_2 = 512, dropout_2 = 0.2, activation_conv=  relu,\n",
      "          activation_dense=  relu\n",
      "Epoch 1/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 1.0969 - accuracy: 0.5352\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.7666 - accuracy: 0.6869\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.5352 - accuracy: 0.7979\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.4300 - accuracy: 0.8374\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.3835 - accuracy: 0.8565\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.3434 - accuracy: 0.8727\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.3254 - accuracy: 0.8787\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.3188 - accuracy: 0.8811\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.2947 - accuracy: 0.8911\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.2870 - accuracy: 0.8926\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.2720 - accuracy: 0.8996\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.2594 - accuracy: 0.9035\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.2551 - accuracy: 0.9040\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.2394 - accuracy: 0.9113\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.2345 - accuracy: 0.9132\n",
      "Epoch 16/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 6s 39ms/step - loss: 0.2291 - accuracy: 0.9147\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.2265 - accuracy: 0.9163 0s - loss: 0.2252 - accuracy\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.2125 - accuracy: 0.9220\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.2083 - accuracy: 0.9235\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.2046 - accuracy: 0.9238\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.2205 - accuracy: 0.9180\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.1929 - accuracy: 0.9287\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.1880 - accuracy: 0.9311\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.1872 - accuracy: 0.9305\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.1821 - accuracy: 0.9325\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.1985 - accuracy: 0.9277\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.1802 - accuracy: 0.9325\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.1749 - accuracy: 0.9360\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.1650 - accuracy: 0.9392 0s - los\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.1644 - accuracy: 0.9396\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.1610 - accuracy: 0.9423\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.1597 - accuracy: 0.9395\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.1604 - accuracy: 0.9409\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.1523 - accuracy: 0.9437\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.1629 - accuracy: 0.9403\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.1439 - accuracy: 0.9452 0s - loss: 0.143\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.1510 - accuracy: 0.9440\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.1412 - accuracy: 0.9470\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.1390 - accuracy: 0.9475\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.1390 - accuracy: 0.9477\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.1321 - accuracy: 0.9512\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.1295 - accuracy: 0.9526\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.1264 - accuracy: 0.9524\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.1289 - accuracy: 0.9524\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.1240 - accuracy: 0.9536\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.1248 - accuracy: 0.9529\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.1218 - accuracy: 0.9534\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.1225 - accuracy: 0.9542\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.1177 - accuracy: 0.9563\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.1148 - accuracy: 0.9565\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.1178 - accuracy: 0.9575\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.1037 - accuracy: 0.9626\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.1048 - accuracy: 0.9609\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.1122 - accuracy: 0.9580\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.1061 - accuracy: 0.9606\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.1001 - accuracy: 0.9625\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.1075 - accuracy: 0.9606\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.0990 - accuracy: 0.9626\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.0921 - accuracy: 0.9646\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.0983 - accuracy: 0.9640\n",
      "76/76 [==============================] - 1s 15ms/step - loss: 0.2019 - accuracy: 0.9446\n",
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_66 (Conv1D)           (None, 89, 512)           3584      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_22 (MaxPooling (None, 29, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_67 (Conv1D)           (None, 28, 512)           524800    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_22 (Averag (None, 9, 512)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_68 (Conv1D)           (None, 8, 512)            524800    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_22  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_44 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_67 (Dense)             (None, 384)               196992    \n",
      "_________________________________________________________________\n",
      "dropout_45 (Dropout)         (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 6)                 2310      \n",
      "=================================================================\n",
      "Total params: 1,515,142\n",
      "Trainable params: 1,515,142\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 512, k_conv_1 = 2,  n_conv_2 = 512, k_conv_2 = 2, \n",
      "          n_conv_3 = 512,  k_conv_3 = 2,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 512, dropout_1 = 0.2,\n",
      "          n_dense_2 = 384, dropout_2 = 0.2, activation_conv=  elu,\n",
      "          activation_dense=  elu\n",
      "Epoch 1/60\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 1.2097 - accuracy: 0.4916\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 1.0977 - accuracy: 0.5373\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 1.0403 - accuracy: 0.5655\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.9886 - accuracy: 0.5818\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.9367 - accuracy: 0.6067\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.8812 - accuracy: 0.6325\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.8273 - accuracy: 0.6566\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.7659 - accuracy: 0.6863\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.7244 - accuracy: 0.6998\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.7029 - accuracy: 0.7124\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.6415 - accuracy: 0.7406\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.5995 - accuracy: 0.7585\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.5785 - accuracy: 0.7677\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.5543 - accuracy: 0.7795\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.5189 - accuracy: 0.7949\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.4923 - accuracy: 0.8049 0s - loss: 0.4926 - accura\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.4803 - accuracy: 0.8125\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.4575 - accuracy: 0.8211\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.4542 - accuracy: 0.8225\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.4351 - accuracy: 0.8310\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.4170 - accuracy: 0.8372 0s - los\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.4067 - accuracy: 0.8417\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.4020 - accuracy: 0.8418\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.3802 - accuracy: 0.8515\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.3742 - accuracy: 0.8535\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.3627 - accuracy: 0.8591\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.3539 - accuracy: 0.8636\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.3417 - accuracy: 0.8668\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.3462 - accuracy: 0.8662\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.3284 - accuracy: 0.8719\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.3306 - accuracy: 0.8716\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.3247 - accuracy: 0.8728\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.3111 - accuracy: 0.8783\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.3105 - accuracy: 0.8787\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.3037 - accuracy: 0.8813\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2953 - accuracy: 0.8840\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2877 - accuracy: 0.8876\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2840 - accuracy: 0.8888\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2864 - accuracy: 0.8881\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2854 - accuracy: 0.8891\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2738 - accuracy: 0.8925\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2679 - accuracy: 0.8958\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2681 - accuracy: 0.8926\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2555 - accuracy: 0.9012\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2687 - accuracy: 0.8947\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2530 - accuracy: 0.9000\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2482 - accuracy: 0.9017\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2473 - accuracy: 0.9039\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2421 - accuracy: 0.9035\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2563 - accuracy: 0.8997\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2372 - accuracy: 0.9059\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2314 - accuracy: 0.9078\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2292 - accuracy: 0.9104\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2325 - accuracy: 0.9087\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2262 - accuracy: 0.9101\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2325 - accuracy: 0.9091\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2157 - accuracy: 0.9161\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2241 - accuracy: 0.9114\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2169 - accuracy: 0.9143\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2101 - accuracy: 0.9173\n",
      "76/76 [==============================] - 1s 15ms/step - loss: 0.2745 - accuracy: 0.9041\n",
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_69 (Conv1D)           (None, 89, 512)           3584      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_23 (MaxPooling (None, 29, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_70 (Conv1D)           (None, 28, 512)           524800    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_23 (Averag (None, 9, 512)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_71 (Conv1D)           (None, 8, 512)            524800    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_23  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_46 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_70 (Dense)             (None, 384)               196992    \n",
      "_________________________________________________________________\n",
      "dropout_47 (Dropout)         (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_71 (Dense)             (None, 6)                 2310      \n",
      "=================================================================\n",
      "Total params: 1,515,142\n",
      "Trainable params: 1,515,142\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 512, k_conv_1 = 2,  n_conv_2 = 512, k_conv_2 = 2, \n",
      "          n_conv_3 = 512,  k_conv_3 = 2,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 512, dropout_1 = 0.2,\n",
      "          n_dense_2 = 384, dropout_2 = 0.2, activation_conv=  elu,\n",
      "          activation_dense=  elu\n",
      "Epoch 1/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 1.2116 - accuracy: 0.4805\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 1.0769 - accuracy: 0.5401\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 1.0229 - accuracy: 0.5656\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.9809 - accuracy: 0.5890\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.9196 - accuracy: 0.6156\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.8848 - accuracy: 0.6316\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.8308 - accuracy: 0.6556\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.7874 - accuracy: 0.6723\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.7423 - accuracy: 0.6935\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.7048 - accuracy: 0.7111\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.6482 - accuracy: 0.7390\n",
      "Epoch 12/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 5s 32ms/step - loss: 0.6214 - accuracy: 0.7520 0s - loss: 0.6229 - accura\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.6014 - accuracy: 0.7607\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.5638 - accuracy: 0.7754\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.5377 - accuracy: 0.7901\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.5050 - accuracy: 0.7995\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.4807 - accuracy: 0.8122\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.4596 - accuracy: 0.8225\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.4402 - accuracy: 0.8276\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.4276 - accuracy: 0.8336\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.4052 - accuracy: 0.8427\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.4075 - accuracy: 0.8422\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.4063 - accuracy: 0.8421\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.3832 - accuracy: 0.8531\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.3722 - accuracy: 0.8545\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.3579 - accuracy: 0.8620\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.3565 - accuracy: 0.8607\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.3446 - accuracy: 0.8634\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.3345 - accuracy: 0.8689\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.3268 - accuracy: 0.8718\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.3257 - accuracy: 0.8717\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.3163 - accuracy: 0.8756\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.3112 - accuracy: 0.8787\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.3037 - accuracy: 0.8809\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.3087 - accuracy: 0.8796\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2977 - accuracy: 0.8817\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2943 - accuracy: 0.8865\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2948 - accuracy: 0.8855\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2899 - accuracy: 0.8864\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2719 - accuracy: 0.8922\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2775 - accuracy: 0.8920\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2712 - accuracy: 0.8923\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2713 - accuracy: 0.8940\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2633 - accuracy: 0.8957\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2585 - accuracy: 0.8973\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2616 - accuracy: 0.8968\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2574 - accuracy: 0.8978\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2588 - accuracy: 0.8978\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2549 - accuracy: 0.8992\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2404 - accuracy: 0.9047\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2431 - accuracy: 0.9030\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2441 - accuracy: 0.9034\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2336 - accuracy: 0.9104\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2260 - accuracy: 0.9095\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2301 - accuracy: 0.9086\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2346 - accuracy: 0.9070\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2275 - accuracy: 0.9090\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2217 - accuracy: 0.9126\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2244 - accuracy: 0.9117\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.2210 - accuracy: 0.9121\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 0.2887 - accuracy: 0.8983\n",
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_72 (Conv1D)           (None, 89, 512)           3584      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_24 (MaxPooling (None, 29, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_73 (Conv1D)           (None, 28, 512)           524800    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_24 (Averag (None, 9, 512)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_74 (Conv1D)           (None, 8, 512)            524800    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_24  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_72 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_48 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_73 (Dense)             (None, 384)               196992    \n",
      "_________________________________________________________________\n",
      "dropout_49 (Dropout)         (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_74 (Dense)             (None, 6)                 2310      \n",
      "=================================================================\n",
      "Total params: 1,515,142\n",
      "Trainable params: 1,515,142\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 512, k_conv_1 = 2,  n_conv_2 = 512, k_conv_2 = 2, \n",
      "          n_conv_3 = 512,  k_conv_3 = 2,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 512, dropout_1 = 0.2,\n",
      "          n_dense_2 = 384, dropout_2 = 0.2, activation_conv=  elu,\n",
      "          activation_dense=  elu\n",
      "Epoch 1/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 1.2199 - accuracy: 0.4860\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 1.0912 - accuracy: 0.5433\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 1.0526 - accuracy: 0.5588\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.9993 - accuracy: 0.5844\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.9480 - accuracy: 0.6047\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.8935 - accuracy: 0.6279\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.8407 - accuracy: 0.6513\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.8026 - accuracy: 0.6668\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.7598 - accuracy: 0.6849\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.7280 - accuracy: 0.6983\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.6809 - accuracy: 0.7227\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.6443 - accuracy: 0.7365\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.6067 - accuracy: 0.7558\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.5741 - accuracy: 0.7717\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.5382 - accuracy: 0.7882\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.5266 - accuracy: 0.7919\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.4966 - accuracy: 0.8047\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.4720 - accuracy: 0.8147\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.4559 - accuracy: 0.8219\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.4531 - accuracy: 0.8229\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.4262 - accuracy: 0.8316\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.4148 - accuracy: 0.8387\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.3927 - accuracy: 0.8433\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.3854 - accuracy: 0.8505\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.3866 - accuracy: 0.8484\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.3750 - accuracy: 0.8550\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.3650 - accuracy: 0.8569\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.3523 - accuracy: 0.8630\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3509 - accuracy: 0.8629\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.3374 - accuracy: 0.8689\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.3373 - accuracy: 0.8704\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.3282 - accuracy: 0.8707\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.3280 - accuracy: 0.8721\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.3237 - accuracy: 0.8762\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.3073 - accuracy: 0.8817\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.3010 - accuracy: 0.8842\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2907 - accuracy: 0.8853\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.3037 - accuracy: 0.8832\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2871 - accuracy: 0.8867\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2829 - accuracy: 0.8894\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2728 - accuracy: 0.8937\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2814 - accuracy: 0.8904\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2807 - accuracy: 0.8901\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2662 - accuracy: 0.8970\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2665 - accuracy: 0.8956\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2552 - accuracy: 0.8989\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2586 - accuracy: 0.8989\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2558 - accuracy: 0.9006\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2551 - accuracy: 0.9005\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2408 - accuracy: 0.9031\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2499 - accuracy: 0.9017\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2437 - accuracy: 0.9042\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2394 - accuracy: 0.9074\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2375 - accuracy: 0.9057\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2257 - accuracy: 0.9106\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2377 - accuracy: 0.9054\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2301 - accuracy: 0.9097\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2252 - accuracy: 0.9132\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.2272 - accuracy: 0.9115\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.2159 - accuracy: 0.9166\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 0.2587 - accuracy: 0.9090\n",
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_75 (Conv1D)           (None, 88, 768)           7680      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_25 (MaxPooling (None, 44, 768)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_76 (Conv1D)           (None, 42, 256)           590080    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_25 (Averag (None, 14, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_77 (Conv1D)           (None, 12, 512)           393728    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_25  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_75 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_50 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_76 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_51 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_77 (Dense)             (None, 6)                 1542      \n",
      "=================================================================\n",
      "Total params: 1,387,014\n",
      "Trainable params: 1,387,014\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 768, k_conv_1 = 3,  n_conv_2 = 256, k_conv_2 = 3, \n",
      "          n_conv_3 = 512,  k_conv_3 = 3,  maxpooling_pool_size = 2,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 512, dropout_1 = 0.2,\n",
      "          n_dense_2 = 256, dropout_2 = 0.2, activation_conv=  relu,\n",
      "          activation_dense=  elu\n",
      "Epoch 1/60\n",
      "152/152 [==============================] - 7s 46ms/step - loss: 0.9951 - accuracy: 0.5795\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.6204 - accuracy: 0.7581\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.4499 - accuracy: 0.8337\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.3979 - accuracy: 0.8536\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.3508 - accuracy: 0.8707\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.3250 - accuracy: 0.8787\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 7s 46ms/step - loss: 0.3123 - accuracy: 0.8842\n",
      "Epoch 8/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 7s 45ms/step - loss: 0.3003 - accuracy: 0.8896\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.2765 - accuracy: 0.8971\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.2598 - accuracy: 0.9025\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.2580 - accuracy: 0.9027\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.2563 - accuracy: 0.9046\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.2452 - accuracy: 0.9081\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.2274 - accuracy: 0.9145\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.2258 - accuracy: 0.9149\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.2255 - accuracy: 0.9160\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.2117 - accuracy: 0.9206\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.2066 - accuracy: 0.9230\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.1989 - accuracy: 0.9246\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.1943 - accuracy: 0.9259\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.1981 - accuracy: 0.9253\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.1901 - accuracy: 0.9285\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.1776 - accuracy: 0.9336\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.1839 - accuracy: 0.9301\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.1777 - accuracy: 0.9324\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.1749 - accuracy: 0.9330\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.1734 - accuracy: 0.9346\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.1609 - accuracy: 0.9381\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.1595 - accuracy: 0.9385\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.1496 - accuracy: 0.9424\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.1599 - accuracy: 0.9402\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.1477 - accuracy: 0.9440\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 7s 46ms/step - loss: 0.1466 - accuracy: 0.9443\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.1436 - accuracy: 0.9450\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.1465 - accuracy: 0.9442\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.1366 - accuracy: 0.9477\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.1283 - accuracy: 0.9509\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.1389 - accuracy: 0.9461\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.1271 - accuracy: 0.9506\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.1203 - accuracy: 0.9542\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.1238 - accuracy: 0.9534\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.1213 - accuracy: 0.9534\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.1186 - accuracy: 0.9543\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.1276 - accuracy: 0.9516\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.1152 - accuracy: 0.9560\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.1155 - accuracy: 0.9546\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.1165 - accuracy: 0.9555\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.1166 - accuracy: 0.9560\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.1116 - accuracy: 0.9578\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.1083 - accuracy: 0.9575\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.1091 - accuracy: 0.9591\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.0998 - accuracy: 0.9615\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.1071 - accuracy: 0.9602\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.1076 - accuracy: 0.9595\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.1020 - accuracy: 0.9602\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.0983 - accuracy: 0.9628\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.1139 - accuracy: 0.9579\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.0880 - accuracy: 0.9665\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.0929 - accuracy: 0.9645\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.0889 - accuracy: 0.9662\n",
      "76/76 [==============================] - 1s 18ms/step - loss: 0.2715 - accuracy: 0.9329\n",
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_78 (Conv1D)           (None, 88, 768)           7680      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_26 (MaxPooling (None, 44, 768)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_79 (Conv1D)           (None, 42, 256)           590080    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_26 (Averag (None, 14, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_80 (Conv1D)           (None, 12, 512)           393728    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_26  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_78 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_52 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_79 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_53 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_80 (Dense)             (None, 6)                 1542      \n",
      "=================================================================\n",
      "Total params: 1,387,014\n",
      "Trainable params: 1,387,014\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 768, k_conv_1 = 3,  n_conv_2 = 256, k_conv_2 = 3, \n",
      "          n_conv_3 = 512,  k_conv_3 = 3,  maxpooling_pool_size = 2,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 512, dropout_1 = 0.2,\n",
      "          n_dense_2 = 256, dropout_2 = 0.2, activation_conv=  relu,\n",
      "          activation_dense=  elu\n",
      "Epoch 1/60\n",
      "152/152 [==============================] - 7s 46ms/step - loss: 1.0138 - accuracy: 0.5712\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.6274 - accuracy: 0.7508\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.4519 - accuracy: 0.8292\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.3863 - accuracy: 0.8548\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.3539 - accuracy: 0.8665\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.3236 - accuracy: 0.8782\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.3098 - accuracy: 0.8840\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.2954 - accuracy: 0.8893\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 7s 46ms/step - loss: 0.2759 - accuracy: 0.8962\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.2625 - accuracy: 0.9018\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.2473 - accuracy: 0.9072\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.2454 - accuracy: 0.9081\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.2376 - accuracy: 0.9091\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.2305 - accuracy: 0.9121\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.2200 - accuracy: 0.9181\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.2102 - accuracy: 0.9203\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.2066 - accuracy: 0.9218\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.1968 - accuracy: 0.9257\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.1962 - accuracy: 0.9262\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.1871 - accuracy: 0.9281\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.1833 - accuracy: 0.9291\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.1807 - accuracy: 0.9331\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.1783 - accuracy: 0.9340\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.1670 - accuracy: 0.9368\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.1705 - accuracy: 0.9359\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.1574 - accuracy: 0.9398\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.1582 - accuracy: 0.9409\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.1621 - accuracy: 0.9380\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.1593 - accuracy: 0.9385\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.1482 - accuracy: 0.9429\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.1374 - accuracy: 0.9487\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.1470 - accuracy: 0.9432\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.1326 - accuracy: 0.9488\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.1343 - accuracy: 0.9488\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.1285 - accuracy: 0.9510\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.1353 - accuracy: 0.9491\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.1238 - accuracy: 0.9527\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.1248 - accuracy: 0.9526\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.1225 - accuracy: 0.9537\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.1172 - accuracy: 0.9553\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 7s 46ms/step - loss: 0.1170 - accuracy: 0.9551\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.1159 - accuracy: 0.9555\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.1174 - accuracy: 0.9557\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.1141 - accuracy: 0.9562\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.1024 - accuracy: 0.9610\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.1046 - accuracy: 0.9606\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.1012 - accuracy: 0.9619\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.1094 - accuracy: 0.9592\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.1025 - accuracy: 0.9611\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.1232 - accuracy: 0.9543\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.0965 - accuracy: 0.9623\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.1002 - accuracy: 0.9609\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.1006 - accuracy: 0.9629\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.0956 - accuracy: 0.9638\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.0896 - accuracy: 0.9651\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.0875 - accuracy: 0.9666\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.0956 - accuracy: 0.9637\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.0873 - accuracy: 0.9671\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.0920 - accuracy: 0.9659\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.0861 - accuracy: 0.9654\n",
      "76/76 [==============================] - 1s 17ms/step - loss: 0.2639 - accuracy: 0.9419\n",
      "Model: \"sequential_27\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_81 (Conv1D)           (None, 88, 768)           7680      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_27 (MaxPooling (None, 44, 768)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_82 (Conv1D)           (None, 42, 256)           590080    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_27 (Averag (None, 14, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_83 (Conv1D)           (None, 12, 512)           393728    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_27  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_81 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_54 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_82 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_55 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_83 (Dense)             (None, 6)                 1542      \n",
      "=================================================================\n",
      "Total params: 1,387,014\n",
      "Trainable params: 1,387,014\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 768, k_conv_1 = 3,  n_conv_2 = 256, k_conv_2 = 3, \n",
      "          n_conv_3 = 512,  k_conv_3 = 3,  maxpooling_pool_size = 2,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 512, dropout_1 = 0.2,\n",
      "          n_dense_2 = 256, dropout_2 = 0.2, activation_conv=  relu,\n",
      "          activation_dense=  elu\n",
      "Epoch 1/60\n",
      "152/152 [==============================] - 7s 46ms/step - loss: 1.0250 - accuracy: 0.5631\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.5896 - accuracy: 0.7739\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.4466 - accuracy: 0.8350\n",
      "Epoch 4/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 7s 45ms/step - loss: 0.3794 - accuracy: 0.8600\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.3505 - accuracy: 0.8705\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.3298 - accuracy: 0.8781\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.3064 - accuracy: 0.8853\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.2962 - accuracy: 0.8901\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.2847 - accuracy: 0.8950\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.2546 - accuracy: 0.9070\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.2582 - accuracy: 0.9051\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.2415 - accuracy: 0.9103\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.2382 - accuracy: 0.9109\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.2292 - accuracy: 0.9136\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.2253 - accuracy: 0.9167\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.2246 - accuracy: 0.9167\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.2058 - accuracy: 0.9240\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.2061 - accuracy: 0.9249\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.1950 - accuracy: 0.9274\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.1877 - accuracy: 0.9296\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.1875 - accuracy: 0.9301\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.1891 - accuracy: 0.9304\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.1760 - accuracy: 0.9350\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.1764 - accuracy: 0.9349\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.1726 - accuracy: 0.9359\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.1677 - accuracy: 0.9386\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.1608 - accuracy: 0.9404\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.1656 - accuracy: 0.9386\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.1590 - accuracy: 0.9409\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.1509 - accuracy: 0.9425\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.1449 - accuracy: 0.9451\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.1517 - accuracy: 0.9423\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.1478 - accuracy: 0.9443\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.1450 - accuracy: 0.9456\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.1339 - accuracy: 0.9497\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.1312 - accuracy: 0.9516\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.1295 - accuracy: 0.9519\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.1344 - accuracy: 0.9489\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.1279 - accuracy: 0.9512\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.1251 - accuracy: 0.9514\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.1217 - accuracy: 0.9538\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.1182 - accuracy: 0.9548\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.1185 - accuracy: 0.9548\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.1174 - accuracy: 0.9560\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.1186 - accuracy: 0.9558\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.1139 - accuracy: 0.9567\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.1095 - accuracy: 0.9570\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.1102 - accuracy: 0.9594\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.1040 - accuracy: 0.9604\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.1128 - accuracy: 0.9569\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.1050 - accuracy: 0.9613\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.0999 - accuracy: 0.9624\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.0973 - accuracy: 0.9638\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.0992 - accuracy: 0.9623\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.0968 - accuracy: 0.9642\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.0915 - accuracy: 0.9651\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.0976 - accuracy: 0.9628\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.0943 - accuracy: 0.9642\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.1021 - accuracy: 0.9613\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.0920 - accuracy: 0.9653\n",
      "76/76 [==============================] - 1s 17ms/step - loss: 0.2389 - accuracy: 0.9384\n",
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_84 (Conv1D)           (None, 89, 512)           3584      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_28 (MaxPooling (None, 44, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_85 (Conv1D)           (None, 42, 512)           786944    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_28 (Averag (None, 14, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_86 (Conv1D)           (None, 13, 512)           524800    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_28  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_84 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_56 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_85 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_57 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_86 (Dense)             (None, 6)                 1542      \n",
      "=================================================================\n",
      "Total params: 1,710,854\n",
      "Trainable params: 1,710,854\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 512, k_conv_1 = 2,  n_conv_2 = 512, k_conv_2 = 3, \n",
      "          n_conv_3 = 512,  k_conv_3 = 2,  maxpooling_pool_size = 2,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 512, dropout_1 = 0.2,\n",
      "          n_dense_2 = 256, dropout_2 = 0.2, activation_conv=  elu,\n",
      "          activation_dense=  elu\n",
      "Epoch 1/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 1.2180 - accuracy: 0.4842\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 1.1061 - accuracy: 0.5266\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 1.0373 - accuracy: 0.5585\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.9707 - accuracy: 0.5894\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.8843 - accuracy: 0.6270\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.8020 - accuracy: 0.6639\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.7364 - accuracy: 0.6983\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.6686 - accuracy: 0.7256\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.6310 - accuracy: 0.7397\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.5878 - accuracy: 0.7604\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.5432 - accuracy: 0.7811\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.5205 - accuracy: 0.7942\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.4911 - accuracy: 0.8070\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.4738 - accuracy: 0.8136\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.4530 - accuracy: 0.8231\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.4355 - accuracy: 0.8301\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.4166 - accuracy: 0.8373\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.4151 - accuracy: 0.8378\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.3939 - accuracy: 0.8477\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.3789 - accuracy: 0.8553\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.3698 - accuracy: 0.8561\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.3616 - accuracy: 0.8590\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.3520 - accuracy: 0.8625\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.3396 - accuracy: 0.8680\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.3346 - accuracy: 0.8708\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.3402 - accuracy: 0.8670\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.3203 - accuracy: 0.8740\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.3099 - accuracy: 0.8788\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.3122 - accuracy: 0.8767\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.3065 - accuracy: 0.8821\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2977 - accuracy: 0.8837\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.3028 - accuracy: 0.8810\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2883 - accuracy: 0.8860\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2916 - accuracy: 0.8855\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2812 - accuracy: 0.8882\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2827 - accuracy: 0.8882\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2758 - accuracy: 0.8905\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2724 - accuracy: 0.8941\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2628 - accuracy: 0.8979\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2641 - accuracy: 0.8960\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2555 - accuracy: 0.8996\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2577 - accuracy: 0.8986\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2478 - accuracy: 0.9021\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2490 - accuracy: 0.8995\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2472 - accuracy: 0.9025\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2408 - accuracy: 0.9053\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2437 - accuracy: 0.9029\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2453 - accuracy: 0.9014\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2307 - accuracy: 0.9080\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2288 - accuracy: 0.9083\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2234 - accuracy: 0.9106\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2155 - accuracy: 0.9152\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2258 - accuracy: 0.9107\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2302 - accuracy: 0.9085\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2202 - accuracy: 0.9126\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2125 - accuracy: 0.9150\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2134 - accuracy: 0.9150\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2234 - accuracy: 0.9126\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2064 - accuracy: 0.9175\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2115 - accuracy: 0.9160\n",
      "76/76 [==============================] - 1s 18ms/step - loss: 0.2559 - accuracy: 0.9137\n",
      "Model: \"sequential_29\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_87 (Conv1D)           (None, 89, 512)           3584      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_29 (MaxPooling (None, 44, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_88 (Conv1D)           (None, 42, 512)           786944    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_29 (Averag (None, 14, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_89 (Conv1D)           (None, 13, 512)           524800    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_29  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_87 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_58 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_88 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_59 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_89 (Dense)             (None, 6)                 1542      \n",
      "=================================================================\n",
      "Total params: 1,710,854\n",
      "Trainable params: 1,710,854\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 512, k_conv_1 = 2,  n_conv_2 = 512, k_conv_2 = 3, \n",
      "          n_conv_3 = 512,  k_conv_3 = 2,  maxpooling_pool_size = 2,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 512, dropout_1 = 0.2,\n",
      "          n_dense_2 = 256, dropout_2 = 0.2, activation_conv=  elu,\n",
      "          activation_dense=  elu\n",
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/152 [..............................] - ETA: 3s - loss: 1.7933 - accuracy: 0.1953WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0189s vs `on_train_batch_end` time: 0.0299s). Check your callbacks.\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 1.2254 - accuracy: 0.4785\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 1.0992 - accuracy: 0.5292\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 1.0417 - accuracy: 0.5519\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.9762 - accuracy: 0.5853\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.8972 - accuracy: 0.6241\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.8097 - accuracy: 0.6621\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.7310 - accuracy: 0.6988\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.6637 - accuracy: 0.7273\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.6154 - accuracy: 0.7514\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.5764 - accuracy: 0.7672\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.5437 - accuracy: 0.7840\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.5174 - accuracy: 0.7950\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.4907 - accuracy: 0.8078\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.4738 - accuracy: 0.8146\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.4483 - accuracy: 0.8245\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.4327 - accuracy: 0.8301\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.4155 - accuracy: 0.8366\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.4164 - accuracy: 0.8356\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.3929 - accuracy: 0.8488\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.3845 - accuracy: 0.8501\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.3816 - accuracy: 0.8513\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.3616 - accuracy: 0.8590\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.3571 - accuracy: 0.8601\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.3541 - accuracy: 0.8605\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.3412 - accuracy: 0.8675\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.3354 - accuracy: 0.8681\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.3316 - accuracy: 0.8700\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.3205 - accuracy: 0.8733\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.3145 - accuracy: 0.8777\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.3198 - accuracy: 0.8742\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.3065 - accuracy: 0.8790\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.3016 - accuracy: 0.8811\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2895 - accuracy: 0.8850\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2916 - accuracy: 0.8839\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2855 - accuracy: 0.8867\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2764 - accuracy: 0.8888\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2806 - accuracy: 0.8886\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2731 - accuracy: 0.8913\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2620 - accuracy: 0.8960\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2649 - accuracy: 0.8956\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2691 - accuracy: 0.8923\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2606 - accuracy: 0.8935\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2570 - accuracy: 0.8966\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2475 - accuracy: 0.9013\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2438 - accuracy: 0.9042\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2440 - accuracy: 0.9032\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2408 - accuracy: 0.9047\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2417 - accuracy: 0.9032\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2435 - accuracy: 0.9040\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2317 - accuracy: 0.9080\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2297 - accuracy: 0.9089\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2234 - accuracy: 0.9106\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2168 - accuracy: 0.9123\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2297 - accuracy: 0.9079\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2173 - accuracy: 0.9141\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2132 - accuracy: 0.9136\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2169 - accuracy: 0.9137\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2150 - accuracy: 0.9138\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2143 - accuracy: 0.9149\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2094 - accuracy: 0.9166\n",
      "76/76 [==============================] - 1s 18ms/step - loss: 0.2603 - accuracy: 0.9083\n",
      "Model: \"sequential_30\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_90 (Conv1D)           (None, 89, 512)           3584      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_30 (MaxPooling (None, 44, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_91 (Conv1D)           (None, 42, 512)           786944    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_30 (Averag (None, 14, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_92 (Conv1D)           (None, 13, 512)           524800    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_30  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_90 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_60 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_91 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_61 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_92 (Dense)             (None, 6)                 1542      \n",
      "=================================================================\n",
      "Total params: 1,710,854\n",
      "Trainable params: 1,710,854\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 512, k_conv_1 = 2,  n_conv_2 = 512, k_conv_2 = 3, \n",
      "          n_conv_3 = 512,  k_conv_3 = 2,  maxpooling_pool_size = 2,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 512, dropout_1 = 0.2,\n",
      "          n_dense_2 = 256, dropout_2 = 0.2, activation_conv=  elu,\n",
      "          activation_dense=  elu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 1.2103 - accuracy: 0.4868\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 1.0997 - accuracy: 0.5284\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 1.0429 - accuracy: 0.5533\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.9833 - accuracy: 0.5842\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.8991 - accuracy: 0.6199\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.8230 - accuracy: 0.6524\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.7474 - accuracy: 0.6894\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.6812 - accuracy: 0.7207\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.6484 - accuracy: 0.7334\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.5841 - accuracy: 0.7656\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.5613 - accuracy: 0.7751\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.5258 - accuracy: 0.7894\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.5080 - accuracy: 0.7990\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.4785 - accuracy: 0.8135\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.4711 - accuracy: 0.8134\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.4417 - accuracy: 0.8256\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.4357 - accuracy: 0.8277\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.4232 - accuracy: 0.8335\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.4080 - accuracy: 0.8402\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.3922 - accuracy: 0.8455\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.3823 - accuracy: 0.8518\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.3727 - accuracy: 0.8534\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.3618 - accuracy: 0.8553\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.3636 - accuracy: 0.8550\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.3544 - accuracy: 0.8610\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.3447 - accuracy: 0.8643 0s - loss: 0.3\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.3283 - accuracy: 0.8712\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.3272 - accuracy: 0.8720\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.3183 - accuracy: 0.8744\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.3124 - accuracy: 0.8762\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.3049 - accuracy: 0.8812\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2937 - accuracy: 0.8844\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.3010 - accuracy: 0.8821\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2859 - accuracy: 0.8869\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2854 - accuracy: 0.8887\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2815 - accuracy: 0.8882\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2738 - accuracy: 0.8937\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2790 - accuracy: 0.8891\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2740 - accuracy: 0.8924\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2636 - accuracy: 0.8959\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2600 - accuracy: 0.8978\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.2580 - accuracy: 0.8992\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2639 - accuracy: 0.8977\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2511 - accuracy: 0.9016\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2456 - accuracy: 0.9041\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2408 - accuracy: 0.9040\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2457 - accuracy: 0.9038\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2363 - accuracy: 0.9076\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2357 - accuracy: 0.9070\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2294 - accuracy: 0.9093\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2302 - accuracy: 0.9076\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2233 - accuracy: 0.9114\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2192 - accuracy: 0.9148\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2275 - accuracy: 0.9108\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2191 - accuracy: 0.9121\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2280 - accuracy: 0.9108\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2174 - accuracy: 0.9152\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2155 - accuracy: 0.9152\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2140 - accuracy: 0.9154\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2184 - accuracy: 0.9153\n",
      "76/76 [==============================] - 1s 18ms/step - loss: 0.2565 - accuracy: 0.9127\n",
      "Model: \"sequential_31\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_93 (Conv1D)           (None, 88, 768)           7680      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_31 (MaxPooling (None, 29, 768)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_94 (Conv1D)           (None, 27, 512)           1180160   \n",
      "_________________________________________________________________\n",
      "average_pooling1d_31 (Averag (None, 9, 512)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_95 (Conv1D)           (None, 7, 256)            393472    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_31  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_93 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_62 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_94 (Dense)             (None, 384)               98688     \n",
      "_________________________________________________________________\n",
      "dropout_63 (Dropout)         (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_95 (Dense)             (None, 6)                 2310      \n",
      "=================================================================\n",
      "Total params: 1,748,102\n",
      "Trainable params: 1,748,102\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 768, k_conv_1 = 3,  n_conv_2 = 512, k_conv_2 = 3, \n",
      "          n_conv_3 = 256,  k_conv_3 = 3,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 256, dropout_1 = 0.3,\n",
      "          n_dense_2 = 384, dropout_2 = 0.3, activation_conv=  relu,\n",
      "          activation_dense=  elu\n",
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 8s 51ms/step - loss: 1.0208 - accuracy: 0.5663\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.6402 - accuracy: 0.7534\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.4922 - accuracy: 0.8138\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.3954 - accuracy: 0.8520\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.3640 - accuracy: 0.8645\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.3329 - accuracy: 0.8766\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.3137 - accuracy: 0.8837\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.3028 - accuracy: 0.8884\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2997 - accuracy: 0.8891\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2754 - accuracy: 0.8988\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2610 - accuracy: 0.9020\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2623 - accuracy: 0.9031\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2450 - accuracy: 0.9088\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2397 - accuracy: 0.9104\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2252 - accuracy: 0.9167\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2279 - accuracy: 0.9160\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2180 - accuracy: 0.9175\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2124 - accuracy: 0.9205\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2067 - accuracy: 0.9224 0s - loss: 0.2069 - accuracy: 0.\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2006 - accuracy: 0.9248\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1883 - accuracy: 0.9296\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1932 - accuracy: 0.9296\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1933 - accuracy: 0.9269 0s - loss: 0.1\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1771 - accuracy: 0.9343\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1760 - accuracy: 0.9337\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1721 - accuracy: 0.9352\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1604 - accuracy: 0.9402\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1590 - accuracy: 0.9401\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1659 - accuracy: 0.9383\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1555 - accuracy: 0.9404\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1529 - accuracy: 0.9414\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1490 - accuracy: 0.9445\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1613 - accuracy: 0.9410\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1471 - accuracy: 0.9455\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1374 - accuracy: 0.9483\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1306 - accuracy: 0.9494\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1415 - accuracy: 0.9473\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1272 - accuracy: 0.9526\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1378 - accuracy: 0.9491\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1264 - accuracy: 0.9508\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1276 - accuracy: 0.9515\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1231 - accuracy: 0.9526\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1192 - accuracy: 0.9541\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1256 - accuracy: 0.9535\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1172 - accuracy: 0.9572\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1086 - accuracy: 0.9590\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1155 - accuracy: 0.9573\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1037 - accuracy: 0.9616\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1096 - accuracy: 0.9579\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1135 - accuracy: 0.9575\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1046 - accuracy: 0.9610\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1156 - accuracy: 0.9568\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1063 - accuracy: 0.9600\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1051 - accuracy: 0.9611\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.0922 - accuracy: 0.9653\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.0993 - accuracy: 0.9632\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1007 - accuracy: 0.9628\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.0875 - accuracy: 0.9680\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1068 - accuracy: 0.9610\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.0941 - accuracy: 0.9659\n",
      "76/76 [==============================] - 1s 19ms/step - loss: 0.2648 - accuracy: 0.9340\n",
      "Model: \"sequential_32\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_96 (Conv1D)           (None, 88, 768)           7680      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_32 (MaxPooling (None, 29, 768)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_97 (Conv1D)           (None, 27, 512)           1180160   \n",
      "_________________________________________________________________\n",
      "average_pooling1d_32 (Averag (None, 9, 512)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_98 (Conv1D)           (None, 7, 256)            393472    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_32  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_96 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_64 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_97 (Dense)             (None, 384)               98688     \n",
      "_________________________________________________________________\n",
      "dropout_65 (Dropout)         (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_98 (Dense)             (None, 6)                 2310      \n",
      "=================================================================\n",
      "Total params: 1,748,102\n",
      "Trainable params: 1,748,102\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 768, k_conv_1 = 3,  n_conv_2 = 512, k_conv_2 = 3, \n",
      "          n_conv_3 = 256,  k_conv_3 = 3,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 256, dropout_1 = 0.3,\n",
      "          n_dense_2 = 384, dropout_2 = 0.3, activation_conv=  relu,\n",
      "          activation_dense=  elu\n",
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 7s 48ms/step - loss: 1.0166 - accuracy: 0.5718\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.6428 - accuracy: 0.7508 0s - loss: 0.6470 - accuracy\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.4746 - accuracy: 0.8229\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.4050 - accuracy: 0.8486\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.3490 - accuracy: 0.8699\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.3280 - accuracy: 0.8777\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.3191 - accuracy: 0.8807\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.3024 - accuracy: 0.8874\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2842 - accuracy: 0.8941\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2733 - accuracy: 0.8973\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2643 - accuracy: 0.9019\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2531 - accuracy: 0.9058\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2421 - accuracy: 0.9100\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2399 - accuracy: 0.9101\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2262 - accuracy: 0.9158\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2248 - accuracy: 0.9159\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2116 - accuracy: 0.9228\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2113 - accuracy: 0.9196\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2077 - accuracy: 0.9226\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1938 - accuracy: 0.9280\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1914 - accuracy: 0.9289\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1884 - accuracy: 0.9293\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1837 - accuracy: 0.9308\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1800 - accuracy: 0.9310\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1793 - accuracy: 0.9319\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1706 - accuracy: 0.9358\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1730 - accuracy: 0.9354\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1602 - accuracy: 0.9399\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1530 - accuracy: 0.9417\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1700 - accuracy: 0.9368\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1495 - accuracy: 0.9433\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1430 - accuracy: 0.9459\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1457 - accuracy: 0.9456\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1392 - accuracy: 0.9481\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1411 - accuracy: 0.9464\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1420 - accuracy: 0.9474\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1432 - accuracy: 0.9453\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1390 - accuracy: 0.9489\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1287 - accuracy: 0.9519\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1326 - accuracy: 0.9505\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1226 - accuracy: 0.9540\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1196 - accuracy: 0.9549\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1280 - accuracy: 0.9525\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1181 - accuracy: 0.9561\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1286 - accuracy: 0.9529\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1135 - accuracy: 0.9577\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1171 - accuracy: 0.9552\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1135 - accuracy: 0.9579\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1112 - accuracy: 0.9580\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1104 - accuracy: 0.9587\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1082 - accuracy: 0.9598\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1171 - accuracy: 0.9569\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1013 - accuracy: 0.9632\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1148 - accuracy: 0.9585\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.0985 - accuracy: 0.9640\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1097 - accuracy: 0.9601\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.0930 - accuracy: 0.9658\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.0935 - accuracy: 0.9652\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1033 - accuracy: 0.9630\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1005 - accuracy: 0.9630 0s - loss: 0.1010 - accuracy\n",
      "76/76 [==============================] - 1s 18ms/step - loss: 0.2572 - accuracy: 0.9377\n",
      "Model: \"sequential_33\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_99 (Conv1D)           (None, 88, 768)           7680      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_33 (MaxPooling (None, 29, 768)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_100 (Conv1D)          (None, 27, 512)           1180160   \n",
      "_________________________________________________________________\n",
      "average_pooling1d_33 (Averag (None, 9, 512)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_101 (Conv1D)          (None, 7, 256)            393472    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_33  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_99 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_66 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_100 (Dense)            (None, 384)               98688     \n",
      "_________________________________________________________________\n",
      "dropout_67 (Dropout)         (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_101 (Dense)            (None, 6)                 2310      \n",
      "=================================================================\n",
      "Total params: 1,748,102\n",
      "Trainable params: 1,748,102\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 768, k_conv_1 = 3,  n_conv_2 = 512, k_conv_2 = 3, \n",
      "          n_conv_3 = 256,  k_conv_3 = 3,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 256, dropout_1 = 0.3,\n",
      "          n_dense_2 = 384, dropout_2 = 0.3, activation_conv=  relu,\n",
      "          activation_dense=  elu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 1.0366 - accuracy: 0.5575\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.6480 - accuracy: 0.7444\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.4828 - accuracy: 0.8195\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.4109 - accuracy: 0.8459\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.3658 - accuracy: 0.8625\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.3332 - accuracy: 0.8757\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.3320 - accuracy: 0.8744 1s -\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.3125 - accuracy: 0.8821\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2891 - accuracy: 0.8920\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2766 - accuracy: 0.8968\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2657 - accuracy: 0.9008\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2608 - accuracy: 0.9027\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2405 - accuracy: 0.9103\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2360 - accuracy: 0.9122\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2451 - accuracy: 0.9099\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2268 - accuracy: 0.9145\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2133 - accuracy: 0.9218\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2073 - accuracy: 0.9226\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2132 - accuracy: 0.9223\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2086 - accuracy: 0.9238\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1903 - accuracy: 0.9307\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1856 - accuracy: 0.9320\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2135 - accuracy: 0.9236\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1933 - accuracy: 0.9306\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1683 - accuracy: 0.9387\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1770 - accuracy: 0.9352\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1668 - accuracy: 0.9388\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1606 - accuracy: 0.9407\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1590 - accuracy: 0.9410\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1578 - accuracy: 0.9415\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1582 - accuracy: 0.9427\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1477 - accuracy: 0.9457\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1481 - accuracy: 0.9462\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1520 - accuracy: 0.9439\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1420 - accuracy: 0.9477\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1361 - accuracy: 0.9493\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1329 - accuracy: 0.9511\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1399 - accuracy: 0.9481\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1409 - accuracy: 0.9490\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1242 - accuracy: 0.9536\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1314 - accuracy: 0.9508\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1270 - accuracy: 0.9533\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1208 - accuracy: 0.9549\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1249 - accuracy: 0.9539\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1176 - accuracy: 0.9566\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1184 - accuracy: 0.9559\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1072 - accuracy: 0.9598\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1125 - accuracy: 0.9581\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1149 - accuracy: 0.9577\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1155 - accuracy: 0.9576\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1082 - accuracy: 0.9589\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1055 - accuracy: 0.9617\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.0989 - accuracy: 0.9639\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1029 - accuracy: 0.9622\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.0992 - accuracy: 0.9629\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.0940 - accuracy: 0.9654\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1006 - accuracy: 0.9620\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.1058 - accuracy: 0.9615\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.0935 - accuracy: 0.9655\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.0948 - accuracy: 0.9650\n",
      "76/76 [==============================] - 1s 18ms/step - loss: 0.2593 - accuracy: 0.9385\n",
      "Model: \"sequential_34\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_102 (Conv1D)          (None, 88, 768)           7680      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_34 (MaxPooling (None, 44, 768)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_103 (Conv1D)          (None, 42, 512)           1180160   \n",
      "_________________________________________________________________\n",
      "average_pooling1d_34 (Averag (None, 14, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_104 (Conv1D)          (None, 12, 256)           393472    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_34  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_102 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_68 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_103 (Dense)            (None, 384)               98688     \n",
      "_________________________________________________________________\n",
      "dropout_69 (Dropout)         (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_104 (Dense)            (None, 6)                 2310      \n",
      "=================================================================\n",
      "Total params: 1,748,102\n",
      "Trainable params: 1,748,102\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 768, k_conv_1 = 3,  n_conv_2 = 512, k_conv_2 = 3, \n",
      "          n_conv_3 = 256,  k_conv_3 = 3,  maxpooling_pool_size = 2,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 256, dropout_1 = 0.3,\n",
      "          n_dense_2 = 384, dropout_2 = 0.2, activation_conv=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001F6FFADDA48>,\n",
      "          activation_dense=  relu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 1.1201 - accuracy: 0.5223\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.8298 - accuracy: 0.6565\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.6613 - accuracy: 0.7385\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.5836 - accuracy: 0.7686\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.5331 - accuracy: 0.7884\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.4833 - accuracy: 0.8077\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.4683 - accuracy: 0.8124\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.4566 - accuracy: 0.8193\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.4339 - accuracy: 0.8315\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.4136 - accuracy: 0.8388\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.4012 - accuracy: 0.8453\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.4045 - accuracy: 0.8432\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.3917 - accuracy: 0.8487\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.3804 - accuracy: 0.8530\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.3692 - accuracy: 0.8574\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.3625 - accuracy: 0.8594\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.3601 - accuracy: 0.8595\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.3476 - accuracy: 0.8657\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.3468 - accuracy: 0.8653\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.3441 - accuracy: 0.8675\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.3397 - accuracy: 0.8694\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.3405 - accuracy: 0.8680\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.3418 - accuracy: 0.8680\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.3254 - accuracy: 0.8717\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.3332 - accuracy: 0.8715\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.3204 - accuracy: 0.8751\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.3233 - accuracy: 0.8750\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.3116 - accuracy: 0.8770\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.3080 - accuracy: 0.8793\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.3082 - accuracy: 0.8800\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.3096 - accuracy: 0.8785\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.2969 - accuracy: 0.8832\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.3031 - accuracy: 0.8812\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.2995 - accuracy: 0.8843\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.2925 - accuracy: 0.8847\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.2941 - accuracy: 0.8846\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.2998 - accuracy: 0.8834\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.2851 - accuracy: 0.8865\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.2852 - accuracy: 0.8874\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.2902 - accuracy: 0.8877\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.2863 - accuracy: 0.8888\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.2783 - accuracy: 0.8913\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.2827 - accuracy: 0.8898\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.2841 - accuracy: 0.8893\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.2769 - accuracy: 0.8920\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.2798 - accuracy: 0.8912\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.2617 - accuracy: 0.8986\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.2705 - accuracy: 0.8947\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.2639 - accuracy: 0.8986\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.2699 - accuracy: 0.8961\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.2635 - accuracy: 0.8978\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.2635 - accuracy: 0.8971\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.2543 - accuracy: 0.9022\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.2562 - accuracy: 0.9002\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.2566 - accuracy: 0.8992\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.2589 - accuracy: 0.8983\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.2557 - accuracy: 0.9012\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.2498 - accuracy: 0.9021\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.2431 - accuracy: 0.9052\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.2493 - accuracy: 0.9036\n",
      "76/76 [==============================] - 2s 24ms/step - loss: 0.2595 - accuracy: 0.9043\n",
      "Model: \"sequential_35\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_105 (Conv1D)          (None, 88, 768)           7680      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_35 (MaxPooling (None, 44, 768)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_106 (Conv1D)          (None, 42, 512)           1180160   \n",
      "_________________________________________________________________\n",
      "average_pooling1d_35 (Averag (None, 14, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_107 (Conv1D)          (None, 12, 256)           393472    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_35  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_105 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_70 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_106 (Dense)            (None, 384)               98688     \n",
      "_________________________________________________________________\n",
      "dropout_71 (Dropout)         (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_107 (Dense)            (None, 6)                 2310      \n",
      "=================================================================\n",
      "Total params: 1,748,102\n",
      "Trainable params: 1,748,102\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 768, k_conv_1 = 3,  n_conv_2 = 512, k_conv_2 = 3, \n",
      "          n_conv_3 = 256,  k_conv_3 = 3,  maxpooling_pool_size = 2,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 256, dropout_1 = 0.3,\n",
      "          n_dense_2 = 384, dropout_2 = 0.2, activation_conv=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001F6FFADDA48>,\n",
      "          activation_dense=  relu\n",
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 10s 65ms/step - loss: 1.1191 - accuracy: 0.5209\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.8405 - accuracy: 0.6431\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.6692 - accuracy: 0.7295\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.5958 - accuracy: 0.7613\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.5206 - accuracy: 0.7905\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.5048 - accuracy: 0.7986\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.4742 - accuracy: 0.8144\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.4541 - accuracy: 0.8199\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.4265 - accuracy: 0.8297\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.4091 - accuracy: 0.8407\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.4295 - accuracy: 0.8308\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.3839 - accuracy: 0.8494\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.3850 - accuracy: 0.8487\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.3748 - accuracy: 0.8526\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.3824 - accuracy: 0.8511\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.3579 - accuracy: 0.8603\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.3486 - accuracy: 0.8660\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.3612 - accuracy: 0.8592\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.3421 - accuracy: 0.8671\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.3361 - accuracy: 0.8686\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.3307 - accuracy: 0.8715\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.3346 - accuracy: 0.87140s - loss: 0.3314 - \n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.3367 - accuracy: 0.8690\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.3424 - accuracy: 0.8664\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.3274 - accuracy: 0.8710\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.3129 - accuracy: 0.8760\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.3083 - accuracy: 0.8782\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.3076 - accuracy: 0.8782\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.3115 - accuracy: 0.8776\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.3055 - accuracy: 0.8814\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.3027 - accuracy: 0.8816\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.3070 - accuracy: 0.8818\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.2977 - accuracy: 0.8838\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.2875 - accuracy: 0.8869\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.2902 - accuracy: 0.8882\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.2958 - accuracy: 0.8847\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.2902 - accuracy: 0.8872\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.2854 - accuracy: 0.8875\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.2805 - accuracy: 0.8898\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.2904 - accuracy: 0.8851\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.2765 - accuracy: 0.8905\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.2764 - accuracy: 0.8921\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.2829 - accuracy: 0.8908\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.2736 - accuracy: 0.8932\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.2778 - accuracy: 0.8909\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.2670 - accuracy: 0.8975\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.2669 - accuracy: 0.8932\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.2617 - accuracy: 0.8984\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.2605 - accuracy: 0.8971\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.2612 - accuracy: 0.8982\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.2649 - accuracy: 0.8973\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.2553 - accuracy: 0.9021\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.2585 - accuracy: 0.8982\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.2527 - accuracy: 0.9026\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.2607 - accuracy: 0.9000\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.2570 - accuracy: 0.9002\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.2576 - accuracy: 0.9011\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.2472 - accuracy: 0.9031\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.2390 - accuracy: 0.9055\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.2445 - accuracy: 0.9027\n",
      "76/76 [==============================] - 2s 23ms/step - loss: 0.2696 - accuracy: 0.8975\n",
      "Model: \"sequential_36\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_108 (Conv1D)          (None, 88, 768)           7680      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_36 (MaxPooling (None, 44, 768)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_109 (Conv1D)          (None, 42, 512)           1180160   \n",
      "_________________________________________________________________\n",
      "average_pooling1d_36 (Averag (None, 14, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_110 (Conv1D)          (None, 12, 256)           393472    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_36  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_108 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_72 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_109 (Dense)            (None, 384)               98688     \n",
      "_________________________________________________________________\n",
      "dropout_73 (Dropout)         (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_110 (Dense)            (None, 6)                 2310      \n",
      "=================================================================\n",
      "Total params: 1,748,102\n",
      "Trainable params: 1,748,102\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 768, k_conv_1 = 3,  n_conv_2 = 512, k_conv_2 = 3, \n",
      "          n_conv_3 = 256,  k_conv_3 = 3,  maxpooling_pool_size = 2,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 256, dropout_1 = 0.3,\n",
      "          n_dense_2 = 384, dropout_2 = 0.2, activation_conv=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001F6FFADDA48>,\n",
      "          activation_dense=  relu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 1.1115 - accuracy: 0.5258\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.8472 - accuracy: 0.6420\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.6936 - accuracy: 0.7218\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.6011 - accuracy: 0.7596\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.5494 - accuracy: 0.7786\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.4974 - accuracy: 0.8017\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.4764 - accuracy: 0.8120\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.4494 - accuracy: 0.8211\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.4507 - accuracy: 0.8234\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.4237 - accuracy: 0.8332\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.4121 - accuracy: 0.8365\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.4085 - accuracy: 0.8398\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.3890 - accuracy: 0.8485\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.3928 - accuracy: 0.8468\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.3782 - accuracy: 0.8536\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.3692 - accuracy: 0.8562\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.3732 - accuracy: 0.8541\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.3532 - accuracy: 0.8614\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.3592 - accuracy: 0.8587\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.3398 - accuracy: 0.8659\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.3510 - accuracy: 0.8622\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.3349 - accuracy: 0.8687\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.3356 - accuracy: 0.8673\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.3290 - accuracy: 0.8683\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.3221 - accuracy: 0.8736\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.3302 - accuracy: 0.8699\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.3328 - accuracy: 0.8712\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.3193 - accuracy: 0.8741\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.3231 - accuracy: 0.8759\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.3105 - accuracy: 0.8773\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.3071 - accuracy: 0.8797\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.3048 - accuracy: 0.8801\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.3078 - accuracy: 0.8799\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.3066 - accuracy: 0.87980s - loss:\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.3064 - accuracy: 0.8805\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.2989 - accuracy: 0.8800\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.2915 - accuracy: 0.8849\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.2999 - accuracy: 0.8819\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.3003 - accuracy: 0.8852\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.2987 - accuracy: 0.8824\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.2960 - accuracy: 0.8846\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.2791 - accuracy: 0.8926\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.2854 - accuracy: 0.8893\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.2781 - accuracy: 0.8916\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.2739 - accuracy: 0.8940\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.2772 - accuracy: 0.8923\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.2699 - accuracy: 0.8952\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.2671 - accuracy: 0.8949\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.2668 - accuracy: 0.8955\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.2667 - accuracy: 0.8973\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.2705 - accuracy: 0.8940\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.2676 - accuracy: 0.8976\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.2641 - accuracy: 0.8971\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.2659 - accuracy: 0.8974\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.2590 - accuracy: 0.8991\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.2579 - accuracy: 0.8997\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.2519 - accuracy: 0.9041\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.2529 - accuracy: 0.9029\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.2535 - accuracy: 0.90110s - loss: 0.2536 - accuracy: 0.\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.2606 - accuracy: 0.9006\n",
      "76/76 [==============================] - 2s 23ms/step - loss: 0.2527 - accuracy: 0.9108\n",
      "Model: \"sequential_37\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_111 (Conv1D)          (None, 88, 512)           5120      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_37 (MaxPooling (None, 44, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_112 (Conv1D)          (None, 43, 512)           524800    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_37 (Averag (None, 21, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_113 (Conv1D)          (None, 20, 256)           262400    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_37  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_111 (Dense)            (None, 384)               98688     \n",
      "_________________________________________________________________\n",
      "dropout_74 (Dropout)         (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_112 (Dense)            (None, 512)               197120    \n",
      "_________________________________________________________________\n",
      "dropout_75 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_113 (Dense)            (None, 6)                 3078      \n",
      "=================================================================\n",
      "Total params: 1,091,206\n",
      "Trainable params: 1,091,206\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 512, k_conv_1 = 3,  n_conv_2 = 512, k_conv_2 = 2, \n",
      "          n_conv_3 = 256,  k_conv_3 = 2,  maxpooling_pool_size = 2,\n",
      "          avepooling_pool_size = 2,  n_dense_1 = 384, dropout_1 = 0.3,\n",
      "          n_dense_2 = 512, dropout_2 = 0.3, activation_conv=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001F6FFADDA48>,\n",
      "          activation_dense=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001F691236408>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 1.1260 - accuracy: 0.5262\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.8271 - accuracy: 0.6583\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.6648 - accuracy: 0.7353\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.5872 - accuracy: 0.7638\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.5529 - accuracy: 0.7805\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.5267 - accuracy: 0.7913\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.4877 - accuracy: 0.8064\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.4672 - accuracy: 0.8156\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.4512 - accuracy: 0.8245\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.4350 - accuracy: 0.8299\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.4285 - accuracy: 0.8306\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.4160 - accuracy: 0.8386\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3982 - accuracy: 0.8469 0s - loss: 0.4000 -  - ETA: 0s - loss: 0.3990 - accu\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3940 - accuracy: 0.8479\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3814 - accuracy: 0.8518\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3762 - accuracy: 0.8569\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3676 - accuracy: 0.8580\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3663 - accuracy: 0.8588\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3612 - accuracy: 0.8602\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3560 - accuracy: 0.8603\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3531 - accuracy: 0.8612\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3546 - accuracy: 0.8627\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3427 - accuracy: 0.8668\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3396 - accuracy: 0.8688\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3410 - accuracy: 0.8681\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3359 - accuracy: 0.8712\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3221 - accuracy: 0.8748\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3308 - accuracy: 0.8705\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3278 - accuracy: 0.8730\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3214 - accuracy: 0.8768\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3275 - accuracy: 0.8722\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3103 - accuracy: 0.8796\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3108 - accuracy: 0.8792\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3174 - accuracy: 0.8786\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3066 - accuracy: 0.8812\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3048 - accuracy: 0.8806\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3059 - accuracy: 0.8800\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3000 - accuracy: 0.8831\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3011 - accuracy: 0.8822\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2901 - accuracy: 0.8862\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2921 - accuracy: 0.8864\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2989 - accuracy: 0.8840\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3043 - accuracy: 0.8820\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2902 - accuracy: 0.8848\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2815 - accuracy: 0.8902\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2816 - accuracy: 0.8903\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2992 - accuracy: 0.8821\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2785 - accuracy: 0.8909\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2855 - accuracy: 0.8890\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2771 - accuracy: 0.8916 0s - loss: 0.2754 - ac\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2773 - accuracy: 0.8903\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2728 - accuracy: 0.8963\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2732 - accuracy: 0.8939\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2655 - accuracy: 0.8970\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2745 - accuracy: 0.8930 0s - los\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2771 - accuracy: 0.8917\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2713 - accuracy: 0.8950\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2708 - accuracy: 0.8949\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2560 - accuracy: 0.9005\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2705 - accuracy: 0.8952\n",
      "76/76 [==============================] - 1s 16ms/step - loss: 0.2873 - accuracy: 0.8943\n",
      "Model: \"sequential_38\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_114 (Conv1D)          (None, 88, 512)           5120      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_38 (MaxPooling (None, 44, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_115 (Conv1D)          (None, 43, 512)           524800    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_38 (Averag (None, 21, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_116 (Conv1D)          (None, 20, 256)           262400    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_38  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_114 (Dense)            (None, 384)               98688     \n",
      "_________________________________________________________________\n",
      "dropout_76 (Dropout)         (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_115 (Dense)            (None, 512)               197120    \n",
      "_________________________________________________________________\n",
      "dropout_77 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_116 (Dense)            (None, 6)                 3078      \n",
      "=================================================================\n",
      "Total params: 1,091,206\n",
      "Trainable params: 1,091,206\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 512, k_conv_1 = 3,  n_conv_2 = 512, k_conv_2 = 2, \n",
      "          n_conv_3 = 256,  k_conv_3 = 2,  maxpooling_pool_size = 2,\n",
      "          avepooling_pool_size = 2,  n_dense_1 = 384, dropout_1 = 0.3,\n",
      "          n_dense_2 = 512, dropout_2 = 0.3, activation_conv=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001F6FFADDA48>,\n",
      "          activation_dense=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001F691236408>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 1.1096 - accuracy: 0.5272\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.8105 - accuracy: 0.6676\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.6609 - accuracy: 0.7365\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.5956 - accuracy: 0.7621\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.5543 - accuracy: 0.7783\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.5100 - accuracy: 0.7970\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.4806 - accuracy: 0.8102\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.4540 - accuracy: 0.8245 0s - loss: 0.4522 - accura\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.4493 - accuracy: 0.8251\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.4372 - accuracy: 0.8306\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.4162 - accuracy: 0.8410\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.4040 - accuracy: 0.8425 0s - loss: 0.4034 - accura\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3945 - accuracy: 0.8502\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3872 - accuracy: 0.8504\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3719 - accuracy: 0.8574\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3717 - accuracy: 0.8571\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3699 - accuracy: 0.8575\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3637 - accuracy: 0.8608\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3553 - accuracy: 0.8623\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3506 - accuracy: 0.8654\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3352 - accuracy: 0.8707\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3407 - accuracy: 0.8689\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3370 - accuracy: 0.8708\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3358 - accuracy: 0.8691\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3346 - accuracy: 0.8703\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3211 - accuracy: 0.8763\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3189 - accuracy: 0.8769\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3217 - accuracy: 0.8783\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3215 - accuracy: 0.8752\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3228 - accuracy: 0.8772\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3156 - accuracy: 0.8790\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3147 - accuracy: 0.8782\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3080 - accuracy: 0.8801\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3071 - accuracy: 0.8800\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2995 - accuracy: 0.8819\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3075 - accuracy: 0.8819\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3075 - accuracy: 0.8802\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2973 - accuracy: 0.8853\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2958 - accuracy: 0.8847\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2921 - accuracy: 0.8854\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2929 - accuracy: 0.8858\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2887 - accuracy: 0.8863\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2983 - accuracy: 0.8845\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2812 - accuracy: 0.8903\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2840 - accuracy: 0.8879\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2867 - accuracy: 0.8881\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2796 - accuracy: 0.8885\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2811 - accuracy: 0.8877\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2788 - accuracy: 0.8902\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2819 - accuracy: 0.8898 0s - loss: 0.2812 - accuracy\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2756 - accuracy: 0.8923\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2669 - accuracy: 0.8954\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2741 - accuracy: 0.8905\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2694 - accuracy: 0.8933\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2810 - accuracy: 0.8914\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2655 - accuracy: 0.8943\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2586 - accuracy: 0.8970\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2685 - accuracy: 0.8935\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2614 - accuracy: 0.8984\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2686 - accuracy: 0.8939\n",
      "76/76 [==============================] - 1s 16ms/step - loss: 0.3674 - accuracy: 0.8669\n",
      "Model: \"sequential_39\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_117 (Conv1D)          (None, 88, 512)           5120      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_39 (MaxPooling (None, 44, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_118 (Conv1D)          (None, 43, 512)           524800    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_39 (Averag (None, 21, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_119 (Conv1D)          (None, 20, 256)           262400    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_39  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_117 (Dense)            (None, 384)               98688     \n",
      "_________________________________________________________________\n",
      "dropout_78 (Dropout)         (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_118 (Dense)            (None, 512)               197120    \n",
      "_________________________________________________________________\n",
      "dropout_79 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_119 (Dense)            (None, 6)                 3078      \n",
      "=================================================================\n",
      "Total params: 1,091,206\n",
      "Trainable params: 1,091,206\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 512, k_conv_1 = 3,  n_conv_2 = 512, k_conv_2 = 2, \n",
      "          n_conv_3 = 256,  k_conv_3 = 2,  maxpooling_pool_size = 2,\n",
      "          avepooling_pool_size = 2,  n_dense_1 = 384, dropout_1 = 0.3,\n",
      "          n_dense_2 = 512, dropout_2 = 0.3, activation_conv=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001F6FFADDA48>,\n",
      "          activation_dense=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001F691236408>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 1.1207 - accuracy: 0.5225\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.8280 - accuracy: 0.6567\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.6867 - accuracy: 0.7245\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.6073 - accuracy: 0.7569\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.5579 - accuracy: 0.7780\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.5172 - accuracy: 0.7928\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.4912 - accuracy: 0.8069\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.4653 - accuracy: 0.8184\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.4595 - accuracy: 0.8169\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.4393 - accuracy: 0.8295\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.4217 - accuracy: 0.8367\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.4040 - accuracy: 0.8455\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3942 - accuracy: 0.8482\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3896 - accuracy: 0.8490\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3774 - accuracy: 0.8550\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3787 - accuracy: 0.8552\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3649 - accuracy: 0.8608\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3578 - accuracy: 0.8645\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3604 - accuracy: 0.8617\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3518 - accuracy: 0.8658\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3433 - accuracy: 0.8675\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3525 - accuracy: 0.8652\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3369 - accuracy: 0.8703\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3380 - accuracy: 0.8684\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3333 - accuracy: 0.8717\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3357 - accuracy: 0.8719\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3243 - accuracy: 0.8777\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3217 - accuracy: 0.8773\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3135 - accuracy: 0.8797\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3106 - accuracy: 0.8791\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3103 - accuracy: 0.8791\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3097 - accuracy: 0.8792\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3080 - accuracy: 0.8817\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3046 - accuracy: 0.8825 0s - loss: 0.3039 - accura\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3072 - accuracy: 0.8796\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3052 - accuracy: 0.8826\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3125 - accuracy: 0.8770\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.3040 - accuracy: 0.8834\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2940 - accuracy: 0.8859\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2925 - accuracy: 0.8851\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2990 - accuracy: 0.8830\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2894 - accuracy: 0.8869\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2883 - accuracy: 0.8875\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2887 - accuracy: 0.8869\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2937 - accuracy: 0.8867\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2861 - accuracy: 0.8888\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2864 - accuracy: 0.8892\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2780 - accuracy: 0.8917\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2795 - accuracy: 0.8897\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2821 - accuracy: 0.8900\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2798 - accuracy: 0.8898\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2812 - accuracy: 0.8882\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2806 - accuracy: 0.8913\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2645 - accuracy: 0.8970\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2687 - accuracy: 0.8942\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2640 - accuracy: 0.8948\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2784 - accuracy: 0.8911\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2673 - accuracy: 0.8967\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2654 - accuracy: 0.8962\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.2618 - accuracy: 0.8982\n",
      "76/76 [==============================] - 1s 16ms/step - loss: 0.2719 - accuracy: 0.8968\n",
      "Model: \"sequential_40\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_120 (Conv1D)          (None, 88, 512)           5120      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_40 (MaxPooling (None, 44, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_121 (Conv1D)          (None, 43, 512)           524800    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_40 (Averag (None, 14, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_122 (Conv1D)          (None, 13, 256)           262400    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_40  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_120 (Dense)            (None, 384)               98688     \n",
      "_________________________________________________________________\n",
      "dropout_80 (Dropout)         (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_121 (Dense)            (None, 512)               197120    \n",
      "_________________________________________________________________\n",
      "dropout_81 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_122 (Dense)            (None, 6)                 3078      \n",
      "=================================================================\n",
      "Total params: 1,091,206\n",
      "Trainable params: 1,091,206\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 512, k_conv_1 = 3,  n_conv_2 = 512, k_conv_2 = 2, \n",
      "          n_conv_3 = 256,  k_conv_3 = 2,  maxpooling_pool_size = 2,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 384, dropout_1 = 0.3,\n",
      "          n_dense_2 = 512, dropout_2 = 0.2, activation_conv=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001F6FFADDA48>,\n",
      "          activation_dense=  relu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 1.1049 - accuracy: 0.5258\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.8343 - accuracy: 0.6499\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.6818 - accuracy: 0.7268\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.5834 - accuracy: 0.7670\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.5342 - accuracy: 0.7886\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.4891 - accuracy: 0.8069\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.4579 - accuracy: 0.8185\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.4341 - accuracy: 0.8284\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.4314 - accuracy: 0.8313\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3986 - accuracy: 0.8436\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3969 - accuracy: 0.8439\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3859 - accuracy: 0.8500\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3735 - accuracy: 0.8547\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3564 - accuracy: 0.8619\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3575 - accuracy: 0.8618\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3467 - accuracy: 0.8640\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3407 - accuracy: 0.8654\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3439 - accuracy: 0.8658\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3447 - accuracy: 0.8672\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3311 - accuracy: 0.8713\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3203 - accuracy: 0.8743\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3265 - accuracy: 0.8722\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3149 - accuracy: 0.8757\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3238 - accuracy: 0.8751\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3068 - accuracy: 0.8810\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3099 - accuracy: 0.8793\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3070 - accuracy: 0.8794\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2975 - accuracy: 0.8835\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3001 - accuracy: 0.8844\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2915 - accuracy: 0.8861\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2973 - accuracy: 0.8834\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2881 - accuracy: 0.8881\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2891 - accuracy: 0.8864\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2871 - accuracy: 0.8874\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2778 - accuracy: 0.8922\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2742 - accuracy: 0.8932\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2795 - accuracy: 0.8915\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2800 - accuracy: 0.8908\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2651 - accuracy: 0.8970\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2652 - accuracy: 0.8963\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2717 - accuracy: 0.8971\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2634 - accuracy: 0.8967\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2612 - accuracy: 0.8982\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2656 - accuracy: 0.8958\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2606 - accuracy: 0.8987\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2531 - accuracy: 0.9023\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2517 - accuracy: 0.9020\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2471 - accuracy: 0.9062\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2472 - accuracy: 0.9034\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2401 - accuracy: 0.9063\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2466 - accuracy: 0.9054\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2396 - accuracy: 0.9071\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2418 - accuracy: 0.9069\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2441 - accuracy: 0.9048\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2382 - accuracy: 0.9084\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2401 - accuracy: 0.9072\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2365 - accuracy: 0.9084\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2449 - accuracy: 0.9060\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2553 - accuracy: 0.9029\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2265 - accuracy: 0.9116\n",
      "76/76 [==============================] - 1s 16ms/step - loss: 0.2422 - accuracy: 0.9113\n",
      "Model: \"sequential_41\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_123 (Conv1D)          (None, 88, 512)           5120      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_41 (MaxPooling (None, 44, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_124 (Conv1D)          (None, 43, 512)           524800    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_41 (Averag (None, 14, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_125 (Conv1D)          (None, 13, 256)           262400    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_41  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_123 (Dense)            (None, 384)               98688     \n",
      "_________________________________________________________________\n",
      "dropout_82 (Dropout)         (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_124 (Dense)            (None, 512)               197120    \n",
      "_________________________________________________________________\n",
      "dropout_83 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_125 (Dense)            (None, 6)                 3078      \n",
      "=================================================================\n",
      "Total params: 1,091,206\n",
      "Trainable params: 1,091,206\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 512, k_conv_1 = 3,  n_conv_2 = 512, k_conv_2 = 2, \n",
      "          n_conv_3 = 256,  k_conv_3 = 2,  maxpooling_pool_size = 2,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 384, dropout_1 = 0.3,\n",
      "          n_dense_2 = 512, dropout_2 = 0.2, activation_conv=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001F6FFADDA48>,\n",
      "          activation_dense=  relu\n",
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 6s 38ms/step - loss: 1.1184 - accuracy: 0.5196\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.8362 - accuracy: 0.6498\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.6768 - accuracy: 0.7250\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.5746 - accuracy: 0.7709\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.5373 - accuracy: 0.7857\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.4828 - accuracy: 0.8076\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.4551 - accuracy: 0.8233\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.4406 - accuracy: 0.8264\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.4216 - accuracy: 0.8370\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3974 - accuracy: 0.8484\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3897 - accuracy: 0.8490\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3843 - accuracy: 0.8508\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3719 - accuracy: 0.8567\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3642 - accuracy: 0.8577\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3615 - accuracy: 0.8615\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3525 - accuracy: 0.8632\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3425 - accuracy: 0.8666\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3421 - accuracy: 0.8663\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3306 - accuracy: 0.8706\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3186 - accuracy: 0.8761\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3227 - accuracy: 0.8749\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3124 - accuracy: 0.8772\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3083 - accuracy: 0.8777\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3128 - accuracy: 0.8790\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3118 - accuracy: 0.8789\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3030 - accuracy: 0.8817\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3011 - accuracy: 0.8837\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3056 - accuracy: 0.8812\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2921 - accuracy: 0.8869\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2937 - accuracy: 0.8864\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2837 - accuracy: 0.8901\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2847 - accuracy: 0.8903\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2806 - accuracy: 0.8911\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2833 - accuracy: 0.8905\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2743 - accuracy: 0.8924\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2650 - accuracy: 0.8963\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2720 - accuracy: 0.8962\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2698 - accuracy: 0.8952\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2609 - accuracy: 0.8984\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2645 - accuracy: 0.8979\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2700 - accuracy: 0.8954\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2608 - accuracy: 0.8998\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2520 - accuracy: 0.9024\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2562 - accuracy: 0.9020\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2613 - accuracy: 0.9003\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2497 - accuracy: 0.9027\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2499 - accuracy: 0.9000\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2442 - accuracy: 0.9059\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2411 - accuracy: 0.9072\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2437 - accuracy: 0.9061\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2386 - accuracy: 0.9073\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2412 - accuracy: 0.9074\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2380 - accuracy: 0.9087\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2383 - accuracy: 0.9069\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2436 - accuracy: 0.9065\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2248 - accuracy: 0.9130\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2450 - accuracy: 0.9064\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2314 - accuracy: 0.9090\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2273 - accuracy: 0.9119\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2285 - accuracy: 0.9122\n",
      "76/76 [==============================] - 1s 15ms/step - loss: 0.2678 - accuracy: 0.9054\n",
      "Model: \"sequential_42\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_126 (Conv1D)          (None, 88, 512)           5120      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_42 (MaxPooling (None, 44, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_127 (Conv1D)          (None, 43, 512)           524800    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_42 (Averag (None, 14, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_128 (Conv1D)          (None, 13, 256)           262400    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_42  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_126 (Dense)            (None, 384)               98688     \n",
      "_________________________________________________________________\n",
      "dropout_84 (Dropout)         (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_127 (Dense)            (None, 512)               197120    \n",
      "_________________________________________________________________\n",
      "dropout_85 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_128 (Dense)            (None, 6)                 3078      \n",
      "=================================================================\n",
      "Total params: 1,091,206\n",
      "Trainable params: 1,091,206\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 512, k_conv_1 = 3,  n_conv_2 = 512, k_conv_2 = 2, \n",
      "          n_conv_3 = 256,  k_conv_3 = 2,  maxpooling_pool_size = 2,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 384, dropout_1 = 0.3,\n",
      "          n_dense_2 = 512, dropout_2 = 0.2, activation_conv=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001F6FFADDA48>,\n",
      "          activation_dense=  relu\n",
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 6s 38ms/step - loss: 1.1085 - accuracy: 0.5287\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.8515 - accuracy: 0.6390\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.6745 - accuracy: 0.7313\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.5800 - accuracy: 0.7710\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.5281 - accuracy: 0.7905\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.4730 - accuracy: 0.8156\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.4818 - accuracy: 0.8105\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.4379 - accuracy: 0.8282\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.4223 - accuracy: 0.8348\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.4133 - accuracy: 0.8405\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3954 - accuracy: 0.8470\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3881 - accuracy: 0.8485\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3744 - accuracy: 0.8570\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3664 - accuracy: 0.8574\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3637 - accuracy: 0.8601\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3482 - accuracy: 0.8666\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3513 - accuracy: 0.8629\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3408 - accuracy: 0.8678\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3340 - accuracy: 0.8704\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3283 - accuracy: 0.8736\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3269 - accuracy: 0.8737\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3376 - accuracy: 0.8701\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3169 - accuracy: 0.8776\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3224 - accuracy: 0.8746\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3155 - accuracy: 0.8772\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3032 - accuracy: 0.8809\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3047 - accuracy: 0.8821\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.3101 - accuracy: 0.8791\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2939 - accuracy: 0.8865\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2983 - accuracy: 0.8865\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2983 - accuracy: 0.8872 0s - loss: 0\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2961 - accuracy: 0.8858\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2928 - accuracy: 0.8892\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2937 - accuracy: 0.8874\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2710 - accuracy: 0.8954\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2750 - accuracy: 0.8934\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2793 - accuracy: 0.8924\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2792 - accuracy: 0.8935\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2904 - accuracy: 0.8908\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2693 - accuracy: 0.8983\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2748 - accuracy: 0.8942\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2719 - accuracy: 0.8985\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2632 - accuracy: 0.8982\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2678 - accuracy: 0.8959\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2570 - accuracy: 0.9013\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2547 - accuracy: 0.9027\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2529 - accuracy: 0.9031\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2607 - accuracy: 0.8997\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2614 - accuracy: 0.8987\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2515 - accuracy: 0.9022\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2417 - accuracy: 0.9065\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2555 - accuracy: 0.9027\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2404 - accuracy: 0.9090\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2474 - accuracy: 0.9061\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2442 - accuracy: 0.9081\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2367 - accuracy: 0.9090\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2438 - accuracy: 0.9062\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2425 - accuracy: 0.9076\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.2376 - accuracy: 0.9092\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.2324 - accuracy: 0.9111\n",
      "76/76 [==============================] - 1s 15ms/step - loss: 0.2455 - accuracy: 0.9097\n",
      "Model: \"sequential_43\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_129 (Conv1D)          (None, 88, 512)           5120      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_43 (MaxPooling (None, 44, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_130 (Conv1D)          (None, 42, 512)           786944    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_43 (Averag (None, 21, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_131 (Conv1D)          (None, 19, 256)           393472    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_43  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_129 (Dense)            (None, 384)               98688     \n",
      "_________________________________________________________________\n",
      "dropout_86 (Dropout)         (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_130 (Dense)            (None, 384)               147840    \n",
      "_________________________________________________________________\n",
      "dropout_87 (Dropout)         (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_131 (Dense)            (None, 6)                 2310      \n",
      "=================================================================\n",
      "Total params: 1,434,374\n",
      "Trainable params: 1,434,374\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 512, k_conv_1 = 3,  n_conv_2 = 512, k_conv_2 = 3, \n",
      "          n_conv_3 = 256,  k_conv_3 = 3,  maxpooling_pool_size = 2,\n",
      "          avepooling_pool_size = 2,  n_dense_1 = 384, dropout_1 = 0.2,\n",
      "          n_dense_2 = 384, dropout_2 = 0.3, activation_conv=  elu,\n",
      "          activation_dense=  elu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 1.2220 - accuracy: 0.4761\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 1.0735 - accuracy: 0.5427\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.9400 - accuracy: 0.6085\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.8341 - accuracy: 0.6635\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.7372 - accuracy: 0.7110\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.7015 - accuracy: 0.7188\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.6319 - accuracy: 0.7468\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.5991 - accuracy: 0.7613\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.5904 - accuracy: 0.7642\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.5490 - accuracy: 0.7793\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.5328 - accuracy: 0.7846\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.5121 - accuracy: 0.7960\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.4886 - accuracy: 0.8082\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.4677 - accuracy: 0.8168\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.4514 - accuracy: 0.8259\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.4460 - accuracy: 0.8283\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.4309 - accuracy: 0.8337\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.4145 - accuracy: 0.8411\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.3935 - accuracy: 0.8482\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.3852 - accuracy: 0.8503\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.3708 - accuracy: 0.8581\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.3799 - accuracy: 0.8541\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.3627 - accuracy: 0.8607\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.3592 - accuracy: 0.8616\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.3565 - accuracy: 0.8631\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.3498 - accuracy: 0.8646\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.3319 - accuracy: 0.8719\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.3269 - accuracy: 0.8741\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.3268 - accuracy: 0.8749\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.3239 - accuracy: 0.8743\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.3170 - accuracy: 0.8789\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.3060 - accuracy: 0.8797\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.2991 - accuracy: 0.8839\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.3019 - accuracy: 0.8826\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.2923 - accuracy: 0.8870\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2875 - accuracy: 0.8879\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.2815 - accuracy: 0.8919\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.2819 - accuracy: 0.8910\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.2754 - accuracy: 0.8928\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.2793 - accuracy: 0.8928\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.2651 - accuracy: 0.8963\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.2669 - accuracy: 0.8963\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.2612 - accuracy: 0.8990\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.2666 - accuracy: 0.8969\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2590 - accuracy: 0.8998\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.2516 - accuracy: 0.9028\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.2499 - accuracy: 0.9058\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.2455 - accuracy: 0.9063\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.2502 - accuracy: 0.9044\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.2326 - accuracy: 0.9102\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2361 - accuracy: 0.9091\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.2327 - accuracy: 0.9092\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.2245 - accuracy: 0.9118\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.2189 - accuracy: 0.9161 0s - loss:\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.2242 - accuracy: 0.9142\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.2224 - accuracy: 0.9146\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2232 - accuracy: 0.9136\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.2216 - accuracy: 0.9143\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.2105 - accuracy: 0.9200\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.2081 - accuracy: 0.9215\n",
      "76/76 [==============================] - 1s 19ms/step - loss: 0.2475 - accuracy: 0.9192\n",
      "Model: \"sequential_44\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_132 (Conv1D)          (None, 88, 512)           5120      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_44 (MaxPooling (None, 44, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_133 (Conv1D)          (None, 42, 512)           786944    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_44 (Averag (None, 21, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_134 (Conv1D)          (None, 19, 256)           393472    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_44  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_132 (Dense)            (None, 384)               98688     \n",
      "_________________________________________________________________\n",
      "dropout_88 (Dropout)         (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_133 (Dense)            (None, 384)               147840    \n",
      "_________________________________________________________________\n",
      "dropout_89 (Dropout)         (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_134 (Dense)            (None, 6)                 2310      \n",
      "=================================================================\n",
      "Total params: 1,434,374\n",
      "Trainable params: 1,434,374\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 512, k_conv_1 = 3,  n_conv_2 = 512, k_conv_2 = 3, \n",
      "          n_conv_3 = 256,  k_conv_3 = 3,  maxpooling_pool_size = 2,\n",
      "          avepooling_pool_size = 2,  n_dense_1 = 384, dropout_1 = 0.2,\n",
      "          n_dense_2 = 384, dropout_2 = 0.3, activation_conv=  elu,\n",
      "          activation_dense=  elu\n",
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 7s 49ms/step - loss: 1.2134 - accuracy: 0.4825\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 1.0577 - accuracy: 0.5535\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.9189 - accuracy: 0.6212\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.8360 - accuracy: 0.6612\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.7650 - accuracy: 0.6971\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.7086 - accuracy: 0.7222\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.6619 - accuracy: 0.7389\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.6165 - accuracy: 0.7536\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.5792 - accuracy: 0.7696\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.5705 - accuracy: 0.7699\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.5367 - accuracy: 0.7848 \n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.5138 - accuracy: 0.7949\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.5152 - accuracy: 0.7938\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.4879 - accuracy: 0.8073\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.4640 - accuracy: 0.8147\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.4622 - accuracy: 0.8185\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.4374 - accuracy: 0.8278\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.4243 - accuracy: 0.8340\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.4066 - accuracy: 0.8426\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.3935 - accuracy: 0.8482\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.3918 - accuracy: 0.8494\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.3848 - accuracy: 0.8524\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.3670 - accuracy: 0.8571\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.3645 - accuracy: 0.8576\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.3557 - accuracy: 0.8619\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.3481 - accuracy: 0.8647\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.3432 - accuracy: 0.8658\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.3309 - accuracy: 0.8694\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.3284 - accuracy: 0.8708\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.3317 - accuracy: 0.8699\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.3226 - accuracy: 0.8729\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.3091 - accuracy: 0.8776\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.3124 - accuracy: 0.8766\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.3040 - accuracy: 0.8799\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.3016 - accuracy: 0.8819\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.2904 - accuracy: 0.8860\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.2862 - accuracy: 0.8874\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.2784 - accuracy: 0.8907\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.2881 - accuracy: 0.8852\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.2807 - accuracy: 0.8906\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.2702 - accuracy: 0.8949\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.2656 - accuracy: 0.8968\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.2629 - accuracy: 0.8966\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.2716 - accuracy: 0.8932\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.2603 - accuracy: 0.8981\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.2509 - accuracy: 0.9026\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.2483 - accuracy: 0.9023\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.2385 - accuracy: 0.9061\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.2421 - accuracy: 0.9044\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2495 - accuracy: 0.9014\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.2378 - accuracy: 0.9071\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.2279 - accuracy: 0.9110\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.2312 - accuracy: 0.9094\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.2166 - accuracy: 0.9135\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.2282 - accuracy: 0.9119\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.2220 - accuracy: 0.9149\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.2077 - accuracy: 0.9199\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.2081 - accuracy: 0.9200\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.2154 - accuracy: 0.9174\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.2058 - accuracy: 0.9197\n",
      "76/76 [==============================] - 1s 18ms/step - loss: 0.2559 - accuracy: 0.9203\n",
      "Model: \"sequential_45\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_135 (Conv1D)          (None, 88, 512)           5120      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_45 (MaxPooling (None, 44, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_136 (Conv1D)          (None, 42, 512)           786944    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_45 (Averag (None, 21, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_137 (Conv1D)          (None, 19, 256)           393472    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_45  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_135 (Dense)            (None, 384)               98688     \n",
      "_________________________________________________________________\n",
      "dropout_90 (Dropout)         (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_136 (Dense)            (None, 384)               147840    \n",
      "_________________________________________________________________\n",
      "dropout_91 (Dropout)         (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_137 (Dense)            (None, 6)                 2310      \n",
      "=================================================================\n",
      "Total params: 1,434,374\n",
      "Trainable params: 1,434,374\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 512, k_conv_1 = 3,  n_conv_2 = 512, k_conv_2 = 3, \n",
      "          n_conv_3 = 256,  k_conv_3 = 3,  maxpooling_pool_size = 2,\n",
      "          avepooling_pool_size = 2,  n_dense_1 = 384, dropout_1 = 0.2,\n",
      "          n_dense_2 = 384, dropout_2 = 0.3, activation_conv=  elu,\n",
      "          activation_dense=  elu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 1.2240 - accuracy: 0.4776\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 1.0753 - accuracy: 0.5414\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.9469 - accuracy: 0.6116\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.8374 - accuracy: 0.6681\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.7548 - accuracy: 0.7008\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.6986 - accuracy: 0.7209\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.6551 - accuracy: 0.7412\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.6231 - accuracy: 0.7522\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.6033 - accuracy: 0.7592\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.5502 - accuracy: 0.7798\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.5291 - accuracy: 0.7914\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.4990 - accuracy: 0.8035\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.4763 - accuracy: 0.8175\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.4686 - accuracy: 0.8207\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.4369 - accuracy: 0.8341\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.4307 - accuracy: 0.8384\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.4110 - accuracy: 0.8452\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.4090 - accuracy: 0.8450\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.3979 - accuracy: 0.8488\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.3744 - accuracy: 0.8586\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.3770 - accuracy: 0.8559\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.3672 - accuracy: 0.8597\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.3567 - accuracy: 0.8645\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.3451 - accuracy: 0.8668\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.3485 - accuracy: 0.8652\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.3382 - accuracy: 0.8689\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.3255 - accuracy: 0.8733\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.3329 - accuracy: 0.8716\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.3194 - accuracy: 0.8771\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.3048 - accuracy: 0.8830\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.3152 - accuracy: 0.8770\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.3014 - accuracy: 0.8831\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.3083 - accuracy: 0.8828\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.3003 - accuracy: 0.8842\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.2879 - accuracy: 0.8887\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.2935 - accuracy: 0.8882\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.2868 - accuracy: 0.8902\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.2805 - accuracy: 0.8915\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.2815 - accuracy: 0.8919\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.2669 - accuracy: 0.8969\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.2752 - accuracy: 0.8971\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.2743 - accuracy: 0.8940\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.2679 - accuracy: 0.8972\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2595 - accuracy: 0.8995\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2543 - accuracy: 0.9026\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.2505 - accuracy: 0.9039\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2543 - accuracy: 0.9038\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.2469 - accuracy: 0.9066\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.2453 - accuracy: 0.9067\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.2406 - accuracy: 0.9064\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.2367 - accuracy: 0.9096\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.2417 - accuracy: 0.9074\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.2248 - accuracy: 0.9150\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.2201 - accuracy: 0.9167\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.2215 - accuracy: 0.9144\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.2172 - accuracy: 0.9175\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.2089 - accuracy: 0.9201\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.2193 - accuracy: 0.9170\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.2092 - accuracy: 0.9227\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.2048 - accuracy: 0.9221\n",
      "76/76 [==============================] - 1s 18ms/step - loss: 0.2383 - accuracy: 0.9126\n",
      "Model: \"sequential_46\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_138 (Conv1D)          (None, 89, 768)           5376      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_46 (MaxPooling (None, 44, 768)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_139 (Conv1D)          (None, 42, 512)           1180160   \n",
      "_________________________________________________________________\n",
      "average_pooling1d_46 (Averag (None, 21, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_140 (Conv1D)          (None, 20, 256)           262400    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_46  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_138 (Dense)            (None, 384)               98688     \n",
      "_________________________________________________________________\n",
      "dropout_92 (Dropout)         (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_139 (Dense)            (None, 256)               98560     \n",
      "_________________________________________________________________\n",
      "dropout_93 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_140 (Dense)            (None, 6)                 1542      \n",
      "=================================================================\n",
      "Total params: 1,646,726\n",
      "Trainable params: 1,646,726\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 768, k_conv_1 = 2,  n_conv_2 = 512, k_conv_2 = 3, \n",
      "          n_conv_3 = 256,  k_conv_3 = 2,  maxpooling_pool_size = 2,\n",
      "          avepooling_pool_size = 2,  n_dense_1 = 384, dropout_1 = 0.3,\n",
      "          n_dense_2 = 256, dropout_2 = 0.3, activation_conv=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001F6FFADDA48>,\n",
      "          activation_dense=  relu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 1.1251 - accuracy: 0.5217\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.8930 - accuracy: 0.6222\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.7811 - accuracy: 0.6711\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.6894 - accuracy: 0.7146\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.6417 - accuracy: 0.7355\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.5768 - accuracy: 0.7653\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.5405 - accuracy: 0.7810\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.5056 - accuracy: 0.7978\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.4755 - accuracy: 0.8118\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.4676 - accuracy: 0.8143\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.4403 - accuracy: 0.8267\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.4286 - accuracy: 0.8299\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.4167 - accuracy: 0.8360\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.4036 - accuracy: 0.8402\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.3862 - accuracy: 0.8473\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.3871 - accuracy: 0.8467\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.3819 - accuracy: 0.8480\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.3740 - accuracy: 0.8531\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.3681 - accuracy: 0.8538\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.3618 - accuracy: 0.8581\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.3551 - accuracy: 0.8608\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.3579 - accuracy: 0.8566\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.3526 - accuracy: 0.8625\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.3447 - accuracy: 0.8635\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.3335 - accuracy: 0.8664\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.3495 - accuracy: 0.8622\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.3355 - accuracy: 0.8655\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.3300 - accuracy: 0.8691\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.3364 - accuracy: 0.8679\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.3269 - accuracy: 0.8696\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.3200 - accuracy: 0.8734\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.3112 - accuracy: 0.8762\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.3142 - accuracy: 0.8758\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.3174 - accuracy: 0.8732\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.3144 - accuracy: 0.8760\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.3123 - accuracy: 0.8777\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.3065 - accuracy: 0.8767\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.3078 - accuracy: 0.8753\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.2993 - accuracy: 0.8829\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.2999 - accuracy: 0.8793\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.2966 - accuracy: 0.8819\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.2931 - accuracy: 0.8813\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.3027 - accuracy: 0.8810\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.2942 - accuracy: 0.8829\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.2911 - accuracy: 0.8833\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.2999 - accuracy: 0.8819\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.2847 - accuracy: 0.8865\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.2761 - accuracy: 0.8909\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.2759 - accuracy: 0.8912\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.2801 - accuracy: 0.8902\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.2871 - accuracy: 0.8891\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.2909 - accuracy: 0.8862\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.2707 - accuracy: 0.8926\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.2677 - accuracy: 0.8960\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.2727 - accuracy: 0.8914\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.2763 - accuracy: 0.8915\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.2705 - accuracy: 0.8931\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.2655 - accuracy: 0.8962\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.2656 - accuracy: 0.8963\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.2654 - accuracy: 0.8948\n",
      "76/76 [==============================] - 2s 24ms/step - loss: 0.2838 - accuracy: 0.8946\n",
      "Model: \"sequential_47\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_141 (Conv1D)          (None, 89, 768)           5376      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_47 (MaxPooling (None, 44, 768)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_142 (Conv1D)          (None, 42, 512)           1180160   \n",
      "_________________________________________________________________\n",
      "average_pooling1d_47 (Averag (None, 21, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_143 (Conv1D)          (None, 20, 256)           262400    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_47  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_141 (Dense)            (None, 384)               98688     \n",
      "_________________________________________________________________\n",
      "dropout_94 (Dropout)         (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_142 (Dense)            (None, 256)               98560     \n",
      "_________________________________________________________________\n",
      "dropout_95 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_143 (Dense)            (None, 6)                 1542      \n",
      "=================================================================\n",
      "Total params: 1,646,726\n",
      "Trainable params: 1,646,726\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 768, k_conv_1 = 2,  n_conv_2 = 512, k_conv_2 = 3, \n",
      "          n_conv_3 = 256,  k_conv_3 = 2,  maxpooling_pool_size = 2,\n",
      "          avepooling_pool_size = 2,  n_dense_1 = 384, dropout_1 = 0.3,\n",
      "          n_dense_2 = 256, dropout_2 = 0.3, activation_conv=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001F6FFADDA48>,\n",
      "          activation_dense=  relu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 1.1085 - accuracy: 0.5273\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.8909 - accuracy: 0.6231\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.7808 - accuracy: 0.6705\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.6845 - accuracy: 0.7167\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.6224 - accuracy: 0.7444\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.5592 - accuracy: 0.7733\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.5301 - accuracy: 0.7882\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.5035 - accuracy: 0.7992\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.4748 - accuracy: 0.8127\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.4650 - accuracy: 0.8158\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.4403 - accuracy: 0.8259\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.4284 - accuracy: 0.8330\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.4041 - accuracy: 0.8421\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.4022 - accuracy: 0.8437\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.4006 - accuracy: 0.8443\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.3816 - accuracy: 0.8488\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.3853 - accuracy: 0.8493\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.3660 - accuracy: 0.8570\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.3657 - accuracy: 0.8567\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.3617 - accuracy: 0.8565\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.3470 - accuracy: 0.8625\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.3434 - accuracy: 0.8649\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.3431 - accuracy: 0.8649\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.3339 - accuracy: 0.8689\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.3501 - accuracy: 0.8627\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.3240 - accuracy: 0.8721\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.3348 - accuracy: 0.8680\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.3259 - accuracy: 0.8736\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.3239 - accuracy: 0.8721\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.3136 - accuracy: 0.8753\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.3263 - accuracy: 0.8713\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.3087 - accuracy: 0.8780\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.3064 - accuracy: 0.8791\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.3051 - accuracy: 0.8781\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.3053 - accuracy: 0.8806\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.3006 - accuracy: 0.8821\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.3028 - accuracy: 0.8787\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.3012 - accuracy: 0.8798\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.2922 - accuracy: 0.8841\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.2982 - accuracy: 0.8801\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.2845 - accuracy: 0.8864\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.2941 - accuracy: 0.8823\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.2848 - accuracy: 0.8846\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.2830 - accuracy: 0.8873\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.2846 - accuracy: 0.8862\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.2866 - accuracy: 0.8848\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.2866 - accuracy: 0.8838\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.2812 - accuracy: 0.8857\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.2777 - accuracy: 0.89010s - loss: 0.2772 - accura\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.2770 - accuracy: 0.8910\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.2746 - accuracy: 0.8911\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.2668 - accuracy: 0.8930\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.2694 - accuracy: 0.8934\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.2801 - accuracy: 0.8882\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.2711 - accuracy: 0.8935\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.2604 - accuracy: 0.8960\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.2655 - accuracy: 0.8932\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.2652 - accuracy: 0.8966\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.2578 - accuracy: 0.8979\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.2654 - accuracy: 0.8951\n",
      "76/76 [==============================] - 2s 24ms/step - loss: 0.2767 - accuracy: 0.8950\n",
      "Model: \"sequential_48\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_144 (Conv1D)          (None, 89, 768)           5376      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_48 (MaxPooling (None, 44, 768)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_145 (Conv1D)          (None, 42, 512)           1180160   \n",
      "_________________________________________________________________\n",
      "average_pooling1d_48 (Averag (None, 21, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_146 (Conv1D)          (None, 20, 256)           262400    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_48  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_144 (Dense)            (None, 384)               98688     \n",
      "_________________________________________________________________\n",
      "dropout_96 (Dropout)         (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_145 (Dense)            (None, 256)               98560     \n",
      "_________________________________________________________________\n",
      "dropout_97 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_146 (Dense)            (None, 6)                 1542      \n",
      "=================================================================\n",
      "Total params: 1,646,726\n",
      "Trainable params: 1,646,726\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 768, k_conv_1 = 2,  n_conv_2 = 512, k_conv_2 = 3, \n",
      "          n_conv_3 = 256,  k_conv_3 = 2,  maxpooling_pool_size = 2,\n",
      "          avepooling_pool_size = 2,  n_dense_1 = 384, dropout_1 = 0.3,\n",
      "          n_dense_2 = 256, dropout_2 = 0.3, activation_conv=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001F6FFADDA48>,\n",
      "          activation_dense=  relu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 1.1217 - accuracy: 0.5194\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.8918 - accuracy: 0.6238\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.7849 - accuracy: 0.6709\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.6974 - accuracy: 0.7098\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.6484 - accuracy: 0.7337\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.6003 - accuracy: 0.7562\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.5612 - accuracy: 0.7768\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.5109 - accuracy: 0.7971\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.4914 - accuracy: 0.8055\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.4650 - accuracy: 0.8199\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.4773 - accuracy: 0.8114\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.4406 - accuracy: 0.8266\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.4205 - accuracy: 0.8353\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.4174 - accuracy: 0.8358\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.4106 - accuracy: 0.8372\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.3971 - accuracy: 0.8433\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.3908 - accuracy: 0.8477\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.3821 - accuracy: 0.8498\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.3811 - accuracy: 0.8512\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.3728 - accuracy: 0.8519\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.3689 - accuracy: 0.8544\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.3590 - accuracy: 0.8586\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.3463 - accuracy: 0.8620\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.3446 - accuracy: 0.8636\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.3415 - accuracy: 0.8663\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.3513 - accuracy: 0.8603\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.3388 - accuracy: 0.8659\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.3389 - accuracy: 0.8672\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.3355 - accuracy: 0.8672\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.3429 - accuracy: 0.8638\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.3253 - accuracy: 0.8709\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.3177 - accuracy: 0.8737\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.3205 - accuracy: 0.8731\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.3151 - accuracy: 0.8756\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.3126 - accuracy: 0.8788\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.3113 - accuracy: 0.8757\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.3092 - accuracy: 0.8770\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.3010 - accuracy: 0.8818\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.3063 - accuracy: 0.8814\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.2985 - accuracy: 0.8821\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.2925 - accuracy: 0.8848\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.2912 - accuracy: 0.8869\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.2869 - accuracy: 0.8893\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.2947 - accuracy: 0.8845\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.2922 - accuracy: 0.8862\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.2901 - accuracy: 0.8890\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.2816 - accuracy: 0.8916\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.2951 - accuracy: 0.8864\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.2841 - accuracy: 0.8885\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.2794 - accuracy: 0.8921\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.2730 - accuracy: 0.8944\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.2788 - accuracy: 0.8911\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.2755 - accuracy: 0.8942\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.2646 - accuracy: 0.8957\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.2681 - accuracy: 0.8952\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.2705 - accuracy: 0.8942\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.2744 - accuracy: 0.8926\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.2663 - accuracy: 0.8969\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.2637 - accuracy: 0.8977\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.2628 - accuracy: 0.8987\n",
      "76/76 [==============================] - 2s 24ms/step - loss: 0.2578 - accuracy: 0.9043\n",
      "Model: \"sequential_49\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_147 (Conv1D)          (None, 88, 512)           5120      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_49 (MaxPooling (None, 44, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_148 (Conv1D)          (None, 42, 256)           393472    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_49 (Averag (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_149 (Conv1D)          (None, 20, 512)           262656    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_49  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_147 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_98 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_148 (Dense)            (None, 384)               196992    \n",
      "_________________________________________________________________\n",
      "dropout_99 (Dropout)         (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_149 (Dense)            (None, 6)                 2310      \n",
      "=================================================================\n",
      "Total params: 1,123,206\n",
      "Trainable params: 1,123,206\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 512, k_conv_1 = 3,  n_conv_2 = 256, k_conv_2 = 3, \n",
      "          n_conv_3 = 512,  k_conv_3 = 2,  maxpooling_pool_size = 2,\n",
      "          avepooling_pool_size = 2,  n_dense_1 = 512, dropout_1 = 0.2,\n",
      "          n_dense_2 = 384, dropout_2 = 0.3, activation_conv=  elu,\n",
      "          activation_dense=  elu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 1.2426 - accuracy: 0.4686\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 1.0788 - accuracy: 0.5403\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.9478 - accuracy: 0.6087 0s - loss: 0.9486 - accuracy: 0.60\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.8537 - accuracy: 0.6587\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.7966 - accuracy: 0.6860\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.7381 - accuracy: 0.7085\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.6956 - accuracy: 0.7266\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.6693 - accuracy: 0.7350\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.6379 - accuracy: 0.7432\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.6198 - accuracy: 0.7504\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.5735 - accuracy: 0.7666\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.5653 - accuracy: 0.7733\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.5390 - accuracy: 0.7802\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.5331 - accuracy: 0.7864\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.5124 - accuracy: 0.7924\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.4943 - accuracy: 0.8026\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.4888 - accuracy: 0.8074\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.4750 - accuracy: 0.8094\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.4665 - accuracy: 0.8138\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.4525 - accuracy: 0.8231\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.4367 - accuracy: 0.8281\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.4266 - accuracy: 0.8331\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.4141 - accuracy: 0.8385\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.4210 - accuracy: 0.8379\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3928 - accuracy: 0.8476\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3965 - accuracy: 0.8464\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3859 - accuracy: 0.8492\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3699 - accuracy: 0.8558\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3772 - accuracy: 0.8544\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3583 - accuracy: 0.8618\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3533 - accuracy: 0.8640\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3416 - accuracy: 0.8683\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3352 - accuracy: 0.8715\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3429 - accuracy: 0.8696\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3251 - accuracy: 0.8747\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3224 - accuracy: 0.8750\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3267 - accuracy: 0.8735\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3085 - accuracy: 0.8810\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3071 - accuracy: 0.8790\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3159 - accuracy: 0.8804\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2991 - accuracy: 0.8835\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2960 - accuracy: 0.8840\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2880 - accuracy: 0.8882\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2936 - accuracy: 0.8871\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2853 - accuracy: 0.8909\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2834 - accuracy: 0.8908\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2803 - accuracy: 0.8916\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2711 - accuracy: 0.8963\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2669 - accuracy: 0.8970\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2594 - accuracy: 0.9000\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2575 - accuracy: 0.9008\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2813 - accuracy: 0.8917\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2503 - accuracy: 0.9032\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2493 - accuracy: 0.9044\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2554 - accuracy: 0.9013\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2580 - accuracy: 0.9007\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2442 - accuracy: 0.9044\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2433 - accuracy: 0.9049\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2337 - accuracy: 0.9080\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2325 - accuracy: 0.9092\n",
      "76/76 [==============================] - 1s 15ms/step - loss: 0.2781 - accuracy: 0.9021\n",
      "Model: \"sequential_50\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_150 (Conv1D)          (None, 88, 512)           5120      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_50 (MaxPooling (None, 44, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_151 (Conv1D)          (None, 42, 256)           393472    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_50 (Averag (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_152 (Conv1D)          (None, 20, 512)           262656    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_50  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_150 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_100 (Dropout)        (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_151 (Dense)            (None, 384)               196992    \n",
      "_________________________________________________________________\n",
      "dropout_101 (Dropout)        (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_152 (Dense)            (None, 6)                 2310      \n",
      "=================================================================\n",
      "Total params: 1,123,206\n",
      "Trainable params: 1,123,206\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 512, k_conv_1 = 3,  n_conv_2 = 256, k_conv_2 = 3, \n",
      "          n_conv_3 = 512,  k_conv_3 = 2,  maxpooling_pool_size = 2,\n",
      "          avepooling_pool_size = 2,  n_dense_1 = 512, dropout_1 = 0.2,\n",
      "          n_dense_2 = 384, dropout_2 = 0.3, activation_conv=  elu,\n",
      "          activation_dense=  elu\n",
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 5s 35ms/step - loss: 1.2322 - accuracy: 0.4773\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 1.0783 - accuracy: 0.5443\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.9445 - accuracy: 0.6118\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.8654 - accuracy: 0.6524\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.7933 - accuracy: 0.6861\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.7224 - accuracy: 0.7175\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.6828 - accuracy: 0.7284\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.6530 - accuracy: 0.7363\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.6329 - accuracy: 0.7466\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.6055 - accuracy: 0.7562\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.5782 - accuracy: 0.7640\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.5503 - accuracy: 0.7786\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.5330 - accuracy: 0.7868\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - ETA: 0s - loss: 0.5078 - accuracy: 0.79 - 5s 35ms/step - loss: 0.5079 - accuracy: 0.7984\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.4999 - accuracy: 0.8022\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.4777 - accuracy: 0.8116\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.4878 - accuracy: 0.8084\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.4446 - accuracy: 0.8302\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.4441 - accuracy: 0.8289\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.4258 - accuracy: 0.8349\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.4161 - accuracy: 0.8394\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3997 - accuracy: 0.8471\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3902 - accuracy: 0.8508\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3806 - accuracy: 0.8542\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3787 - accuracy: 0.8539\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3662 - accuracy: 0.8600\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3566 - accuracy: 0.8660\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3511 - accuracy: 0.8671\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3637 - accuracy: 0.8618\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3344 - accuracy: 0.8732\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3271 - accuracy: 0.8732\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3179 - accuracy: 0.8770\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3237 - accuracy: 0.8745\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3133 - accuracy: 0.8770\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3105 - accuracy: 0.8797\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3035 - accuracy: 0.8830\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2938 - accuracy: 0.8861\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3011 - accuracy: 0.8828\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2842 - accuracy: 0.8910\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2954 - accuracy: 0.8877\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2833 - accuracy: 0.8891\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2805 - accuracy: 0.8911\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2809 - accuracy: 0.8908\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2689 - accuracy: 0.8970\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2806 - accuracy: 0.8898\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2586 - accuracy: 0.8992\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2679 - accuracy: 0.8966\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2649 - accuracy: 0.8969\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2555 - accuracy: 0.9022\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2606 - accuracy: 0.8978\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2497 - accuracy: 0.9013\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2429 - accuracy: 0.9032\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2496 - accuracy: 0.9040\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2482 - accuracy: 0.9022\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2469 - accuracy: 0.9060\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2431 - accuracy: 0.9046\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2401 - accuracy: 0.9070\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2334 - accuracy: 0.9082\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2288 - accuracy: 0.9101\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2366 - accuracy: 0.9079\n",
      "76/76 [==============================] - 1s 14ms/step - loss: 0.2604 - accuracy: 0.9147\n",
      "Model: \"sequential_51\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_153 (Conv1D)          (None, 88, 512)           5120      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_51 (MaxPooling (None, 44, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_154 (Conv1D)          (None, 42, 256)           393472    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_51 (Averag (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_155 (Conv1D)          (None, 20, 512)           262656    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_51  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_153 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_102 (Dropout)        (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_154 (Dense)            (None, 384)               196992    \n",
      "_________________________________________________________________\n",
      "dropout_103 (Dropout)        (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_155 (Dense)            (None, 6)                 2310      \n",
      "=================================================================\n",
      "Total params: 1,123,206\n",
      "Trainable params: 1,123,206\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 512, k_conv_1 = 3,  n_conv_2 = 256, k_conv_2 = 3, \n",
      "          n_conv_3 = 512,  k_conv_3 = 2,  maxpooling_pool_size = 2,\n",
      "          avepooling_pool_size = 2,  n_dense_1 = 512, dropout_1 = 0.2,\n",
      "          n_dense_2 = 384, dropout_2 = 0.3, activation_conv=  elu,\n",
      "          activation_dense=  elu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 1.2294 - accuracy: 0.4753\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 1.0843 - accuracy: 0.5399\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.9611 - accuracy: 0.6008\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.8706 - accuracy: 0.6484\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.8200 - accuracy: 0.6750\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.7489 - accuracy: 0.7065\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.7017 - accuracy: 0.7258\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.6674 - accuracy: 0.7299\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.6384 - accuracy: 0.7453\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.6034 - accuracy: 0.7559\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.5954 - accuracy: 0.7579\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.5618 - accuracy: 0.7722\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.5512 - accuracy: 0.7795\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.5094 - accuracy: 0.7962\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.5040 - accuracy: 0.7996\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.5017 - accuracy: 0.7992\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.4798 - accuracy: 0.8095\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.4602 - accuracy: 0.8214\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.4410 - accuracy: 0.8274\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.4256 - accuracy: 0.8353\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.4227 - accuracy: 0.8347\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.4153 - accuracy: 0.8385\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3943 - accuracy: 0.8485\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3966 - accuracy: 0.8469\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3806 - accuracy: 0.8512\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3755 - accuracy: 0.8534\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3654 - accuracy: 0.8597\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3559 - accuracy: 0.8637\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3454 - accuracy: 0.8677\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3391 - accuracy: 0.8694\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3374 - accuracy: 0.8687\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3339 - accuracy: 0.8712\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3241 - accuracy: 0.8745\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3303 - accuracy: 0.8741\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3167 - accuracy: 0.8785\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3084 - accuracy: 0.8807\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2976 - accuracy: 0.8849\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3119 - accuracy: 0.8786\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3010 - accuracy: 0.8838\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2861 - accuracy: 0.8901\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2876 - accuracy: 0.8907\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2865 - accuracy: 0.8915\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2786 - accuracy: 0.8941\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2743 - accuracy: 0.8949\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2782 - accuracy: 0.8927\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2636 - accuracy: 0.8990\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2725 - accuracy: 0.8945\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2715 - accuracy: 0.8959\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2684 - accuracy: 0.8962\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2572 - accuracy: 0.9002\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2502 - accuracy: 0.9043\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2526 - accuracy: 0.9003\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2477 - accuracy: 0.9047\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2469 - accuracy: 0.9050\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2425 - accuracy: 0.9051\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2401 - accuracy: 0.9068\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2391 - accuracy: 0.9084\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2361 - accuracy: 0.9080\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2313 - accuracy: 0.9093\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.2363 - accuracy: 0.9096\n",
      "76/76 [==============================] - 1s 14ms/step - loss: 0.2390 - accuracy: 0.9170\n",
      "Model: \"sequential_52\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_156 (Conv1D)          (None, 89, 768)           5376      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_52 (MaxPooling (None, 29, 768)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_157 (Conv1D)          (None, 27, 512)           1180160   \n",
      "_________________________________________________________________\n",
      "average_pooling1d_52 (Averag (None, 9, 512)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_158 (Conv1D)          (None, 7, 256)            393472    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_52  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_156 (Dense)            (None, 384)               98688     \n",
      "_________________________________________________________________\n",
      "dropout_104 (Dropout)        (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_157 (Dense)            (None, 384)               147840    \n",
      "_________________________________________________________________\n",
      "dropout_105 (Dropout)        (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_158 (Dense)            (None, 6)                 2310      \n",
      "=================================================================\n",
      "Total params: 1,827,846\n",
      "Trainable params: 1,827,846\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 768, k_conv_1 = 2,  n_conv_2 = 512, k_conv_2 = 3, \n",
      "          n_conv_3 = 256,  k_conv_3 = 3,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 384, dropout_1 = 0.3,\n",
      "          n_dense_2 = 384, dropout_2 = 0.3, activation_conv=  elu,\n",
      "          activation_dense=  relu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 1.1347 - accuracy: 0.5201\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.9682 - accuracy: 0.5798 0s - loss: 0.9699 - accuracy: \n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.8799 - accuracy: 0.6226\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.8121 - accuracy: 0.6517\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.7527 - accuracy: 0.6771\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.7019 - accuracy: 0.7017\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.6520 - accuracy: 0.7244\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.6167 - accuracy: 0.7443\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.5837 - accuracy: 0.7596\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.5341 - accuracy: 0.7858\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.5096 - accuracy: 0.7973\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.4866 - accuracy: 0.8086 0s - loss: 0.4868 - accuracy\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.4549 - accuracy: 0.8230\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.4428 - accuracy: 0.8276\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.4229 - accuracy: 0.8376\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.4050 - accuracy: 0.8431\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.3867 - accuracy: 0.8520\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.3851 - accuracy: 0.8514\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.3803 - accuracy: 0.8528\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.3654 - accuracy: 0.8587\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.3587 - accuracy: 0.8616\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.3536 - accuracy: 0.8627\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.3400 - accuracy: 0.8696\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.3365 - accuracy: 0.8696\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.3317 - accuracy: 0.8719\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.3383 - accuracy: 0.8710\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.3215 - accuracy: 0.8769\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.3188 - accuracy: 0.8775\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.3109 - accuracy: 0.8791\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.3065 - accuracy: 0.8839\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.3062 - accuracy: 0.8809\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.3082 - accuracy: 0.8800\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2960 - accuracy: 0.8853\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2974 - accuracy: 0.8857\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2987 - accuracy: 0.8847\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2799 - accuracy: 0.8912\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2894 - accuracy: 0.8892\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2840 - accuracy: 0.8895\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2809 - accuracy: 0.8893\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2698 - accuracy: 0.8926\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2788 - accuracy: 0.8917\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2708 - accuracy: 0.8923\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2641 - accuracy: 0.8971\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2756 - accuracy: 0.8917\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2562 - accuracy: 0.8999\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2667 - accuracy: 0.8975\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2618 - accuracy: 0.8962\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2558 - accuracy: 0.9019\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2516 - accuracy: 0.9008\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2525 - accuracy: 0.9014\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2528 - accuracy: 0.8995\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2425 - accuracy: 0.9040\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2436 - accuracy: 0.9046\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2475 - accuracy: 0.9035\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2414 - accuracy: 0.9052\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2427 - accuracy: 0.9070\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2386 - accuracy: 0.9069\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2341 - accuracy: 0.9082\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2329 - accuracy: 0.9090\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2273 - accuracy: 0.9115\n",
      "76/76 [==============================] - 1s 18ms/step - loss: 0.2637 - accuracy: 0.9071\n",
      "Model: \"sequential_53\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_159 (Conv1D)          (None, 89, 768)           5376      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_53 (MaxPooling (None, 29, 768)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_160 (Conv1D)          (None, 27, 512)           1180160   \n",
      "_________________________________________________________________\n",
      "average_pooling1d_53 (Averag (None, 9, 512)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_161 (Conv1D)          (None, 7, 256)            393472    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_53  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_159 (Dense)            (None, 384)               98688     \n",
      "_________________________________________________________________\n",
      "dropout_106 (Dropout)        (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_160 (Dense)            (None, 384)               147840    \n",
      "_________________________________________________________________\n",
      "dropout_107 (Dropout)        (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_161 (Dense)            (None, 6)                 2310      \n",
      "=================================================================\n",
      "Total params: 1,827,846\n",
      "Trainable params: 1,827,846\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 768, k_conv_1 = 2,  n_conv_2 = 512, k_conv_2 = 3, \n",
      "          n_conv_3 = 256,  k_conv_3 = 3,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 384, dropout_1 = 0.3,\n",
      "          n_dense_2 = 384, dropout_2 = 0.3, activation_conv=  elu,\n",
      "          activation_dense=  relu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 1.1342 - accuracy: 0.5186\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.9874 - accuracy: 0.5746\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.8861 - accuracy: 0.6179\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.8038 - accuracy: 0.6554\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.7534 - accuracy: 0.6792\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.7039 - accuracy: 0.7065\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.6635 - accuracy: 0.7189\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.6167 - accuracy: 0.7442\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.5798 - accuracy: 0.7619\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.5406 - accuracy: 0.7809\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.5119 - accuracy: 0.7978\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.4811 - accuracy: 0.8096\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.4542 - accuracy: 0.8197\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.4417 - accuracy: 0.8254\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.4284 - accuracy: 0.8326\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.4102 - accuracy: 0.8403\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.3989 - accuracy: 0.8434\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.3972 - accuracy: 0.8453\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.3806 - accuracy: 0.8532\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.3649 - accuracy: 0.8556\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.3654 - accuracy: 0.8568 0s - loss: 0.3655 - accuracy: 0.85\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.3618 - accuracy: 0.8604\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.3442 - accuracy: 0.8642\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.3367 - accuracy: 0.8669\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.3361 - accuracy: 0.8686\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.3283 - accuracy: 0.8720\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.3240 - accuracy: 0.8719\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.3283 - accuracy: 0.8711\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.3196 - accuracy: 0.8734\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.3127 - accuracy: 0.8753\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.3102 - accuracy: 0.8759\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.3086 - accuracy: 0.8780\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2947 - accuracy: 0.8832\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2935 - accuracy: 0.8821\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2972 - accuracy: 0.8832\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2929 - accuracy: 0.8842\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2912 - accuracy: 0.8842\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2850 - accuracy: 0.8881\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2821 - accuracy: 0.8873\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2821 - accuracy: 0.8855\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2746 - accuracy: 0.8905\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2778 - accuracy: 0.8901\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2723 - accuracy: 0.8906\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2631 - accuracy: 0.8952\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2714 - accuracy: 0.8931\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2640 - accuracy: 0.8951\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2583 - accuracy: 0.8974\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2696 - accuracy: 0.8924\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2596 - accuracy: 0.8953\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2517 - accuracy: 0.8991\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2587 - accuracy: 0.8964\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2530 - accuracy: 0.8999\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2579 - accuracy: 0.8973\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2412 - accuracy: 0.9027\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2409 - accuracy: 0.9029\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2385 - accuracy: 0.9044\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2418 - accuracy: 0.9041\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2296 - accuracy: 0.9094\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2349 - accuracy: 0.9060\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2389 - accuracy: 0.9066\n",
      "76/76 [==============================] - 1s 18ms/step - loss: 0.2781 - accuracy: 0.9076\n",
      "Model: \"sequential_54\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_162 (Conv1D)          (None, 89, 768)           5376      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_54 (MaxPooling (None, 29, 768)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_163 (Conv1D)          (None, 27, 512)           1180160   \n",
      "_________________________________________________________________\n",
      "average_pooling1d_54 (Averag (None, 9, 512)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_164 (Conv1D)          (None, 7, 256)            393472    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_54  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_162 (Dense)            (None, 384)               98688     \n",
      "_________________________________________________________________\n",
      "dropout_108 (Dropout)        (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_163 (Dense)            (None, 384)               147840    \n",
      "_________________________________________________________________\n",
      "dropout_109 (Dropout)        (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_164 (Dense)            (None, 6)                 2310      \n",
      "=================================================================\n",
      "Total params: 1,827,846\n",
      "Trainable params: 1,827,846\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 768, k_conv_1 = 2,  n_conv_2 = 512, k_conv_2 = 3, \n",
      "          n_conv_3 = 256,  k_conv_3 = 3,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 384, dropout_1 = 0.3,\n",
      "          n_dense_2 = 384, dropout_2 = 0.3, activation_conv=  elu,\n",
      "          activation_dense=  relu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 1.1332 - accuracy: 0.5235\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.9737 - accuracy: 0.5802\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.8807 - accuracy: 0.6221\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.8048 - accuracy: 0.6529\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.7528 - accuracy: 0.6822\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.6953 - accuracy: 0.7041\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.6503 - accuracy: 0.7258\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.6124 - accuracy: 0.7448\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.5760 - accuracy: 0.7630\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.5504 - accuracy: 0.7739\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.5204 - accuracy: 0.7893\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.4932 - accuracy: 0.7992\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.4751 - accuracy: 0.8124\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.4435 - accuracy: 0.8250\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.4409 - accuracy: 0.8244\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.4156 - accuracy: 0.8379\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.4141 - accuracy: 0.8388\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.3915 - accuracy: 0.8459\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.3816 - accuracy: 0.8496\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.3800 - accuracy: 0.8514\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.3737 - accuracy: 0.8547\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.3571 - accuracy: 0.8619 0s - loss: 0.357\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.3584 - accuracy: 0.8610\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.3560 - accuracy: 0.8618\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.3435 - accuracy: 0.8672\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.3372 - accuracy: 0.8692\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.3339 - accuracy: 0.8697\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.3267 - accuracy: 0.8725\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.3250 - accuracy: 0.8739\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.3077 - accuracy: 0.8808\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.3124 - accuracy: 0.8788\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.3146 - accuracy: 0.8753\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.3094 - accuracy: 0.8810\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.3003 - accuracy: 0.8845\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2931 - accuracy: 0.8871\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2943 - accuracy: 0.8860\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2971 - accuracy: 0.8861\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2844 - accuracy: 0.8891\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2866 - accuracy: 0.8881\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2871 - accuracy: 0.8903\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2715 - accuracy: 0.8935\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2725 - accuracy: 0.8933\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2619 - accuracy: 0.8971\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2743 - accuracy: 0.8930\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2689 - accuracy: 0.8962\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2740 - accuracy: 0.8925\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2622 - accuracy: 0.8968\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2634 - accuracy: 0.8966\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2661 - accuracy: 0.8965\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2553 - accuracy: 0.8998\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2575 - accuracy: 0.9003\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2460 - accuracy: 0.9041\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2484 - accuracy: 0.9034\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2459 - accuracy: 0.9064\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2466 - accuracy: 0.9038\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2389 - accuracy: 0.9057\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2406 - accuracy: 0.9059\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2380 - accuracy: 0.9067\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2360 - accuracy: 0.9070\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.2307 - accuracy: 0.9080\n",
      "76/76 [==============================] - 1s 18ms/step - loss: 0.2746 - accuracy: 0.9076\n",
      "Model: \"sequential_55\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_165 (Conv1D)          (None, 89, 512)           3584      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_55 (MaxPooling (None, 44, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_166 (Conv1D)          (None, 42, 256)           393472    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_55 (Averag (None, 14, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_167 (Conv1D)          (None, 13, 256)           131328    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_55  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_165 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_110 (Dropout)        (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_166 (Dense)            (None, 384)               98688     \n",
      "_________________________________________________________________\n",
      "dropout_111 (Dropout)        (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_167 (Dense)            (None, 6)                 2310      \n",
      "=================================================================\n",
      "Total params: 695,174\n",
      "Trainable params: 695,174\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 512, k_conv_1 = 2,  n_conv_2 = 256, k_conv_2 = 3, \n",
      "          n_conv_3 = 256,  k_conv_3 = 2,  maxpooling_pool_size = 2,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 256, dropout_1 = 0.2,\n",
      "          n_dense_2 = 384, dropout_2 = 0.3, activation_conv=  relu,\n",
      "          activation_dense=  elu\n",
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 5s 31ms/step - loss: 1.0513 - accuracy: 0.5503\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.7316 - accuracy: 0.6978\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.5951 - accuracy: 0.7636\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4970 - accuracy: 0.8157\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4325 - accuracy: 0.8381\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3847 - accuracy: 0.8577\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3584 - accuracy: 0.8699\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3299 - accuracy: 0.8782\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3043 - accuracy: 0.8883\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2947 - accuracy: 0.8932\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2856 - accuracy: 0.8953\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2683 - accuracy: 0.9009\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2564 - accuracy: 0.9053\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2578 - accuracy: 0.9066\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2478 - accuracy: 0.9097\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2388 - accuracy: 0.9128\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2284 - accuracy: 0.9167\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2242 - accuracy: 0.9195\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2140 - accuracy: 0.9216\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2169 - accuracy: 0.9215\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2072 - accuracy: 0.9247\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2059 - accuracy: 0.9263\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2080 - accuracy: 0.9245\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2055 - accuracy: 0.9256\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1928 - accuracy: 0.9292\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1860 - accuracy: 0.9316\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1796 - accuracy: 0.9334\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1836 - accuracy: 0.9331\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1662 - accuracy: 0.9390\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1783 - accuracy: 0.9345\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1803 - accuracy: 0.9337\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1668 - accuracy: 0.9388\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1619 - accuracy: 0.9396\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1606 - accuracy: 0.9405\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1651 - accuracy: 0.9391\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1504 - accuracy: 0.9438\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1568 - accuracy: 0.9413\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1491 - accuracy: 0.9445\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1540 - accuracy: 0.9428\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1475 - accuracy: 0.9453\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1421 - accuracy: 0.9473\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1455 - accuracy: 0.9454\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1404 - accuracy: 0.9471\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1360 - accuracy: 0.9482\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1372 - accuracy: 0.9487\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1370 - accuracy: 0.9484\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1303 - accuracy: 0.9507\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1306 - accuracy: 0.9494\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1310 - accuracy: 0.9508\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1264 - accuracy: 0.9525\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1201 - accuracy: 0.9539\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1214 - accuracy: 0.9544\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1281 - accuracy: 0.9509\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1153 - accuracy: 0.9564\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1139 - accuracy: 0.9563\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1255 - accuracy: 0.9526\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1162 - accuracy: 0.9558\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1129 - accuracy: 0.9581\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1051 - accuracy: 0.9598\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1099 - accuracy: 0.9587\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 0.2495 - accuracy: 0.9285\n",
      "Model: \"sequential_56\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_168 (Conv1D)          (None, 89, 512)           3584      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_56 (MaxPooling (None, 44, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_169 (Conv1D)          (None, 42, 256)           393472    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_56 (Averag (None, 14, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_170 (Conv1D)          (None, 13, 256)           131328    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_56  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_168 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_112 (Dropout)        (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_169 (Dense)            (None, 384)               98688     \n",
      "_________________________________________________________________\n",
      "dropout_113 (Dropout)        (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_170 (Dense)            (None, 6)                 2310      \n",
      "=================================================================\n",
      "Total params: 695,174\n",
      "Trainable params: 695,174\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 512, k_conv_1 = 2,  n_conv_2 = 256, k_conv_2 = 3, \n",
      "          n_conv_3 = 256,  k_conv_3 = 2,  maxpooling_pool_size = 2,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 256, dropout_1 = 0.2,\n",
      "          n_dense_2 = 384, dropout_2 = 0.3, activation_conv=  relu,\n",
      "          activation_dense=  elu\n",
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 5s 31ms/step - loss: 1.0630 - accuracy: 0.5455\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.7385 - accuracy: 0.6941\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.5656 - accuracy: 0.7805\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4700 - accuracy: 0.8245\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3933 - accuracy: 0.8549\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3573 - accuracy: 0.8673\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3348 - accuracy: 0.8760\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3136 - accuracy: 0.8847\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3048 - accuracy: 0.8877\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2818 - accuracy: 0.8968\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2709 - accuracy: 0.8989\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2579 - accuracy: 0.9060\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2488 - accuracy: 0.9086\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2418 - accuracy: 0.9127\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2320 - accuracy: 0.9156\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2287 - accuracy: 0.9160\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2203 - accuracy: 0.9191\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2195 - accuracy: 0.9205\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2085 - accuracy: 0.9246\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2050 - accuracy: 0.9256\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1937 - accuracy: 0.9282\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1996 - accuracy: 0.9279\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1973 - accuracy: 0.9273\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1816 - accuracy: 0.9344\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1800 - accuracy: 0.9344\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1783 - accuracy: 0.9345\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1759 - accuracy: 0.9361\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1713 - accuracy: 0.9370\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1693 - accuracy: 0.9379\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1628 - accuracy: 0.9405\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1616 - accuracy: 0.9404\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1564 - accuracy: 0.9423\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1550 - accuracy: 0.9431\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1500 - accuracy: 0.9436\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1470 - accuracy: 0.9439\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1501 - accuracy: 0.9438\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1521 - accuracy: 0.9429\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1388 - accuracy: 0.9480\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1466 - accuracy: 0.9445\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1422 - accuracy: 0.9470\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1495 - accuracy: 0.9449\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1300 - accuracy: 0.9509\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1292 - accuracy: 0.9505 0s - loss: 0.130\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1281 - accuracy: 0.9516\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1288 - accuracy: 0.9513\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1228 - accuracy: 0.9531\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1172 - accuracy: 0.9555\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1290 - accuracy: 0.9535\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1201 - accuracy: 0.9543\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1137 - accuracy: 0.9570\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1154 - accuracy: 0.9565\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1152 - accuracy: 0.9559\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1139 - accuracy: 0.9568\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1114 - accuracy: 0.9574\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1105 - accuracy: 0.9569\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1161 - accuracy: 0.9560\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1273 - accuracy: 0.9534\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.0983 - accuracy: 0.9629\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1032 - accuracy: 0.9603\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1102 - accuracy: 0.9583\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 0.2678 - accuracy: 0.9270\n",
      "Model: \"sequential_57\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_171 (Conv1D)          (None, 89, 512)           3584      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_57 (MaxPooling (None, 44, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_172 (Conv1D)          (None, 42, 256)           393472    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_57 (Averag (None, 14, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_173 (Conv1D)          (None, 13, 256)           131328    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_57  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_171 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_114 (Dropout)        (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_172 (Dense)            (None, 384)               98688     \n",
      "_________________________________________________________________\n",
      "dropout_115 (Dropout)        (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_173 (Dense)            (None, 6)                 2310      \n",
      "=================================================================\n",
      "Total params: 695,174\n",
      "Trainable params: 695,174\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 512, k_conv_1 = 2,  n_conv_2 = 256, k_conv_2 = 3, \n",
      "          n_conv_3 = 256,  k_conv_3 = 2,  maxpooling_pool_size = 2,\n",
      "          avepooling_pool_size = 3,  n_dense_1 = 256, dropout_1 = 0.2,\n",
      "          n_dense_2 = 384, dropout_2 = 0.3, activation_conv=  relu,\n",
      "          activation_dense=  elu\n",
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 5s 31ms/step - loss: 1.0515 - accuracy: 0.5532\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.7334 - accuracy: 0.6979\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.5788 - accuracy: 0.7750\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4740 - accuracy: 0.8242\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.4107 - accuracy: 0.8473\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3749 - accuracy: 0.8630\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3406 - accuracy: 0.8761\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3166 - accuracy: 0.8852\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.3022 - accuracy: 0.8864\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2878 - accuracy: 0.8941\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2735 - accuracy: 0.9005\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2683 - accuracy: 0.9021\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2554 - accuracy: 0.9053\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2497 - accuracy: 0.9074\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2366 - accuracy: 0.9135\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2295 - accuracy: 0.9164\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2302 - accuracy: 0.9158\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2166 - accuracy: 0.9188\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2131 - accuracy: 0.9212\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.2127 - accuracy: 0.9212\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1991 - accuracy: 0.9278\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1981 - accuracy: 0.9272\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1906 - accuracy: 0.9298\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1974 - accuracy: 0.9276\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1929 - accuracy: 0.9291\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1829 - accuracy: 0.9331\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1805 - accuracy: 0.9319\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1808 - accuracy: 0.9328\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1740 - accuracy: 0.9355\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1726 - accuracy: 0.9360\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1740 - accuracy: 0.9363\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1650 - accuracy: 0.9386\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1614 - accuracy: 0.9410\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1722 - accuracy: 0.9363\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1568 - accuracy: 0.9419\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1525 - accuracy: 0.9433\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1543 - accuracy: 0.9445\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1532 - accuracy: 0.9436\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1457 - accuracy: 0.9452\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1444 - accuracy: 0.9468\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1458 - accuracy: 0.9467\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1418 - accuracy: 0.9478\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1381 - accuracy: 0.9489\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1381 - accuracy: 0.9484\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1305 - accuracy: 0.9518\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1328 - accuracy: 0.9507\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1338 - accuracy: 0.9496\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1261 - accuracy: 0.9529\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1308 - accuracy: 0.9508\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1234 - accuracy: 0.9544\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1266 - accuracy: 0.9518\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1215 - accuracy: 0.9540\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1197 - accuracy: 0.9548\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1162 - accuracy: 0.9567\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1151 - accuracy: 0.9564\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1151 - accuracy: 0.9571\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1184 - accuracy: 0.9559\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1179 - accuracy: 0.9560\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1181 - accuracy: 0.9575\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.1170 - accuracy: 0.9570\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 0.2252 - accuracy: 0.9337\n",
      "Model: \"sequential_58\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_174 (Conv1D)          (None, 89, 768)           5376      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_58 (MaxPooling (None, 44, 768)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_175 (Conv1D)          (None, 43, 512)           786944    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_58 (Averag (None, 21, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_176 (Conv1D)          (None, 20, 512)           524800    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_58  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_174 (Dense)            (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_116 (Dropout)        (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_175 (Dense)            (None, 384)               98688     \n",
      "_________________________________________________________________\n",
      "dropout_117 (Dropout)        (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_176 (Dense)            (None, 6)                 2310      \n",
      "=================================================================\n",
      "Total params: 1,549,446\n",
      "Trainable params: 1,549,446\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 768, k_conv_1 = 2,  n_conv_2 = 512, k_conv_2 = 2, \n",
      "          n_conv_3 = 512,  k_conv_3 = 2,  maxpooling_pool_size = 2,\n",
      "          avepooling_pool_size = 2,  n_dense_1 = 256, dropout_1 = 0.3,\n",
      "          n_dense_2 = 384, dropout_2 = 0.3, activation_conv=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001F6FFADDA48>,\n",
      "          activation_dense=  relu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "152/152 [==============================] - 10s 63ms/step - loss: 1.1161 - accuracy: 0.5243\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.9139 - accuracy: 0.6152\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.7938 - accuracy: 0.6654\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.6986 - accuracy: 0.7062\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.6433 - accuracy: 0.7339\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.5852 - accuracy: 0.7627\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.5541 - accuracy: 0.7777\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.5099 - accuracy: 0.7976\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.5006 - accuracy: 0.7997\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.4640 - accuracy: 0.8166\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.4437 - accuracy: 0.8225\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.4375 - accuracy: 0.8298\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.4369 - accuracy: 0.8286\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.4171 - accuracy: 0.8342\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.4046 - accuracy: 0.8403\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.3995 - accuracy: 0.8447\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.3843 - accuracy: 0.8494\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.3836 - accuracy: 0.8500\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.3748 - accuracy: 0.8518\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.3704 - accuracy: 0.8532\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.3667 - accuracy: 0.8551\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.3516 - accuracy: 0.8603\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.3519 - accuracy: 0.8611\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.3440 - accuracy: 0.8646\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.3488 - accuracy: 0.8639\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.3360 - accuracy: 0.8675\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.3537 - accuracy: 0.8608\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.3350 - accuracy: 0.8687\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.3352 - accuracy: 0.8678\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 9s 59ms/step - loss: 0.3251 - accuracy: 0.8718\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 9s 59ms/step - loss: 0.3221 - accuracy: 0.8742\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.3245 - accuracy: 0.8722\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.3244 - accuracy: 0.8725\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.3125 - accuracy: 0.8762\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.3226 - accuracy: 0.8714\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.3129 - accuracy: 0.8762\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.3119 - accuracy: 0.8766\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.3057 - accuracy: 0.8800\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 9s 59ms/step - loss: 0.2967 - accuracy: 0.8819\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 9s 59ms/step - loss: 0.3066 - accuracy: 0.8806\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.3077 - accuracy: 0.8771\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.2975 - accuracy: 0.8800\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.3001 - accuracy: 0.8832\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 9s 59ms/step - loss: 0.3059 - accuracy: 0.8808\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.2933 - accuracy: 0.8859\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.2971 - accuracy: 0.8849\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.2889 - accuracy: 0.8864\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.2896 - accuracy: 0.8871\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.2881 - accuracy: 0.8864\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.2799 - accuracy: 0.8899\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.2913 - accuracy: 0.8874\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 9s 59ms/step - loss: 0.2838 - accuracy: 0.8905\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 9s 59ms/step - loss: 0.2670 - accuracy: 0.8937\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.2810 - accuracy: 0.8911\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.2690 - accuracy: 0.8951\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.2685 - accuracy: 0.8952\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.2763 - accuracy: 0.8914\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 9s 59ms/step - loss: 0.2788 - accuracy: 0.8915\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.2694 - accuracy: 0.8948\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.2713 - accuracy: 0.8936\n",
      "76/76 [==============================] - 2s 25ms/step - loss: 0.2900 - accuracy: 0.8866\n",
      "Model: \"sequential_59\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_177 (Conv1D)          (None, 89, 768)           5376      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_59 (MaxPooling (None, 44, 768)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_178 (Conv1D)          (None, 43, 512)           786944    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_59 (Averag (None, 21, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_179 (Conv1D)          (None, 20, 512)           524800    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_59  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_177 (Dense)            (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_118 (Dropout)        (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_178 (Dense)            (None, 384)               98688     \n",
      "_________________________________________________________________\n",
      "dropout_119 (Dropout)        (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_179 (Dense)            (None, 6)                 2310      \n",
      "=================================================================\n",
      "Total params: 1,549,446\n",
      "Trainable params: 1,549,446\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 768, k_conv_1 = 2,  n_conv_2 = 512, k_conv_2 = 2, \n",
      "          n_conv_3 = 512,  k_conv_3 = 2,  maxpooling_pool_size = 2,\n",
      "          avepooling_pool_size = 2,  n_dense_1 = 256, dropout_1 = 0.3,\n",
      "          n_dense_2 = 384, dropout_2 = 0.3, activation_conv=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001F6FFADDA48>,\n",
      "          activation_dense=  relu\n",
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 9s 59ms/step - loss: 1.1094 - accuracy: 0.5255\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.9049 - accuracy: 0.6150\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.8018 - accuracy: 0.6629\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.7174 - accuracy: 0.6984\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.6477 - accuracy: 0.7327\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.5937 - accuracy: 0.7593\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.5380 - accuracy: 0.7855\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.5146 - accuracy: 0.7976\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.4962 - accuracy: 0.8038\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.4734 - accuracy: 0.8141\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.4419 - accuracy: 0.8283\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.4274 - accuracy: 0.8336\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.4196 - accuracy: 0.8397\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 9s 59ms/step - loss: 0.4082 - accuracy: 0.8401\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 9s 59ms/step - loss: 0.4084 - accuracy: 0.8409\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.3896 - accuracy: 0.8482\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.3836 - accuracy: 0.8513\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.3803 - accuracy: 0.8511\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.3735 - accuracy: 0.8555\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.3665 - accuracy: 0.8564\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.3669 - accuracy: 0.8591\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.3539 - accuracy: 0.8638\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.3583 - accuracy: 0.8617\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.3531 - accuracy: 0.8640\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.3412 - accuracy: 0.8672 \n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.3432 - accuracy: 0.8663\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.3330 - accuracy: 0.8698\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.3402 - accuracy: 0.8670\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.3350 - accuracy: 0.8689\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.3292 - accuracy: 0.8730\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 9s 59ms/step - loss: 0.3194 - accuracy: 0.8749\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.3279 - accuracy: 0.8705\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.3118 - accuracy: 0.8770\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.3202 - accuracy: 0.8752\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 9s 59ms/step - loss: 0.3090 - accuracy: 0.8804\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.3024 - accuracy: 0.8801\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.3074 - accuracy: 0.8782\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.3101 - accuracy: 0.8801 0s - loss: 0.3110 - accuracy: \n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.3071 - accuracy: 0.8808\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.3069 - accuracy: 0.8803\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.3039 - accuracy: 0.8801\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.2926 - accuracy: 0.8848\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.2881 - accuracy: 0.8884\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.2959 - accuracy: 0.8825\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 9s 59ms/step - loss: 0.2885 - accuracy: 0.8869\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.2913 - accuracy: 0.8864\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.2881 - accuracy: 0.8874\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.2858 - accuracy: 0.8888\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.2805 - accuracy: 0.8916\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.2890 - accuracy: 0.8859\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.2862 - accuracy: 0.8891\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.2726 - accuracy: 0.8934\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 9s 59ms/step - loss: 0.2701 - accuracy: 0.8938\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.2735 - accuracy: 0.8923\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.2696 - accuracy: 0.8949\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.2825 - accuracy: 0.8904\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 9s 59ms/step - loss: 0.2842 - accuracy: 0.8909\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.2632 - accuracy: 0.8967\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.2679 - accuracy: 0.8946\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.2672 - accuracy: 0.8978\n",
      "76/76 [==============================] - 2s 22ms/step - loss: 0.2665 - accuracy: 0.8994\n",
      "Model: \"sequential_60\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_180 (Conv1D)          (None, 89, 768)           5376      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_60 (MaxPooling (None, 44, 768)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_181 (Conv1D)          (None, 43, 512)           786944    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_60 (Averag (None, 21, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_182 (Conv1D)          (None, 20, 512)           524800    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_60  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_180 (Dense)            (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_120 (Dropout)        (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_181 (Dense)            (None, 384)               98688     \n",
      "_________________________________________________________________\n",
      "dropout_121 (Dropout)        (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_182 (Dense)            (None, 6)                 2310      \n",
      "=================================================================\n",
      "Total params: 1,549,446\n",
      "Trainable params: 1,549,446\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 768, k_conv_1 = 2,  n_conv_2 = 512, k_conv_2 = 2, \n",
      "          n_conv_3 = 512,  k_conv_3 = 2,  maxpooling_pool_size = 2,\n",
      "          avepooling_pool_size = 2,  n_dense_1 = 256, dropout_1 = 0.3,\n",
      "          n_dense_2 = 384, dropout_2 = 0.3, activation_conv=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x000001F6FFADDA48>,\n",
      "          activation_dense=  relu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 1.1201 - accuracy: 0.5216\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.9054 - accuracy: 0.6156\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.7860 - accuracy: 0.6679\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.7177 - accuracy: 0.6966\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 9s 59ms/step - loss: 0.6350 - accuracy: 0.7406\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 9s 59ms/step - loss: 0.5899 - accuracy: 0.7599\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.5455 - accuracy: 0.7809\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.5176 - accuracy: 0.7949\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.4852 - accuracy: 0.8083\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.4682 - accuracy: 0.8171 1s\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.4498 - accuracy: 0.8230\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.4437 - accuracy: 0.8259\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.4201 - accuracy: 0.8355\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.4148 - accuracy: 0.8394\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.4163 - accuracy: 0.8382\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.4010 - accuracy: 0.8425\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.3982 - accuracy: 0.8449\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.3917 - accuracy: 0.8476\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.3811 - accuracy: 0.8512\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.3803 - accuracy: 0.8530\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.3715 - accuracy: 0.8560\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.3651 - accuracy: 0.8568\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.3547 - accuracy: 0.8604\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.3404 - accuracy: 0.8669\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.3473 - accuracy: 0.8649\n",
      "Epoch 26/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.3391 - accuracy: 0.8677\n",
      "Epoch 27/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.3480 - accuracy: 0.8639\n",
      "Epoch 28/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.3459 - accuracy: 0.8654\n",
      "Epoch 29/60\n",
      "152/152 [==============================] - 9s 59ms/step - loss: 0.3466 - accuracy: 0.8666\n",
      "Epoch 30/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.3373 - accuracy: 0.8678\n",
      "Epoch 31/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.3341 - accuracy: 0.8688\n",
      "Epoch 32/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.3331 - accuracy: 0.8704\n",
      "Epoch 33/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.3294 - accuracy: 0.8699\n",
      "Epoch 34/60\n",
      "152/152 [==============================] - 9s 59ms/step - loss: 0.3265 - accuracy: 0.8713\n",
      "Epoch 35/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.3144 - accuracy: 0.8764\n",
      "Epoch 36/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.3102 - accuracy: 0.8773\n",
      "Epoch 37/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.3173 - accuracy: 0.8761\n",
      "Epoch 38/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.3099 - accuracy: 0.8788\n",
      "Epoch 39/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.3147 - accuracy: 0.8761\n",
      "Epoch 40/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.3201 - accuracy: 0.8742\n",
      "Epoch 41/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.3152 - accuracy: 0.8785\n",
      "Epoch 42/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.3072 - accuracy: 0.8801\n",
      "Epoch 43/60\n",
      "152/152 [==============================] - 9s 59ms/step - loss: 0.3023 - accuracy: 0.8814\n",
      "Epoch 44/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.2956 - accuracy: 0.8828\n",
      "Epoch 45/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.3053 - accuracy: 0.8833\n",
      "Epoch 46/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.2947 - accuracy: 0.8851\n",
      "Epoch 47/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.3014 - accuracy: 0.8837\n",
      "Epoch 48/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.2923 - accuracy: 0.8860\n",
      "Epoch 49/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.2968 - accuracy: 0.8837\n",
      "Epoch 50/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.2938 - accuracy: 0.8860\n",
      "Epoch 51/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.2847 - accuracy: 0.8891\n",
      "Epoch 52/60\n",
      "152/152 [==============================] - 9s 59ms/step - loss: 0.2947 - accuracy: 0.8851\n",
      "Epoch 53/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.2892 - accuracy: 0.8883\n",
      "Epoch 54/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.2818 - accuracy: 0.8913\n",
      "Epoch 55/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.2846 - accuracy: 0.8882\n",
      "Epoch 56/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.2737 - accuracy: 0.8934\n",
      "Epoch 57/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.2821 - accuracy: 0.8903\n",
      "Epoch 58/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.2755 - accuracy: 0.8924\n",
      "Epoch 59/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.2698 - accuracy: 0.8957\n",
      "Epoch 60/60\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.2733 - accuracy: 0.8943\n",
      "76/76 [==============================] - 2s 22ms/step - loss: 0.2647 - accuracy: 0.8970\n",
      "Model: \"sequential_61\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_183 (Conv1D)          (None, 88, 512)           5120      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_61 (MaxPooling (None, 44, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_184 (Conv1D)          (None, 43, 512)           524800    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_61 (Averag (None, 21, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_185 (Conv1D)          (None, 20, 256)           262400    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_61  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_183 (Dense)            (None, 384)               98688     \n",
      "_________________________________________________________________\n",
      "dropout_122 (Dropout)        (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_184 (Dense)            (None, 512)               197120    \n",
      "_________________________________________________________________\n",
      "dropout_123 (Dropout)        (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_185 (Dense)            (None, 6)                 3078      \n",
      "=================================================================\n",
      "Total params: 1,091,206\n",
      "Trainable params: 1,091,206\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 512, k_conv_1 = 3,  n_conv_2 = 512, k_conv_2 = 2, \n",
      "          n_conv_3 = 256,  k_conv_3 = 2,  maxpooling_pool_size = 2,\n",
      "          avepooling_pool_size = 2,  n_dense_1 = 384, dropout_1 = 0.2,\n",
      "          n_dense_2 = 512, dropout_2 = 0.2, activation_conv=  relu,\n",
      "          activation_dense=  relu\n",
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/228 [..............................] - ETA: 7s - loss: 1.7913 - accuracy: 0.1875WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0043s vs `on_train_batch_end` time: 0.0350s). Check your callbacks.\n",
      "228/228 [==============================] - 9s 41ms/step - loss: 0.9980 - accuracy: 0.5814\n",
      "Epoch 2/60\n",
      "228/228 [==============================] - 9s 39ms/step - loss: 0.5766 - accuracy: 0.7788\n",
      "Epoch 3/60\n",
      "228/228 [==============================] - 9s 39ms/step - loss: 0.4163 - accuracy: 0.8427\n",
      "Epoch 4/60\n",
      "228/228 [==============================] - 9s 39ms/step - loss: 0.3541 - accuracy: 0.8655\n",
      "Epoch 5/60\n",
      "228/228 [==============================] - 9s 39ms/step - loss: 0.3220 - accuracy: 0.8794 0s - loss: 0.3\n",
      "Epoch 6/60\n",
      "228/228 [==============================] - 9s 39ms/step - loss: 0.2986 - accuracy: 0.8867\n",
      "Epoch 7/60\n",
      "228/228 [==============================] - 9s 39ms/step - loss: 0.2818 - accuracy: 0.8947\n",
      "Epoch 8/60\n",
      "228/228 [==============================] - 9s 39ms/step - loss: 0.2712 - accuracy: 0.8975\n",
      "Epoch 9/60\n",
      "228/228 [==============================] - 9s 39ms/step - loss: 0.2571 - accuracy: 0.9044\n",
      "Epoch 10/60\n",
      "228/228 [==============================] - 9s 39ms/step - loss: 0.2476 - accuracy: 0.9079\n",
      "Epoch 11/60\n",
      "228/228 [==============================] - 9s 39ms/step - loss: 0.2371 - accuracy: 0.9125\n",
      "Epoch 12/60\n",
      "228/228 [==============================] - 9s 39ms/step - loss: 0.2281 - accuracy: 0.9145\n",
      "Epoch 13/60\n",
      "228/228 [==============================] - 9s 39ms/step - loss: 0.2222 - accuracy: 0.9186\n",
      "Epoch 14/60\n",
      "228/228 [==============================] - 9s 39ms/step - loss: 0.2159 - accuracy: 0.9206\n",
      "Epoch 15/60\n",
      "228/228 [==============================] - 9s 39ms/step - loss: 0.2089 - accuracy: 0.9229\n",
      "Epoch 16/60\n",
      "228/228 [==============================] - 9s 39ms/step - loss: 0.2015 - accuracy: 0.9249\n",
      "Epoch 17/60\n",
      "228/228 [==============================] - 9s 39ms/step - loss: 0.1955 - accuracy: 0.9280\n",
      "Epoch 18/60\n",
      "228/228 [==============================] - 9s 39ms/step - loss: 0.1906 - accuracy: 0.9287\n",
      "Epoch 19/60\n",
      "228/228 [==============================] - 9s 39ms/step - loss: 0.1822 - accuracy: 0.9332\n",
      "Epoch 20/60\n",
      "228/228 [==============================] - 9s 39ms/step - loss: 0.1831 - accuracy: 0.9332\n",
      "Epoch 21/60\n",
      "228/228 [==============================] - 9s 39ms/step - loss: 0.1750 - accuracy: 0.9339\n",
      "Epoch 22/60\n",
      "228/228 [==============================] - 9s 39ms/step - loss: 0.1753 - accuracy: 0.9340\n",
      "Epoch 23/60\n",
      "228/228 [==============================] - 9s 39ms/step - loss: 0.1626 - accuracy: 0.9392\n",
      "Epoch 24/60\n",
      "228/228 [==============================] - 9s 39ms/step - loss: 0.1596 - accuracy: 0.9412\n",
      "Epoch 25/60\n",
      "228/228 [==============================] - 9s 39ms/step - loss: 0.1594 - accuracy: 0.9405\n",
      "Epoch 26/60\n",
      "228/228 [==============================] - 9s 39ms/step - loss: 0.1561 - accuracy: 0.9424\n",
      "Epoch 27/60\n",
      "228/228 [==============================] - 9s 39ms/step - loss: 0.1573 - accuracy: 0.9422\n",
      "Epoch 28/60\n",
      "228/228 [==============================] - 9s 39ms/step - loss: 0.1469 - accuracy: 0.9451\n",
      "Epoch 29/60\n",
      "228/228 [==============================] - 9s 39ms/step - loss: 0.1452 - accuracy: 0.9472\n",
      "Epoch 30/60\n",
      "228/228 [==============================] - 9s 39ms/step - loss: 0.1341 - accuracy: 0.9508\n",
      "Epoch 31/60\n",
      "228/228 [==============================] - 9s 39ms/step - loss: 0.1438 - accuracy: 0.9464\n",
      "Epoch 32/60\n",
      "228/228 [==============================] - 9s 39ms/step - loss: 0.1421 - accuracy: 0.9469\n",
      "Epoch 33/60\n",
      "228/228 [==============================] - 9s 39ms/step - loss: 0.1338 - accuracy: 0.9500\n",
      "Epoch 34/60\n",
      "228/228 [==============================] - 9s 39ms/step - loss: 0.1306 - accuracy: 0.9514\n",
      "Epoch 35/60\n",
      "228/228 [==============================] - 9s 39ms/step - loss: 0.1206 - accuracy: 0.9548\n",
      "Epoch 36/60\n",
      "228/228 [==============================] - 9s 39ms/step - loss: 0.1245 - accuracy: 0.9536\n",
      "Epoch 37/60\n",
      "228/228 [==============================] - 9s 39ms/step - loss: 0.1176 - accuracy: 0.9556\n",
      "Epoch 38/60\n",
      "228/228 [==============================] - 9s 39ms/step - loss: 0.1205 - accuracy: 0.9549\n",
      "Epoch 39/60\n",
      "228/228 [==============================] - 9s 39ms/step - loss: 0.1186 - accuracy: 0.9566\n",
      "Epoch 40/60\n",
      "228/228 [==============================] - 9s 39ms/step - loss: 0.1146 - accuracy: 0.9575\n",
      "Epoch 41/60\n",
      "228/228 [==============================] - 9s 39ms/step - loss: 0.1107 - accuracy: 0.9590\n",
      "Epoch 42/60\n",
      "228/228 [==============================] - 9s 39ms/step - loss: 0.1055 - accuracy: 0.9605\n",
      "Epoch 43/60\n",
      "228/228 [==============================] - 9s 39ms/step - loss: 0.1027 - accuracy: 0.9607\n",
      "Epoch 44/60\n",
      "228/228 [==============================] - 9s 39ms/step - loss: 0.1040 - accuracy: 0.9612\n",
      "Epoch 45/60\n",
      "228/228 [==============================] - 9s 39ms/step - loss: 0.1044 - accuracy: 0.9606\n",
      "Epoch 46/60\n",
      "228/228 [==============================] - 9s 39ms/step - loss: 0.1053 - accuracy: 0.9609\n",
      "Epoch 47/60\n",
      "228/228 [==============================] - 9s 39ms/step - loss: 0.0920 - accuracy: 0.9654\n",
      "Epoch 48/60\n",
      "228/228 [==============================] - 9s 39ms/step - loss: 0.0956 - accuracy: 0.9643\n",
      "Epoch 49/60\n",
      "228/228 [==============================] - 9s 39ms/step - loss: 0.0954 - accuracy: 0.9641\n",
      "Epoch 50/60\n",
      "228/228 [==============================] - 9s 39ms/step - loss: 0.0940 - accuracy: 0.9643\n",
      "Epoch 51/60\n",
      "228/228 [==============================] - 9s 39ms/step - loss: 0.0981 - accuracy: 0.9639\n",
      "Epoch 52/60\n",
      "228/228 [==============================] - 9s 39ms/step - loss: 0.0922 - accuracy: 0.9652\n",
      "Epoch 53/60\n",
      "228/228 [==============================] - 9s 39ms/step - loss: 0.0877 - accuracy: 0.9664\n",
      "Epoch 54/60\n",
      "228/228 [==============================] - 9s 39ms/step - loss: 0.0901 - accuracy: 0.9666\n",
      "Epoch 55/60\n",
      "228/228 [==============================] - 9s 39ms/step - loss: 0.0891 - accuracy: 0.9664\n",
      "Epoch 56/60\n",
      "228/228 [==============================] - 9s 39ms/step - loss: 0.0818 - accuracy: 0.9686\n",
      "Epoch 57/60\n",
      "228/228 [==============================] - 9s 39ms/step - loss: 0.0790 - accuracy: 0.9706\n",
      "Epoch 58/60\n",
      "228/228 [==============================] - 9s 39ms/step - loss: 0.0832 - accuracy: 0.9683\n",
      "Epoch 59/60\n",
      "228/228 [==============================] - 9s 39ms/step - loss: 0.0901 - accuracy: 0.9665\n",
      "Epoch 60/60\n",
      "228/228 [==============================] - 9s 39ms/step - loss: 0.0814 - accuracy: 0.9691\n",
      "Wall time: 6h 51min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rscv = RandomizedSearchCV(model, param_distributions=params, cv=cv, n_iter=n_tune_iter)\n",
    "rscv_results = rscv.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score is: 0.9415044983228048 using {'n_dense_2': 512, 'n_dense_1': 384, 'n_conv_3': 256, 'n_conv_2': 512, 'n_conv_1': 512, 'maxpooling_pool_size': 2, 'k_conv_3': 2, 'k_conv_2': 2, 'k_conv_1': 3, 'dropout_2': 0.2, 'dropout_1': 0.2, 'avepooling_pool_size': 2, 'activation_dense': 'relu', 'activation_conv': 'relu'}\n"
     ]
    }
   ],
   "source": [
    "print('Best score is: {} using {}'.format(rscv_results.best_score_,\n",
    "rscv_results.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = rscv_results.best_estimator_\n",
    "best_param = rscv_results.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JkbhJMox8Jl9"
   },
   "source": [
    "### Test the best model based on the validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kZwGk5dR8JmS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\dfuller\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\wrappers\\scikit_learn.py:241: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
     ]
    }
   ],
   "source": [
    "y_hat = best_model.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E_GNq-R_8JmZ",
    "outputId": "0fc16efe-7739-4394-f1a3-46da92e79584"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 1.], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = to_categorical(y_hat)\n",
    "y_hat[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SFqRQ5XB8Jmc",
    "outputId": "a957fbed-92f8-4bdd-d24b-5df3361a8bac"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 1.], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FTWf6Cf-8Jme",
    "outputId": "1256b170-33dc-4171-f2ff-7a3d7ddd74e3"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_hat)\n",
    "_ = plt.axvline(x=0.5, color='orange')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 1.] [0. 0. 0. 0. 0. 1.] [0. 0. 0. 0. 0. 1.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "95.02779493514515"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import  accuracy_score as score\n",
    "y_pred_classes = y_hat.round()\n",
    "print(y_valid[0], y_hat[0], y_pred_classes[0])\n",
    "acc = score(y_valid, y_pred_classes) * 100\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RNljSx3v8Jmh"
   },
   "outputs": [],
   "source": [
    "pct_auc = roc_auc_score(y_valid, y_hat)*100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SO_N9lJG8Jmj",
    "outputId": "20968a52-8ca0-44d3-abf6-a1382bba5cde"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'97.02'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"{:0.2f}\".format(pct_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vU3hnA298Jmo"
   },
   "outputs": [],
   "source": [
    "float_y_hat = []\n",
    "for y in y_hat:\n",
    "    float_y_hat.append(y[0:6].round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zrTf-aQl8Jmr"
   },
   "outputs": [],
   "source": [
    "ydf = pd.DataFrame(list(zip(float_y_hat, y_valid)), columns=['y_hat', 'y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zAyKh_mX8Jmu",
    "outputId": "611224b8-f980-47df-d596-9aa3a5811009"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_hat</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            y_hat                               y\n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0]  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0]\n",
       "1  [0.0, 0.0, 1.0, 0.0, 0.0, 0.0]  [0.0, 0.0, 1.0, 0.0, 0.0, 0.0]\n",
       "2  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0]  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0]\n",
       "3  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0]  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
       "4  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0]  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0]\n",
       "5  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0]  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0]\n",
       "6  [0.0, 0.0, 0.0, 1.0, 0.0, 0.0]  [0.0, 0.0, 0.0, 1.0, 0.0, 0.0]\n",
       "7  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0]  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0]\n",
       "8  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0]  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
       "9  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0]  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ydf.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_dense_2</th>\n",
       "      <th>n_dense_1</th>\n",
       "      <th>n_conv_3</th>\n",
       "      <th>n_conv_2</th>\n",
       "      <th>n_conv_1</th>\n",
       "      <th>maxpooling_pool_size</th>\n",
       "      <th>k_conv_3</th>\n",
       "      <th>k_conv_2</th>\n",
       "      <th>k_conv_1</th>\n",
       "      <th>dropout_2</th>\n",
       "      <th>dropout_1</th>\n",
       "      <th>avepooling_pool_size</th>\n",
       "      <th>activation_dense</th>\n",
       "      <th>activation_conv</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>512</td>\n",
       "      <td>384</td>\n",
       "      <td>256</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>relu</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.941504</td>\n",
       "      <td>0.003143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>256</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>256</td>\n",
       "      <td>768</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>elu</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.937730</td>\n",
       "      <td>0.003727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>256</td>\n",
       "      <td>384</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>512</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2</td>\n",
       "      <td>relu</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.937095</td>\n",
       "      <td>0.002040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>384</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>512</td>\n",
       "      <td>768</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>elu</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.936717</td>\n",
       "      <td>0.001946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>512</td>\n",
       "      <td>256</td>\n",
       "      <td>512</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>&lt;tensorflow.python.keras.layers.advanced_activ...</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.931466</td>\n",
       "      <td>0.002494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>384</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>512</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>elu</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.929733</td>\n",
       "      <td>0.002908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>384</td>\n",
       "      <td>384</td>\n",
       "      <td>256</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>elu</td>\n",
       "      <td>elu</td>\n",
       "      <td>0.917379</td>\n",
       "      <td>0.003375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>384</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>768</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>relu</td>\n",
       "      <td>&lt;tensorflow.python.keras.layers.advanced_activ...</td>\n",
       "      <td>0.913569</td>\n",
       "      <td>0.001225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>256</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>elu</td>\n",
       "      <td>elu</td>\n",
       "      <td>0.911579</td>\n",
       "      <td>0.002376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>384</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>256</td>\n",
       "      <td>512</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>elu</td>\n",
       "      <td>elu</td>\n",
       "      <td>0.911253</td>\n",
       "      <td>0.006545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>768</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>elu</td>\n",
       "      <td>elu</td>\n",
       "      <td>0.909571</td>\n",
       "      <td>0.004974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>512</td>\n",
       "      <td>384</td>\n",
       "      <td>256</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>relu</td>\n",
       "      <td>&lt;tensorflow.python.keras.layers.advanced_activ...</td>\n",
       "      <td>0.908799</td>\n",
       "      <td>0.002501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>384</td>\n",
       "      <td>384</td>\n",
       "      <td>256</td>\n",
       "      <td>512</td>\n",
       "      <td>768</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>relu</td>\n",
       "      <td>elu</td>\n",
       "      <td>0.907461</td>\n",
       "      <td>0.000231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>384</td>\n",
       "      <td>384</td>\n",
       "      <td>512</td>\n",
       "      <td>256</td>\n",
       "      <td>512</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>elu</td>\n",
       "      <td>elu</td>\n",
       "      <td>0.907306</td>\n",
       "      <td>0.002632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>384</td>\n",
       "      <td>384</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>768</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2</td>\n",
       "      <td>elu</td>\n",
       "      <td>elu</td>\n",
       "      <td>0.905299</td>\n",
       "      <td>0.006428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>384</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>512</td>\n",
       "      <td>768</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>relu</td>\n",
       "      <td>&lt;tensorflow.python.keras.layers.advanced_activ...</td>\n",
       "      <td>0.904201</td>\n",
       "      <td>0.005465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>384</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>elu</td>\n",
       "      <td>elu</td>\n",
       "      <td>0.903806</td>\n",
       "      <td>0.004397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>256</td>\n",
       "      <td>384</td>\n",
       "      <td>256</td>\n",
       "      <td>512</td>\n",
       "      <td>768</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2</td>\n",
       "      <td>relu</td>\n",
       "      <td>&lt;tensorflow.python.keras.layers.advanced_activ...</td>\n",
       "      <td>0.897972</td>\n",
       "      <td>0.004444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>384</td>\n",
       "      <td>256</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>768</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2</td>\n",
       "      <td>relu</td>\n",
       "      <td>&lt;tensorflow.python.keras.layers.advanced_activ...</td>\n",
       "      <td>0.894334</td>\n",
       "      <td>0.005553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>512</td>\n",
       "      <td>384</td>\n",
       "      <td>256</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;tensorflow.python.keras.layers.advanced_activ...</td>\n",
       "      <td>&lt;tensorflow.python.keras.layers.advanced_activ...</td>\n",
       "      <td>0.886012</td>\n",
       "      <td>0.013568</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    n_dense_2  n_dense_1  n_conv_3  n_conv_2  n_conv_1  maxpooling_pool_size  \\\n",
       "6         512        384       256       512       512                     2   \n",
       "8         256        512       512       256       768                     2   \n",
       "4         256        384       256       256       512                     3   \n",
       "10        384        256       256       512       768                     3   \n",
       "0         256        256       512       256       512                     3   \n",
       "18        384        256       256       256       512                     2   \n",
       "14        384        384       256       512       512                     2   \n",
       "2         384        512       512       512       768                     2   \n",
       "9         256        512       512       512       512                     2   \n",
       "16        384        512       512       256       512                     2   \n",
       "3         512        512       256       256       768                     2   \n",
       "13        512        384       256       512       512                     2   \n",
       "17        384        384       256       512       768                     3   \n",
       "5         384        384       512       256       512                     2   \n",
       "1         384        384       256       256       768                     2   \n",
       "11        384        256       256       512       768                     2   \n",
       "7         384        512       512       512       512                     3   \n",
       "15        256        384       256       512       768                     2   \n",
       "19        384        256       512       512       768                     2   \n",
       "12        512        384       256       512       512                     2   \n",
       "\n",
       "    k_conv_3  k_conv_2  k_conv_1  dropout_2  dropout_1  avepooling_pool_size  \\\n",
       "6          2         2         3        0.2        0.2                     2   \n",
       "8          3         3         3        0.2        0.2                     3   \n",
       "4          2         2         3        0.3        0.3                     2   \n",
       "10         3         3         3        0.3        0.3                     3   \n",
       "0          3         2         3        0.3        0.2                     3   \n",
       "18         2         3         2        0.3        0.2                     3   \n",
       "14         3         3         3        0.3        0.2                     2   \n",
       "2          2         3         3        0.2        0.2                     3   \n",
       "9          2         3         2        0.2        0.2                     3   \n",
       "16         2         3         3        0.3        0.2                     2   \n",
       "3          3         2         2        0.3        0.2                     3   \n",
       "13         2         2         3        0.2        0.3                     3   \n",
       "17         3         3         2        0.3        0.3                     3   \n",
       "5          2         2         2        0.3        0.2                     3   \n",
       "1          2         3         3        0.2        0.3                     2   \n",
       "11         3         3         3        0.2        0.3                     3   \n",
       "7          2         2         2        0.2        0.2                     3   \n",
       "15         2         3         2        0.3        0.3                     2   \n",
       "19         2         2         2        0.3        0.3                     2   \n",
       "12         2         2         3        0.3        0.3                     2   \n",
       "\n",
       "                                     activation_dense  \\\n",
       "6                                                relu   \n",
       "8                                                 elu   \n",
       "4                                                relu   \n",
       "10                                                elu   \n",
       "0   <tensorflow.python.keras.layers.advanced_activ...   \n",
       "18                                                elu   \n",
       "14                                                elu   \n",
       "2                                                relu   \n",
       "9                                                 elu   \n",
       "16                                                elu   \n",
       "3                                                 elu   \n",
       "13                                               relu   \n",
       "17                                               relu   \n",
       "5                                                 elu   \n",
       "1                                                 elu   \n",
       "11                                               relu   \n",
       "7                                                 elu   \n",
       "15                                               relu   \n",
       "19                                               relu   \n",
       "12  <tensorflow.python.keras.layers.advanced_activ...   \n",
       "\n",
       "                                      activation_conv      mean       std  \n",
       "6                                                relu  0.941504  0.003143  \n",
       "8                                                relu  0.937730  0.003727  \n",
       "4                                                relu  0.937095  0.002040  \n",
       "10                                               relu  0.936717  0.001946  \n",
       "0                                                relu  0.931466  0.002494  \n",
       "18                                               relu  0.929733  0.002908  \n",
       "14                                                elu  0.917379  0.003375  \n",
       "2   <tensorflow.python.keras.layers.advanced_activ...  0.913569  0.001225  \n",
       "9                                                 elu  0.911579  0.002376  \n",
       "16                                                elu  0.911253  0.006545  \n",
       "3                                                 elu  0.909571  0.004974  \n",
       "13  <tensorflow.python.keras.layers.advanced_activ...  0.908799  0.002501  \n",
       "17                                                elu  0.907461  0.000231  \n",
       "5                                                 elu  0.907306  0.002632  \n",
       "1                                                 elu  0.905299  0.006428  \n",
       "11  <tensorflow.python.keras.layers.advanced_activ...  0.904201  0.005465  \n",
       "7                                                 elu  0.903806  0.004397  \n",
       "15  <tensorflow.python.keras.layers.advanced_activ...  0.897972  0.004444  \n",
       "19  <tensorflow.python.keras.layers.advanced_activ...  0.894334  0.005553  \n",
       "12  <tensorflow.python.keras.layers.advanced_activ...  0.886012  0.013568  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame(rscv_results.cv_results_['params'])\n",
    "results_df['mean'] = rscv_results.cv_results_['mean_test_score']\n",
    "results_df['std'] = rscv_results.cv_results_['std_test_score']\n",
    "results_df.sort_values('mean', ascending=False, ignore_index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating best model from the best param and train it for 60 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_dense_2': 512,\n",
       " 'n_dense_1': 384,\n",
       " 'n_conv_3': 256,\n",
       " 'n_conv_2': 512,\n",
       " 'n_conv_1': 512,\n",
       " 'maxpooling_pool_size': 2,\n",
       " 'k_conv_3': 2,\n",
       " 'k_conv_2': 2,\n",
       " 'k_conv_1': 3,\n",
       " 'dropout_2': 0.2,\n",
       " 'dropout_1': 0.2,\n",
       " 'avepooling_pool_size': 2,\n",
       " 'activation_dense': 'relu',\n",
       " 'activation_conv': 'relu'}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rscv_results.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_dense_2= 512\n",
    "n_dense_1= 384\n",
    "n_conv_3= 256\n",
    "n_conv_2= 512\n",
    "n_conv_1= 512\n",
    "maxpooling_pool_size= 2\n",
    "k_conv_3= 2\n",
    "k_conv_2= 2\n",
    "k_conv_1= 2\n",
    "dropout_2= 0.2\n",
    "dropout_1= 0.2\n",
    "avepooling_pool_size= 2\n",
    "activation_dense = 'relu'\n",
    "activation_conv = 'relu'\n",
    "model = Sequential()\n",
    "model.add(Conv1D(n_conv_1, k_conv_1, activation=activation_conv, input_shape=input_shape[1:]))\n",
    "model.add(MaxPool1D(pool_size = maxpooling_pool_size))\n",
    "model.add(Conv1D(n_conv_2, k_conv_2, activation=activation_conv))\n",
    "model.add(AveragePooling1D(pool_size = avepooling_pool_size))\n",
    "model.add(Conv1D(n_conv_3, k_conv_3, activation=activation_conv))\n",
    "# model.add(GlobalMaxPooling1D())\n",
    "model.add(GlobalAveragePooling1D())\n",
    "model.add(Dense(n_dense_1, activation=activation_dense))\n",
    "model.add(Dropout(dropout_1))\n",
    "model.add(Dense(n_dense_2, activation=activation_dense))\n",
    "model.add(Dropout(dropout_2))\n",
    "model.add(Dense(n_class, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir= 'model_ouput/tune-sklearn-3'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "modelcheckpoint = ModelCheckpoint(filepath=output_dir+\n",
    "                                  \"/weights.{epoch:02d}.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "228/228 [==============================] - 10s 42ms/step - loss: 0.9828 - accuracy: 0.5847 - val_loss: 0.7141 - val_accuracy: 0.7052\n",
      "Epoch 2/120\n",
      "228/228 [==============================] - 9s 41ms/step - loss: 0.6416 - accuracy: 0.7431 - val_loss: 0.5265 - val_accuracy: 0.8056\n",
      "Epoch 3/120\n",
      "228/228 [==============================] - 9s 41ms/step - loss: 0.4738 - accuracy: 0.8190 - val_loss: 0.3879 - val_accuracy: 0.8550\n",
      "Epoch 4/120\n",
      "228/228 [==============================] - 9s 41ms/step - loss: 0.3963 - accuracy: 0.8506 - val_loss: 0.3485 - val_accuracy: 0.8620\n",
      "Epoch 5/120\n",
      "228/228 [==============================] - 9s 41ms/step - loss: 0.3559 - accuracy: 0.8652 - val_loss: 0.3329 - val_accuracy: 0.8697\n",
      "Epoch 6/120\n",
      "228/228 [==============================] - 9s 41ms/step - loss: 0.3241 - accuracy: 0.8772 - val_loss: 0.3074 - val_accuracy: 0.8808\n",
      "Epoch 7/120\n",
      "228/228 [==============================] - 9s 41ms/step - loss: 0.3027 - accuracy: 0.8847 - val_loss: 0.3030 - val_accuracy: 0.8777\n",
      "Epoch 8/120\n",
      "228/228 [==============================] - 9s 41ms/step - loss: 0.2895 - accuracy: 0.8913 - val_loss: 0.2743 - val_accuracy: 0.8958\n",
      "Epoch 9/120\n",
      "228/228 [==============================] - 9s 41ms/step - loss: 0.2704 - accuracy: 0.8987 - val_loss: 0.2493 - val_accuracy: 0.9060\n",
      "Epoch 10/120\n",
      "228/228 [==============================] - 9s 41ms/step - loss: 0.2646 - accuracy: 0.9000 - val_loss: 0.2731 - val_accuracy: 0.8927\n",
      "Epoch 11/120\n",
      "228/228 [==============================] - 9s 41ms/step - loss: 0.2511 - accuracy: 0.9055 - val_loss: 0.2447 - val_accuracy: 0.9072\n",
      "Epoch 12/120\n",
      "228/228 [==============================] - 9s 41ms/step - loss: 0.2402 - accuracy: 0.9094 - val_loss: 0.2463 - val_accuracy: 0.9069\n",
      "Epoch 13/120\n",
      "228/228 [==============================] - 9s 41ms/step - loss: 0.2357 - accuracy: 0.9118 - val_loss: 0.2332 - val_accuracy: 0.9134\n",
      "Epoch 14/120\n",
      "228/228 [==============================] - 9s 41ms/step - loss: 0.2189 - accuracy: 0.9177 - val_loss: 0.2158 - val_accuracy: 0.9174\n",
      "Epoch 15/120\n",
      "228/228 [==============================] - 9s 41ms/step - loss: 0.2121 - accuracy: 0.9218 - val_loss: 0.2159 - val_accuracy: 0.9243\n",
      "Epoch 16/120\n",
      "228/228 [==============================] - 9s 41ms/step - loss: 0.2130 - accuracy: 0.9214 - val_loss: 0.2084 - val_accuracy: 0.9253\n",
      "Epoch 17/120\n",
      "228/228 [==============================] - 9s 41ms/step - loss: 0.2087 - accuracy: 0.9225 - val_loss: 0.2153 - val_accuracy: 0.9205\n",
      "Epoch 18/120\n",
      "228/228 [==============================] - 9s 41ms/step - loss: 0.1974 - accuracy: 0.9270 - val_loss: 0.2030 - val_accuracy: 0.9305\n",
      "Epoch 19/120\n",
      "228/228 [==============================] - 9s 41ms/step - loss: 0.1931 - accuracy: 0.9287 - val_loss: 0.1991 - val_accuracy: 0.9260\n",
      "Epoch 20/120\n",
      "228/228 [==============================] - 9s 41ms/step - loss: 0.1872 - accuracy: 0.9306 - val_loss: 0.1798 - val_accuracy: 0.9356\n",
      "Epoch 21/120\n",
      "228/228 [==============================] - 9s 41ms/step - loss: 0.1865 - accuracy: 0.9306 - val_loss: 0.1870 - val_accuracy: 0.9342\n",
      "Epoch 22/120\n",
      "228/228 [==============================] - 9s 41ms/step - loss: 0.1756 - accuracy: 0.9349 - val_loss: 0.1801 - val_accuracy: 0.9331\n",
      "Epoch 23/120\n",
      "228/228 [==============================] - 9s 41ms/step - loss: 0.1774 - accuracy: 0.9334 - val_loss: 0.1818 - val_accuracy: 0.9375\n",
      "Epoch 24/120\n",
      "228/228 [==============================] - 9s 41ms/step - loss: 0.1656 - accuracy: 0.9379 - val_loss: 0.1735 - val_accuracy: 0.9344\n",
      "Epoch 25/120\n",
      "228/228 [==============================] - 9s 42ms/step - loss: 0.1676 - accuracy: 0.9387 - val_loss: 0.1834 - val_accuracy: 0.9368\n",
      "Epoch 26/120\n",
      "228/228 [==============================] - 9s 42ms/step - loss: 0.1603 - accuracy: 0.9410 - val_loss: 0.1834 - val_accuracy: 0.9321\n",
      "Epoch 27/120\n",
      "228/228 [==============================] - 9s 41ms/step - loss: 0.1565 - accuracy: 0.9417 - val_loss: 0.1954 - val_accuracy: 0.9338\n",
      "Epoch 28/120\n",
      "228/228 [==============================] - 9s 41ms/step - loss: 0.1494 - accuracy: 0.9436 - val_loss: 0.1797 - val_accuracy: 0.9392\n",
      "Epoch 29/120\n",
      "228/228 [==============================] - 9s 42ms/step - loss: 0.1504 - accuracy: 0.9434 - val_loss: 0.1776 - val_accuracy: 0.9395\n",
      "Epoch 30/120\n",
      "228/228 [==============================] - 9s 42ms/step - loss: 0.1511 - accuracy: 0.9428 - val_loss: 0.1762 - val_accuracy: 0.9402\n",
      "Epoch 31/120\n",
      "228/228 [==============================] - 9s 42ms/step - loss: 0.1465 - accuracy: 0.9449 - val_loss: 0.1787 - val_accuracy: 0.9382\n",
      "Epoch 32/120\n",
      "228/228 [==============================] - 9s 42ms/step - loss: 0.1429 - accuracy: 0.9456 - val_loss: 0.1799 - val_accuracy: 0.9336\n",
      "Epoch 33/120\n",
      "228/228 [==============================] - 9s 42ms/step - loss: 0.1412 - accuracy: 0.9469 - val_loss: 0.1696 - val_accuracy: 0.9413\n",
      "Epoch 34/120\n",
      "228/228 [==============================] - 9s 42ms/step - loss: 0.1338 - accuracy: 0.9496 - val_loss: 0.1690 - val_accuracy: 0.9443\n",
      "Epoch 35/120\n",
      "228/228 [==============================] - 9s 41ms/step - loss: 0.1288 - accuracy: 0.9501 - val_loss: 0.1676 - val_accuracy: 0.9458\n",
      "Epoch 36/120\n",
      "228/228 [==============================] - 10s 42ms/step - loss: 0.1301 - accuracy: 0.9505 - val_loss: 0.1539 - val_accuracy: 0.9486\n",
      "Epoch 37/120\n",
      "228/228 [==============================] - 10s 42ms/step - loss: 0.1242 - accuracy: 0.9527 - val_loss: 0.1655 - val_accuracy: 0.9469\n",
      "Epoch 38/120\n",
      "228/228 [==============================] - 10s 42ms/step - loss: 0.1267 - accuracy: 0.9516 - val_loss: 0.1636 - val_accuracy: 0.9464\n",
      "Epoch 39/120\n",
      "228/228 [==============================] - 10s 42ms/step - loss: 0.1236 - accuracy: 0.9528 - val_loss: 0.1535 - val_accuracy: 0.9463\n",
      "Epoch 40/120\n",
      "228/228 [==============================] - 9s 42ms/step - loss: 0.1208 - accuracy: 0.9535 - val_loss: 0.1707 - val_accuracy: 0.9449\n",
      "Epoch 41/120\n",
      "228/228 [==============================] - 10s 42ms/step - loss: 0.1220 - accuracy: 0.9531 - val_loss: 0.1541 - val_accuracy: 0.9473\n",
      "Epoch 42/120\n",
      "228/228 [==============================] - 10s 42ms/step - loss: 0.1174 - accuracy: 0.9549 - val_loss: 0.1626 - val_accuracy: 0.9473\n",
      "Epoch 43/120\n",
      "228/228 [==============================] - 10s 42ms/step - loss: 0.1125 - accuracy: 0.9563 - val_loss: 0.1663 - val_accuracy: 0.9450\n",
      "Epoch 44/120\n",
      "228/228 [==============================] - 9s 42ms/step - loss: 0.1091 - accuracy: 0.9577 - val_loss: 0.1702 - val_accuracy: 0.9464\n",
      "Epoch 45/120\n",
      "228/228 [==============================] - 10s 42ms/step - loss: 0.1165 - accuracy: 0.9562 - val_loss: 0.1631 - val_accuracy: 0.9461\n",
      "Epoch 46/120\n",
      "228/228 [==============================] - 9s 42ms/step - loss: 0.1057 - accuracy: 0.9589 - val_loss: 0.1533 - val_accuracy: 0.9503\n",
      "Epoch 47/120\n",
      "228/228 [==============================] - 9s 42ms/step - loss: 0.1062 - accuracy: 0.9593 - val_loss: 0.1550 - val_accuracy: 0.9473\n",
      "Epoch 48/120\n",
      "228/228 [==============================] - 9s 42ms/step - loss: 0.1044 - accuracy: 0.9593 - val_loss: 0.1522 - val_accuracy: 0.9507\n",
      "Epoch 49/120\n",
      "228/228 [==============================] - 9s 42ms/step - loss: 0.1028 - accuracy: 0.9605 - val_loss: 0.1522 - val_accuracy: 0.9461\n",
      "Epoch 50/120\n",
      "228/228 [==============================] - 10s 42ms/step - loss: 0.0988 - accuracy: 0.9631 - val_loss: 0.1588 - val_accuracy: 0.9507\n",
      "Epoch 51/120\n",
      "228/228 [==============================] - 9s 42ms/step - loss: 0.1032 - accuracy: 0.9608 - val_loss: 0.1611 - val_accuracy: 0.9500\n",
      "Epoch 52/120\n",
      "228/228 [==============================] - 9s 42ms/step - loss: 0.0975 - accuracy: 0.9632 - val_loss: 0.1663 - val_accuracy: 0.9456\n",
      "Epoch 53/120\n",
      "228/228 [==============================] - 10s 42ms/step - loss: 0.0944 - accuracy: 0.9637 - val_loss: 0.1737 - val_accuracy: 0.9506\n",
      "Epoch 54/120\n",
      "228/228 [==============================] - 9s 42ms/step - loss: 0.1003 - accuracy: 0.9618 - val_loss: 0.1651 - val_accuracy: 0.9478\n",
      "Epoch 55/120\n",
      "228/228 [==============================] - 9s 42ms/step - loss: 0.0912 - accuracy: 0.9662 - val_loss: 0.1597 - val_accuracy: 0.9498\n",
      "Epoch 56/120\n",
      "228/228 [==============================] - 9s 42ms/step - loss: 0.0938 - accuracy: 0.9642 - val_loss: 0.1547 - val_accuracy: 0.9548\n",
      "Epoch 57/120\n",
      "228/228 [==============================] - 9s 41ms/step - loss: 0.0919 - accuracy: 0.9657 - val_loss: 0.1869 - val_accuracy: 0.9450\n",
      "Epoch 58/120\n",
      "228/228 [==============================] - 9s 42ms/step - loss: 0.0878 - accuracy: 0.9663 - val_loss: 0.1530 - val_accuracy: 0.9548\n",
      "Epoch 59/120\n",
      "228/228 [==============================] - 9s 41ms/step - loss: 0.0920 - accuracy: 0.9647 - val_loss: 0.1651 - val_accuracy: 0.9521\n",
      "Epoch 60/120\n",
      "228/228 [==============================] - 9s 41ms/step - loss: 0.0832 - accuracy: 0.9683 - val_loss: 0.1503 - val_accuracy: 0.9574\n",
      "Epoch 61/120\n",
      "228/228 [==============================] - 9s 42ms/step - loss: 0.0840 - accuracy: 0.9683 - val_loss: 0.1517 - val_accuracy: 0.9560\n",
      "Epoch 62/120\n",
      "228/228 [==============================] - 9s 41ms/step - loss: 0.0837 - accuracy: 0.9683 - val_loss: 0.1460 - val_accuracy: 0.9566\n",
      "Epoch 63/120\n",
      "228/228 [==============================] - 9s 42ms/step - loss: 0.0845 - accuracy: 0.9684 - val_loss: 0.1426 - val_accuracy: 0.9582\n",
      "Epoch 64/120\n",
      "228/228 [==============================] - 9s 41ms/step - loss: 0.0802 - accuracy: 0.9692 - val_loss: 0.1629 - val_accuracy: 0.9478\n",
      "Epoch 65/120\n",
      "228/228 [==============================] - 9s 41ms/step - loss: 0.0832 - accuracy: 0.9684 - val_loss: 0.1825 - val_accuracy: 0.9489\n",
      "Epoch 66/120\n",
      "228/228 [==============================] - 9s 41ms/step - loss: 0.0769 - accuracy: 0.9712 - val_loss: 0.1656 - val_accuracy: 0.9551\n",
      "Epoch 67/120\n",
      "228/228 [==============================] - 9s 41ms/step - loss: 0.0747 - accuracy: 0.9718 - val_loss: 0.1637 - val_accuracy: 0.9574\n",
      "Epoch 68/120\n",
      "228/228 [==============================] - 9s 42ms/step - loss: 0.0770 - accuracy: 0.9717 - val_loss: 0.1566 - val_accuracy: 0.9574\n",
      "Epoch 69/120\n",
      "228/228 [==============================] - 9s 42ms/step - loss: 0.0764 - accuracy: 0.9714 - val_loss: 0.1787 - val_accuracy: 0.9477\n",
      "Epoch 70/120\n",
      "228/228 [==============================] - 9s 41ms/step - loss: 0.0759 - accuracy: 0.9708 - val_loss: 0.1617 - val_accuracy: 0.9541\n",
      "Epoch 71/120\n",
      "228/228 [==============================] - 9s 41ms/step - loss: 0.0804 - accuracy: 0.9698 - val_loss: 0.1937 - val_accuracy: 0.9494\n",
      "Epoch 72/120\n",
      "228/228 [==============================] - 9s 41ms/step - loss: 0.0736 - accuracy: 0.9727 - val_loss: 0.1652 - val_accuracy: 0.9541\n",
      "Epoch 73/120\n",
      "228/228 [==============================] - 9s 41ms/step - loss: 0.0734 - accuracy: 0.9724 - val_loss: 0.1502 - val_accuracy: 0.9585\n",
      "Epoch 74/120\n",
      "228/228 [==============================] - 9s 42ms/step - loss: 0.0715 - accuracy: 0.9736 - val_loss: 0.1563 - val_accuracy: 0.9595\n",
      "Epoch 75/120\n",
      "228/228 [==============================] - 9s 41ms/step - loss: 0.0712 - accuracy: 0.9729 - val_loss: 0.1567 - val_accuracy: 0.9603\n",
      "Epoch 76/120\n",
      "228/228 [==============================] - 9s 41ms/step - loss: 0.0709 - accuracy: 0.9729 - val_loss: 0.1679 - val_accuracy: 0.9569\n",
      "Epoch 77/120\n",
      "228/228 [==============================] - 9s 41ms/step - loss: 0.0687 - accuracy: 0.9736 - val_loss: 0.1604 - val_accuracy: 0.9554\n",
      "Epoch 78/120\n",
      "228/228 [==============================] - 9s 41ms/step - loss: 0.0673 - accuracy: 0.9741 - val_loss: 0.1842 - val_accuracy: 0.9486\n",
      "Epoch 79/120\n",
      "228/228 [==============================] - 9s 41ms/step - loss: 0.0739 - accuracy: 0.9733 - val_loss: 0.1581 - val_accuracy: 0.9557\n",
      "Epoch 80/120\n",
      "228/228 [==============================] - 9s 41ms/step - loss: 0.0675 - accuracy: 0.9754 - val_loss: 0.1526 - val_accuracy: 0.9555\n",
      "Epoch 81/120\n",
      "228/228 [==============================] - 9s 42ms/step - loss: 0.0700 - accuracy: 0.9736 - val_loss: 0.1532 - val_accuracy: 0.9551\n",
      "Epoch 82/120\n",
      "228/228 [==============================] - 9s 41ms/step - loss: 0.0672 - accuracy: 0.9747 - val_loss: 0.1576 - val_accuracy: 0.9628\n",
      "Epoch 83/120\n",
      "228/228 [==============================] - 9s 41ms/step - loss: 0.0656 - accuracy: 0.9753 - val_loss: 0.1713 - val_accuracy: 0.9558\n",
      "Epoch 84/120\n",
      "228/228 [==============================] - 9s 41ms/step - loss: 0.0651 - accuracy: 0.9757 - val_loss: 0.1812 - val_accuracy: 0.9527\n",
      "Epoch 85/120\n",
      "228/228 [==============================] - 9s 41ms/step - loss: 0.0660 - accuracy: 0.9754 - val_loss: 0.1825 - val_accuracy: 0.9548\n",
      "Epoch 86/120\n",
      "228/228 [==============================] - 9s 41ms/step - loss: 0.0616 - accuracy: 0.9771 - val_loss: 0.1712 - val_accuracy: 0.9578\n",
      "Epoch 87/120\n",
      "228/228 [==============================] - 9s 41ms/step - loss: 0.0633 - accuracy: 0.9759 - val_loss: 0.1707 - val_accuracy: 0.9603\n",
      "Epoch 88/120\n",
      "228/228 [==============================] - 9s 41ms/step - loss: 0.0621 - accuracy: 0.9769 - val_loss: 0.1804 - val_accuracy: 0.9552\n",
      "Epoch 89/120\n",
      "228/228 [==============================] - 9s 41ms/step - loss: 0.0618 - accuracy: 0.9763 - val_loss: 0.1515 - val_accuracy: 0.9614\n",
      "Epoch 90/120\n",
      "228/228 [==============================] - 9s 42ms/step - loss: 0.0653 - accuracy: 0.9758 - val_loss: 0.1514 - val_accuracy: 0.9588\n",
      "Epoch 91/120\n",
      "228/228 [==============================] - 9s 41ms/step - loss: 0.0600 - accuracy: 0.9774 - val_loss: 0.1502 - val_accuracy: 0.9619\n",
      "Epoch 92/120\n",
      "228/228 [==============================] - 9s 41ms/step - loss: 0.0649 - accuracy: 0.9759 - val_loss: 0.1689 - val_accuracy: 0.9551\n",
      "Epoch 93/120\n",
      "228/228 [==============================] - 9s 41ms/step - loss: 0.0587 - accuracy: 0.9783 - val_loss: 0.1568 - val_accuracy: 0.9623\n",
      "Epoch 94/120\n",
      "228/228 [==============================] - 9s 41ms/step - loss: 0.0623 - accuracy: 0.9762 - val_loss: 0.1729 - val_accuracy: 0.9583\n",
      "Epoch 95/120\n",
      "228/228 [==============================] - 9s 41ms/step - loss: 0.0650 - accuracy: 0.9763 - val_loss: 0.1861 - val_accuracy: 0.9546\n",
      "Epoch 96/120\n",
      "228/228 [==============================] - 9s 41ms/step - loss: 0.0556 - accuracy: 0.9794 - val_loss: 0.1674 - val_accuracy: 0.9594\n",
      "Epoch 97/120\n",
      "228/228 [==============================] - 9s 41ms/step - loss: 0.0609 - accuracy: 0.9778 - val_loss: 0.1849 - val_accuracy: 0.9561\n",
      "Epoch 98/120\n",
      "228/228 [==============================] - 9s 42ms/step - loss: 0.0630 - accuracy: 0.9764 - val_loss: 0.1635 - val_accuracy: 0.9606\n",
      "Epoch 99/120\n",
      "228/228 [==============================] - 9s 41ms/step - loss: 0.0575 - accuracy: 0.9786 - val_loss: 0.1632 - val_accuracy: 0.9623\n",
      "Epoch 100/120\n",
      "228/228 [==============================] - 9s 41ms/step - loss: 0.0543 - accuracy: 0.9801 - val_loss: 0.1761 - val_accuracy: 0.9572\n",
      "Epoch 101/120\n",
      "228/228 [==============================] - 9s 42ms/step - loss: 0.0519 - accuracy: 0.9807 - val_loss: 0.1788 - val_accuracy: 0.9557\n",
      "Epoch 102/120\n",
      "228/228 [==============================] - 9s 41ms/step - loss: 0.0556 - accuracy: 0.9789 - val_loss: 0.1747 - val_accuracy: 0.9532\n",
      "Epoch 103/120\n",
      "228/228 [==============================] - 9s 41ms/step - loss: 0.0526 - accuracy: 0.9805 - val_loss: 0.1736 - val_accuracy: 0.9602\n",
      "Epoch 104/120\n",
      "228/228 [==============================] - 9s 41ms/step - loss: 0.0556 - accuracy: 0.9788 - val_loss: 0.1655 - val_accuracy: 0.9589\n",
      "Epoch 105/120\n",
      "228/228 [==============================] - 9s 41ms/step - loss: 0.0547 - accuracy: 0.9800 - val_loss: 0.1736 - val_accuracy: 0.9599\n",
      "Epoch 106/120\n",
      "228/228 [==============================] - 9s 41ms/step - loss: 0.0626 - accuracy: 0.9777 - val_loss: 0.1588 - val_accuracy: 0.9606\n",
      "Epoch 107/120\n",
      "228/228 [==============================] - 9s 41ms/step - loss: 0.0539 - accuracy: 0.9800 - val_loss: 0.1692 - val_accuracy: 0.9591\n",
      "Epoch 108/120\n",
      "228/228 [==============================] - 9s 41ms/step - loss: 0.0534 - accuracy: 0.9805 - val_loss: 0.1680 - val_accuracy: 0.9617\n",
      "Epoch 109/120\n",
      "228/228 [==============================] - 9s 41ms/step - loss: 0.0563 - accuracy: 0.9797 - val_loss: 0.1628 - val_accuracy: 0.9583\n",
      "Epoch 110/120\n",
      "228/228 [==============================] - 9s 41ms/step - loss: 0.0523 - accuracy: 0.9812 - val_loss: 0.1738 - val_accuracy: 0.9578\n",
      "Epoch 111/120\n",
      "228/228 [==============================] - 9s 41ms/step - loss: 0.0493 - accuracy: 0.9819 - val_loss: 0.1846 - val_accuracy: 0.9578\n",
      "Epoch 112/120\n",
      "228/228 [==============================] - 9s 41ms/step - loss: 0.0604 - accuracy: 0.9778 - val_loss: 0.1821 - val_accuracy: 0.9557\n",
      "Epoch 113/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "228/228 [==============================] - 9s 42ms/step - loss: 0.0504 - accuracy: 0.9819 - val_loss: 0.1626 - val_accuracy: 0.9643\n",
      "Epoch 114/120\n",
      "228/228 [==============================] - 9s 41ms/step - loss: 0.0529 - accuracy: 0.9798 - val_loss: 0.1727 - val_accuracy: 0.9631\n",
      "Epoch 115/120\n",
      "228/228 [==============================] - 9s 42ms/step - loss: 0.0565 - accuracy: 0.9803 - val_loss: 0.1599 - val_accuracy: 0.9629\n",
      "Epoch 116/120\n",
      "228/228 [==============================] - 9s 41ms/step - loss: 0.0503 - accuracy: 0.9816 - val_loss: 0.1755 - val_accuracy: 0.9625\n",
      "Epoch 117/120\n",
      "228/228 [==============================] - 9s 41ms/step - loss: 0.0541 - accuracy: 0.9799 - val_loss: 0.1614 - val_accuracy: 0.9611\n",
      "Epoch 118/120\n",
      "228/228 [==============================] - 9s 41ms/step - loss: 0.0504 - accuracy: 0.9815 - val_loss: 0.1752 - val_accuracy: 0.9619\n",
      "Epoch 119/120\n",
      "228/228 [==============================] - 9s 41ms/step - loss: 0.0502 - accuracy: 0.9817 - val_loss: 0.1696 - val_accuracy: 0.9599\n",
      "Epoch 120/120\n",
      "228/228 [==============================] - 9s 41ms/step - loss: 0.0480 - accuracy: 0.9817 - val_loss: 0.1958 - val_accuracy: 0.9586\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1f7ed289ac8>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 120\n",
    "model.fit(X_train, y_train, \n",
    "         batch_size=batch_size, epochs=epochs, verbose=1, \n",
    "         validation_data=(X_valid, y_valid), \n",
    "         callbacks=[modelcheckpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z8t0nVCw8JmP"
   },
   "outputs": [],
   "source": [
    "model.load_weights(output_dir+\"/weights.113.hdf5\") # 96.43"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kZwGk5dR8JmS"
   },
   "outputs": [],
   "source": [
    "y_hat = model.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EPc5_h6K8JmW",
    "outputId": "cad99da9-9f89-437f-854b-a315616ed50f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6476"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E_GNq-R_8JmZ",
    "outputId": "0fc16efe-7739-4394-f1a3-46da92e79584"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.3744292e-04, 1.9361429e-11, 3.9238501e-10, 3.7778257e-12,\n",
       "       3.4377590e-06, 9.9935907e-01], dtype=float32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SFqRQ5XB8Jmc",
    "outputId": "a957fbed-92f8-4bdd-d24b-5df3361a8bac"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 1.], dtype=float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FTWf6Cf-8Jme",
    "outputId": "1256b170-33dc-4171-f2ff-7a3d7ddd74e3"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_hat)\n",
    "_ = plt.axvline(x=0.5, color='orange')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RNljSx3v8Jmh"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'99.80'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pct_auc = roc_auc_score(y_valid, y_hat)*100.0\n",
    "\"{:0.2f}\".format(pct_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SO_N9lJG8Jmj",
    "outputId": "20968a52-8ca0-44d3-abf6-a1382bba5cde"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'96.34'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_classes = y_hat.round()\n",
    "acc = score(y_valid, y_pred_classes) * 100\n",
    "\"{:0.2f}\".format(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vU3hnA298Jmo"
   },
   "outputs": [],
   "source": [
    "float_y_hat = []\n",
    "for y in y_hat:\n",
    "    float_y_hat.append(y[0:6].round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zrTf-aQl8Jmr"
   },
   "outputs": [],
   "source": [
    "ydf = pd.DataFrame(list(zip(float_y_hat, y_valid)), columns=['y_hat', 'y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zAyKh_mX8Jmu",
    "outputId": "611224b8-f980-47df-d596-9aa3a5811009"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_hat</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.001, 0.0, 0.0, 0.0, 0.0, 0.999]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.0, 0.999, 0.001, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                y_hat                               y\n",
       "0  [0.001, 0.0, 0.0, 0.0, 0.0, 0.999]  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0]\n",
       "1      [0.0, 0.0, 1.0, 0.0, 0.0, 0.0]  [0.0, 0.0, 1.0, 0.0, 0.0, 0.0]\n",
       "2  [0.0, 0.999, 0.001, 0.0, 0.0, 0.0]  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0]\n",
       "3      [1.0, 0.0, 0.0, 0.0, 0.0, 0.0]  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
       "4      [0.0, 1.0, 0.0, 0.0, 0.0, 0.0]  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0]\n",
       "5      [0.0, 0.0, 0.0, 0.0, 0.0, 1.0]  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0]\n",
       "6      [0.0, 0.0, 0.0, 1.0, 0.0, 0.0]  [0.0, 0.0, 0.0, 1.0, 0.0, 0.0]\n",
       "7      [0.0, 1.0, 0.0, 0.0, 0.0, 0.0]  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0]\n",
       "8      [1.0, 0.0, 0.0, 0.0, 0.0, 0.0]  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
       "9      [0.0, 1.0, 0.0, 0.0, 0.0, 0.0]  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ydf.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "dense_sentiment_classifier.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
