{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ahUZuAfz8Jje"
   },
   "source": [
    "# Sklearn Tuner for CNN - LSTM Activity Classifier "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Re0ecmVI8Jjk"
   },
   "source": [
    "In this notebook, we use SKlearn  to tune a CNN-LSTM neural net to classify PE activity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ixsGb9tY8Jjm"
   },
   "source": [
    "#### Load dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5At1PKQp8Jjp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 11633662699428622942\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 4993672144390965880\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 4022219571\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 10180279242237958329\n",
      "physical_device_desc: \"device: 0, name: Quadro P2000, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 13379853376503830196\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      "]\n",
      "# GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import os  \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "import tensorflow\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, Conv1D, GlobalMaxPooling1D, LSTM\n",
    "from tensorflow.keras.layers import AveragePooling1D, LeakyReLU , MaxPool1D, GlobalAveragePooling1D\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint \n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, roc_curve \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "print(device_lib.list_local_devices())\n",
    "import tensorflow as tf\n",
    "print(\"# GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "import sklearn\n",
    "# bug in sklearn wrapper\n",
    "#https://stackoverflow.com/questions/59746974/cannot-clone-object-tensorflow-python-keras-wrappers-scikit-learn-kerasclassifi\n",
    "if sklearn.__version__ != '0.21.2':\n",
    "    print(\"updating sklearn ...\")\n",
    "    !pip install --user scikit-learn==0.21.2\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hg5wX2Dd8Jjz"
   },
   "source": [
    "#### Set hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lYLOM99-8Jj2"
   },
   "outputs": [],
   "source": [
    "# output directory name:\n",
    "output_dir = 'model_output/tune-cnn-lstm'\n",
    "input_dir =  'Z:/Research/dfuller/Walkabilly/studies/smarphone_accel/data/Ethica_Jaeger_Merged/pocket/'\n",
    "input_file_name = 'pocket-NN-data.npz'\n",
    "\n",
    "# from the data preparation section we have:\n",
    "window_size_second = 3\n",
    "frequency = 30\n",
    "lenght_of_each_seq = window_size_second * frequency\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn hyperparams\n",
    "params = {\n",
    "    \n",
    "    # Conv layers\n",
    "    'n_conv_1':[512, 768], # filters, a.k.a. kernels\n",
    "    'k_conv_1':[2, 3], # kernel length\n",
    "    'n_conv_2':[256, 512], # filters, a.k.a. kernels\n",
    "    'k_conv_2':[2, 3], # kernel length\n",
    "    'n_conv_3':[256, 512], # filters, a.k.a. kernels\n",
    "    'k_conv_3':[2, 3], # kernel length\n",
    "    'maxpooling_pool_size':[2, 3],\n",
    "    'avepooling_pool_size':[2, 3],\n",
    "    \n",
    "    # LSTM layers\n",
    "    'n_lstm_1' : [128, 256],\n",
    "    'n_lstm_2' : [128, 256],\n",
    "    'drop_lstm_1' : [0.02,0.1],\n",
    "    'drop_lstm_2' : [0.02,0.1],\n",
    "\n",
    "    \n",
    "    # Dense layers\n",
    "    'n_dense_1':[256, 384, 512],\n",
    "    'dropout_1':[0.2, 0.3],\n",
    "    'n_dense_2':[256, 384, 512],\n",
    "    'dropout_2':[0.2, 0.3],\n",
    "    'activation_conv':['elu', 'relu', LeakyReLU()],\n",
    "    'activation_dense':['elu', 'relu', LeakyReLU()]\n",
    "}\n",
    "\n",
    "# training:\n",
    "n_tune_iter = 20\n",
    "cv = 3\n",
    "epochs = 60\n",
    "batch_size = 256\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to get reproducable results\n",
    "from numpy.random import seed\n",
    "seed(85)\n",
    "from tensorflow.random import set_seed\n",
    "set_seed(75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DaLx4yZ48Jj9"
   },
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CD9X0yJg8Jj_"
   },
   "source": [
    "##### For this notebook we use the acceleration data gathered from the pocket location. It was prepared in the DataPrep-Deep notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6r44JKj-8JkA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acceleration_data\n",
      "metadata\n",
      "labels\n"
     ]
    }
   ],
   "source": [
    "# read the raw file and get the keys:\n",
    "raw_data = np.load(file=input_dir+input_file_name,allow_pickle=True)\n",
    "for k in raw_data.keys():\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the data\n",
    "\n",
    "accel_array = raw_data['acceleration_data']\n",
    "meta_array = raw_data['metadata']\n",
    "labels_array = raw_data['labels']\n",
    "input_shape = list(accel_array.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WWq3ipbu8JlG"
   },
   "source": [
    "#### Preprocess data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert the  labels to integer.\n",
    "In the raw data format of the labels is String and there are 6 classes. 'Lying', 'Sitting', 'Self Pace walk', 'Running 3 METs',\n",
    "       'Running 5 METs', 'Running 7 METs' <br>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LyReiequ8Jln"
   },
   "outputs": [],
   "source": [
    "n_class = len(np.unique(labels_array))\n",
    "class_list, labels_array_int = np.unique(labels_array,return_inverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = to_categorical(labels_array_int, num_classes=n_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "40x3s0KY8Jlv",
    "outputId": "d3ac3e31-3c47-4b01-c2f9-ada0684b31b7"
   },
   "source": [
    "### Splitting and shuffeling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f5grc2H78Jlz",
    "outputId": "3f7eeb55-f851-4796-de4e-0c68eb9df88d"
   },
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "     accel_array, y, test_size=0.1, random_state=65)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "GscSnCpk8Jlm"
   },
   "source": [
    "\n",
    "#### Design neural network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_conv_1': [512, 768],\n",
       " 'k_conv_1': [2, 3],\n",
       " 'n_conv_2': [256, 512],\n",
       " 'k_conv_2': [2, 3],\n",
       " 'n_conv_3': [256, 512],\n",
       " 'k_conv_3': [2, 3],\n",
       " 'maxpooling_pool_size': [2, 3],\n",
       " 'avepooling_pool_size': [2, 3],\n",
       " 'n_lstm_1': [128, 256],\n",
       " 'n_lstm_2': [128, 256],\n",
       " 'drop_lstm_1': [0.02, 0.1],\n",
       " 'drop_lstm_2': [0.02, 0.1],\n",
       " 'n_dense_1': [256, 384, 512],\n",
       " 'dropout_1': [0.2, 0.3],\n",
       " 'n_dense_2': [256, 384, 512],\n",
       " 'dropout_2': [0.2, 0.3],\n",
       " 'activation_conv': ['elu',\n",
       "  'relu',\n",
       "  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU at 0x2527e6dd448>],\n",
       " 'activation_dense': ['elu',\n",
       "  'relu',\n",
       "  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU at 0x252062f3d48>]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(n_conv_1=256, k_conv_1=3, n_conv_2=256, k_conv_2=3, n_conv_3=256, k_conv_3=3,\n",
    "                 maxpooling_pool_size = 2, avepooling_pool_size = 2, n_lstm_1=128, n_lstm_2=128,\n",
    "                 drop_lstm_1=0.02,drop_lstm_2=0.02, n_dense_1=256, dropout_1=0.2,\n",
    "                 n_dense_2=256, dropout_2=0.2, activation_conv= 'relu', activation_dense= 'elu'\n",
    "                ):\n",
    "    model = Sequential()\n",
    "    # Conv layers\n",
    "    model.add(Conv1D(n_conv_1, k_conv_1, activation=activation_conv, input_shape=input_shape[1:]))\n",
    "    model.add(MaxPool1D(pool_size = maxpooling_pool_size))\n",
    "    model.add(Conv1D(n_conv_2, k_conv_2, activation=activation_conv))\n",
    "    model.add(AveragePooling1D(pool_size = avepooling_pool_size))\n",
    "    model.add(Conv1D(n_conv_3, k_conv_3, activation=activation_conv))\n",
    "#     model.add(GlobalAveragePooling1D())\n",
    "\n",
    "    # LSTM layers\n",
    "    model.add(LSTM(n_lstm_1, dropout=drop_lstm_1, \n",
    "                             return_sequences=True)) \n",
    "    model.add(LSTM(n_lstm_2, dropout=drop_lstm_2, \n",
    "                             return_sequences=True))\n",
    "    \n",
    "    # Dense layers\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(n_dense_1, activation=activation_dense))\n",
    "    model.add(Dropout(dropout_1))\n",
    "    model.add(Dense(n_dense_2, activation=activation_dense))\n",
    "    model.add(Dropout(dropout_2))\n",
    "    model.add(Dense(n_class, activation='softmax'))\n",
    "    model.summary()\n",
    "    print(f\"\"\"n_conv_1 = {n_conv_1}, k_conv_1 = {k_conv_1},  n_conv_2 = {n_conv_2}, k_conv_2 = {k_conv_2}, \n",
    "          n_conv_3 = {n_conv_3},  k_conv_3 = {k_conv_3},  maxpooling_pool_size = {maxpooling_pool_size},\n",
    "          avepooling_pool_size = {avepooling_pool_size},\n",
    "          n_lstm_1 = {n_lstm_1}, n_lstm_2 = {n_lstm_2},\n",
    "          drop_lstm_1 = {drop_lstm_1}, drop_lstm_2 = {drop_lstm_2},\n",
    "          n_dense_1 = {n_dense_1}, dropout_1 = {dropout_1},\n",
    "          n_dense_2 = {n_dense_2}, dropout_2 = {dropout_2}, activation_conv=  {activation_conv},\n",
    "          activation_dense=  {activation_dense}\"\"\")\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_9 (Conv1D)            (None, 88, 256)           2560      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 44, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_10 (Conv1D)           (None, 42, 256)           196864    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_3 (Average (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 19, 256)           196864    \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 19, 128)           197120    \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 19, 128)           131584    \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2432)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               622848    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 6)                 1542      \n",
      "=================================================================\n",
      "Total params: 1,415,174\n",
      "Trainable params: 1,415,174\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 256, k_conv_1 = 3,  n_conv_2 = 256, k_conv_2 = 3, \n",
      "          n_conv_3 = 256,  k_conv_3 = 3,  maxpooling_pool_size = 2,\n",
      "          avepooling_pool_size = 2,\n",
      "          n_lstm_1 = 128, n_lstm_2 = 128,\n",
      "          drop_lstm_1 = 0.02, drop_lstm_2 = 0.02,\n",
      "          n_dense_1 = 256, dropout_1 = 0.2,\n",
      "          n_dense_2 = 256, dropout_2 = 0.2, activation_conv=  relu,\n",
      "          activation_dense=  elu\n"
     ]
    }
   ],
   "source": [
    "model_default = create_model()\n",
    "# model_default.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasClassifier(build_fn=create_model, epochs=epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_12 (Conv1D)           (None, 88, 512)           5120      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 29, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_13 (Conv1D)           (None, 28, 256)           262400    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_4 (Average (None, 9, 256)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 7, 512)            393728    \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 7, 256)            787456    \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 7, 256)            525312    \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 1792)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 384)               688512    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 512)               197120    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 6)                 3078      \n",
      "=================================================================\n",
      "Total params: 2,862,726\n",
      "Trainable params: 2,862,726\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "n_conv_1 = 512, k_conv_1 = 3,  n_conv_2 = 256, k_conv_2 = 2, \n",
      "          n_conv_3 = 512,  k_conv_3 = 3,  maxpooling_pool_size = 3,\n",
      "          avepooling_pool_size = 3,\n",
      "          n_lstm_1 = 256, n_lstm_2 = 256,\n",
      "          drop_lstm_1 = 0.1, drop_lstm_2 = 0.02,\n",
      "          n_dense_1 = 384, dropout_1 = 0.3,\n",
      "          n_dense_2 = 512, dropout_2 = 0.3, activation_conv=  relu,\n",
      "          activation_dense=  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x00000252062F3D48>\n",
      "Epoch 1/60\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 1.0695 - accuracy: 0.5395\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.7041 - accuracy: 0.7201\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.5314 - accuracy: 0.7974\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.4232 - accuracy: 0.8376\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.3896 - accuracy: 0.8515\n",
      "Epoch 6/60\n",
      "121/152 [======================>.......] - ETA: 1s - loss: 0.3472 - accuracy: 0.8684"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rscv = RandomizedSearchCV(model, param_distributions=params, cv=cv, n_iter=n_tune_iter)\n",
    "rscv_results = rscv.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best score is: {} using {}'.format(rscv_results.best_score_,\n",
    "rscv_results.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = rscv_results.best_estimator_\n",
    "best_param = rscv_results.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JkbhJMox8Jl9"
   },
   "source": [
    "### Test the best model based on the validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kZwGk5dR8JmS"
   },
   "outputs": [],
   "source": [
    "y_hat = best_model.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E_GNq-R_8JmZ",
    "outputId": "0fc16efe-7739-4394-f1a3-46da92e79584"
   },
   "outputs": [],
   "source": [
    "y_hat = to_categorical(y_hat)\n",
    "y_hat[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SFqRQ5XB8Jmc",
    "outputId": "a957fbed-92f8-4bdd-d24b-5df3361a8bac"
   },
   "outputs": [],
   "source": [
    "y_valid[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FTWf6Cf-8Jme",
    "outputId": "1256b170-33dc-4171-f2ff-7a3d7ddd74e3"
   },
   "outputs": [],
   "source": [
    "plt.hist(y_hat)\n",
    "_ = plt.axvline(x=0.5, color='orange')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import  accuracy_score as score\n",
    "y_pred_classes = y_hat.round()\n",
    "print(y_valid[0], y_hat[0], y_pred_classes[0])\n",
    "acc = score(y_valid, y_pred_classes) * 100\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RNljSx3v8Jmh"
   },
   "outputs": [],
   "source": [
    "pct_auc = roc_auc_score(y_valid, y_hat)*100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SO_N9lJG8Jmj",
    "outputId": "20968a52-8ca0-44d3-abf6-a1382bba5cde"
   },
   "outputs": [],
   "source": [
    "\"{:0.2f}\".format(pct_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vU3hnA298Jmo"
   },
   "outputs": [],
   "source": [
    "float_y_hat = []\n",
    "for y in y_hat:\n",
    "    float_y_hat.append(y[0:6].round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zrTf-aQl8Jmr"
   },
   "outputs": [],
   "source": [
    "ydf = pd.DataFrame(list(zip(float_y_hat, y_valid)), columns=['y_hat', 'y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zAyKh_mX8Jmu",
    "outputId": "611224b8-f980-47df-d596-9aa3a5811009"
   },
   "outputs": [],
   "source": [
    "ydf.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(rscv_results.cv_results_['params'])\n",
    "results_df['mean'] = rscv_results.cv_results_['mean_test_score']\n",
    "results_df['std'] = rscv_results.cv_results_['std_test_score']\n",
    "results_df.sort_values('mean', ascending=False, ignore_index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating best model from the best param and train it for 60 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rscv_results.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_dense_2= 512\n",
    "n_dense_1= 384\n",
    "n_conv_3= 256\n",
    "n_conv_2= 512\n",
    "n_conv_1= 512\n",
    "maxpooling_pool_size= 2\n",
    "k_conv_3= 2\n",
    "k_conv_2= 2\n",
    "k_conv_1= 2\n",
    "dropout_2= 0.2\n",
    "dropout_1= 0.2\n",
    "avepooling_pool_size= 2\n",
    "activation_dense = 'relu'\n",
    "activation_conv = 'relu'\n",
    "model = Sequential()\n",
    "model.add(Conv1D(n_conv_1, k_conv_1, activation=activation_conv, input_shape=input_shape[1:]))\n",
    "model.add(MaxPool1D(pool_size = maxpooling_pool_size))\n",
    "model.add(Conv1D(n_conv_2, k_conv_2, activation=activation_conv))\n",
    "model.add(AveragePooling1D(pool_size = avepooling_pool_size))\n",
    "model.add(Conv1D(n_conv_3, k_conv_3, activation=activation_conv))\n",
    "# model.add(GlobalMaxPooling1D())\n",
    "model.add(GlobalAveragePooling1D())\n",
    "model.add(Dense(n_dense_1, activation=activation_dense))\n",
    "model.add(Dropout(dropout_1))\n",
    "model.add(Dense(n_dense_2, activation=activation_dense))\n",
    "model.add(Dropout(dropout_2))\n",
    "model.add(Dense(n_class, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir= 'model_ouput/tune-sklearn-3'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "modelcheckpoint = ModelCheckpoint(filepath=output_dir+\n",
    "                                  \"/weights.{epoch:02d}.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 120\n",
    "model.fit(X_train, y_train, \n",
    "         batch_size=batch_size, epochs=epochs, verbose=1, \n",
    "         validation_data=(X_valid, y_valid), \n",
    "         callbacks=[modelcheckpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z8t0nVCw8JmP"
   },
   "outputs": [],
   "source": [
    "model.load_weights(output_dir+\"/weights.113.hdf5\") # 96.43"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kZwGk5dR8JmS"
   },
   "outputs": [],
   "source": [
    "y_hat = model.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EPc5_h6K8JmW",
    "outputId": "cad99da9-9f89-437f-854b-a315616ed50f"
   },
   "outputs": [],
   "source": [
    "len(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E_GNq-R_8JmZ",
    "outputId": "0fc16efe-7739-4394-f1a3-46da92e79584"
   },
   "outputs": [],
   "source": [
    "y_hat[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SFqRQ5XB8Jmc",
    "outputId": "a957fbed-92f8-4bdd-d24b-5df3361a8bac"
   },
   "outputs": [],
   "source": [
    "y_valid[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FTWf6Cf-8Jme",
    "outputId": "1256b170-33dc-4171-f2ff-7a3d7ddd74e3"
   },
   "outputs": [],
   "source": [
    "plt.hist(y_hat)\n",
    "_ = plt.axvline(x=0.5, color='orange')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RNljSx3v8Jmh"
   },
   "outputs": [],
   "source": [
    "pct_auc = roc_auc_score(y_valid, y_hat)*100.0\n",
    "\"{:0.2f}\".format(pct_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SO_N9lJG8Jmj",
    "outputId": "20968a52-8ca0-44d3-abf6-a1382bba5cde"
   },
   "outputs": [],
   "source": [
    "y_pred_classes = y_hat.round()\n",
    "acc = score(y_valid, y_pred_classes) * 100\n",
    "\"{:0.2f}\".format(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vU3hnA298Jmo"
   },
   "outputs": [],
   "source": [
    "float_y_hat = []\n",
    "for y in y_hat:\n",
    "    float_y_hat.append(y[0:6].round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zrTf-aQl8Jmr"
   },
   "outputs": [],
   "source": [
    "ydf = pd.DataFrame(list(zip(float_y_hat, y_valid)), columns=['y_hat', 'y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zAyKh_mX8Jmu",
    "outputId": "611224b8-f980-47df-d596-9aa3a5811009"
   },
   "outputs": [],
   "source": [
    "ydf.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "dense_sentiment_classifier.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
