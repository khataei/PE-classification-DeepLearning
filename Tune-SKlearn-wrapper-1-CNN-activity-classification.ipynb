{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/khataei/PE-classification-DeepLearning/blob/master/Tunned-Talos-1-CNN-activity-classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ahUZuAfz8Jje"
   },
   "source": [
    "# Talos Tuner for CNN Activity Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Re0ecmVI8Jjk"
   },
   "source": [
    "In this notebook, we use SKlearn  to tune a CNN neural net to classify PE activity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ixsGb9tY8Jjm"
   },
   "source": [
    "#### Load dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5At1PKQp8Jjp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 4021926830220582436\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 7005546176762618463\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 4022219571\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 8187960795673950703\n",
      "physical_device_desc: \"device: 0, name: Quadro P2000, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 16589542880459548679\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      "]\n",
      "# GPUs Available:  1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.3.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os  \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "import tensorflow\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, Conv1D, GlobalMaxPooling1D\n",
    "from tensorflow.keras.layers import AveragePooling1D, LeakyReLU , MaxPool1D, GlobalAveragePooling1D\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint \n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, roc_curve \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "print(device_lib.list_local_devices())\n",
    "import tensorflow as tf\n",
    "print(\"# GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "tensorflow.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hg5wX2Dd8Jjz"
   },
   "source": [
    "#### Set hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lYLOM99-8Jj2"
   },
   "outputs": [],
   "source": [
    "# output directory name:\n",
    "output_dir = 'model_output/tunecnn1'\n",
    "input_dir =  'Z:/Research/dfuller/Walkabilly/studies/smarphone_accel/data/Ethica_Jaeger_Merged/pocket/'\n",
    "input_file_name = 'pocket-NN-data.npz'\n",
    "\n",
    "# from the data preparation section we have:\n",
    "window_size_second = 3\n",
    "frequency = 30\n",
    "lenght_of_each_seq = window_size_second * frequency\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn hyperparams\n",
    "params = {\n",
    "    'n_conv_1':[256, 512, 768], # filters, a.k.a. kernels\n",
    "    'k_conv_1':[3, 5], # kernel length\n",
    "    'n_conv_2':[256, 512, 768], # filters, a.k.a. kernels\n",
    "    'k_conv_2':[3, 5], # kernel length\n",
    "    'n_conv_3':[256, 512, 768], # filters, a.k.a. kernels\n",
    "    'k_conv_3':[3, 5], # kernel length\n",
    "    'maxpooling_pool_size':[2, 4],\n",
    "    'avepooling_pool_size':[2, 4],\n",
    "    'n_dense_1':[256, 512],\n",
    "    'dropout_1':[0.2, 0.4],\n",
    "    'n_dense_2':[256, 512],\n",
    "    'dropout_2':[0.2, 0.4],\n",
    "    'activation':['elu', 'relu', LeakyReLU()]\n",
    "}\n",
    "\n",
    "# training:\n",
    "n_tune_iter = 40\n",
    "cv = 5\n",
    "epochs = 60\n",
    "batch_size = 256\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DaLx4yZ48Jj9"
   },
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CD9X0yJg8Jj_"
   },
   "source": [
    "##### For this notebook we use the acceleration data gathered from the pocket location. It was prepared in the DataPrep-Deep notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6r44JKj-8JkA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acceleration_data\n",
      "metadata\n",
      "labels\n"
     ]
    }
   ],
   "source": [
    "# read the raw file and get the keys:\n",
    "raw_data = np.load(file=input_dir+input_file_name,allow_pickle=True)\n",
    "for k in raw_data.keys():\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the data\n",
    "\n",
    "accel_array = raw_data['acceleration_data']\n",
    "meta_array = raw_data['metadata']\n",
    "labels_array = raw_data['labels']\n",
    "input_shape = list(accel_array.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WWq3ipbu8JlG"
   },
   "source": [
    "#### Preprocess data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert the  labels to integer.\n",
    "In the raw data format of the labels is String and there are 6 classes. 'Lying', 'Sitting', 'Self Pace walk', 'Running 3 METs',\n",
    "       'Running 5 METs', 'Running 7 METs' <br>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LyReiequ8Jln"
   },
   "outputs": [],
   "source": [
    "n_class = len(np.unique(labels_array))\n",
    "class_list, labels_array_int = np.unique(labels_array,return_inverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = to_categorical(labels_array_int, num_classes=n_class)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "40x3s0KY8Jlv",
    "outputId": "d3ac3e31-3c47-4b01-c2f9-ada0684b31b7"
   },
   "source": [
    "### Splitting and shuffeling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f5grc2H78Jlz",
    "outputId": "3f7eeb55-f851-4796-de4e-0c68eb9df88d"
   },
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "     accel_array, y, test_size=0.1, random_state=65)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "GscSnCpk8Jlm"
   },
   "source": [
    "\n",
    "#### Design neural network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_conv_1': [256, 512, 768],\n",
       " 'k_conv_1': [3, 5],\n",
       " 'n_conv_2': [256, 512, 768],\n",
       " 'k_conv_2': [3, 5],\n",
       " 'n_conv_3': [256, 512, 768],\n",
       " 'k_conv_3': [3, 5],\n",
       " 'maxpooling_pool_size': [2, 4],\n",
       " 'avepooling_pool_size': [2, 4],\n",
       " 'n_dense_1': [256, 512],\n",
       " 'dropout_1': [0.2, 0.4],\n",
       " 'n_dense_2': [256, 512],\n",
       " 'dropout_2': [0.2, 0.4],\n",
       " 'activation': ['elu',\n",
       "  'relu',\n",
       "  <tensorflow.python.keras.layers.advanced_activations.LeakyReLU at 0x238cb4127c8>]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(n_conv_1=256, k_conv_1=3, n_conv_2=256, k_conv_2=3, n_conv_3=256, k_conv_3=3,\n",
    "                 maxpooling_pool_size = 2, avepooling_pool_size = 2, n_dense_1=256, dropout_1=0.2,\n",
    "                 n_dense_2=256, dropout_2=0.2, activation= 'elu'\n",
    "                ):\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(n_conv_1, k_conv_1, activation=activation, input_shape=input_shape[1:]))\n",
    "    model.add(MaxPool1D(pool_size = maxpooling_pool_size))\n",
    "    model.add(Conv1D(n_conv_2, k_conv_2, activation=activation))\n",
    "    model.add(AveragePooling1D(pool_size = avepooling_pool_size))\n",
    "    model.add(Conv1D(n_conv_3, k_conv_3, activation=activation))\n",
    "    # model.add(GlobalMaxPooling1D())\n",
    "    model.add(GlobalAveragePooling1D())\n",
    "    model.add(Dense(n_dense_1, activation=activation))\n",
    "    model.add(Dropout(dropout_1))\n",
    "    model.add(Dense(n_dense_2, activation=activation))\n",
    "    model.add(Dropout(dropout_2))\n",
    "    model.add(Dense(n_class, activation='softmax'))\n",
    "    model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='nadam', metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 88, 256)           2560      \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 44, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 42, 256)           196864    \n",
      "_________________________________________________________________\n",
      "average_pooling1d (AveragePo (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 19, 256)           196864    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 1542      \n",
      "=================================================================\n",
      "Total params: 529,414\n",
      "Trainable params: 529,414\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 88, 256)           2560      \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 44, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 42, 256)           196864    \n",
      "_________________________________________________________________\n",
      "average_pooling1d (AveragePo (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 19, 256)           196864    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 1542      \n",
      "=================================================================\n",
      "Total params: 529,414\n",
      "Trainable params: 529,414\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_default = create_model()\n",
    "model_default.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasClassifier(build_fn=create_model, epochs=epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_3 (Conv1D)            (None, 86, 256)           4096      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 43, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 39, 256)           327936    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average (None, 9, 256)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 7, 256)            196864    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_1 ( (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 6)                 3078      \n",
      "=================================================================\n",
      "Total params: 729,350\n",
      "Trainable params: 729,350\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/60\n",
      "183/183 [==============================] - 4s 25ms/step - loss: 1.1536 - accuracy: 0.5089\n",
      "Epoch 2/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.8862 - accuracy: 0.6375\n",
      "Epoch 3/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.7180 - accuracy: 0.7115\n",
      "Epoch 4/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.6511 - accuracy: 0.7412\n",
      "Epoch 5/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.5766 - accuracy: 0.7673\n",
      "Epoch 6/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.5458 - accuracy: 0.7833\n",
      "Epoch 7/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.4996 - accuracy: 0.8002\n",
      "Epoch 8/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.4754 - accuracy: 0.8102\n",
      "Epoch 9/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.4697 - accuracy: 0.8135\n",
      "Epoch 10/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.4332 - accuracy: 0.8290\n",
      "Epoch 11/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.4337 - accuracy: 0.8298\n",
      "Epoch 12/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.4093 - accuracy: 0.8408\n",
      "Epoch 13/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.4059 - accuracy: 0.8435\n",
      "Epoch 14/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.3869 - accuracy: 0.8502\n",
      "Epoch 15/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.3674 - accuracy: 0.8560\n",
      "Epoch 16/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.3646 - accuracy: 0.8574\n",
      "Epoch 17/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.3483 - accuracy: 0.8621\n",
      "Epoch 18/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.3572 - accuracy: 0.8626\n",
      "Epoch 19/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.3382 - accuracy: 0.8689\n",
      "Epoch 20/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.3959 - accuracy: 0.8555\n",
      "Epoch 21/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.3274 - accuracy: 0.8739\n",
      "Epoch 22/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.3146 - accuracy: 0.8784\n",
      "Epoch 23/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.3189 - accuracy: 0.8769\n",
      "Epoch 24/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.3102 - accuracy: 0.8787\n",
      "Epoch 25/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.3169 - accuracy: 0.8786\n",
      "Epoch 26/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.3007 - accuracy: 0.8837\n",
      "Epoch 27/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2951 - accuracy: 0.8849\n",
      "Epoch 28/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2859 - accuracy: 0.8896\n",
      "Epoch 29/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.3043 - accuracy: 0.8858\n",
      "Epoch 30/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2834 - accuracy: 0.8896\n",
      "Epoch 31/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2777 - accuracy: 0.8933\n",
      "Epoch 32/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.6735 - accuracy: 0.8062\n",
      "Epoch 33/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.3270 - accuracy: 0.8794\n",
      "Epoch 34/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2819 - accuracy: 0.8929\n",
      "Epoch 35/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2736 - accuracy: 0.8952\n",
      "Epoch 36/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2673 - accuracy: 0.8979\n",
      "Epoch 37/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2628 - accuracy: 0.8993\n",
      "Epoch 38/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2665 - accuracy: 0.8985\n",
      "Epoch 39/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2565 - accuracy: 0.8998\n",
      "Epoch 40/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2517 - accuracy: 0.9020\n",
      "Epoch 41/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2535 - accuracy: 0.9023\n",
      "Epoch 42/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2930 - accuracy: 0.8921\n",
      "Epoch 43/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2522 - accuracy: 0.9012\n",
      "Epoch 44/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2472 - accuracy: 0.9053\n",
      "Epoch 45/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2429 - accuracy: 0.9055\n",
      "Epoch 46/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2420 - accuracy: 0.9064\n",
      "Epoch 47/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2348 - accuracy: 0.9078\n",
      "Epoch 48/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2492 - accuracy: 0.9054\n",
      "Epoch 49/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2392 - accuracy: 0.9076\n",
      "Epoch 50/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2334 - accuracy: 0.9092\n",
      "Epoch 51/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2330 - accuracy: 0.9095\n",
      "Epoch 52/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2317 - accuracy: 0.9095\n",
      "Epoch 53/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2292 - accuracy: 0.9113\n",
      "Epoch 54/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2263 - accuracy: 0.9117\n",
      "Epoch 55/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2254 - accuracy: 0.9133\n",
      "Epoch 56/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2309 - accuracy: 0.9109\n",
      "Epoch 57/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2318 - accuracy: 0.9092\n",
      "Epoch 58/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2191 - accuracy: 0.9137\n",
      "Epoch 59/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2228 - accuracy: 0.9129\n",
      "Epoch 60/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2426 - accuracy: 0.9105\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.5382 - accuracy: 0.8408\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_6 (Conv1D)            (None, 86, 256)           4096      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 43, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 39, 256)           327936    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_2 (Average (None, 9, 256)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 7, 256)            196864    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_2 ( (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 6)                 3078      \n",
      "=================================================================\n",
      "Total params: 729,350\n",
      "Trainable params: 729,350\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183/183 [==============================] - 4s 23ms/step - loss: 1.1475 - accuracy: 0.5099\n",
      "Epoch 2/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.9150 - accuracy: 0.6282\n",
      "Epoch 3/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.7201 - accuracy: 0.7125\n",
      "Epoch 4/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.6469 - accuracy: 0.7431\n",
      "Epoch 5/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.5674 - accuracy: 0.7723\n",
      "Epoch 6/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.5395 - accuracy: 0.7817\n",
      "Epoch 7/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.5123 - accuracy: 0.7954\n",
      "Epoch 8/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.4835 - accuracy: 0.8067\n",
      "Epoch 9/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.4631 - accuracy: 0.8169\n",
      "Epoch 10/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.4578 - accuracy: 0.8230\n",
      "Epoch 11/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.4150 - accuracy: 0.8349\n",
      "Epoch 12/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.4142 - accuracy: 0.8395\n",
      "Epoch 13/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.4052 - accuracy: 0.8421\n",
      "Epoch 14/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.3871 - accuracy: 0.8489\n",
      "Epoch 15/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.3691 - accuracy: 0.8542\n",
      "Epoch 16/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.4008 - accuracy: 0.8472\n",
      "Epoch 17/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.3572 - accuracy: 0.8599\n",
      "Epoch 18/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.3567 - accuracy: 0.8625\n",
      "Epoch 19/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.3677 - accuracy: 0.8573\n",
      "Epoch 20/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.3355 - accuracy: 0.8683\n",
      "Epoch 21/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.3752 - accuracy: 0.8573\n",
      "Epoch 22/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.3677 - accuracy: 0.8595\n",
      "Epoch 23/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.3228 - accuracy: 0.8747\n",
      "Epoch 24/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.3174 - accuracy: 0.8749\n",
      "Epoch 25/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.3066 - accuracy: 0.8773\n",
      "Epoch 26/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.3071 - accuracy: 0.8779\n",
      "Epoch 27/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.3094 - accuracy: 0.8795\n",
      "Epoch 28/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.3036 - accuracy: 0.8812\n",
      "Epoch 29/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2984 - accuracy: 0.8818\n",
      "Epoch 30/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.3201 - accuracy: 0.8740\n",
      "Epoch 31/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2913 - accuracy: 0.8847\n",
      "Epoch 32/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2876 - accuracy: 0.8860\n",
      "Epoch 33/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.3230 - accuracy: 0.8775\n",
      "Epoch 34/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2786 - accuracy: 0.8897\n",
      "Epoch 35/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2806 - accuracy: 0.8869\n",
      "Epoch 36/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2725 - accuracy: 0.8924\n",
      "Epoch 37/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2698 - accuracy: 0.8933\n",
      "Epoch 38/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2637 - accuracy: 0.8943\n",
      "Epoch 39/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2702 - accuracy: 0.8931\n",
      "Epoch 40/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2592 - accuracy: 0.8962\n",
      "Epoch 41/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.3227 - accuracy: 0.8827\n",
      "Epoch 42/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2589 - accuracy: 0.8982\n",
      "Epoch 43/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2560 - accuracy: 0.8994\n",
      "Epoch 44/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2493 - accuracy: 0.9009\n",
      "Epoch 45/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2553 - accuracy: 0.8970\n",
      "Epoch 46/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2432 - accuracy: 0.9041\n",
      "Epoch 47/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2378 - accuracy: 0.9048\n",
      "Epoch 48/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2418 - accuracy: 0.9030\n",
      "Epoch 49/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2527 - accuracy: 0.8973\n",
      "Epoch 50/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2357 - accuracy: 0.9057\n",
      "Epoch 51/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2337 - accuracy: 0.9064\n",
      "Epoch 52/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2267 - accuracy: 0.9094\n",
      "Epoch 53/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.3169 - accuracy: 0.8875\n",
      "Epoch 54/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2273 - accuracy: 0.9089\n",
      "Epoch 55/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2233 - accuracy: 0.9106\n",
      "Epoch 56/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2202 - accuracy: 0.9127\n",
      "Epoch 57/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2202 - accuracy: 0.9116\n",
      "Epoch 58/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2164 - accuracy: 0.9137\n",
      "Epoch 59/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2134 - accuracy: 0.9138\n",
      "Epoch 60/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2144 - accuracy: 0.9127\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.4127 - accuracy: 0.8654\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_9 (Conv1D)            (None, 86, 256)           4096      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 43, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_10 (Conv1D)           (None, 39, 256)           327936    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_3 (Average (None, 9, 256)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 7, 256)            196864    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_3 ( (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 6)                 3078      \n",
      "=================================================================\n",
      "Total params: 729,350\n",
      "Trainable params: 729,350\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 1.1499 - accuracy: 0.5103\n",
      "Epoch 2/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183/183 [==============================] - 4s 23ms/step - loss: 0.8908 - accuracy: 0.6385\n",
      "Epoch 3/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.7306 - accuracy: 0.7085\n",
      "Epoch 4/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.6747 - accuracy: 0.7361\n",
      "Epoch 5/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.5663 - accuracy: 0.7700\n",
      "Epoch 6/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.5290 - accuracy: 0.7841\n",
      "Epoch 7/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.5249 - accuracy: 0.7907\n",
      "Epoch 8/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.4785 - accuracy: 0.8066\n",
      "Epoch 9/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.4723 - accuracy: 0.8110\n",
      "Epoch 10/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.4287 - accuracy: 0.8305\n",
      "Epoch 11/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.4289 - accuracy: 0.8311\n",
      "Epoch 12/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.4070 - accuracy: 0.8395\n",
      "Epoch 13/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.4155 - accuracy: 0.8395\n",
      "Epoch 14/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.4013 - accuracy: 0.8455\n",
      "Epoch 15/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.3692 - accuracy: 0.8544\n",
      "Epoch 16/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.3771 - accuracy: 0.8534\n",
      "Epoch 17/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.3542 - accuracy: 0.8606\n",
      "Epoch 18/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.3672 - accuracy: 0.8607\n",
      "Epoch 19/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.3414 - accuracy: 0.8669\n",
      "Epoch 20/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.3650 - accuracy: 0.8598\n",
      "Epoch 21/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.3460 - accuracy: 0.8652\n",
      "Epoch 22/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.3209 - accuracy: 0.8734\n",
      "Epoch 23/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.3643 - accuracy: 0.8636\n",
      "Epoch 24/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.3188 - accuracy: 0.8759\n",
      "Epoch 25/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2996 - accuracy: 0.8810\n",
      "Epoch 26/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.3212 - accuracy: 0.8760\n",
      "Epoch 27/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2988 - accuracy: 0.8820\n",
      "Epoch 28/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2900 - accuracy: 0.8856\n",
      "Epoch 29/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2997 - accuracy: 0.8824\n",
      "Epoch 30/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.3244 - accuracy: 0.8756\n",
      "Epoch 31/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2847 - accuracy: 0.8877\n",
      "Epoch 32/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2766 - accuracy: 0.8908\n",
      "Epoch 33/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2773 - accuracy: 0.8904\n",
      "Epoch 34/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2702 - accuracy: 0.8940\n",
      "Epoch 35/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2865 - accuracy: 0.8886\n",
      "Epoch 36/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2662 - accuracy: 0.8949\n",
      "Epoch 37/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2649 - accuracy: 0.8944\n",
      "Epoch 38/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2593 - accuracy: 0.8965\n",
      "Epoch 39/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2922 - accuracy: 0.8899\n",
      "Epoch 40/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2559 - accuracy: 0.8981\n",
      "Epoch 41/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2662 - accuracy: 0.8964\n",
      "Epoch 42/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2469 - accuracy: 0.9025\n",
      "Epoch 43/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2831 - accuracy: 0.8863\n",
      "Epoch 44/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2551 - accuracy: 0.8973\n",
      "Epoch 45/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2480 - accuracy: 0.9024\n",
      "Epoch 46/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2378 - accuracy: 0.9046\n",
      "Epoch 47/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2387 - accuracy: 0.9039\n",
      "Epoch 48/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.3989 - accuracy: 0.8727\n",
      "Epoch 49/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2643 - accuracy: 0.8958\n",
      "Epoch 50/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2413 - accuracy: 0.9036\n",
      "Epoch 51/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2328 - accuracy: 0.9074\n",
      "Epoch 52/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2289 - accuracy: 0.9092\n",
      "Epoch 53/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2290 - accuracy: 0.9078\n",
      "Epoch 54/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2220 - accuracy: 0.9110\n",
      "Epoch 55/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2240 - accuracy: 0.9096\n",
      "Epoch 56/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2248 - accuracy: 0.9102\n",
      "Epoch 57/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2197 - accuracy: 0.9122\n",
      "Epoch 58/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2196 - accuracy: 0.9114\n",
      "Epoch 59/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2173 - accuracy: 0.9122\n",
      "Epoch 60/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2190 - accuracy: 0.9121\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.5035 - accuracy: 0.8523\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_12 (Conv1D)           (None, 86, 256)           4096      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 43, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_13 (Conv1D)           (None, 39, 256)           327936    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_4 (Average (None, 9, 256)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 7, 256)            196864    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_4 ( (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 6)                 3078      \n",
      "=================================================================\n",
      "Total params: 729,350\n",
      "Trainable params: 729,350\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/60\n",
      "183/183 [==============================] - 5s 25ms/step - loss: 1.1423 - accuracy: 0.5152\n",
      "Epoch 2/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.8768 - accuracy: 0.6461\n",
      "Epoch 3/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183/183 [==============================] - 4s 23ms/step - loss: 0.7141 - accuracy: 0.7159\n",
      "Epoch 4/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.6297 - accuracy: 0.7477\n",
      "Epoch 5/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.5789 - accuracy: 0.7703\n",
      "Epoch 6/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.5422 - accuracy: 0.7844\n",
      "Epoch 7/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.5490 - accuracy: 0.7863\n",
      "Epoch 8/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.4725 - accuracy: 0.8131\n",
      "Epoch 9/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.4758 - accuracy: 0.8136\n",
      "Epoch 10/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.4303 - accuracy: 0.8316\n",
      "Epoch 11/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.4177 - accuracy: 0.8369\n",
      "Epoch 12/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.4072 - accuracy: 0.8398\n",
      "Epoch 13/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.4288 - accuracy: 0.8357\n",
      "Epoch 14/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.3786 - accuracy: 0.8518\n",
      "Epoch 15/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.3752 - accuracy: 0.8534\n",
      "Epoch 16/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.3724 - accuracy: 0.8562\n",
      "Epoch 17/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.3596 - accuracy: 0.8601\n",
      "Epoch 18/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.3471 - accuracy: 0.8655\n",
      "Epoch 19/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.3393 - accuracy: 0.8685\n",
      "Epoch 20/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.3401 - accuracy: 0.8700\n",
      "Epoch 21/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.3374 - accuracy: 0.8697\n",
      "Epoch 22/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.3191 - accuracy: 0.8736\n",
      "Epoch 23/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.3266 - accuracy: 0.8737\n",
      "Epoch 24/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.4128 - accuracy: 0.8550\n",
      "Epoch 25/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.3501 - accuracy: 0.8666\n",
      "Epoch 26/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.3040 - accuracy: 0.8797\n",
      "Epoch 27/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2957 - accuracy: 0.8832\n",
      "Epoch 28/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.3076 - accuracy: 0.8812\n",
      "Epoch 29/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2906 - accuracy: 0.8859\n",
      "Epoch 30/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2858 - accuracy: 0.8860\n",
      "Epoch 31/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2892 - accuracy: 0.8869\n",
      "Epoch 32/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2794 - accuracy: 0.8888\n",
      "Epoch 33/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2792 - accuracy: 0.8905\n",
      "Epoch 34/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2756 - accuracy: 0.8906\n",
      "Epoch 35/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2724 - accuracy: 0.8920\n",
      "Epoch 36/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2714 - accuracy: 0.8934\n",
      "Epoch 37/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.3955 - accuracy: 0.8646\n",
      "Epoch 38/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2662 - accuracy: 0.8969\n",
      "Epoch 39/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2610 - accuracy: 0.8971\n",
      "Epoch 40/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2555 - accuracy: 0.8987\n",
      "Epoch 41/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2529 - accuracy: 0.9001\n",
      "Epoch 42/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2529 - accuracy: 0.9007\n",
      "Epoch 43/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2677 - accuracy: 0.8953\n",
      "Epoch 44/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2448 - accuracy: 0.9018\n",
      "Epoch 45/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2475 - accuracy: 0.9022\n",
      "Epoch 46/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2416 - accuracy: 0.9049\n",
      "Epoch 47/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2483 - accuracy: 0.9031\n",
      "Epoch 48/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2363 - accuracy: 0.9061\n",
      "Epoch 49/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2326 - accuracy: 0.9066\n",
      "Epoch 50/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2330 - accuracy: 0.9065\n",
      "Epoch 51/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2332 - accuracy: 0.9069\n",
      "Epoch 52/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2383 - accuracy: 0.9065\n",
      "Epoch 53/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2291 - accuracy: 0.9087\n",
      "Epoch 54/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2250 - accuracy: 0.9106\n",
      "Epoch 55/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2323 - accuracy: 0.9091\n",
      "Epoch 56/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2222 - accuracy: 0.9111\n",
      "Epoch 57/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2221 - accuracy: 0.9108\n",
      "Epoch 58/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2233 - accuracy: 0.9111\n",
      "Epoch 59/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2304 - accuracy: 0.9060\n",
      "Epoch 60/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2160 - accuracy: 0.9129\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.3808 - accuracy: 0.8781\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_15 (Conv1D)           (None, 86, 256)           4096      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 43, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_16 (Conv1D)           (None, 39, 256)           327936    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_5 (Average (None, 9, 256)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_17 (Conv1D)           (None, 7, 256)            196864    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_5 ( (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 6)                 3078      \n",
      "=================================================================\n",
      "Total params: 729,350\n",
      "Trainable params: 729,350\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 1.1479 - accuracy: 0.5109\n",
      "Epoch 2/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.8979 - accuracy: 0.6322\n",
      "Epoch 3/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.7483 - accuracy: 0.7021\n",
      "Epoch 4/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183/183 [==============================] - 4s 23ms/step - loss: 0.6450 - accuracy: 0.7442\n",
      "Epoch 5/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.5817 - accuracy: 0.7654\n",
      "Epoch 6/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.5326 - accuracy: 0.7856\n",
      "Epoch 7/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.5123 - accuracy: 0.7959\n",
      "Epoch 8/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.4768 - accuracy: 0.8088\n",
      "Epoch 9/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.4619 - accuracy: 0.8199\n",
      "Epoch 10/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.4611 - accuracy: 0.8206\n",
      "Epoch 11/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.4261 - accuracy: 0.8338\n",
      "Epoch 12/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.4101 - accuracy: 0.8399\n",
      "Epoch 13/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.4026 - accuracy: 0.8457\n",
      "Epoch 14/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.3751 - accuracy: 0.8524\n",
      "Epoch 15/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.4197 - accuracy: 0.8422\n",
      "Epoch 16/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.3867 - accuracy: 0.8506\n",
      "Epoch 17/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.3634 - accuracy: 0.8593\n",
      "Epoch 18/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.3585 - accuracy: 0.8624\n",
      "Epoch 19/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.3515 - accuracy: 0.8643\n",
      "Epoch 20/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.3357 - accuracy: 0.8691\n",
      "Epoch 21/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.3329 - accuracy: 0.8704\n",
      "Epoch 22/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.3542 - accuracy: 0.8656\n",
      "Epoch 23/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.3201 - accuracy: 0.8756\n",
      "Epoch 24/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.3220 - accuracy: 0.8743\n",
      "Epoch 25/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.3219 - accuracy: 0.8761\n",
      "Epoch 26/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.3071 - accuracy: 0.8810\n",
      "Epoch 27/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2991 - accuracy: 0.8826\n",
      "Epoch 28/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.3015 - accuracy: 0.8817\n",
      "Epoch 29/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2998 - accuracy: 0.8840\n",
      "Epoch 30/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.3214 - accuracy: 0.8790\n",
      "Epoch 31/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2960 - accuracy: 0.8869\n",
      "Epoch 32/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2804 - accuracy: 0.8898\n",
      "Epoch 33/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2778 - accuracy: 0.8921\n",
      "Epoch 34/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2737 - accuracy: 0.8916\n",
      "Epoch 35/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2785 - accuracy: 0.8907\n",
      "Epoch 36/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2721 - accuracy: 0.8937\n",
      "Epoch 37/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2800 - accuracy: 0.8925\n",
      "Epoch 38/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2649 - accuracy: 0.8960\n",
      "Epoch 39/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2601 - accuracy: 0.8974\n",
      "Epoch 40/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.3156 - accuracy: 0.8850\n",
      "Epoch 41/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2534 - accuracy: 0.9004\n",
      "Epoch 42/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2530 - accuracy: 0.8996\n",
      "Epoch 43/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2497 - accuracy: 0.9006\n",
      "Epoch 44/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2495 - accuracy: 0.9020\n",
      "Epoch 45/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2438 - accuracy: 0.9031\n",
      "Epoch 46/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2400 - accuracy: 0.9047\n",
      "Epoch 47/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2398 - accuracy: 0.9048\n",
      "Epoch 48/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2474 - accuracy: 0.9009\n",
      "Epoch 49/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2367 - accuracy: 0.9052\n",
      "Epoch 50/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2330 - accuracy: 0.9064\n",
      "Epoch 51/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2348 - accuracy: 0.9063\n",
      "Epoch 52/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2538 - accuracy: 0.9012\n",
      "Epoch 53/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2295 - accuracy: 0.9076\n",
      "Epoch 54/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2372 - accuracy: 0.9054\n",
      "Epoch 55/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2275 - accuracy: 0.9084\n",
      "Epoch 56/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2259 - accuracy: 0.9081\n",
      "Epoch 57/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2215 - accuracy: 0.9104\n",
      "Epoch 58/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2219 - accuracy: 0.9114\n",
      "Epoch 59/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2159 - accuracy: 0.9126\n",
      "Epoch 60/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2375 - accuracy: 0.9063\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.3215 - accuracy: 0.8783\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_18 (Conv1D)           (None, 86, 768)           12288     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 43, 768)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_19 (Conv1D)           (None, 41, 256)           590080    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_6 (Average (None, 20, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_20 (Conv1D)           (None, 18, 768)           590592    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_6 ( (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 256)               196864    \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 6)                 1542      \n",
      "=================================================================\n",
      "Total params: 1,457,158\n",
      "Trainable params: 1,457,158\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/60\n",
      "  2/183 [..............................] - ETA: 5s - loss: 1.7772 - accuracy: 0.1855WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0200s vs `on_train_batch_end` time: 0.0339s). Check your callbacks.\n",
      "183/183 [==============================] - 10s 56ms/step - loss: 1.1231 - accuracy: 0.5277\n",
      "Epoch 2/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.7949 - accuracy: 0.6699\n",
      "Epoch 3/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183/183 [==============================] - 10s 53ms/step - loss: 0.5732 - accuracy: 0.7773\n",
      "Epoch 4/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.4462 - accuracy: 0.8347\n",
      "Epoch 5/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.3657 - accuracy: 0.8653\n",
      "Epoch 6/60\n",
      "183/183 [==============================] - 10s 54ms/step - loss: 0.3310 - accuracy: 0.8772\n",
      "Epoch 7/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.3061 - accuracy: 0.8859\n",
      "Epoch 8/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.3222 - accuracy: 0.8856\n",
      "Epoch 9/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.2613 - accuracy: 0.9032\n",
      "Epoch 10/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.2500 - accuracy: 0.9079\n",
      "Epoch 11/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.2344 - accuracy: 0.9126\n",
      "Epoch 12/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.2679 - accuracy: 0.9046\n",
      "Epoch 13/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.2258 - accuracy: 0.9188\n",
      "Epoch 14/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.2065 - accuracy: 0.9250\n",
      "Epoch 15/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1953 - accuracy: 0.9297\n",
      "Epoch 16/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1937 - accuracy: 0.9292\n",
      "Epoch 17/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1762 - accuracy: 0.9358\n",
      "Epoch 18/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1716 - accuracy: 0.9372\n",
      "Epoch 19/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1674 - accuracy: 0.9388\n",
      "Epoch 20/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1673 - accuracy: 0.9390\n",
      "Epoch 21/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1938 - accuracy: 0.9327\n",
      "Epoch 22/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1576 - accuracy: 0.9419\n",
      "Epoch 23/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1470 - accuracy: 0.9453\n",
      "Epoch 24/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1469 - accuracy: 0.9450\n",
      "Epoch 25/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1395 - accuracy: 0.9476\n",
      "Epoch 26/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1515 - accuracy: 0.9459\n",
      "Epoch 27/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1323 - accuracy: 0.9506\n",
      "Epoch 28/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1807 - accuracy: 0.9418\n",
      "Epoch 29/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1353 - accuracy: 0.9507\n",
      "Epoch 30/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1245 - accuracy: 0.9540\n",
      "Epoch 31/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1221 - accuracy: 0.9540\n",
      "Epoch 32/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1147 - accuracy: 0.9572\n",
      "Epoch 33/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1396 - accuracy: 0.9502\n",
      "Epoch 34/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1222 - accuracy: 0.9541\n",
      "Epoch 35/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1116 - accuracy: 0.9585\n",
      "Epoch 36/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1069 - accuracy: 0.9601\n",
      "Epoch 37/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1118 - accuracy: 0.9584\n",
      "Epoch 38/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1055 - accuracy: 0.9610\n",
      "Epoch 39/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1008 - accuracy: 0.9623\n",
      "Epoch 40/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.0988 - accuracy: 0.9626\n",
      "Epoch 41/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1075 - accuracy: 0.9611\n",
      "Epoch 42/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1020 - accuracy: 0.9619\n",
      "Epoch 43/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.0951 - accuracy: 0.9650\n",
      "Epoch 44/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.0941 - accuracy: 0.9648\n",
      "Epoch 45/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.0917 - accuracy: 0.9651\n",
      "Epoch 46/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.0899 - accuracy: 0.9669\n",
      "Epoch 47/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.0916 - accuracy: 0.9660\n",
      "Epoch 48/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.0922 - accuracy: 0.9656\n",
      "Epoch 49/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.0878 - accuracy: 0.9663\n",
      "Epoch 50/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.0949 - accuracy: 0.9654\n",
      "Epoch 51/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.0892 - accuracy: 0.9663\n",
      "Epoch 52/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.0820 - accuracy: 0.9698\n",
      "Epoch 53/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.0797 - accuracy: 0.9700\n",
      "Epoch 54/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.0863 - accuracy: 0.9677\n",
      "Epoch 55/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.0827 - accuracy: 0.9690\n",
      "Epoch 56/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.0789 - accuracy: 0.9702\n",
      "Epoch 57/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.0825 - accuracy: 0.9688\n",
      "Epoch 58/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.0793 - accuracy: 0.9699\n",
      "Epoch 59/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.0758 - accuracy: 0.9713\n",
      "Epoch 60/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.0790 - accuracy: 0.9720\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 0.2210 - accuracy: 0.9460\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_21 (Conv1D)           (None, 86, 768)           12288     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 43, 768)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_22 (Conv1D)           (None, 41, 256)           590080    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_7 (Average (None, 20, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_23 (Conv1D)           (None, 18, 768)           590592    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_7 ( (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 256)               196864    \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 6)                 1542      \n",
      "=================================================================\n",
      "Total params: 1,457,158\n",
      "Trainable params: 1,457,158\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/60\n",
      "  2/183 [..............................] - ETA: 8s - loss: 1.7823 - accuracy: 0.1953WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0219s vs `on_train_batch_end` time: 0.0339s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183/183 [==============================] - 10s 53ms/step - loss: 1.1201 - accuracy: 0.5308\n",
      "Epoch 2/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.7764 - accuracy: 0.6799\n",
      "Epoch 3/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.5653 - accuracy: 0.7832\n",
      "Epoch 4/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.4812 - accuracy: 0.8218\n",
      "Epoch 5/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.3826 - accuracy: 0.8557\n",
      "Epoch 6/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.3371 - accuracy: 0.8725\n",
      "Epoch 7/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.3360 - accuracy: 0.8782\n",
      "Epoch 8/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.2996 - accuracy: 0.8887\n",
      "Epoch 9/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.2744 - accuracy: 0.8979\n",
      "Epoch 10/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.2622 - accuracy: 0.9034\n",
      "Epoch 11/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.2430 - accuracy: 0.9091\n",
      "Epoch 12/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.2310 - accuracy: 0.9150\n",
      "Epoch 13/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.2546 - accuracy: 0.9100\n",
      "Epoch 14/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.2144 - accuracy: 0.9218\n",
      "Epoch 15/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.2054 - accuracy: 0.9262\n",
      "Epoch 16/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1937 - accuracy: 0.9282\n",
      "Epoch 17/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.2051 - accuracy: 0.9268\n",
      "Epoch 18/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1808 - accuracy: 0.9341\n",
      "Epoch 19/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1743 - accuracy: 0.9367\n",
      "Epoch 20/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1669 - accuracy: 0.9390\n",
      "Epoch 21/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1546 - accuracy: 0.9416\n",
      "Epoch 22/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1566 - accuracy: 0.9421\n",
      "Epoch 23/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1526 - accuracy: 0.9440\n",
      "Epoch 24/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1448 - accuracy: 0.9472\n",
      "Epoch 25/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1446 - accuracy: 0.9463\n",
      "Epoch 26/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1371 - accuracy: 0.9498\n",
      "Epoch 27/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1367 - accuracy: 0.9493\n",
      "Epoch 28/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1324 - accuracy: 0.9501\n",
      "Epoch 29/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1283 - accuracy: 0.9527\n",
      "Epoch 30/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1251 - accuracy: 0.9541\n",
      "Epoch 31/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1224 - accuracy: 0.9529\n",
      "Epoch 32/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1197 - accuracy: 0.9557\n",
      "Epoch 33/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1174 - accuracy: 0.9558\n",
      "Epoch 34/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1154 - accuracy: 0.9570\n",
      "Epoch 35/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1138 - accuracy: 0.9567\n",
      "Epoch 36/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1133 - accuracy: 0.9573\n",
      "Epoch 37/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1061 - accuracy: 0.9605\n",
      "Epoch 38/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1030 - accuracy: 0.9609\n",
      "Epoch 39/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1033 - accuracy: 0.9610\n",
      "Epoch 40/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1066 - accuracy: 0.9604\n",
      "Epoch 41/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1014 - accuracy: 0.9617\n",
      "Epoch 42/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.0978 - accuracy: 0.9624\n",
      "Epoch 43/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.0952 - accuracy: 0.9642\n",
      "Epoch 44/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.0949 - accuracy: 0.9648\n",
      "Epoch 45/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.0923 - accuracy: 0.9655\n",
      "Epoch 46/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.0930 - accuracy: 0.9638\n",
      "Epoch 47/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.0964 - accuracy: 0.9641\n",
      "Epoch 48/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.0879 - accuracy: 0.9669\n",
      "Epoch 49/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.0859 - accuracy: 0.9682\n",
      "Epoch 50/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.0889 - accuracy: 0.9662\n",
      "Epoch 51/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.0807 - accuracy: 0.9689\n",
      "Epoch 52/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.0864 - accuracy: 0.9677\n",
      "Epoch 53/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.0831 - accuracy: 0.9681\n",
      "Epoch 54/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.0816 - accuracy: 0.9688\n",
      "Epoch 55/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.0808 - accuracy: 0.9691\n",
      "Epoch 56/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.0790 - accuracy: 0.9709\n",
      "Epoch 57/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.0803 - accuracy: 0.9688\n",
      "Epoch 58/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.0791 - accuracy: 0.9710\n",
      "Epoch 59/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.0748 - accuracy: 0.9711\n",
      "Epoch 60/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.0809 - accuracy: 0.9701\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 0.2208 - accuracy: 0.9456\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_24 (Conv1D)           (None, 86, 768)           12288     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 43, 768)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_25 (Conv1D)           (None, 41, 256)           590080    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_8 (Average (None, 20, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_26 (Conv1D)           (None, 18, 768)           590592    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_8 ( (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 256)               196864    \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 6)                 1542      \n",
      "=================================================================\n",
      "Total params: 1,457,158\n",
      "Trainable params: 1,457,158\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 1.1314 - accuracy: 0.5227\n",
      "Epoch 2/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183/183 [==============================] - 10s 53ms/step - loss: 0.8227 - accuracy: 0.6602\n",
      "Epoch 3/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.6115 - accuracy: 0.7575\n",
      "Epoch 4/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.4613 - accuracy: 0.8211\n",
      "Epoch 5/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.3700 - accuracy: 0.8599\n",
      "Epoch 6/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.4063 - accuracy: 0.8528\n",
      "Epoch 7/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.3054 - accuracy: 0.8855\n",
      "Epoch 8/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.2822 - accuracy: 0.8919\n",
      "Epoch 9/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.2760 - accuracy: 0.8955\n",
      "Epoch 10/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.2631 - accuracy: 0.9004\n",
      "Epoch 11/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.2433 - accuracy: 0.9090\n",
      "Epoch 12/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.2270 - accuracy: 0.9183\n",
      "Epoch 13/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.2212 - accuracy: 0.9188\n",
      "Epoch 14/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.2306 - accuracy: 0.9166\n",
      "Epoch 15/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.2019 - accuracy: 0.9273\n",
      "Epoch 16/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1968 - accuracy: 0.9283\n",
      "Epoch 17/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.3576 - accuracy: 0.8834\n",
      "Epoch 18/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1962 - accuracy: 0.9298\n",
      "Epoch 19/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1822 - accuracy: 0.9336\n",
      "Epoch 20/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1696 - accuracy: 0.9375\n",
      "Epoch 21/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1661 - accuracy: 0.9399\n",
      "Epoch 22/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1578 - accuracy: 0.9416\n",
      "Epoch 23/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1602 - accuracy: 0.9408\n",
      "Epoch 24/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1477 - accuracy: 0.9448\n",
      "Epoch 25/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1433 - accuracy: 0.9466\n",
      "Epoch 26/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1406 - accuracy: 0.9484\n",
      "Epoch 27/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1364 - accuracy: 0.9483\n",
      "Epoch 28/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1335 - accuracy: 0.9502\n",
      "Epoch 29/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1336 - accuracy: 0.9502\n",
      "Epoch 30/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1300 - accuracy: 0.9520\n",
      "Epoch 31/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1261 - accuracy: 0.9520\n",
      "Epoch 32/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1237 - accuracy: 0.9532\n",
      "Epoch 33/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1214 - accuracy: 0.9549\n",
      "Epoch 34/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1187 - accuracy: 0.9552\n",
      "Epoch 35/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1125 - accuracy: 0.9571\n",
      "Epoch 36/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1094 - accuracy: 0.9584\n",
      "Epoch 37/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1178 - accuracy: 0.9567\n",
      "Epoch 38/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1061 - accuracy: 0.9589\n",
      "Epoch 39/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1063 - accuracy: 0.9598\n",
      "Epoch 40/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.0988 - accuracy: 0.9621\n",
      "Epoch 41/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.0992 - accuracy: 0.9623\n",
      "Epoch 42/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.0980 - accuracy: 0.9623\n",
      "Epoch 43/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.0993 - accuracy: 0.9624\n",
      "Epoch 44/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.0948 - accuracy: 0.9641\n",
      "Epoch 45/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.0937 - accuracy: 0.9645\n",
      "Epoch 46/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.0931 - accuracy: 0.9652\n",
      "Epoch 47/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.0936 - accuracy: 0.9644\n",
      "Epoch 48/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.0907 - accuracy: 0.9656\n",
      "Epoch 49/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.0903 - accuracy: 0.9666\n",
      "Epoch 50/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.0885 - accuracy: 0.9669\n",
      "Epoch 51/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.0833 - accuracy: 0.9680\n",
      "Epoch 52/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.0863 - accuracy: 0.9682\n",
      "Epoch 53/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.0820 - accuracy: 0.9690\n",
      "Epoch 54/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.0844 - accuracy: 0.9685\n",
      "Epoch 55/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.0855 - accuracy: 0.9673\n",
      "Epoch 56/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.0922 - accuracy: 0.9661\n",
      "Epoch 57/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.0812 - accuracy: 0.9697\n",
      "Epoch 58/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.0935 - accuracy: 0.9647\n",
      "Epoch 59/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.0789 - accuracy: 0.9701\n",
      "Epoch 60/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.0801 - accuracy: 0.9709\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 0.2112 - accuracy: 0.9484\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_27 (Conv1D)           (None, 86, 768)           12288     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1 (None, 43, 768)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_28 (Conv1D)           (None, 41, 256)           590080    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_9 (Average (None, 20, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_29 (Conv1D)           (None, 18, 768)           590592    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_9 ( (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 256)               196864    \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 6)                 1542      \n",
      "=================================================================\n",
      "Total params: 1,457,158\n",
      "Trainable params: 1,457,158\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/60\n",
      "183/183 [==============================] - 10s 56ms/step - loss: 1.1384 - accuracy: 0.5180\n",
      "Epoch 2/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.8188 - accuracy: 0.6589\n",
      "Epoch 3/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183/183 [==============================] - 10s 53ms/step - loss: 0.6049 - accuracy: 0.7593\n",
      "Epoch 4/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.4351 - accuracy: 0.8374\n",
      "Epoch 5/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.3644 - accuracy: 0.8633\n",
      "Epoch 6/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.3273 - accuracy: 0.8779\n",
      "Epoch 7/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.3746 - accuracy: 0.8688\n",
      "Epoch 8/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.2975 - accuracy: 0.8895\n",
      "Epoch 9/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.2712 - accuracy: 0.8990\n",
      "Epoch 10/60\n",
      "183/183 [==============================] - 10s 54ms/step - loss: 0.2615 - accuracy: 0.9042\n",
      "Epoch 11/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.2378 - accuracy: 0.9122\n",
      "Epoch 12/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.2295 - accuracy: 0.9159\n",
      "Epoch 13/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.2136 - accuracy: 0.9202\n",
      "Epoch 14/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.2242 - accuracy: 0.9199\n",
      "Epoch 15/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.2009 - accuracy: 0.9260\n",
      "Epoch 16/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1917 - accuracy: 0.9287\n",
      "Epoch 17/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.2071 - accuracy: 0.9267\n",
      "Epoch 18/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1871 - accuracy: 0.9326\n",
      "Epoch 19/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1803 - accuracy: 0.9341\n",
      "Epoch 20/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1667 - accuracy: 0.9373\n",
      "Epoch 21/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1616 - accuracy: 0.9393\n",
      "Epoch 22/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1692 - accuracy: 0.9389\n",
      "Epoch 23/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1533 - accuracy: 0.9424\n",
      "Epoch 24/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1499 - accuracy: 0.9441\n",
      "Epoch 25/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1401 - accuracy: 0.9471\n",
      "Epoch 26/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1408 - accuracy: 0.9472\n",
      "Epoch 27/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1368 - accuracy: 0.9485\n",
      "Epoch 28/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1310 - accuracy: 0.9520\n",
      "Epoch 29/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1297 - accuracy: 0.9513\n",
      "Epoch 30/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1423 - accuracy: 0.9461\n",
      "Epoch 31/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1418 - accuracy: 0.9475\n",
      "Epoch 32/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1294 - accuracy: 0.9514\n",
      "Epoch 33/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1173 - accuracy: 0.9561\n",
      "Epoch 34/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1137 - accuracy: 0.9572\n",
      "Epoch 35/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1173 - accuracy: 0.9570\n",
      "Epoch 36/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1110 - accuracy: 0.9575\n",
      "Epoch 37/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1051 - accuracy: 0.9595\n",
      "Epoch 38/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1091 - accuracy: 0.9579\n",
      "Epoch 39/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1028 - accuracy: 0.9606\n",
      "Epoch 40/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1046 - accuracy: 0.9610\n",
      "Epoch 41/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.0980 - accuracy: 0.9626\n",
      "Epoch 42/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.0978 - accuracy: 0.9629\n",
      "Epoch 43/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1225 - accuracy: 0.9578\n",
      "Epoch 44/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1051 - accuracy: 0.9608\n",
      "Epoch 45/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.0943 - accuracy: 0.9644\n",
      "Epoch 46/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.0894 - accuracy: 0.9662\n",
      "Epoch 47/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.0901 - accuracy: 0.9661\n",
      "Epoch 48/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.0938 - accuracy: 0.9650\n",
      "Epoch 49/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.0930 - accuracy: 0.9655\n",
      "Epoch 50/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.0845 - accuracy: 0.9676\n",
      "Epoch 51/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.0832 - accuracy: 0.9684\n",
      "Epoch 52/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.0868 - accuracy: 0.9679\n",
      "Epoch 53/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.0802 - accuracy: 0.9692\n",
      "Epoch 54/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.0816 - accuracy: 0.9698\n",
      "Epoch 55/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.0753 - accuracy: 0.9711\n",
      "Epoch 56/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.0807 - accuracy: 0.9705\n",
      "Epoch 57/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.0776 - accuracy: 0.9717\n",
      "Epoch 58/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.0806 - accuracy: 0.9706\n",
      "Epoch 59/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.0786 - accuracy: 0.9711\n",
      "Epoch 60/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.0811 - accuracy: 0.9708\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 0.2330 - accuracy: 0.9426\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_30 (Conv1D)           (None, 86, 768)           12288     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling (None, 43, 768)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_31 (Conv1D)           (None, 41, 256)           590080    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_10 (Averag (None, 20, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_32 (Conv1D)           (None, 18, 768)           590592    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_10  (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 256)               196864    \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 6)                 1542      \n",
      "=================================================================\n",
      "Total params: 1,457,158\n",
      "Trainable params: 1,457,158\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/60\n",
      "  2/183 [..............................] - ETA: 7s - loss: 1.7829 - accuracy: 0.1758WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0210s vs `on_train_batch_end` time: 0.0319s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183/183 [==============================] - 10s 54ms/step - loss: 1.1270 - accuracy: 0.5238\n",
      "Epoch 2/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.8057 - accuracy: 0.6639\n",
      "Epoch 3/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.5984 - accuracy: 0.7625\n",
      "Epoch 4/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.4838 - accuracy: 0.8180\n",
      "Epoch 5/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.3839 - accuracy: 0.8534\n",
      "Epoch 6/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.3352 - accuracy: 0.8726\n",
      "Epoch 7/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.3025 - accuracy: 0.8843\n",
      "Epoch 8/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.3220 - accuracy: 0.8806\n",
      "Epoch 9/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.2738 - accuracy: 0.8987\n",
      "Epoch 10/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.2590 - accuracy: 0.9047\n",
      "Epoch 11/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.2450 - accuracy: 0.9095\n",
      "Epoch 12/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.2272 - accuracy: 0.9153\n",
      "Epoch 13/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.2259 - accuracy: 0.9188\n",
      "Epoch 14/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.2215 - accuracy: 0.9182\n",
      "Epoch 15/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.2036 - accuracy: 0.9256\n",
      "Epoch 16/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1913 - accuracy: 0.9295\n",
      "Epoch 17/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1797 - accuracy: 0.9339\n",
      "Epoch 18/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1834 - accuracy: 0.9337\n",
      "Epoch 19/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1765 - accuracy: 0.9352\n",
      "Epoch 20/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.2159 - accuracy: 0.9285\n",
      "Epoch 21/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1624 - accuracy: 0.9399\n",
      "Epoch 22/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1601 - accuracy: 0.9411\n",
      "Epoch 23/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1566 - accuracy: 0.9425\n",
      "Epoch 24/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1600 - accuracy: 0.9414\n",
      "Epoch 25/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1447 - accuracy: 0.9452\n",
      "Epoch 26/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1401 - accuracy: 0.9472\n",
      "Epoch 27/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1450 - accuracy: 0.9471\n",
      "Epoch 28/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1351 - accuracy: 0.9498\n",
      "Epoch 29/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1335 - accuracy: 0.9510\n",
      "Epoch 30/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1304 - accuracy: 0.9515\n",
      "Epoch 31/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1239 - accuracy: 0.9539\n",
      "Epoch 32/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1189 - accuracy: 0.9554\n",
      "Epoch 33/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1231 - accuracy: 0.9547\n",
      "Epoch 34/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1176 - accuracy: 0.9563\n",
      "Epoch 35/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1224 - accuracy: 0.9554\n",
      "Epoch 36/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1086 - accuracy: 0.9597\n",
      "Epoch 37/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1093 - accuracy: 0.9598\n",
      "Epoch 38/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1048 - accuracy: 0.9607\n",
      "Epoch 39/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1027 - accuracy: 0.9616\n",
      "Epoch 40/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1053 - accuracy: 0.9608\n",
      "Epoch 41/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1050 - accuracy: 0.9598\n",
      "Epoch 42/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1046 - accuracy: 0.9615\n",
      "Epoch 43/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.0974 - accuracy: 0.9634\n",
      "Epoch 44/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.1121 - accuracy: 0.9586\n",
      "Epoch 45/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.0982 - accuracy: 0.9636\n",
      "Epoch 46/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.0982 - accuracy: 0.9641\n",
      "Epoch 47/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.0902 - accuracy: 0.9660\n",
      "Epoch 48/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.0895 - accuracy: 0.9671\n",
      "Epoch 49/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.0919 - accuracy: 0.9667\n",
      "Epoch 50/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.0943 - accuracy: 0.9659\n",
      "Epoch 51/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.0926 - accuracy: 0.9646\n",
      "Epoch 52/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.0867 - accuracy: 0.9683\n",
      "Epoch 53/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.0840 - accuracy: 0.9686\n",
      "Epoch 54/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.0856 - accuracy: 0.9678\n",
      "Epoch 55/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.0791 - accuracy: 0.9700\n",
      "Epoch 56/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.0808 - accuracy: 0.9703\n",
      "Epoch 57/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.0829 - accuracy: 0.9689\n",
      "Epoch 58/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.0815 - accuracy: 0.9694\n",
      "Epoch 59/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.0752 - accuracy: 0.9716\n",
      "Epoch 60/60\n",
      "183/183 [==============================] - 10s 53ms/step - loss: 0.0732 - accuracy: 0.9724\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 0.2072 - accuracy: 0.9544\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_33 (Conv1D)           (None, 88, 256)           2560      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling (None, 44, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_34 (Conv1D)           (None, 40, 256)           327936    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_11 (Averag (None, 20, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_35 (Conv1D)           (None, 18, 768)           590592    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_11  (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 256)               196864    \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 6)                 3078      \n",
      "=================================================================\n",
      "Total params: 1,252,614\n",
      "Trainable params: 1,252,614\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 1.1601 - accuracy: 0.4989\n",
      "Epoch 2/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183/183 [==============================] - 6s 32ms/step - loss: 0.8879 - accuracy: 0.6335\n",
      "Epoch 3/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.7312 - accuracy: 0.7065\n",
      "Epoch 4/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.6252 - accuracy: 0.7458\n",
      "Epoch 5/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.5544 - accuracy: 0.7752\n",
      "Epoch 6/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.5202 - accuracy: 0.7906\n",
      "Epoch 7/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.5333 - accuracy: 0.7907\n",
      "Epoch 8/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.4694 - accuracy: 0.8133\n",
      "Epoch 9/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.4401 - accuracy: 0.8250\n",
      "Epoch 10/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.4439 - accuracy: 0.8277\n",
      "Epoch 11/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.4048 - accuracy: 0.8414\n",
      "Epoch 12/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.4017 - accuracy: 0.8433\n",
      "Epoch 13/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.4083 - accuracy: 0.8439\n",
      "Epoch 14/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.3802 - accuracy: 0.8531\n",
      "Epoch 15/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.3712 - accuracy: 0.8573\n",
      "Epoch 16/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.3584 - accuracy: 0.8599\n",
      "Epoch 17/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.3407 - accuracy: 0.8701\n",
      "Epoch 18/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.3298 - accuracy: 0.8722\n",
      "Epoch 19/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.3457 - accuracy: 0.8679\n",
      "Epoch 20/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.3407 - accuracy: 0.8705\n",
      "Epoch 21/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.3159 - accuracy: 0.8776\n",
      "Epoch 22/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.3692 - accuracy: 0.8644\n",
      "Epoch 23/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.3066 - accuracy: 0.8828\n",
      "Epoch 24/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.3038 - accuracy: 0.8833\n",
      "Epoch 25/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2945 - accuracy: 0.8858\n",
      "Epoch 26/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2976 - accuracy: 0.8849\n",
      "Epoch 27/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2944 - accuracy: 0.8874\n",
      "Epoch 28/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2953 - accuracy: 0.8878\n",
      "Epoch 29/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2842 - accuracy: 0.8918\n",
      "Epoch 30/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2852 - accuracy: 0.8920\n",
      "Epoch 31/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2759 - accuracy: 0.8940\n",
      "Epoch 32/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2756 - accuracy: 0.8949 0s - loss:\n",
      "Epoch 33/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2755 - accuracy: 0.8949\n",
      "Epoch 34/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2658 - accuracy: 0.8969\n",
      "Epoch 35/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2746 - accuracy: 0.8973\n",
      "Epoch 36/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2670 - accuracy: 0.8984\n",
      "Epoch 37/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2574 - accuracy: 0.9019\n",
      "Epoch 38/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2567 - accuracy: 0.9005\n",
      "Epoch 39/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2574 - accuracy: 0.9008\n",
      "Epoch 40/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2490 - accuracy: 0.9047 1s\n",
      "Epoch 41/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2461 - accuracy: 0.9057\n",
      "Epoch 42/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2435 - accuracy: 0.9069\n",
      "Epoch 43/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2488 - accuracy: 0.9052\n",
      "Epoch 44/60\n",
      "183/183 [==============================] - 6s 33ms/step - loss: 0.2394 - accuracy: 0.9079\n",
      "Epoch 45/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2744 - accuracy: 0.8981\n",
      "Epoch 46/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2332 - accuracy: 0.9100\n",
      "Epoch 47/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2316 - accuracy: 0.9115\n",
      "Epoch 48/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2286 - accuracy: 0.9118\n",
      "Epoch 49/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2330 - accuracy: 0.9106\n",
      "Epoch 50/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2249 - accuracy: 0.9129\n",
      "Epoch 51/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2265 - accuracy: 0.9135\n",
      "Epoch 52/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2230 - accuracy: 0.9145\n",
      "Epoch 53/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2237 - accuracy: 0.9135\n",
      "Epoch 54/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.4648 - accuracy: 0.8618\n",
      "Epoch 55/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2339 - accuracy: 0.9119\n",
      "Epoch 56/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2222 - accuracy: 0.9167\n",
      "Epoch 57/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2150 - accuracy: 0.9171\n",
      "Epoch 58/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2129 - accuracy: 0.9182\n",
      "Epoch 59/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2126 - accuracy: 0.9182\n",
      "Epoch 60/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2154 - accuracy: 0.9167\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.6950 - accuracy: 0.8228\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_36 (Conv1D)           (None, 88, 256)           2560      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling (None, 44, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_37 (Conv1D)           (None, 40, 256)           327936    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_12 (Averag (None, 20, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_38 (Conv1D)           (None, 18, 768)           590592    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_12  (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 256)               196864    \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 6)                 3078      \n",
      "=================================================================\n",
      "Total params: 1,252,614\n",
      "Trainable params: 1,252,614\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/60\n",
      "  1/183 [..............................] - ETA: 3s - loss: 1.7895 - accuracy: 0.1797WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0150s vs `on_train_batch_end` time: 0.0229s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183/183 [==============================] - 6s 32ms/step - loss: 1.1547 - accuracy: 0.5047\n",
      "Epoch 2/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.8916 - accuracy: 0.6302\n",
      "Epoch 3/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.7059 - accuracy: 0.7131\n",
      "Epoch 4/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.6127 - accuracy: 0.7494\n",
      "Epoch 5/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.5702 - accuracy: 0.7712\n",
      "Epoch 6/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.5102 - accuracy: 0.7933\n",
      "Epoch 7/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.4880 - accuracy: 0.8057\n",
      "Epoch 8/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.4806 - accuracy: 0.8119\n",
      "Epoch 9/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.4708 - accuracy: 0.8138\n",
      "Epoch 10/60\n",
      "183/183 [==============================] - 6s 33ms/step - loss: 0.4347 - accuracy: 0.8255\n",
      "Epoch 11/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.4262 - accuracy: 0.8335\n",
      "Epoch 12/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.3953 - accuracy: 0.8448\n",
      "Epoch 13/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.4077 - accuracy: 0.8410\n",
      "Epoch 14/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.3787 - accuracy: 0.8521\n",
      "Epoch 15/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.3805 - accuracy: 0.8543\n",
      "Epoch 16/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.3786 - accuracy: 0.8561\n",
      "Epoch 17/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.3437 - accuracy: 0.8657\n",
      "Epoch 18/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.3502 - accuracy: 0.8645\n",
      "Epoch 19/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.3457 - accuracy: 0.8679\n",
      "Epoch 20/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.3309 - accuracy: 0.8725\n",
      "Epoch 21/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.3342 - accuracy: 0.8711\n",
      "Epoch 22/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.3259 - accuracy: 0.8757\n",
      "Epoch 23/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.3176 - accuracy: 0.8797\n",
      "Epoch 24/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.3069 - accuracy: 0.8803\n",
      "Epoch 25/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.3444 - accuracy: 0.8727\n",
      "Epoch 26/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.3014 - accuracy: 0.8827\n",
      "Epoch 27/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2926 - accuracy: 0.8858\n",
      "Epoch 28/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2936 - accuracy: 0.8847\n",
      "Epoch 29/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2968 - accuracy: 0.8852\n",
      "Epoch 30/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2877 - accuracy: 0.8868\n",
      "Epoch 31/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2868 - accuracy: 0.8882\n",
      "Epoch 32/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2807 - accuracy: 0.8928\n",
      "Epoch 33/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.4530 - accuracy: 0.8518\n",
      "Epoch 34/60\n",
      "183/183 [==============================] - ETA: 0s - loss: 0.3016 - accuracy: 0.88 - 6s 32ms/step - loss: 0.3016 - accuracy: 0.8853\n",
      "Epoch 35/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2796 - accuracy: 0.8924\n",
      "Epoch 36/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2657 - accuracy: 0.8972\n",
      "Epoch 37/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2683 - accuracy: 0.8959 \n",
      "Epoch 38/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2642 - accuracy: 0.8975\n",
      "Epoch 39/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2586 - accuracy: 0.9000\n",
      "Epoch 40/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2505 - accuracy: 0.9017\n",
      "Epoch 41/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2619 - accuracy: 0.8994\n",
      "Epoch 42/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2471 - accuracy: 0.9053\n",
      "Epoch 43/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2471 - accuracy: 0.9046\n",
      "Epoch 44/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2437 - accuracy: 0.9046\n",
      "Epoch 45/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2423 - accuracy: 0.9066\n",
      "Epoch 46/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2375 - accuracy: 0.9079\n",
      "Epoch 47/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.3247 - accuracy: 0.8852\n",
      "Epoch 48/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2451 - accuracy: 0.9064\n",
      "Epoch 49/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2345 - accuracy: 0.9081\n",
      "Epoch 50/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2351 - accuracy: 0.9088\n",
      "Epoch 51/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2276 - accuracy: 0.9118\n",
      "Epoch 52/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2271 - accuracy: 0.9114\n",
      "Epoch 53/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2259 - accuracy: 0.9117\n",
      "Epoch 54/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2344 - accuracy: 0.9107\n",
      "Epoch 55/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2226 - accuracy: 0.9143\n",
      "Epoch 56/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2214 - accuracy: 0.9138\n",
      "Epoch 57/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2306 - accuracy: 0.9117\n",
      "Epoch 58/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2123 - accuracy: 0.9157\n",
      "Epoch 59/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2229 - accuracy: 0.9136\n",
      "Epoch 60/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2169 - accuracy: 0.9166\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.7075 - accuracy: 0.8063\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_39 (Conv1D)           (None, 88, 256)           2560      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling (None, 44, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_40 (Conv1D)           (None, 40, 256)           327936    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_13 (Averag (None, 20, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_41 (Conv1D)           (None, 18, 768)           590592    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_13  (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 256)               196864    \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 6)                 3078      \n",
      "=================================================================\n",
      "Total params: 1,252,614\n",
      "Trainable params: 1,252,614\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/60\n",
      "  1/183 [..............................] - ETA: 3s - loss: 1.7947 - accuracy: 0.1641WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0130s vs `on_train_batch_end` time: 0.0199s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183/183 [==============================] - 6s 32ms/step - loss: 1.1689 - accuracy: 0.5055\n",
      "Epoch 2/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.9108 - accuracy: 0.6212\n",
      "Epoch 3/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.7587 - accuracy: 0.6942\n",
      "Epoch 4/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.6455 - accuracy: 0.7419\n",
      "Epoch 5/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.5701 - accuracy: 0.7694\n",
      "Epoch 6/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.5284 - accuracy: 0.7872\n",
      "Epoch 7/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.6455 - accuracy: 0.7617\n",
      "Epoch 8/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.4846 - accuracy: 0.8078\n",
      "Epoch 9/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.4632 - accuracy: 0.8182\n",
      "Epoch 10/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.4229 - accuracy: 0.8309\n",
      "Epoch 11/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.4217 - accuracy: 0.8337\n",
      "Epoch 12/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.4057 - accuracy: 0.8415\n",
      "Epoch 13/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.4020 - accuracy: 0.8440\n",
      "Epoch 14/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.3801 - accuracy: 0.8519\n",
      "Epoch 15/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.3766 - accuracy: 0.8530\n",
      "Epoch 16/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.3611 - accuracy: 0.8593\n",
      "Epoch 17/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.3487 - accuracy: 0.8638\n",
      "Epoch 18/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.3403 - accuracy: 0.8661\n",
      "Epoch 19/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.3421 - accuracy: 0.8663\n",
      "Epoch 20/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.3343 - accuracy: 0.8723\n",
      "Epoch 21/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.3270 - accuracy: 0.8737\n",
      "Epoch 22/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.6114 - accuracy: 0.7986\n",
      "Epoch 23/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.3598 - accuracy: 0.8625\n",
      "Epoch 24/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.3251 - accuracy: 0.8749\n",
      "Epoch 25/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.3126 - accuracy: 0.8789\n",
      "Epoch 26/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.3085 - accuracy: 0.8808\n",
      "Epoch 27/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.3083 - accuracy: 0.8819\n",
      "Epoch 28/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2993 - accuracy: 0.8847\n",
      "Epoch 29/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2944 - accuracy: 0.8861\n",
      "Epoch 30/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2943 - accuracy: 0.8856\n",
      "Epoch 31/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2926 - accuracy: 0.8872\n",
      "Epoch 32/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.3096 - accuracy: 0.8847\n",
      "Epoch 33/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2816 - accuracy: 0.8923\n",
      "Epoch 34/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2767 - accuracy: 0.8934\n",
      "Epoch 35/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2709 - accuracy: 0.8941\n",
      "Epoch 36/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2703 - accuracy: 0.8955\n",
      "Epoch 37/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2740 - accuracy: 0.8944\n",
      "Epoch 38/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.3334 - accuracy: 0.8822\n",
      "Epoch 39/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2779 - accuracy: 0.8931\n",
      "Epoch 40/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2586 - accuracy: 0.8999\n",
      "Epoch 41/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2545 - accuracy: 0.9026\n",
      "Epoch 42/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2526 - accuracy: 0.9018\n",
      "Epoch 43/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2523 - accuracy: 0.9030\n",
      "Epoch 44/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2446 - accuracy: 0.9052\n",
      "Epoch 45/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2509 - accuracy: 0.9034\n",
      "Epoch 46/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2488 - accuracy: 0.9050\n",
      "Epoch 47/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2445 - accuracy: 0.9040\n",
      "Epoch 48/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2427 - accuracy: 0.9050\n",
      "Epoch 49/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2395 - accuracy: 0.9072\n",
      "Epoch 50/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2351 - accuracy: 0.9092\n",
      "Epoch 51/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2484 - accuracy: 0.9072\n",
      "Epoch 52/60\n",
      "183/183 [==============================] - 6s 33ms/step - loss: 0.2481 - accuracy: 0.9048\n",
      "Epoch 53/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2292 - accuracy: 0.9088\n",
      "Epoch 54/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2275 - accuracy: 0.9114\n",
      "Epoch 55/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2245 - accuracy: 0.9135\n",
      "Epoch 56/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2249 - accuracy: 0.9112\n",
      "Epoch 57/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2245 - accuracy: 0.9115\n",
      "Epoch 58/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2200 - accuracy: 0.9146\n",
      "Epoch 59/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2178 - accuracy: 0.9156\n",
      "Epoch 60/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.5804 - accuracy: 0.8432\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.3147 - accuracy: 0.8962\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_42 (Conv1D)           (None, 88, 256)           2560      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling (None, 44, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_43 (Conv1D)           (None, 40, 256)           327936    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_14 (Averag (None, 20, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_44 (Conv1D)           (None, 18, 768)           590592    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_14  (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 256)               196864    \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 6)                 3078      \n",
      "=================================================================\n",
      "Total params: 1,252,614\n",
      "Trainable params: 1,252,614\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 1.1607 - accuracy: 0.5058\n",
      "Epoch 2/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183/183 [==============================] - 6s 32ms/step - loss: 0.9043 - accuracy: 0.6329\n",
      "Epoch 3/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.7322 - accuracy: 0.7051\n",
      "Epoch 4/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.6079 - accuracy: 0.7529\n",
      "Epoch 5/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.6029 - accuracy: 0.7612\n",
      "Epoch 6/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.5105 - accuracy: 0.7951\n",
      "Epoch 7/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.5112 - accuracy: 0.7987\n",
      "Epoch 8/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.4679 - accuracy: 0.8144\n",
      "Epoch 9/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.4378 - accuracy: 0.8274\n",
      "Epoch 10/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.4366 - accuracy: 0.8289\n",
      "Epoch 11/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.4014 - accuracy: 0.8434\n",
      "Epoch 12/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.4170 - accuracy: 0.8421\n",
      "Epoch 13/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.3825 - accuracy: 0.8512\n",
      "Epoch 14/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.3594 - accuracy: 0.8608\n",
      "Epoch 15/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.4453 - accuracy: 0.8386\n",
      "Epoch 16/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.3506 - accuracy: 0.8657\n",
      "Epoch 17/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.3427 - accuracy: 0.8663\n",
      "Epoch 18/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.3345 - accuracy: 0.8700\n",
      "Epoch 19/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.3313 - accuracy: 0.8726\n",
      "Epoch 20/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.3359 - accuracy: 0.8704\n",
      "Epoch 21/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.3349 - accuracy: 0.8712\n",
      "Epoch 22/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.3149 - accuracy: 0.8788\n",
      "Epoch 23/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.3252 - accuracy: 0.8754\n",
      "Epoch 24/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.3064 - accuracy: 0.8816\n",
      "Epoch 25/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.3086 - accuracy: 0.8819\n",
      "Epoch 26/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.4202 - accuracy: 0.8634\n",
      "Epoch 27/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.3663 - accuracy: 0.8654\n",
      "Epoch 28/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.3043 - accuracy: 0.8846\n",
      "Epoch 29/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2896 - accuracy: 0.8895\n",
      "Epoch 30/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2863 - accuracy: 0.8898\n",
      "Epoch 31/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2781 - accuracy: 0.8929\n",
      "Epoch 32/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2824 - accuracy: 0.8900\n",
      "Epoch 33/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2788 - accuracy: 0.8943\n",
      "Epoch 34/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2677 - accuracy: 0.8963\n",
      "Epoch 35/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2690 - accuracy: 0.8970\n",
      "Epoch 36/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2679 - accuracy: 0.8965\n",
      "Epoch 37/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2611 - accuracy: 0.8973\n",
      "Epoch 38/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2572 - accuracy: 0.9004\n",
      "Epoch 39/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2836 - accuracy: 0.8935\n",
      "Epoch 40/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2612 - accuracy: 0.9002\n",
      "Epoch 41/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2513 - accuracy: 0.9039\n",
      "Epoch 42/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2485 - accuracy: 0.9043\n",
      "Epoch 43/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2438 - accuracy: 0.9058\n",
      "Epoch 44/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2421 - accuracy: 0.9060\n",
      "Epoch 45/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2430 - accuracy: 0.9050\n",
      "Epoch 46/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2425 - accuracy: 0.9068\n",
      "Epoch 47/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.3321 - accuracy: 0.8821\n",
      "Epoch 48/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2426 - accuracy: 0.9067\n",
      "Epoch 49/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2294 - accuracy: 0.9105\n",
      "Epoch 50/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2301 - accuracy: 0.9102\n",
      "Epoch 51/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2318 - accuracy: 0.9095\n",
      "Epoch 52/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2251 - accuracy: 0.9128\n",
      "Epoch 53/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2310 - accuracy: 0.9108\n",
      "Epoch 54/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2492 - accuracy: 0.9018\n",
      "Epoch 55/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2286 - accuracy: 0.9118\n",
      "Epoch 56/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2247 - accuracy: 0.9108\n",
      "Epoch 57/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2235 - accuracy: 0.9127\n",
      "Epoch 58/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2215 - accuracy: 0.9138\n",
      "Epoch 59/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2200 - accuracy: 0.9143\n",
      "Epoch 60/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2159 - accuracy: 0.9154\n",
      "46/46 [==============================] - 1s 15ms/step - loss: 0.3144 - accuracy: 0.8953\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_45 (Conv1D)           (None, 88, 256)           2560      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling (None, 44, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_46 (Conv1D)           (None, 40, 256)           327936    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_15 (Averag (None, 20, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_47 (Conv1D)           (None, 18, 768)           590592    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_15  (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 256)               196864    \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_31 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 6)                 3078      \n",
      "=================================================================\n",
      "Total params: 1,252,614\n",
      "Trainable params: 1,252,614\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 1.1608 - accuracy: 0.5082\n",
      "Epoch 2/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.8951 - accuracy: 0.6293\n",
      "Epoch 3/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183/183 [==============================] - 6s 32ms/step - loss: 0.7514 - accuracy: 0.6958\n",
      "Epoch 4/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.6426 - accuracy: 0.7409\n",
      "Epoch 5/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.5694 - accuracy: 0.7700\n",
      "Epoch 6/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.5584 - accuracy: 0.7793\n",
      "Epoch 7/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.4906 - accuracy: 0.8035 0s - l\n",
      "Epoch 8/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.4571 - accuracy: 0.8142\n",
      "Epoch 9/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.4694 - accuracy: 0.8165\n",
      "Epoch 10/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.4268 - accuracy: 0.8306\n",
      "Epoch 11/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.4049 - accuracy: 0.8403\n",
      "Epoch 12/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.4364 - accuracy: 0.8312\n",
      "Epoch 13/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.3918 - accuracy: 0.8472\n",
      "Epoch 14/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.3738 - accuracy: 0.8549\n",
      "Epoch 15/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.3779 - accuracy: 0.8531\n",
      "Epoch 16/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.3541 - accuracy: 0.8614\n",
      "Epoch 17/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.3552 - accuracy: 0.8614\n",
      "Epoch 18/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.3429 - accuracy: 0.8661\n",
      "Epoch 19/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.7888 - accuracy: 0.7525\n",
      "Epoch 20/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.3923 - accuracy: 0.8529\n",
      "Epoch 21/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.3483 - accuracy: 0.8676\n",
      "Epoch 22/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.3436 - accuracy: 0.8663\n",
      "Epoch 23/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.3186 - accuracy: 0.8771\n",
      "Epoch 24/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.3609 - accuracy: 0.8690\n",
      "Epoch 25/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.3185 - accuracy: 0.8770\n",
      "Epoch 26/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.3046 - accuracy: 0.8821\n",
      "Epoch 27/60\n",
      "183/183 [==============================] - 6s 33ms/step - loss: 0.3093 - accuracy: 0.8813\n",
      "Epoch 28/60\n",
      "183/183 [==============================] - 6s 33ms/step - loss: 0.3080 - accuracy: 0.8823\n",
      "Epoch 29/60\n",
      "183/183 [==============================] - 6s 33ms/step - loss: 0.2902 - accuracy: 0.8881\n",
      "Epoch 30/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2876 - accuracy: 0.8886\n",
      "Epoch 31/60\n",
      "183/183 [==============================] - 6s 33ms/step - loss: 0.3232 - accuracy: 0.8788\n",
      "Epoch 32/60\n",
      "183/183 [==============================] - 6s 33ms/step - loss: 0.2825 - accuracy: 0.8915\n",
      "Epoch 33/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2804 - accuracy: 0.8919\n",
      "Epoch 34/60\n",
      "183/183 [==============================] - 6s 33ms/step - loss: 0.2741 - accuracy: 0.8943\n",
      "Epoch 35/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2719 - accuracy: 0.8952\n",
      "Epoch 36/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2678 - accuracy: 0.8964\n",
      "Epoch 37/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2722 - accuracy: 0.8969\n",
      "Epoch 38/60\n",
      "183/183 [==============================] - 6s 33ms/step - loss: 0.2653 - accuracy: 0.8982\n",
      "Epoch 39/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2581 - accuracy: 0.9007\n",
      "Epoch 40/60\n",
      "183/183 [==============================] - 6s 33ms/step - loss: 0.2603 - accuracy: 0.8985\n",
      "Epoch 41/60\n",
      "183/183 [==============================] - 6s 33ms/step - loss: 0.4217 - accuracy: 0.8665\n",
      "Epoch 42/60\n",
      "183/183 [==============================] - 6s 33ms/step - loss: 0.2786 - accuracy: 0.8946\n",
      "Epoch 43/60\n",
      "183/183 [==============================] - 6s 33ms/step - loss: 0.2614 - accuracy: 0.8996\n",
      "Epoch 44/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2480 - accuracy: 0.9046\n",
      "Epoch 45/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2484 - accuracy: 0.9037\n",
      "Epoch 46/60\n",
      "183/183 [==============================] - 6s 33ms/step - loss: 0.2616 - accuracy: 0.8990\n",
      "Epoch 47/60\n",
      "183/183 [==============================] - 6s 33ms/step - loss: 0.2412 - accuracy: 0.9063\n",
      "Epoch 48/60\n",
      "183/183 [==============================] - 6s 33ms/step - loss: 0.2422 - accuracy: 0.9073\n",
      "Epoch 49/60\n",
      "183/183 [==============================] - 6s 33ms/step - loss: 0.2375 - accuracy: 0.9092\n",
      "Epoch 50/60\n",
      "183/183 [==============================] - 6s 33ms/step - loss: 0.2379 - accuracy: 0.9094\n",
      "Epoch 51/60\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 0.2428 - accuracy: 0.9085\n",
      "Epoch 52/60\n",
      "183/183 [==============================] - 6s 33ms/step - loss: 0.2331 - accuracy: 0.9096\n",
      "Epoch 53/60\n",
      "183/183 [==============================] - 6s 33ms/step - loss: 0.2336 - accuracy: 0.9105\n",
      "Epoch 54/60\n",
      "183/183 [==============================] - 6s 33ms/step - loss: 0.2296 - accuracy: 0.9108\n",
      "Epoch 55/60\n",
      "183/183 [==============================] - 6s 33ms/step - loss: 0.2244 - accuracy: 0.9132\n",
      "Epoch 56/60\n",
      "183/183 [==============================] - 6s 33ms/step - loss: 0.2719 - accuracy: 0.8999\n",
      "Epoch 57/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.2379 - accuracy: 0.9083\n",
      "Epoch 58/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.2225 - accuracy: 0.9147\n",
      "Epoch 59/60\n",
      "183/183 [==============================] - 6s 33ms/step - loss: 0.2185 - accuracy: 0.9151\n",
      "Epoch 60/60\n",
      "183/183 [==============================] - 6s 33ms/step - loss: 0.2203 - accuracy: 0.9149\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 0.4235 - accuracy: 0.8688\n",
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_48 (Conv1D)           (None, 88, 256)           2560      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_16 (MaxPooling (None, 22, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_49 (Conv1D)           (None, 20, 768)           590592    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_16 (Averag (None, 5, 768)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_50 (Conv1D)           (None, 1, 768)            2949888   \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_16  (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 256)               196864    \n",
      "_________________________________________________________________\n",
      "dropout_32 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_33 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 6)                 1542      \n",
      "=================================================================\n",
      "Total params: 3,807,238\n",
      "Trainable params: 3,807,238\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/60\n",
      "  1/183 [..............................] - ETA: 1s - loss: 1.7933 - accuracy: 0.1562WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0120s vs `on_train_batch_end` time: 0.0269s). Check your callbacks.\n",
      "183/183 [==============================] - 7s 36ms/step - loss: 1.1221 - accuracy: 0.5240\n",
      "Epoch 2/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183/183 [==============================] - 7s 36ms/step - loss: 0.7508 - accuracy: 0.6946\n",
      "Epoch 3/60\n",
      "183/183 [==============================] - 6s 35ms/step - loss: 0.5053 - accuracy: 0.8098\n",
      "Epoch 4/60\n",
      "183/183 [==============================] - 7s 36ms/step - loss: 0.4102 - accuracy: 0.8531\n",
      "Epoch 5/60\n",
      "183/183 [==============================] - 6s 35ms/step - loss: 0.3357 - accuracy: 0.8763\n",
      "Epoch 6/60\n",
      "183/183 [==============================] - 7s 36ms/step - loss: 0.3565 - accuracy: 0.8728\n",
      "Epoch 7/60\n",
      "183/183 [==============================] - 7s 36ms/step - loss: 0.2971 - accuracy: 0.8843\n",
      "Epoch 8/60\n",
      "183/183 [==============================] - 7s 36ms/step - loss: 0.2578 - accuracy: 0.9028\n",
      "Epoch 9/60\n",
      "183/183 [==============================] - 7s 36ms/step - loss: 0.2479 - accuracy: 0.9081\n",
      "Epoch 10/60\n",
      "183/183 [==============================] - 7s 36ms/step - loss: 0.2162 - accuracy: 0.9185\n",
      "Epoch 11/60\n",
      "183/183 [==============================] - 7s 36ms/step - loss: 0.2067 - accuracy: 0.9236\n",
      "Epoch 12/60\n",
      "183/183 [==============================] - 6s 35ms/step - loss: 0.1936 - accuracy: 0.9296\n",
      "Epoch 13/60\n",
      "183/183 [==============================] - 7s 36ms/step - loss: 0.1797 - accuracy: 0.9330\n",
      "Epoch 14/60\n",
      "183/183 [==============================] - 6s 35ms/step - loss: 0.1663 - accuracy: 0.9389\n",
      "Epoch 15/60\n",
      "183/183 [==============================] - 6s 35ms/step - loss: 0.1555 - accuracy: 0.9425\n",
      "Epoch 16/60\n",
      "183/183 [==============================] - 7s 36ms/step - loss: 0.1956 - accuracy: 0.9334\n",
      "Epoch 17/60\n",
      "183/183 [==============================] - 6s 35ms/step - loss: 0.1616 - accuracy: 0.9432\n",
      "Epoch 18/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.1334 - accuracy: 0.9504\n",
      "Epoch 19/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.1280 - accuracy: 0.9532\n",
      "Epoch 20/60\n",
      "183/183 [==============================] - 6s 35ms/step - loss: 0.1264 - accuracy: 0.9538\n",
      "Epoch 21/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.1169 - accuracy: 0.9568\n",
      "Epoch 22/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.1157 - accuracy: 0.9581\n",
      "Epoch 23/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.1103 - accuracy: 0.9596\n",
      "Epoch 24/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.1060 - accuracy: 0.9608\n",
      "Epoch 25/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.1043 - accuracy: 0.9624\n",
      "Epoch 26/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.1081 - accuracy: 0.9594\n",
      "Epoch 27/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.1052 - accuracy: 0.9621\n",
      "Epoch 28/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0929 - accuracy: 0.9674\n",
      "Epoch 29/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0918 - accuracy: 0.9670 0s - loss: 0.0922 - accu\n",
      "Epoch 30/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0902 - accuracy: 0.9681\n",
      "Epoch 31/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0998 - accuracy: 0.9660\n",
      "Epoch 32/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0872 - accuracy: 0.9680\n",
      "Epoch 33/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0825 - accuracy: 0.9699\n",
      "Epoch 34/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0761 - accuracy: 0.9725\n",
      "Epoch 35/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.1030 - accuracy: 0.9629\n",
      "Epoch 36/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0866 - accuracy: 0.9688\n",
      "Epoch 37/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0773 - accuracy: 0.9720\n",
      "Epoch 38/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0805 - accuracy: 0.9707\n",
      "Epoch 39/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0753 - accuracy: 0.9723\n",
      "Epoch 40/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0748 - accuracy: 0.9731\n",
      "Epoch 41/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0841 - accuracy: 0.9708\n",
      "Epoch 42/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0720 - accuracy: 0.9739\n",
      "Epoch 43/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0669 - accuracy: 0.9749\n",
      "Epoch 44/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0690 - accuracy: 0.9736\n",
      "Epoch 45/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0700 - accuracy: 0.9742\n",
      "Epoch 46/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0691 - accuracy: 0.9750\n",
      "Epoch 47/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0734 - accuracy: 0.9732\n",
      "Epoch 48/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0629 - accuracy: 0.9767\n",
      "Epoch 49/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0625 - accuracy: 0.9773\n",
      "Epoch 50/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0726 - accuracy: 0.9738\n",
      "Epoch 51/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0677 - accuracy: 0.9759\n",
      "Epoch 52/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0598 - accuracy: 0.9784\n",
      "Epoch 53/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0649 - accuracy: 0.9762\n",
      "Epoch 54/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0638 - accuracy: 0.9764\n",
      "Epoch 55/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0598 - accuracy: 0.9780\n",
      "Epoch 56/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0568 - accuracy: 0.9786\n",
      "Epoch 57/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0627 - accuracy: 0.9773\n",
      "Epoch 58/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0564 - accuracy: 0.9795\n",
      "Epoch 59/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0618 - accuracy: 0.9776\n",
      "Epoch 60/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0566 - accuracy: 0.9788\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.3352 - accuracy: 0.9384\n",
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_51 (Conv1D)           (None, 88, 256)           2560      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_17 (MaxPooling (None, 22, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_52 (Conv1D)           (None, 20, 768)           590592    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_17 (Averag (None, 5, 768)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_53 (Conv1D)           (None, 1, 768)            2949888   \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_17  (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 256)               196864    \n",
      "_________________________________________________________________\n",
      "dropout_34 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_35 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 6)                 1542      \n",
      "=================================================================\n",
      "Total params: 3,807,238\n",
      "Trainable params: 3,807,238\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/60\n",
      "  1/183 [..............................] - ETA: 5s - loss: 1.7912 - accuracy: 0.1680WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0142s vs `on_train_batch_end` time: 0.0259s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183/183 [==============================] - 6s 35ms/step - loss: 1.1022 - accuracy: 0.5281\n",
      "Epoch 2/60\n",
      "183/183 [==============================] - 6s 35ms/step - loss: 0.7383 - accuracy: 0.7024\n",
      "Epoch 3/60\n",
      "183/183 [==============================] - 6s 35ms/step - loss: 0.5165 - accuracy: 0.8034\n",
      "Epoch 4/60\n",
      "183/183 [==============================] - 6s 35ms/step - loss: 0.4028 - accuracy: 0.8517\n",
      "Epoch 5/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.3437 - accuracy: 0.8737\n",
      "Epoch 6/60\n",
      "183/183 [==============================] - 6s 35ms/step - loss: 0.2888 - accuracy: 0.8914\n",
      "Epoch 7/60\n",
      "183/183 [==============================] - 6s 35ms/step - loss: 0.2654 - accuracy: 0.8997\n",
      "Epoch 8/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.2477 - accuracy: 0.9070\n",
      "Epoch 9/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.2233 - accuracy: 0.9160\n",
      "Epoch 10/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.2426 - accuracy: 0.9137\n",
      "Epoch 11/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.2380 - accuracy: 0.9165\n",
      "Epoch 12/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.1894 - accuracy: 0.9320\n",
      "Epoch 13/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.1806 - accuracy: 0.9350\n",
      "Epoch 14/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.1655 - accuracy: 0.9403\n",
      "Epoch 15/60\n",
      "183/183 [==============================] - 6s 35ms/step - loss: 0.1490 - accuracy: 0.9451\n",
      "Epoch 16/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.1503 - accuracy: 0.9462\n",
      "Epoch 17/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.1820 - accuracy: 0.9386\n",
      "Epoch 18/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.1378 - accuracy: 0.9511\n",
      "Epoch 19/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.1311 - accuracy: 0.9526\n",
      "Epoch 20/60\n",
      "183/183 [==============================] - 6s 35ms/step - loss: 0.1193 - accuracy: 0.9568\n",
      "Epoch 21/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.1166 - accuracy: 0.9568\n",
      "Epoch 22/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.1282 - accuracy: 0.9563\n",
      "Epoch 23/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.1082 - accuracy: 0.9610\n",
      "Epoch 24/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.1038 - accuracy: 0.9619\n",
      "Epoch 25/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.1043 - accuracy: 0.9613\n",
      "Epoch 26/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0982 - accuracy: 0.9646\n",
      "Epoch 27/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0990 - accuracy: 0.9644\n",
      "Epoch 28/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0910 - accuracy: 0.9671\n",
      "Epoch 29/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.1029 - accuracy: 0.9636\n",
      "Epoch 30/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0928 - accuracy: 0.9663\n",
      "Epoch 31/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0856 - accuracy: 0.9694\n",
      "Epoch 32/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0918 - accuracy: 0.9660\n",
      "Epoch 33/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0894 - accuracy: 0.9669\n",
      "Epoch 34/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0892 - accuracy: 0.9673\n",
      "Epoch 35/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0782 - accuracy: 0.9721\n",
      "Epoch 36/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0804 - accuracy: 0.9709\n",
      "Epoch 37/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0806 - accuracy: 0.9702\n",
      "Epoch 38/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0769 - accuracy: 0.9715\n",
      "Epoch 39/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0734 - accuracy: 0.9732\n",
      "Epoch 40/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0743 - accuracy: 0.9730\n",
      "Epoch 41/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0741 - accuracy: 0.9731\n",
      "Epoch 42/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0680 - accuracy: 0.9752\n",
      "Epoch 43/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0707 - accuracy: 0.9735\n",
      "Epoch 44/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0734 - accuracy: 0.9729\n",
      "Epoch 45/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0698 - accuracy: 0.9738\n",
      "Epoch 46/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0710 - accuracy: 0.9737\n",
      "Epoch 47/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0694 - accuracy: 0.9740\n",
      "Epoch 48/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0684 - accuracy: 0.9742\n",
      "Epoch 49/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0645 - accuracy: 0.9761\n",
      "Epoch 50/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0658 - accuracy: 0.9763\n",
      "Epoch 51/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0688 - accuracy: 0.9747\n",
      "Epoch 52/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0602 - accuracy: 0.9787\n",
      "Epoch 53/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0644 - accuracy: 0.9764\n",
      "Epoch 54/60\n",
      "183/183 [==============================] - 6s 35ms/step - loss: 0.0659 - accuracy: 0.9762\n",
      "Epoch 55/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0597 - accuracy: 0.9780\n",
      "Epoch 56/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0606 - accuracy: 0.9775\n",
      "Epoch 57/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0568 - accuracy: 0.9789\n",
      "Epoch 58/60\n",
      "183/183 [==============================] - 6s 35ms/step - loss: 0.0599 - accuracy: 0.9782\n",
      "Epoch 59/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0600 - accuracy: 0.9788\n",
      "Epoch 60/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0541 - accuracy: 0.9796\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.2828 - accuracy: 0.9429\n",
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_54 (Conv1D)           (None, 88, 256)           2560      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_18 (MaxPooling (None, 22, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_55 (Conv1D)           (None, 20, 768)           590592    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_18 (Averag (None, 5, 768)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_56 (Conv1D)           (None, 1, 768)            2949888   \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_18  (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 256)               196864    \n",
      "_________________________________________________________________\n",
      "dropout_36 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 6)                 1542      \n",
      "=================================================================\n",
      "Total params: 3,807,238\n",
      "Trainable params: 3,807,238\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/60\n",
      "183/183 [==============================] - 6s 35ms/step - loss: 1.1048 - accuracy: 0.5272\n",
      "Epoch 2/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183/183 [==============================] - 6s 35ms/step - loss: 0.7243 - accuracy: 0.7099\n",
      "Epoch 3/60\n",
      "183/183 [==============================] - 6s 35ms/step - loss: 0.5081 - accuracy: 0.8121\n",
      "Epoch 4/60\n",
      "183/183 [==============================] - 6s 35ms/step - loss: 0.3796 - accuracy: 0.8608\n",
      "Epoch 5/60\n",
      "183/183 [==============================] - 6s 35ms/step - loss: 0.3394 - accuracy: 0.8751\n",
      "Epoch 6/60\n",
      "183/183 [==============================] - 6s 35ms/step - loss: 0.2931 - accuracy: 0.8928\n",
      "Epoch 7/60\n",
      "183/183 [==============================] - 6s 35ms/step - loss: 0.2668 - accuracy: 0.9014\n",
      "Epoch 8/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.2615 - accuracy: 0.9076\n",
      "Epoch 9/60\n",
      "183/183 [==============================] - 6s 35ms/step - loss: 0.2498 - accuracy: 0.9116\n",
      "Epoch 10/60\n",
      "183/183 [==============================] - 6s 35ms/step - loss: 0.2117 - accuracy: 0.9240\n",
      "Epoch 11/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.2002 - accuracy: 0.9292\n",
      "Epoch 12/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.1860 - accuracy: 0.9350\n",
      "Epoch 13/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.1776 - accuracy: 0.9369\n",
      "Epoch 14/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.1801 - accuracy: 0.9370\n",
      "Epoch 15/60\n",
      "183/183 [==============================] - 6s 35ms/step - loss: 0.1626 - accuracy: 0.9431\n",
      "Epoch 16/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.1702 - accuracy: 0.9393\n",
      "Epoch 17/60\n",
      "183/183 [==============================] - 6s 35ms/step - loss: 0.1388 - accuracy: 0.9514\n",
      "Epoch 18/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.1375 - accuracy: 0.9491\n",
      "Epoch 19/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.1328 - accuracy: 0.9527\n",
      "Epoch 20/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.1203 - accuracy: 0.9570\n",
      "Epoch 21/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.1137 - accuracy: 0.9585\n",
      "Epoch 22/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.1159 - accuracy: 0.9579\n",
      "Epoch 23/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.1114 - accuracy: 0.9599\n",
      "Epoch 24/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.1072 - accuracy: 0.9606\n",
      "Epoch 25/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.1013 - accuracy: 0.9640\n",
      "Epoch 26/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0951 - accuracy: 0.9660\n",
      "Epoch 27/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0952 - accuracy: 0.9649\n",
      "Epoch 28/60\n",
      "183/183 [==============================] - 6s 35ms/step - loss: 0.0936 - accuracy: 0.9661\n",
      "Epoch 29/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0935 - accuracy: 0.9673\n",
      "Epoch 30/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0911 - accuracy: 0.9675\n",
      "Epoch 31/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0886 - accuracy: 0.9684\n",
      "Epoch 32/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0821 - accuracy: 0.9698\n",
      "Epoch 33/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0816 - accuracy: 0.9698\n",
      "Epoch 34/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0832 - accuracy: 0.9698\n",
      "Epoch 35/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0960 - accuracy: 0.9641\n",
      "Epoch 36/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0768 - accuracy: 0.9723\n",
      "Epoch 37/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0770 - accuracy: 0.9718\n",
      "Epoch 38/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0730 - accuracy: 0.9734\n",
      "Epoch 39/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0746 - accuracy: 0.9722\n",
      "Epoch 40/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0818 - accuracy: 0.9706\n",
      "Epoch 41/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0743 - accuracy: 0.9739\n",
      "Epoch 42/60\n",
      "183/183 [==============================] - 6s 35ms/step - loss: 0.0665 - accuracy: 0.9751\n",
      "Epoch 43/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0742 - accuracy: 0.9735\n",
      "Epoch 44/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0722 - accuracy: 0.9742\n",
      "Epoch 45/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0675 - accuracy: 0.9752\n",
      "Epoch 46/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0643 - accuracy: 0.9765\n",
      "Epoch 47/60\n",
      "183/183 [==============================] - 6s 35ms/step - loss: 0.0632 - accuracy: 0.9767\n",
      "Epoch 48/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0651 - accuracy: 0.9768\n",
      "Epoch 49/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0622 - accuracy: 0.9768\n",
      "Epoch 50/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0637 - accuracy: 0.9768\n",
      "Epoch 51/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0602 - accuracy: 0.9775\n",
      "Epoch 52/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0550 - accuracy: 0.9798\n",
      "Epoch 53/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0653 - accuracy: 0.9768\n",
      "Epoch 54/60\n",
      "183/183 [==============================] - 6s 35ms/step - loss: 0.0658 - accuracy: 0.9767\n",
      "Epoch 55/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0558 - accuracy: 0.9792\n",
      "Epoch 56/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0530 - accuracy: 0.9803\n",
      "Epoch 57/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0553 - accuracy: 0.9794\n",
      "Epoch 58/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0570 - accuracy: 0.9791\n",
      "Epoch 59/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0527 - accuracy: 0.9807\n",
      "Epoch 60/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0557 - accuracy: 0.9796\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.3517 - accuracy: 0.9419\n",
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_57 (Conv1D)           (None, 88, 256)           2560      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_19 (MaxPooling (None, 22, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_58 (Conv1D)           (None, 20, 768)           590592    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_19 (Averag (None, 5, 768)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_59 (Conv1D)           (None, 1, 768)            2949888   \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_19  (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 256)               196864    \n",
      "_________________________________________________________________\n",
      "dropout_38 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_39 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 6)                 1542      \n",
      "=================================================================\n",
      "Total params: 3,807,238\n",
      "Trainable params: 3,807,238\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/60\n",
      "183/183 [==============================] - 7s 36ms/step - loss: 1.1061 - accuracy: 0.5315\n",
      "Epoch 2/60\n",
      "183/183 [==============================] - 6s 35ms/step - loss: 0.7535 - accuracy: 0.6983\n",
      "Epoch 3/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183/183 [==============================] - 6s 34ms/step - loss: 0.5152 - accuracy: 0.8063\n",
      "Epoch 4/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.4047 - accuracy: 0.8551\n",
      "Epoch 5/60\n",
      "183/183 [==============================] - 6s 35ms/step - loss: 0.3432 - accuracy: 0.8760\n",
      "Epoch 6/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.3025 - accuracy: 0.8888\n",
      "Epoch 7/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.2761 - accuracy: 0.8989\n",
      "Epoch 8/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.2367 - accuracy: 0.9115\n",
      "Epoch 9/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.2380 - accuracy: 0.9135\n",
      "Epoch 10/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.2085 - accuracy: 0.9239\n",
      "Epoch 11/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.1971 - accuracy: 0.9268\n",
      "Epoch 12/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.1898 - accuracy: 0.9298\n",
      "Epoch 13/60\n",
      "183/183 [==============================] - 6s 35ms/step - loss: 0.2091 - accuracy: 0.9263\n",
      "Epoch 14/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.1765 - accuracy: 0.9399\n",
      "Epoch 15/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.1562 - accuracy: 0.9426\n",
      "Epoch 16/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.1630 - accuracy: 0.9415\n",
      "Epoch 17/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.1371 - accuracy: 0.9503\n",
      "Epoch 18/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.1368 - accuracy: 0.9510\n",
      "Epoch 19/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.1242 - accuracy: 0.9543\n",
      "Epoch 20/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.1676 - accuracy: 0.9459\n",
      "Epoch 21/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.1242 - accuracy: 0.9551\n",
      "Epoch 22/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.1124 - accuracy: 0.9590\n",
      "Epoch 23/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.1269 - accuracy: 0.9538\n",
      "Epoch 24/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.1067 - accuracy: 0.9593\n",
      "Epoch 25/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0985 - accuracy: 0.9636\n",
      "Epoch 26/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.1008 - accuracy: 0.9633\n",
      "Epoch 27/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0983 - accuracy: 0.9633\n",
      "Epoch 28/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.1005 - accuracy: 0.9638\n",
      "Epoch 29/60\n",
      "183/183 [==============================] - 6s 35ms/step - loss: 0.0986 - accuracy: 0.9639\n",
      "Epoch 30/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0901 - accuracy: 0.9671\n",
      "Epoch 31/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0933 - accuracy: 0.9661\n",
      "Epoch 32/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0832 - accuracy: 0.9686\n",
      "Epoch 33/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0858 - accuracy: 0.9685\n",
      "Epoch 34/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0842 - accuracy: 0.9703\n",
      "Epoch 35/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0799 - accuracy: 0.9710\n",
      "Epoch 36/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0773 - accuracy: 0.9706\n",
      "Epoch 37/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0776 - accuracy: 0.9716\n",
      "Epoch 38/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0761 - accuracy: 0.9724\n",
      "Epoch 39/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0730 - accuracy: 0.9736\n",
      "Epoch 40/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0710 - accuracy: 0.9733\n",
      "Epoch 41/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0768 - accuracy: 0.9729\n",
      "Epoch 42/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0746 - accuracy: 0.9730\n",
      "Epoch 43/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0709 - accuracy: 0.9740\n",
      "Epoch 44/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0729 - accuracy: 0.9736\n",
      "Epoch 45/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0747 - accuracy: 0.9726\n",
      "Epoch 46/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0705 - accuracy: 0.9742\n",
      "Epoch 47/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0654 - accuracy: 0.9760\n",
      "Epoch 48/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0619 - accuracy: 0.9771\n",
      "Epoch 49/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0628 - accuracy: 0.9765\n",
      "Epoch 50/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0617 - accuracy: 0.9766 1s\n",
      "Epoch 51/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0610 - accuracy: 0.9770\n",
      "Epoch 52/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0632 - accuracy: 0.9770\n",
      "Epoch 53/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0605 - accuracy: 0.9780\n",
      "Epoch 54/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0608 - accuracy: 0.9777\n",
      "Epoch 55/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0647 - accuracy: 0.9766\n",
      "Epoch 56/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0576 - accuracy: 0.9791\n",
      "Epoch 57/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0688 - accuracy: 0.9752\n",
      "Epoch 58/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0635 - accuracy: 0.9768\n",
      "Epoch 59/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0595 - accuracy: 0.9781\n",
      "Epoch 60/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0555 - accuracy: 0.9794\n",
      "46/46 [==============================] - 1s 13ms/step - loss: 0.3398 - accuracy: 0.9410\n",
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_60 (Conv1D)           (None, 88, 256)           2560      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_20 (MaxPooling (None, 22, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_61 (Conv1D)           (None, 20, 768)           590592    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_20 (Averag (None, 5, 768)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_62 (Conv1D)           (None, 1, 768)            2949888   \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_20  (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 256)               196864    \n",
      "_________________________________________________________________\n",
      "dropout_40 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_41 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 6)                 1542      \n",
      "=================================================================\n",
      "Total params: 3,807,238\n",
      "Trainable params: 3,807,238\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/60\n",
      "183/183 [==============================] - 6s 35ms/step - loss: 1.1113 - accuracy: 0.5258\n",
      "Epoch 2/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.7374 - accuracy: 0.7009\n",
      "Epoch 3/60\n",
      "183/183 [==============================] - 6s 35ms/step - loss: 0.5342 - accuracy: 0.7990\n",
      "Epoch 4/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183/183 [==============================] - 6s 34ms/step - loss: 0.4134 - accuracy: 0.8502\n",
      "Epoch 5/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.3344 - accuracy: 0.8782\n",
      "Epoch 6/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.2892 - accuracy: 0.8902\n",
      "Epoch 7/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.2865 - accuracy: 0.8948\n",
      "Epoch 8/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.2494 - accuracy: 0.9051\n",
      "Epoch 9/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.2393 - accuracy: 0.9072\n",
      "Epoch 10/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.2106 - accuracy: 0.9208\n",
      "Epoch 11/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.2020 - accuracy: 0.9260\n",
      "Epoch 12/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.2025 - accuracy: 0.9273\n",
      "Epoch 13/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.1924 - accuracy: 0.9313\n",
      "Epoch 14/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.1621 - accuracy: 0.9403\n",
      "Epoch 15/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.1568 - accuracy: 0.9437\n",
      "Epoch 16/60\n",
      "183/183 [==============================] - 6s 35ms/step - loss: 0.1470 - accuracy: 0.9470\n",
      "Epoch 17/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.1386 - accuracy: 0.9503\n",
      "Epoch 18/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.1375 - accuracy: 0.9506\n",
      "Epoch 19/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.1335 - accuracy: 0.9520\n",
      "Epoch 20/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.1259 - accuracy: 0.9554\n",
      "Epoch 21/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.1179 - accuracy: 0.9576\n",
      "Epoch 22/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.1116 - accuracy: 0.9605\n",
      "Epoch 23/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.1071 - accuracy: 0.9616\n",
      "Epoch 24/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.1043 - accuracy: 0.9624\n",
      "Epoch 25/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.1137 - accuracy: 0.9597\n",
      "Epoch 26/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.1044 - accuracy: 0.9626\n",
      "Epoch 27/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0964 - accuracy: 0.9656\n",
      "Epoch 28/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0942 - accuracy: 0.9662\n",
      "Epoch 29/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0917 - accuracy: 0.9666\n",
      "Epoch 30/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0885 - accuracy: 0.9679\n",
      "Epoch 31/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0887 - accuracy: 0.9683\n",
      "Epoch 32/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0840 - accuracy: 0.9691\n",
      "Epoch 33/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0825 - accuracy: 0.9699\n",
      "Epoch 34/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0827 - accuracy: 0.9697\n",
      "Epoch 35/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0864 - accuracy: 0.9695\n",
      "Epoch 36/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0859 - accuracy: 0.9687\n",
      "Epoch 37/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0795 - accuracy: 0.9711\n",
      "Epoch 38/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0911 - accuracy: 0.9674\n",
      "Epoch 39/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0787 - accuracy: 0.9711\n",
      "Epoch 40/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0737 - accuracy: 0.9730\n",
      "Epoch 41/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0702 - accuracy: 0.9742\n",
      "Epoch 42/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0721 - accuracy: 0.9737\n",
      "Epoch 43/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0728 - accuracy: 0.9739\n",
      "Epoch 44/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0657 - accuracy: 0.9757\n",
      "Epoch 45/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0675 - accuracy: 0.9749\n",
      "Epoch 46/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0627 - accuracy: 0.9759\n",
      "Epoch 47/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0630 - accuracy: 0.9766\n",
      "Epoch 48/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0608 - accuracy: 0.9775\n",
      "Epoch 49/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0709 - accuracy: 0.9744\n",
      "Epoch 50/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0680 - accuracy: 0.9757\n",
      "Epoch 51/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0639 - accuracy: 0.9759\n",
      "Epoch 52/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0579 - accuracy: 0.9791\n",
      "Epoch 53/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0598 - accuracy: 0.9783\n",
      "Epoch 54/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0577 - accuracy: 0.9789\n",
      "Epoch 55/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0621 - accuracy: 0.9781\n",
      "Epoch 56/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0582 - accuracy: 0.9792\n",
      "Epoch 57/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0568 - accuracy: 0.9797\n",
      "Epoch 58/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0587 - accuracy: 0.9777\n",
      "Epoch 59/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0540 - accuracy: 0.9802\n",
      "Epoch 60/60\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.0655 - accuracy: 0.9769\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.3650 - accuracy: 0.9407\n",
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_63 (Conv1D)           (None, 86, 512)           8192      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_21 (MaxPooling (None, 43, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_64 (Conv1D)           (None, 39, 768)           1966848   \n",
      "_________________________________________________________________\n",
      "average_pooling1d_21 (Averag (None, 19, 768)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_65 (Conv1D)           (None, 15, 768)           2949888   \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_21  (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (None, 256)               196864    \n",
      "_________________________________________________________________\n",
      "dropout_42 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_64 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_43 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 6)                 1542      \n",
      "=================================================================\n",
      "Total params: 5,189,126\n",
      "Trainable params: 5,189,126\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/60\n",
      "  2/183 [..............................] - ETA: 9s - loss: 1.7665 - accuracy: 0.1875WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0400s vs `on_train_batch_end` time: 0.0669s). Check your callbacks.\n",
      "183/183 [==============================] - 20s 107ms/step - loss: 1.1927 - accuracy: 0.4982\n",
      "Epoch 2/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.9601 - accuracy: 0.6090\n",
      "Epoch 3/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183/183 [==============================] - 19s 106ms/step - loss: 0.7636 - accuracy: 0.6939\n",
      "Epoch 4/60\n",
      "183/183 [==============================] - 19s 106ms/step - loss: 0.6707 - accuracy: 0.7294\n",
      "Epoch 5/60\n",
      "183/183 [==============================] - 19s 106ms/step - loss: 0.6074 - accuracy: 0.7565\n",
      "Epoch 6/60\n",
      "183/183 [==============================] - 19s 106ms/step - loss: 0.5523 - accuracy: 0.7768\n",
      "Epoch 7/60\n",
      "183/183 [==============================] - 19s 106ms/step - loss: 0.5227 - accuracy: 0.7910\n",
      "Epoch 8/60\n",
      "183/183 [==============================] - 19s 106ms/step - loss: 0.5045 - accuracy: 0.7989\n",
      "Epoch 9/60\n",
      "183/183 [==============================] - 19s 106ms/step - loss: 0.4741 - accuracy: 0.8091\n",
      "Epoch 10/60\n",
      "183/183 [==============================] - 19s 106ms/step - loss: 0.4613 - accuracy: 0.8162\n",
      "Epoch 11/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.4499 - accuracy: 0.8235\n",
      "Epoch 12/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.4680 - accuracy: 0.8196\n",
      "Epoch 13/60\n",
      "183/183 [==============================] - 19s 106ms/step - loss: 0.4364 - accuracy: 0.8307\n",
      "Epoch 14/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.3867 - accuracy: 0.8497\n",
      "Epoch 15/60\n",
      "183/183 [==============================] - 19s 106ms/step - loss: 0.3880 - accuracy: 0.8481\n",
      "Epoch 16/60\n",
      "183/183 [==============================] - 19s 106ms/step - loss: 0.3859 - accuracy: 0.8515\n",
      "Epoch 17/60\n",
      "183/183 [==============================] - 19s 106ms/step - loss: 0.4026 - accuracy: 0.8489\n",
      "Epoch 18/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.4260 - accuracy: 0.8414\n",
      "Epoch 19/60\n",
      "183/183 [==============================] - 19s 106ms/step - loss: 0.3440 - accuracy: 0.8667\n",
      "Epoch 20/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.3550 - accuracy: 0.8611\n",
      "Epoch 21/60\n",
      "183/183 [==============================] - 19s 106ms/step - loss: 0.4024 - accuracy: 0.8520\n",
      "Epoch 22/60\n",
      "183/183 [==============================] - 19s 106ms/step - loss: 0.3297 - accuracy: 0.8721\n",
      "Epoch 23/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.3259 - accuracy: 0.8708\n",
      "Epoch 24/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.3182 - accuracy: 0.8756\n",
      "Epoch 25/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.3395 - accuracy: 0.8718\n",
      "Epoch 26/60\n",
      "183/183 [==============================] - 19s 106ms/step - loss: 0.3166 - accuracy: 0.8766\n",
      "Epoch 27/60\n",
      "183/183 [==============================] - 19s 106ms/step - loss: 0.2998 - accuracy: 0.8814\n",
      "Epoch 28/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 2.1966 - accuracy: 0.6815\n",
      "Epoch 29/60\n",
      "183/183 [==============================] - 20s 108ms/step - loss: 0.5226 - accuracy: 0.8015\n",
      "Epoch 30/60\n",
      "183/183 [==============================] - 20s 107ms/step - loss: 0.4181 - accuracy: 0.8432\n",
      "Epoch 31/60\n",
      "183/183 [==============================] - 20s 108ms/step - loss: 0.3750 - accuracy: 0.8585\n",
      "Epoch 32/60\n",
      "183/183 [==============================] - 20s 108ms/step - loss: 0.3578 - accuracy: 0.8650\n",
      "Epoch 33/60\n",
      "183/183 [==============================] - 20s 108ms/step - loss: 0.3414 - accuracy: 0.8715\n",
      "Epoch 34/60\n",
      "183/183 [==============================] - 20s 107ms/step - loss: 0.3233 - accuracy: 0.8756\n",
      "Epoch 35/60\n",
      "183/183 [==============================] - 20s 108ms/step - loss: 0.3153 - accuracy: 0.8779\n",
      "Epoch 36/60\n",
      "183/183 [==============================] - 20s 110ms/step - loss: 0.3058 - accuracy: 0.8807\n",
      "Epoch 37/60\n",
      "183/183 [==============================] - 20s 108ms/step - loss: 0.3055 - accuracy: 0.8806\n",
      "Epoch 38/60\n",
      "183/183 [==============================] - 20s 108ms/step - loss: 0.2983 - accuracy: 0.8823\n",
      "Epoch 39/60\n",
      "183/183 [==============================] - 20s 108ms/step - loss: 0.2868 - accuracy: 0.8879\n",
      "Epoch 40/60\n",
      "183/183 [==============================] - 19s 106ms/step - loss: 0.3192 - accuracy: 0.8799\n",
      "Epoch 41/60\n",
      "183/183 [==============================] - 19s 106ms/step - loss: 0.2938 - accuracy: 0.8853\n",
      "Epoch 42/60\n",
      "183/183 [==============================] - 20s 107ms/step - loss: 0.2852 - accuracy: 0.8881\n",
      "Epoch 43/60\n",
      "183/183 [==============================] - 19s 106ms/step - loss: 0.2756 - accuracy: 0.8916\n",
      "Epoch 44/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.2733 - accuracy: 0.8918\n",
      "Epoch 45/60\n",
      "183/183 [==============================] - 19s 106ms/step - loss: 0.2696 - accuracy: 0.8930\n",
      "Epoch 46/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.2696 - accuracy: 0.8935\n",
      "Epoch 47/60\n",
      "183/183 [==============================] - 20s 107ms/step - loss: 0.2726 - accuracy: 0.8948\n",
      "Epoch 48/60\n",
      "183/183 [==============================] - 19s 106ms/step - loss: 0.2610 - accuracy: 0.8964\n",
      "Epoch 49/60\n",
      "183/183 [==============================] - 20s 108ms/step - loss: 0.2610 - accuracy: 0.8973\n",
      "Epoch 50/60\n",
      "183/183 [==============================] - 20s 109ms/step - loss: 0.2700 - accuracy: 0.8942\n",
      "Epoch 51/60\n",
      "183/183 [==============================] - 21s 112ms/step - loss: 0.2606 - accuracy: 0.8988\n",
      "Epoch 52/60\n",
      "183/183 [==============================] - 20s 108ms/step - loss: 0.2539 - accuracy: 0.8997\n",
      "Epoch 53/60\n",
      "183/183 [==============================] - 20s 108ms/step - loss: 0.2543 - accuracy: 0.8986\n",
      "Epoch 54/60\n",
      "183/183 [==============================] - 20s 107ms/step - loss: 0.2491 - accuracy: 0.9013\n",
      "Epoch 55/60\n",
      "183/183 [==============================] - 20s 109ms/step - loss: 0.2456 - accuracy: 0.9025\n",
      "Epoch 56/60\n",
      "183/183 [==============================] - 20s 107ms/step - loss: 0.2455 - accuracy: 0.9012\n",
      "Epoch 57/60\n",
      "183/183 [==============================] - 19s 106ms/step - loss: 0.2434 - accuracy: 0.9032\n",
      "Epoch 58/60\n",
      "183/183 [==============================] - 19s 106ms/step - loss: 0.2418 - accuracy: 0.9052\n",
      "Epoch 59/60\n",
      "183/183 [==============================] - 19s 106ms/step - loss: 0.2370 - accuracy: 0.9054\n",
      "Epoch 60/60\n",
      "183/183 [==============================] - 19s 106ms/step - loss: 0.3259 - accuracy: 0.8831\n",
      "46/46 [==============================] - 2s 35ms/step - loss: 0.4981 - accuracy: 0.8267\n",
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_66 (Conv1D)           (None, 86, 512)           8192      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_22 (MaxPooling (None, 43, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_67 (Conv1D)           (None, 39, 768)           1966848   \n",
      "_________________________________________________________________\n",
      "average_pooling1d_22 (Averag (None, 19, 768)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_68 (Conv1D)           (None, 15, 768)           2949888   \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_22  (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             (None, 256)               196864    \n",
      "_________________________________________________________________\n",
      "dropout_44 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_67 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_45 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 6)                 1542      \n",
      "=================================================================\n",
      "Total params: 5,189,126\n",
      "Trainable params: 5,189,126\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/60\n",
      "  2/183 [..............................] - ETA: 16s - loss: 1.7576 - accuracy: 0.2227WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0389s vs `on_train_batch_end` time: 0.0629s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183/183 [==============================] - 19s 105ms/step - loss: 1.1715 - accuracy: 0.5053\n",
      "Epoch 2/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.9474 - accuracy: 0.6247\n",
      "Epoch 3/60\n",
      "183/183 [==============================] - 19s 106ms/step - loss: 0.7765 - accuracy: 0.6932\n",
      "Epoch 4/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.6469 - accuracy: 0.7454\n",
      "Epoch 5/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.5963 - accuracy: 0.7623\n",
      "Epoch 6/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.5580 - accuracy: 0.7773\n",
      "Epoch 7/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.5247 - accuracy: 0.7881\n",
      "Epoch 8/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.5219 - accuracy: 0.7929\n",
      "Epoch 9/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.5058 - accuracy: 0.8010\n",
      "Epoch 10/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.4634 - accuracy: 0.8161\n",
      "Epoch 11/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.4482 - accuracy: 0.8218\n",
      "Epoch 12/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.4092 - accuracy: 0.8341\n",
      "Epoch 13/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 1.1160 - accuracy: 0.7027\n",
      "Epoch 14/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.4904 - accuracy: 0.8023\n",
      "Epoch 15/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.4462 - accuracy: 0.8172\n",
      "Epoch 16/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.4239 - accuracy: 0.8293\n",
      "Epoch 17/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.4262 - accuracy: 0.8312\n",
      "Epoch 18/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.3924 - accuracy: 0.8429\n",
      "Epoch 19/60\n",
      "183/183 [==============================] - 19s 106ms/step - loss: 0.3780 - accuracy: 0.8490\n",
      "Epoch 20/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.3817 - accuracy: 0.8500\n",
      "Epoch 21/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.3537 - accuracy: 0.8606\n",
      "Epoch 22/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.3587 - accuracy: 0.8599\n",
      "Epoch 23/60\n",
      "183/183 [==============================] - 19s 106ms/step - loss: 0.3645 - accuracy: 0.8600\n",
      "Epoch 24/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.3446 - accuracy: 0.8677\n",
      "Epoch 25/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.3305 - accuracy: 0.8709s - loss: 0.3297 - accuracy\n",
      "Epoch 26/60\n",
      "183/183 [==============================] - 19s 106ms/step - loss: 0.3346 - accuracy: 0.8694\n",
      "Epoch 27/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 1.4141 - accuracy: 0.6859\n",
      "Epoch 28/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.4787 - accuracy: 0.8101\n",
      "Epoch 29/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.3964 - accuracy: 0.8478\n",
      "Epoch 30/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.3741 - accuracy: 0.8564\n",
      "Epoch 31/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.3589 - accuracy: 0.8628\n",
      "Epoch 32/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.3395 - accuracy: 0.8702\n",
      "Epoch 33/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.3345 - accuracy: 0.8716\n",
      "Epoch 34/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.3267 - accuracy: 0.8735\n",
      "Epoch 35/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.3210 - accuracy: 0.8756\n",
      "Epoch 36/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.3095 - accuracy: 0.8780\n",
      "Epoch 37/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.3079 - accuracy: 0.8791s - loss: 0.3066 - \n",
      "Epoch 38/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.3038 - accuracy: 0.8809\n",
      "Epoch 39/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.2972 - accuracy: 0.8830\n",
      "Epoch 40/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.3025 - accuracy: 0.8811\n",
      "Epoch 41/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.3190 - accuracy: 0.8782\n",
      "Epoch 42/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.2947 - accuracy: 0.8849\n",
      "Epoch 43/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.2880 - accuracy: 0.8869\n",
      "Epoch 44/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.2887 - accuracy: 0.8882\n",
      "Epoch 45/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.2855 - accuracy: 0.8878\n",
      "Epoch 46/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.3131 - accuracy: 0.8827\n",
      "Epoch 47/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.2793 - accuracy: 0.8893\n",
      "Epoch 48/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.2782 - accuracy: 0.8924\n",
      "Epoch 49/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.2738 - accuracy: 0.8931\n",
      "Epoch 50/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.2727 - accuracy: 0.8944\n",
      "Epoch 51/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.2656 - accuracy: 0.8968\n",
      "Epoch 52/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.2778 - accuracy: 0.8928\n",
      "Epoch 53/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.2671 - accuracy: 0.8955\n",
      "Epoch 54/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.2557 - accuracy: 0.9000\n",
      "Epoch 55/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.4387 - accuracy: 0.8590\n",
      "Epoch 56/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.2823 - accuracy: 0.8934\n",
      "Epoch 57/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.2752 - accuracy: 0.8944\n",
      "Epoch 58/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.2524 - accuracy: 0.9022\n",
      "Epoch 59/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.2523 - accuracy: 0.9027\n",
      "Epoch 60/60\n",
      "183/183 [==============================] - 19s 106ms/step - loss: 0.2473 - accuracy: 0.9049\n",
      "46/46 [==============================] - 2s 33ms/step - loss: 0.2866 - accuracy: 0.8952\n",
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_69 (Conv1D)           (None, 86, 512)           8192      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_23 (MaxPooling (None, 43, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_70 (Conv1D)           (None, 39, 768)           1966848   \n",
      "_________________________________________________________________\n",
      "average_pooling1d_23 (Averag (None, 19, 768)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_71 (Conv1D)           (None, 15, 768)           2949888   \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_23  (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 256)               196864    \n",
      "_________________________________________________________________\n",
      "dropout_46 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_70 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_47 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_71 (Dense)             (None, 6)                 1542      \n",
      "=================================================================\n",
      "Total params: 5,189,126\n",
      "Trainable params: 5,189,126\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2/183 [..............................] - ETA: 16s - loss: 1.7683 - accuracy: 0.1992WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0392s vs `on_train_batch_end` time: 0.0669s). Check your callbacks.\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 1.1879 - accuracy: 0.4981\n",
      "Epoch 2/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.8922 - accuracy: 0.6426\n",
      "Epoch 3/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.7623 - accuracy: 0.6976\n",
      "Epoch 4/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.6301 - accuracy: 0.7507\n",
      "Epoch 5/60\n",
      "183/183 [==============================] - 19s 106ms/step - loss: 0.5881 - accuracy: 0.7655\n",
      "Epoch 6/60\n",
      "183/183 [==============================] - 19s 106ms/step - loss: 0.5284 - accuracy: 0.7871\n",
      "Epoch 7/60\n",
      "183/183 [==============================] - 19s 106ms/step - loss: 0.6023 - accuracy: 0.7662\n",
      "Epoch 8/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.4942 - accuracy: 0.8015\n",
      "Epoch 9/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.4599 - accuracy: 0.8141\n",
      "Epoch 10/60\n",
      "183/183 [==============================] - 19s 106ms/step - loss: 0.4638 - accuracy: 0.8147\n",
      "Epoch 11/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 2.7842 - accuracy: 0.5857\n",
      "Epoch 12/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.6708 - accuracy: 0.7353\n",
      "Epoch 13/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.5853 - accuracy: 0.7709\n",
      "Epoch 14/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.5220 - accuracy: 0.7946\n",
      "Epoch 15/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.4824 - accuracy: 0.8088\n",
      "Epoch 16/60\n",
      "183/183 [==============================] - 19s 106ms/step - loss: 0.4741 - accuracy: 0.8149\n",
      "Epoch 17/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.4350 - accuracy: 0.8272\n",
      "Epoch 18/60\n",
      "183/183 [==============================] - 19s 106ms/step - loss: 0.4355 - accuracy: 0.8304\n",
      "Epoch 19/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.4285 - accuracy: 0.8333\n",
      "Epoch 20/60\n",
      "183/183 [==============================] - 19s 106ms/step - loss: 0.4189 - accuracy: 0.8352\n",
      "Epoch 21/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.4061 - accuracy: 0.8413\n",
      "Epoch 22/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.3912 - accuracy: 0.8487\n",
      "Epoch 23/60\n",
      "183/183 [==============================] - 19s 106ms/step - loss: 0.3995 - accuracy: 0.8459\n",
      "Epoch 24/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.3731 - accuracy: 0.8553\n",
      "Epoch 25/60\n",
      "183/183 [==============================] - 19s 106ms/step - loss: 0.3870 - accuracy: 0.8522\n",
      "Epoch 26/60\n",
      "183/183 [==============================] - 19s 106ms/step - loss: 0.3686 - accuracy: 0.8573\n",
      "Epoch 27/60\n",
      "183/183 [==============================] - 19s 106ms/step - loss: 0.3750 - accuracy: 0.8562\n",
      "Epoch 28/60\n",
      "183/183 [==============================] - 19s 106ms/step - loss: 0.3501 - accuracy: 0.8642\n",
      "Epoch 29/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.3577 - accuracy: 0.8612\n",
      "Epoch 30/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.3428 - accuracy: 0.8658\n",
      "Epoch 31/60\n",
      "183/183 [==============================] - 19s 106ms/step - loss: 0.3852 - accuracy: 0.8555\n",
      "Epoch 32/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.3438 - accuracy: 0.8664\n",
      "Epoch 33/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.3294 - accuracy: 0.8720\n",
      "Epoch 34/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.3370 - accuracy: 0.8687\n",
      "Epoch 35/60\n",
      "183/183 [==============================] - 19s 106ms/step - loss: 0.3274 - accuracy: 0.8706\n",
      "Epoch 36/60\n",
      "183/183 [==============================] - 19s 106ms/step - loss: 0.3330 - accuracy: 0.8717\n",
      "Epoch 37/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.3276 - accuracy: 0.8729\n",
      "Epoch 38/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.3156 - accuracy: 0.8761\n",
      "Epoch 39/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.4923 - accuracy: 0.8346\n",
      "Epoch 40/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.3284 - accuracy: 0.8734\n",
      "Epoch 41/60\n",
      "183/183 [==============================] - 19s 106ms/step - loss: 0.3081 - accuracy: 0.8789\n",
      "Epoch 42/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.3093 - accuracy: 0.8788\n",
      "Epoch 43/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.3031 - accuracy: 0.8803\n",
      "Epoch 44/60\n",
      "183/183 [==============================] - 19s 106ms/step - loss: 0.2996 - accuracy: 0.8812\n",
      "Epoch 45/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.3104 - accuracy: 0.8795\n",
      "Epoch 46/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.3059 - accuracy: 0.8797\n",
      "Epoch 47/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.2897 - accuracy: 0.8847\n",
      "Epoch 48/60\n",
      "183/183 [==============================] - 19s 106ms/step - loss: 0.3081 - accuracy: 0.8814\n",
      "Epoch 49/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.2870 - accuracy: 0.8873\n",
      "Epoch 50/60\n",
      "183/183 [==============================] - 19s 106ms/step - loss: 0.2893 - accuracy: 0.8861\n",
      "Epoch 51/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.2846 - accuracy: 0.8873\n",
      "Epoch 52/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.2784 - accuracy: 0.8900\n",
      "Epoch 53/60\n",
      "183/183 [==============================] - 19s 106ms/step - loss: 0.2747 - accuracy: 0.8904\n",
      "Epoch 54/60\n",
      "183/183 [==============================] - 19s 106ms/step - loss: 0.2718 - accuracy: 0.8932\n",
      "Epoch 55/60\n",
      "183/183 [==============================] - 19s 106ms/step - loss: 0.2885 - accuracy: 0.8896\n",
      "Epoch 56/60\n",
      "183/183 [==============================] - 19s 106ms/step - loss: 0.2704 - accuracy: 0.8938\n",
      "Epoch 57/60\n",
      "183/183 [==============================] - 19s 106ms/step - loss: 0.2651 - accuracy: 0.8943\n",
      "Epoch 58/60\n",
      "183/183 [==============================] - 19s 106ms/step - loss: 0.2642 - accuracy: 0.8952\n",
      "Epoch 59/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.2564 - accuracy: 0.8995\n",
      "Epoch 60/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.3868 - accuracy: 0.8664\n",
      "46/46 [==============================] - 2s 33ms/step - loss: 0.4565 - accuracy: 0.8505\n",
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_72 (Conv1D)           (None, 86, 512)           8192      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_24 (MaxPooling (None, 43, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_73 (Conv1D)           (None, 39, 768)           1966848   \n",
      "_________________________________________________________________\n",
      "average_pooling1d_24 (Averag (None, 19, 768)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_74 (Conv1D)           (None, 15, 768)           2949888   \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_24  (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dense_72 (Dense)             (None, 256)               196864    \n",
      "_________________________________________________________________\n",
      "dropout_48 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_73 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_49 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_74 (Dense)             (None, 6)                 1542      \n",
      "=================================================================\n",
      "Total params: 5,189,126\n",
      "Trainable params: 5,189,126\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2/183 [..............................] - ETA: 16s - loss: 1.7649 - accuracy: 0.2324WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0401s vs `on_train_batch_end` time: 0.0619s). Check your callbacks.\n",
      "183/183 [==============================] - 20s 107ms/step - loss: 1.1770 - accuracy: 0.5043\n",
      "Epoch 2/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.9368 - accuracy: 0.6250\n",
      "Epoch 3/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.8024 - accuracy: 0.6862\n",
      "Epoch 4/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.6509 - accuracy: 0.7414\n",
      "Epoch 5/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.5916 - accuracy: 0.7650\n",
      "Epoch 6/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.5589 - accuracy: 0.7781\n",
      "Epoch 7/60\n",
      "183/183 [==============================] - 19s 106ms/step - loss: 0.5097 - accuracy: 0.7948\n",
      "Epoch 8/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.5012 - accuracy: 0.8003\n",
      "Epoch 9/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.4810 - accuracy: 0.8076\n",
      "Epoch 10/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 2.0977 - accuracy: 0.6813\n",
      "Epoch 11/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.6261 - accuracy: 0.7575\n",
      "Epoch 12/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.5227 - accuracy: 0.7930\n",
      "Epoch 13/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.4777 - accuracy: 0.8115\n",
      "Epoch 14/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.4501 - accuracy: 0.8199\n",
      "Epoch 15/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.4352 - accuracy: 0.8251\n",
      "Epoch 16/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.4236 - accuracy: 0.8294\n",
      "Epoch 17/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.4136 - accuracy: 0.8348\n",
      "Epoch 18/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.4438 - accuracy: 0.8298\n",
      "Epoch 19/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.3891 - accuracy: 0.8456\n",
      "Epoch 20/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.3776 - accuracy: 0.8531\n",
      "Epoch 21/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.3702 - accuracy: 0.8539\n",
      "Epoch 22/60\n",
      "183/183 [==============================] - 19s 106ms/step - loss: 0.3875 - accuracy: 0.8525\n",
      "Epoch 23/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.3589 - accuracy: 0.8593\n",
      "Epoch 24/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.3627 - accuracy: 0.8606\n",
      "Epoch 25/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.3636 - accuracy: 0.8603\n",
      "Epoch 26/60\n",
      "183/183 [==============================] - 19s 106ms/step - loss: 0.3594 - accuracy: 0.8606\n",
      "Epoch 27/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.3516 - accuracy: 0.8646\n",
      "Epoch 28/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.3525 - accuracy: 0.8653\n",
      "Epoch 29/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.3287 - accuracy: 0.8712\n",
      "Epoch 30/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.3496 - accuracy: 0.8679\n",
      "Epoch 31/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.3236 - accuracy: 0.8756\n",
      "Epoch 32/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.3176 - accuracy: 0.8763\n",
      "Epoch 33/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.3599 - accuracy: 0.8670\n",
      "Epoch 34/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.3190 - accuracy: 0.8764\n",
      "Epoch 35/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.3059 - accuracy: 0.8808\n",
      "Epoch 36/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.3330 - accuracy: 0.8729\n",
      "Epoch 37/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.3075 - accuracy: 0.8780\n",
      "Epoch 38/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.2968 - accuracy: 0.8836\n",
      "Epoch 39/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.3101 - accuracy: 0.8807\n",
      "Epoch 40/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.2875 - accuracy: 0.8885\n",
      "Epoch 41/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.6842 - accuracy: 0.8013\n",
      "Epoch 42/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.3374 - accuracy: 0.8729\n",
      "Epoch 43/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.3051 - accuracy: 0.8830\n",
      "Epoch 44/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.2928 - accuracy: 0.8853s - - ETA: 0s - loss: 0.2928 - accuracy: 0.88\n",
      "Epoch 45/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.2836 - accuracy: 0.8901\n",
      "Epoch 46/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.2823 - accuracy: 0.8894\n",
      "Epoch 47/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.2753 - accuracy: 0.8935\n",
      "Epoch 48/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.2654 - accuracy: 0.8974\n",
      "Epoch 49/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.2673 - accuracy: 0.8923\n",
      "Epoch 50/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.2656 - accuracy: 0.8957\n",
      "Epoch 51/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.2591 - accuracy: 0.8988\n",
      "Epoch 52/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.2569 - accuracy: 0.9001\n",
      "Epoch 53/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.2591 - accuracy: 0.8986\n",
      "Epoch 54/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.2549 - accuracy: 0.9003\n",
      "Epoch 55/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.4173 - accuracy: 0.8635\n",
      "Epoch 56/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.2728 - accuracy: 0.8962\n",
      "Epoch 57/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.2610 - accuracy: 0.8992\n",
      "Epoch 58/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.2468 - accuracy: 0.9040\n",
      "Epoch 59/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.2423 - accuracy: 0.9056\n",
      "Epoch 60/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.2647 - accuracy: 0.9006\n",
      "46/46 [==============================] - 2s 35ms/step - loss: 0.4794 - accuracy: 0.8399\n",
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_75 (Conv1D)           (None, 86, 512)           8192      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_25 (MaxPooling (None, 43, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_76 (Conv1D)           (None, 39, 768)           1966848   \n",
      "_________________________________________________________________\n",
      "average_pooling1d_25 (Averag (None, 19, 768)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_77 (Conv1D)           (None, 15, 768)           2949888   \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_25  (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dense_75 (Dense)             (None, 256)               196864    \n",
      "_________________________________________________________________\n",
      "dropout_50 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_76 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_51 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_77 (Dense)             (None, 6)                 1542      \n",
      "=================================================================\n",
      "Total params: 5,189,126\n",
      "Trainable params: 5,189,126\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183/183 [==============================] - 19s 105ms/step - loss: 1.1701 - accuracy: 0.5040\n",
      "Epoch 2/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.9085 - accuracy: 0.6364\n",
      "Epoch 3/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.7335 - accuracy: 0.7078\n",
      "Epoch 4/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.6168 - accuracy: 0.7525\n",
      "Epoch 5/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.5710 - accuracy: 0.7708\n",
      "Epoch 6/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.5281 - accuracy: 0.7881\n",
      "Epoch 7/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.5836 - accuracy: 0.7695\n",
      "Epoch 8/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.4716 - accuracy: 0.8091\n",
      "Epoch 9/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 4.0124 - accuracy: 0.5414\n",
      "Epoch 10/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.7360 - accuracy: 0.7035\n",
      "Epoch 11/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.6655 - accuracy: 0.7361\n",
      "Epoch 12/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.5638 - accuracy: 0.7770\n",
      "Epoch 13/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.5302 - accuracy: 0.7892\n",
      "Epoch 14/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.4995 - accuracy: 0.7994\n",
      "Epoch 15/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.4775 - accuracy: 0.8087\n",
      "Epoch 16/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.4606 - accuracy: 0.8155\n",
      "Epoch 17/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.4413 - accuracy: 0.8245\n",
      "Epoch 18/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.4412 - accuracy: 0.8242\n",
      "Epoch 19/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.4376 - accuracy: 0.8261\n",
      "Epoch 20/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.4128 - accuracy: 0.8389\n",
      "Epoch 21/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.4126 - accuracy: 0.8369\n",
      "Epoch 22/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.3957 - accuracy: 0.8424\n",
      "Epoch 23/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.3876 - accuracy: 0.8481\n",
      "Epoch 24/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.3892 - accuracy: 0.8491\n",
      "Epoch 25/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.3932 - accuracy: 0.8435\n",
      "Epoch 26/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.3679 - accuracy: 0.8547\n",
      "Epoch 27/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.3877 - accuracy: 0.8512\n",
      "Epoch 28/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.3556 - accuracy: 0.8619\n",
      "Epoch 29/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.3893 - accuracy: 0.8506\n",
      "Epoch 30/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.3457 - accuracy: 0.8651\n",
      "Epoch 31/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.3561 - accuracy: 0.8614\n",
      "Epoch 32/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.3391 - accuracy: 0.8665\n",
      "Epoch 33/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.3354 - accuracy: 0.8689\n",
      "Epoch 34/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.3659 - accuracy: 0.8607\n",
      "Epoch 35/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.3362 - accuracy: 0.8710\n",
      "Epoch 36/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.3327 - accuracy: 0.8719\n",
      "Epoch 37/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.3232 - accuracy: 0.8754\n",
      "Epoch 38/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.3261 - accuracy: 0.8745\n",
      "Epoch 39/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.3130 - accuracy: 0.8787\n",
      "Epoch 40/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.3203 - accuracy: 0.8753\n",
      "Epoch 41/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.3819 - accuracy: 0.8611\n",
      "Epoch 42/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.3069 - accuracy: 0.8810\n",
      "Epoch 43/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.3056 - accuracy: 0.8812\n",
      "Epoch 44/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.2976 - accuracy: 0.8837\n",
      "Epoch 45/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.2966 - accuracy: 0.8837\n",
      "Epoch 46/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.3059 - accuracy: 0.8831\n",
      "Epoch 47/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.2893 - accuracy: 0.8878\n",
      "Epoch 48/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.2928 - accuracy: 0.8862\n",
      "Epoch 49/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.2947 - accuracy: 0.8854\n",
      "Epoch 50/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.2968 - accuracy: 0.8864\n",
      "Epoch 51/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.2876 - accuracy: 0.8897\n",
      "Epoch 52/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.2750 - accuracy: 0.8928\n",
      "Epoch 53/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.2766 - accuracy: 0.8904\n",
      "Epoch 54/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.2710 - accuracy: 0.8951\n",
      "Epoch 55/60\n",
      "183/183 [==============================] - 19s 106ms/step - loss: 0.3514 - accuracy: 0.8767\n",
      "Epoch 56/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.2723 - accuracy: 0.8934\n",
      "Epoch 57/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.2644 - accuracy: 0.8966\n",
      "Epoch 58/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.2648 - accuracy: 0.8970\n",
      "Epoch 59/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.2588 - accuracy: 0.8982\n",
      "Epoch 60/60\n",
      "183/183 [==============================] - 19s 105ms/step - loss: 0.2538 - accuracy: 0.9013\n",
      "46/46 [==============================] - 2s 33ms/step - loss: 0.5715 - accuracy: 0.8179\n",
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_78 (Conv1D)           (None, 88, 256)           2560      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_26 (MaxPooling (None, 44, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_79 (Conv1D)           (None, 40, 256)           327936    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_26 (Averag (None, 10, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_80 (Conv1D)           (None, 6, 256)            327936    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_26  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_78 (Dense)             (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_52 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_79 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_53 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_80 (Dense)             (None, 6)                 3078      \n",
      "=================================================================\n",
      "Total params: 1,055,750\n",
      "Trainable params: 1,055,750\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183/183 [==============================] - 4s 24ms/step - loss: 1.0955 - accuracy: 0.5355\n",
      "Epoch 2/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.7367 - accuracy: 0.7057\n",
      "Epoch 3/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.5117 - accuracy: 0.8096\n",
      "Epoch 4/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.4010 - accuracy: 0.8504\n",
      "Epoch 5/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.3606 - accuracy: 0.8658\n",
      "Epoch 6/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.2990 - accuracy: 0.8870\n",
      "Epoch 7/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.2735 - accuracy: 0.8987\n",
      "Epoch 8/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.2570 - accuracy: 0.9041\n",
      "Epoch 9/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.2852 - accuracy: 0.8982\n",
      "Epoch 10/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.2302 - accuracy: 0.9151\n",
      "Epoch 11/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.2355 - accuracy: 0.9145\n",
      "Epoch 12/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.2082 - accuracy: 0.9224\n",
      "Epoch 13/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.2035 - accuracy: 0.9242\n",
      "Epoch 14/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.1884 - accuracy: 0.9304\n",
      "Epoch 15/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.1854 - accuracy: 0.9323\n",
      "Epoch 16/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.1793 - accuracy: 0.9329\n",
      "Epoch 17/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.1734 - accuracy: 0.9355\n",
      "Epoch 18/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.1639 - accuracy: 0.9379\n",
      "Epoch 19/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.1597 - accuracy: 0.9405\n",
      "Epoch 20/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.1635 - accuracy: 0.9395\n",
      "Epoch 21/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.1538 - accuracy: 0.9434\n",
      "Epoch 22/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.1491 - accuracy: 0.9444\n",
      "Epoch 23/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.1523 - accuracy: 0.9432\n",
      "Epoch 24/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.1396 - accuracy: 0.9472\n",
      "Epoch 25/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.1366 - accuracy: 0.9482\n",
      "Epoch 26/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.1349 - accuracy: 0.9491\n",
      "Epoch 27/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.1291 - accuracy: 0.9521\n",
      "Epoch 28/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.1261 - accuracy: 0.9528\n",
      "Epoch 29/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.1207 - accuracy: 0.9546\n",
      "Epoch 30/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.1250 - accuracy: 0.9532\n",
      "Epoch 31/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.1162 - accuracy: 0.9561\n",
      "Epoch 32/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.1089 - accuracy: 0.9584\n",
      "Epoch 33/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.1121 - accuracy: 0.9580\n",
      "Epoch 34/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.1078 - accuracy: 0.9598\n",
      "Epoch 35/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.1037 - accuracy: 0.9614\n",
      "Epoch 36/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.1028 - accuracy: 0.9617\n",
      "Epoch 37/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.1042 - accuracy: 0.9615\n",
      "Epoch 38/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.1047 - accuracy: 0.9609\n",
      "Epoch 39/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.0949 - accuracy: 0.9640\n",
      "Epoch 40/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.0960 - accuracy: 0.9638\n",
      "Epoch 41/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.0959 - accuracy: 0.9642\n",
      "Epoch 42/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.0903 - accuracy: 0.9662\n",
      "Epoch 43/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.0904 - accuracy: 0.9665\n",
      "Epoch 44/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.0891 - accuracy: 0.9662 0s - loss: 0.0886 - accura\n",
      "Epoch 45/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.0885 - accuracy: 0.9665\n",
      "Epoch 46/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.0925 - accuracy: 0.9651\n",
      "Epoch 47/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.0857 - accuracy: 0.9684\n",
      "Epoch 48/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.0826 - accuracy: 0.9693\n",
      "Epoch 49/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.0838 - accuracy: 0.9686\n",
      "Epoch 50/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.0803 - accuracy: 0.9698\n",
      "Epoch 51/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.0820 - accuracy: 0.9689\n",
      "Epoch 52/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.0802 - accuracy: 0.9703\n",
      "Epoch 53/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.0795 - accuracy: 0.9697\n",
      "Epoch 54/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.0766 - accuracy: 0.9709\n",
      "Epoch 55/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.0781 - accuracy: 0.9707\n",
      "Epoch 56/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.0792 - accuracy: 0.9690\n",
      "Epoch 57/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.0752 - accuracy: 0.9720\n",
      "Epoch 58/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.0784 - accuracy: 0.9706\n",
      "Epoch 59/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.0726 - accuracy: 0.9722\n",
      "Epoch 60/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.0708 - accuracy: 0.9729\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.2816 - accuracy: 0.9430\n",
      "Model: \"sequential_27\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_81 (Conv1D)           (None, 88, 256)           2560      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_27 (MaxPooling (None, 44, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_82 (Conv1D)           (None, 40, 256)           327936    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_27 (Averag (None, 10, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_83 (Conv1D)           (None, 6, 256)            327936    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_27  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_81 (Dense)             (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_54 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_82 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_55 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_83 (Dense)             (None, 6)                 3078      \n",
      "=================================================================\n",
      "Total params: 1,055,750\n",
      "Trainable params: 1,055,750\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 1.0964 - accuracy: 0.5363\n",
      "Epoch 2/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183/183 [==============================] - 4s 24ms/step - loss: 0.7355 - accuracy: 0.7088\n",
      "Epoch 3/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.5318 - accuracy: 0.8073\n",
      "Epoch 4/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.3910 - accuracy: 0.8585\n",
      "Epoch 5/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.3276 - accuracy: 0.8809\n",
      "Epoch 6/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.2971 - accuracy: 0.8907\n",
      "Epoch 7/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.2830 - accuracy: 0.8966\n",
      "Epoch 8/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.2672 - accuracy: 0.9007\n",
      "Epoch 9/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.2432 - accuracy: 0.9089\n",
      "Epoch 10/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.2921 - accuracy: 0.8989\n",
      "Epoch 11/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.2269 - accuracy: 0.9165\n",
      "Epoch 12/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.2103 - accuracy: 0.9216\n",
      "Epoch 13/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.2155 - accuracy: 0.9217\n",
      "Epoch 14/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.2029 - accuracy: 0.9267\n",
      "Epoch 15/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.2018 - accuracy: 0.9254\n",
      "Epoch 16/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.1823 - accuracy: 0.9331\n",
      "Epoch 17/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.1762 - accuracy: 0.9352\n",
      "Epoch 18/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.1679 - accuracy: 0.9378\n",
      "Epoch 19/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.1618 - accuracy: 0.9394\n",
      "Epoch 20/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.1640 - accuracy: 0.9390\n",
      "Epoch 21/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.1525 - accuracy: 0.9441\n",
      "Epoch 22/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.1825 - accuracy: 0.9357\n",
      "Epoch 23/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.1393 - accuracy: 0.9478\n",
      "Epoch 24/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.1376 - accuracy: 0.9499\n",
      "Epoch 25/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.1396 - accuracy: 0.9475\n",
      "Epoch 26/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.1336 - accuracy: 0.9502\n",
      "Epoch 27/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.1208 - accuracy: 0.9555\n",
      "Epoch 28/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.1189 - accuracy: 0.9557\n",
      "Epoch 29/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.1220 - accuracy: 0.9552\n",
      "Epoch 30/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.1225 - accuracy: 0.9550\n",
      "Epoch 31/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.1164 - accuracy: 0.9560\n",
      "Epoch 32/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.1104 - accuracy: 0.9594\n",
      "Epoch 33/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.1069 - accuracy: 0.9600\n",
      "Epoch 34/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.1073 - accuracy: 0.9603\n",
      "Epoch 35/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.0996 - accuracy: 0.9631\n",
      "Epoch 36/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.1032 - accuracy: 0.9608\n",
      "Epoch 37/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.0978 - accuracy: 0.9630 0s - loss: 0.0\n",
      "Epoch 38/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.0999 - accuracy: 0.9624\n",
      "Epoch 39/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.0957 - accuracy: 0.9647\n",
      "Epoch 40/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.0989 - accuracy: 0.9622\n",
      "Epoch 41/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.1021 - accuracy: 0.9622\n",
      "Epoch 42/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.0922 - accuracy: 0.9660\n",
      "Epoch 43/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.0896 - accuracy: 0.9671\n",
      "Epoch 44/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.0867 - accuracy: 0.9675\n",
      "Epoch 45/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.0925 - accuracy: 0.9658\n",
      "Epoch 46/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.0851 - accuracy: 0.9680\n",
      "Epoch 47/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.0972 - accuracy: 0.9644\n",
      "Epoch 48/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.0917 - accuracy: 0.9660\n",
      "Epoch 49/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.0824 - accuracy: 0.9697\n",
      "Epoch 50/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.0900 - accuracy: 0.9664\n",
      "Epoch 51/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.0849 - accuracy: 0.9685\n",
      "Epoch 52/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.0804 - accuracy: 0.9698 0s - loss: 0.0809 \n",
      "Epoch 53/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.0747 - accuracy: 0.9718\n",
      "Epoch 54/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.0807 - accuracy: 0.9698\n",
      "Epoch 55/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.0755 - accuracy: 0.9725\n",
      "Epoch 56/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.0761 - accuracy: 0.9715\n",
      "Epoch 57/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.0734 - accuracy: 0.9729\n",
      "Epoch 58/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.0734 - accuracy: 0.9719\n",
      "Epoch 59/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.0758 - accuracy: 0.9732\n",
      "Epoch 60/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.0752 - accuracy: 0.9724\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.2884 - accuracy: 0.9428\n",
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_84 (Conv1D)           (None, 88, 256)           2560      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_28 (MaxPooling (None, 44, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_85 (Conv1D)           (None, 40, 256)           327936    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_28 (Averag (None, 10, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_86 (Conv1D)           (None, 6, 256)            327936    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_28  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_84 (Dense)             (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_56 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_85 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_57 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_86 (Dense)             (None, 6)                 3078      \n",
      "=================================================================\n",
      "Total params: 1,055,750\n",
      "Trainable params: 1,055,750\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 1.1103 - accuracy: 0.5343\n",
      "Epoch 2/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.7334 - accuracy: 0.7053\n",
      "Epoch 3/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183/183 [==============================] - 4s 24ms/step - loss: 0.5129 - accuracy: 0.8112\n",
      "Epoch 4/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.3892 - accuracy: 0.8582\n",
      "Epoch 5/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.3348 - accuracy: 0.8756\n",
      "Epoch 6/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.3039 - accuracy: 0.8871\n",
      "Epoch 7/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.2774 - accuracy: 0.8976\n",
      "Epoch 8/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.2988 - accuracy: 0.8927\n",
      "Epoch 9/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.2511 - accuracy: 0.9065\n",
      "Epoch 10/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.2632 - accuracy: 0.9051\n",
      "Epoch 11/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.2318 - accuracy: 0.9140\n",
      "Epoch 12/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.2082 - accuracy: 0.9221\n",
      "Epoch 13/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.1955 - accuracy: 0.9283\n",
      "Epoch 14/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.1896 - accuracy: 0.9286\n",
      "Epoch 15/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.1899 - accuracy: 0.9295\n",
      "Epoch 16/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.1768 - accuracy: 0.9334\n",
      "Epoch 17/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.1651 - accuracy: 0.9380\n",
      "Epoch 18/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.1617 - accuracy: 0.9395\n",
      "Epoch 19/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.1564 - accuracy: 0.9425\n",
      "Epoch 20/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.1638 - accuracy: 0.9399\n",
      "Epoch 21/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.1427 - accuracy: 0.9481\n",
      "Epoch 22/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.1542 - accuracy: 0.9438\n",
      "Epoch 23/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.1456 - accuracy: 0.9458\n",
      "Epoch 24/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.1315 - accuracy: 0.9511\n",
      "Epoch 25/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.1299 - accuracy: 0.9519\n",
      "Epoch 26/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.1289 - accuracy: 0.9519\n",
      "Epoch 27/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.1300 - accuracy: 0.9529\n",
      "Epoch 28/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.1252 - accuracy: 0.9541\n",
      "Epoch 29/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.1189 - accuracy: 0.9555\n",
      "Epoch 30/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.1238 - accuracy: 0.9547\n",
      "Epoch 31/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.1119 - accuracy: 0.9591\n",
      "Epoch 32/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.1046 - accuracy: 0.9613\n",
      "Epoch 33/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.1048 - accuracy: 0.9612\n",
      "Epoch 34/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.1039 - accuracy: 0.9614\n",
      "Epoch 35/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.1057 - accuracy: 0.9600\n",
      "Epoch 36/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.1038 - accuracy: 0.9624\n",
      "Epoch 37/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.0969 - accuracy: 0.9642\n",
      "Epoch 38/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.0951 - accuracy: 0.9644\n",
      "Epoch 39/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.0929 - accuracy: 0.9659\n",
      "Epoch 40/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.0908 - accuracy: 0.9661\n",
      "Epoch 41/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.0926 - accuracy: 0.9654\n",
      "Epoch 42/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.0889 - accuracy: 0.9679\n",
      "Epoch 43/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.0893 - accuracy: 0.9673\n",
      "Epoch 44/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.0839 - accuracy: 0.9684\n",
      "Epoch 45/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.0842 - accuracy: 0.9685\n",
      "Epoch 46/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.0968 - accuracy: 0.9639\n",
      "Epoch 47/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.0823 - accuracy: 0.9682\n",
      "Epoch 48/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.0856 - accuracy: 0.9665\n",
      "Epoch 49/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.0830 - accuracy: 0.9682\n",
      "Epoch 50/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.0824 - accuracy: 0.9688\n",
      "Epoch 51/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.0774 - accuracy: 0.9715\n",
      "Epoch 52/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.0737 - accuracy: 0.9726\n",
      "Epoch 53/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.0741 - accuracy: 0.9731\n",
      "Epoch 54/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.0836 - accuracy: 0.9701\n",
      "Epoch 55/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.1115 - accuracy: 0.9625\n",
      "Epoch 56/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.0793 - accuracy: 0.9711\n",
      "Epoch 57/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.0755 - accuracy: 0.9721\n",
      "Epoch 58/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.0771 - accuracy: 0.9722\n",
      "Epoch 59/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.0672 - accuracy: 0.9749\n",
      "Epoch 60/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.0715 - accuracy: 0.9735\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.3311 - accuracy: 0.9343\n",
      "Model: \"sequential_29\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_87 (Conv1D)           (None, 88, 256)           2560      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_29 (MaxPooling (None, 44, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_88 (Conv1D)           (None, 40, 256)           327936    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_29 (Averag (None, 10, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_89 (Conv1D)           (None, 6, 256)            327936    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_29  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_87 (Dense)             (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_58 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_88 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_59 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_89 (Dense)             (None, 6)                 3078      \n",
      "=================================================================\n",
      "Total params: 1,055,750\n",
      "Trainable params: 1,055,750\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 1.1089 - accuracy: 0.5343\n",
      "Epoch 2/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.7445 - accuracy: 0.7050\n",
      "Epoch 3/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.4982 - accuracy: 0.8141\n",
      "Epoch 4/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183/183 [==============================] - 4s 24ms/step - loss: 0.3920 - accuracy: 0.8551\n",
      "Epoch 5/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.3284 - accuracy: 0.8768\n",
      "Epoch 6/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.2971 - accuracy: 0.8877 0s - loss: 0.3016 - ac - ETA: 0s - loss: 0.2993 \n",
      "Epoch 7/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.2997 - accuracy: 0.8895\n",
      "Epoch 8/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.2593 - accuracy: 0.9009\n",
      "Epoch 9/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.2430 - accuracy: 0.9078\n",
      "Epoch 10/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.2449 - accuracy: 0.9079\n",
      "Epoch 11/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.2266 - accuracy: 0.9170\n",
      "Epoch 12/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.2101 - accuracy: 0.9211\n",
      "Epoch 13/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.2045 - accuracy: 0.9232\n",
      "Epoch 14/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.1907 - accuracy: 0.9285\n",
      "Epoch 15/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.1951 - accuracy: 0.9267\n",
      "Epoch 16/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.1948 - accuracy: 0.9287\n",
      "Epoch 17/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.1689 - accuracy: 0.9363\n",
      "Epoch 18/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.1642 - accuracy: 0.9385\n",
      "Epoch 19/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.1647 - accuracy: 0.9385\n",
      "Epoch 20/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.1613 - accuracy: 0.9396\n",
      "Epoch 21/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.1541 - accuracy: 0.9416\n",
      "Epoch 22/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.1515 - accuracy: 0.9434\n",
      "Epoch 23/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.1476 - accuracy: 0.9433\n",
      "Epoch 24/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.1429 - accuracy: 0.9462\n",
      "Epoch 25/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.1327 - accuracy: 0.9487\n",
      "Epoch 26/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.1320 - accuracy: 0.9498\n",
      "Epoch 27/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.1269 - accuracy: 0.9518\n",
      "Epoch 28/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.1258 - accuracy: 0.9522\n",
      "Epoch 29/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.1295 - accuracy: 0.9515\n",
      "Epoch 30/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.1173 - accuracy: 0.9555\n",
      "Epoch 31/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.1189 - accuracy: 0.9550\n",
      "Epoch 32/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.1097 - accuracy: 0.9585\n",
      "Epoch 33/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.1093 - accuracy: 0.9577\n",
      "Epoch 34/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.1072 - accuracy: 0.9590\n",
      "Epoch 35/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.1100 - accuracy: 0.9578\n",
      "Epoch 36/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.1098 - accuracy: 0.9589\n",
      "Epoch 37/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.0992 - accuracy: 0.9623\n",
      "Epoch 38/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.1002 - accuracy: 0.9622\n",
      "Epoch 39/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.0945 - accuracy: 0.9651\n",
      "Epoch 40/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.0952 - accuracy: 0.9650\n",
      "Epoch 41/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.0924 - accuracy: 0.9664\n",
      "Epoch 42/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.0955 - accuracy: 0.9638\n",
      "Epoch 43/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.0913 - accuracy: 0.9663\n",
      "Epoch 44/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.0900 - accuracy: 0.9667\n",
      "Epoch 45/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.0860 - accuracy: 0.9680\n",
      "Epoch 46/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.0833 - accuracy: 0.9683\n",
      "Epoch 47/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.0862 - accuracy: 0.9684\n",
      "Epoch 48/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.0856 - accuracy: 0.9685\n",
      "Epoch 49/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.0811 - accuracy: 0.9699\n",
      "Epoch 50/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.0803 - accuracy: 0.9705\n",
      "Epoch 51/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.0805 - accuracy: 0.9698\n",
      "Epoch 52/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.0790 - accuracy: 0.9710\n",
      "Epoch 53/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.0784 - accuracy: 0.9704\n",
      "Epoch 54/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.0769 - accuracy: 0.9719\n",
      "Epoch 55/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.0812 - accuracy: 0.9700\n",
      "Epoch 56/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.0788 - accuracy: 0.9708\n",
      "Epoch 57/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.0717 - accuracy: 0.9734\n",
      "Epoch 58/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.0733 - accuracy: 0.9732\n",
      "Epoch 59/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.0691 - accuracy: 0.9746\n",
      "Epoch 60/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.0697 - accuracy: 0.9741\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.3284 - accuracy: 0.9396\n",
      "Model: \"sequential_30\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_90 (Conv1D)           (None, 88, 256)           2560      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_30 (MaxPooling (None, 44, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_91 (Conv1D)           (None, 40, 256)           327936    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_30 (Averag (None, 10, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_92 (Conv1D)           (None, 6, 256)            327936    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_30  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_90 (Dense)             (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_60 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_91 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_61 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_92 (Dense)             (None, 6)                 3078      \n",
      "=================================================================\n",
      "Total params: 1,055,750\n",
      "Trainable params: 1,055,750\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 1.1022 - accuracy: 0.5368\n",
      "Epoch 2/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.7315 - accuracy: 0.7052\n",
      "Epoch 3/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.5058 - accuracy: 0.8133\n",
      "Epoch 4/60\n",
      "183/183 [==============================] - 4s 23ms/step - loss: 0.3788 - accuracy: 0.8586\n",
      "Epoch 5/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183/183 [==============================] - 4s 24ms/step - loss: 0.3586 - accuracy: 0.8669\n",
      "Epoch 6/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.3070 - accuracy: 0.8843\n",
      "Epoch 7/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.2813 - accuracy: 0.8948\n",
      "Epoch 8/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.2742 - accuracy: 0.8959\n",
      "Epoch 9/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.2514 - accuracy: 0.9047\n",
      "Epoch 10/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.2523 - accuracy: 0.9067\n",
      "Epoch 11/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.2345 - accuracy: 0.9121\n",
      "Epoch 12/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.2122 - accuracy: 0.9211\n",
      "Epoch 13/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.2038 - accuracy: 0.9239\n",
      "Epoch 14/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.1958 - accuracy: 0.9262\n",
      "Epoch 15/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.1858 - accuracy: 0.9302\n",
      "Epoch 16/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.1759 - accuracy: 0.9333\n",
      "Epoch 17/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.1703 - accuracy: 0.9365\n",
      "Epoch 18/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.1654 - accuracy: 0.9369\n",
      "Epoch 19/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.1890 - accuracy: 0.9331\n",
      "Epoch 20/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.1587 - accuracy: 0.9407 0s - loss: 0\n",
      "Epoch 21/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.1461 - accuracy: 0.9452\n",
      "Epoch 22/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.1443 - accuracy: 0.9458\n",
      "Epoch 23/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.1406 - accuracy: 0.9473\n",
      "Epoch 24/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.1340 - accuracy: 0.9498\n",
      "Epoch 25/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.1365 - accuracy: 0.9493\n",
      "Epoch 26/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.1312 - accuracy: 0.9512\n",
      "Epoch 27/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.1321 - accuracy: 0.9506\n",
      "Epoch 28/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.1219 - accuracy: 0.9539\n",
      "Epoch 29/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.1392 - accuracy: 0.9476\n",
      "Epoch 30/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.1231 - accuracy: 0.9539\n",
      "Epoch 31/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.1170 - accuracy: 0.9559 1s\n",
      "Epoch 32/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.1093 - accuracy: 0.9582\n",
      "Epoch 33/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.1093 - accuracy: 0.9592\n",
      "Epoch 34/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.1040 - accuracy: 0.9596\n",
      "Epoch 35/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.1048 - accuracy: 0.9611\n",
      "Epoch 36/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.1021 - accuracy: 0.9612\n",
      "Epoch 37/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.1031 - accuracy: 0.9617\n",
      "Epoch 38/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.0981 - accuracy: 0.9630\n",
      "Epoch 39/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.1018 - accuracy: 0.9610\n",
      "Epoch 40/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.0984 - accuracy: 0.9630\n",
      "Epoch 41/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.1013 - accuracy: 0.9612\n",
      "Epoch 42/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.0925 - accuracy: 0.9639\n",
      "Epoch 43/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.0893 - accuracy: 0.9664\n",
      "Epoch 44/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.0999 - accuracy: 0.9636\n",
      "Epoch 45/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.0921 - accuracy: 0.9653\n",
      "Epoch 46/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.0845 - accuracy: 0.9686\n",
      "Epoch 47/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.0876 - accuracy: 0.9675\n",
      "Epoch 48/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.0775 - accuracy: 0.9697\n",
      "Epoch 49/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.0846 - accuracy: 0.9683\n",
      "Epoch 50/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.0791 - accuracy: 0.9706\n",
      "Epoch 51/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.0816 - accuracy: 0.9693\n",
      "Epoch 52/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.0769 - accuracy: 0.9708\n",
      "Epoch 53/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.0807 - accuracy: 0.9694\n",
      "Epoch 54/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.0815 - accuracy: 0.9697\n",
      "Epoch 55/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.0747 - accuracy: 0.9719\n",
      "Epoch 56/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.0742 - accuracy: 0.9719\n",
      "Epoch 57/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.0763 - accuracy: 0.9704\n",
      "Epoch 58/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.0728 - accuracy: 0.9720\n",
      "Epoch 59/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.0701 - accuracy: 0.9738\n",
      "Epoch 60/60\n",
      "183/183 [==============================] - 4s 24ms/step - loss: 0.0656 - accuracy: 0.9756\n",
      "46/46 [==============================] - 0s 9ms/step - loss: 0.2722 - accuracy: 0.9471\n",
      "Model: \"sequential_31\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_93 (Conv1D)           (None, 88, 256)           2560      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_31 (MaxPooling (None, 22, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_94 (Conv1D)           (None, 18, 256)           327936    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_31 (Averag (None, 9, 256)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_95 (Conv1D)           (None, 5, 256)            327936    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_31  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_93 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_62 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_94 (Dense)             (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_63 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_95 (Dense)             (None, 6)                 3078      \n",
      "=================================================================\n",
      "Total params: 858,886\n",
      "Trainable params: 858,886\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/60\n",
      "  1/183 [..............................] - ETA: 1s - loss: 1.7913 - accuracy: 0.1484WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0080s vs `on_train_batch_end` time: 0.0120s). Check your callbacks.\n",
      "183/183 [==============================] - 3s 19ms/step - loss: 1.1328 - accuracy: 0.5188\n",
      "Epoch 2/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.7579 - accuracy: 0.7021\n",
      "Epoch 3/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.5228 - accuracy: 0.8112\n",
      "Epoch 4/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183/183 [==============================] - 3s 18ms/step - loss: 0.4101 - accuracy: 0.8491\n",
      "Epoch 5/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.3446 - accuracy: 0.8734\n",
      "Epoch 6/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.3621 - accuracy: 0.8717\n",
      "Epoch 7/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.2914 - accuracy: 0.8944\n",
      "Epoch 8/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.2759 - accuracy: 0.8990\n",
      "Epoch 9/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.2677 - accuracy: 0.9030\n",
      "Epoch 10/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.2487 - accuracy: 0.9079\n",
      "Epoch 11/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.2358 - accuracy: 0.9144\n",
      "Epoch 12/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.2245 - accuracy: 0.9193\n",
      "Epoch 13/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.2176 - accuracy: 0.9198\n",
      "Epoch 14/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.1989 - accuracy: 0.9272\n",
      "Epoch 15/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.1909 - accuracy: 0.9308\n",
      "Epoch 16/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.1988 - accuracy: 0.9289\n",
      "Epoch 17/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.1780 - accuracy: 0.9372\n",
      "Epoch 18/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.1696 - accuracy: 0.9381\n",
      "Epoch 19/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.1619 - accuracy: 0.9411\n",
      "Epoch 20/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.2101 - accuracy: 0.9295\n",
      "Epoch 21/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.1596 - accuracy: 0.9424\n",
      "Epoch 22/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.1490 - accuracy: 0.9460\n",
      "Epoch 23/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.1466 - accuracy: 0.9469\n",
      "Epoch 24/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.1389 - accuracy: 0.9497\n",
      "Epoch 25/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.1370 - accuracy: 0.9505\n",
      "Epoch 26/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.1339 - accuracy: 0.9521\n",
      "Epoch 27/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.1286 - accuracy: 0.9541\n",
      "Epoch 28/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.1249 - accuracy: 0.9549\n",
      "Epoch 29/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.1216 - accuracy: 0.9561\n",
      "Epoch 30/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.1192 - accuracy: 0.9565\n",
      "Epoch 31/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.1244 - accuracy: 0.9557\n",
      "Epoch 32/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.1173 - accuracy: 0.9574\n",
      "Epoch 33/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.1197 - accuracy: 0.9564\n",
      "Epoch 34/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.1121 - accuracy: 0.9600\n",
      "Epoch 35/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.1124 - accuracy: 0.9588\n",
      "Epoch 36/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.1031 - accuracy: 0.9626\n",
      "Epoch 37/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.1064 - accuracy: 0.9612\n",
      "Epoch 38/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.0996 - accuracy: 0.9635\n",
      "Epoch 39/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.1102 - accuracy: 0.9595\n",
      "Epoch 40/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.1047 - accuracy: 0.9625\n",
      "Epoch 41/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.1018 - accuracy: 0.9618\n",
      "Epoch 42/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.1098 - accuracy: 0.9593\n",
      "Epoch 43/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.0991 - accuracy: 0.9638\n",
      "Epoch 44/60\n",
      "183/183 [==============================] - 3s 19ms/step - loss: 0.0962 - accuracy: 0.9644\n",
      "Epoch 45/60\n",
      "183/183 [==============================] - 3s 19ms/step - loss: 0.0971 - accuracy: 0.9648\n",
      "Epoch 46/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.0959 - accuracy: 0.9644\n",
      "Epoch 47/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.0862 - accuracy: 0.9678\n",
      "Epoch 48/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.0857 - accuracy: 0.9680\n",
      "Epoch 49/60\n",
      "183/183 [==============================] - 3s 19ms/step - loss: 0.0879 - accuracy: 0.9678\n",
      "Epoch 50/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.0871 - accuracy: 0.9685\n",
      "Epoch 51/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.0879 - accuracy: 0.9692\n",
      "Epoch 52/60\n",
      "183/183 [==============================] - 3s 19ms/step - loss: 0.0882 - accuracy: 0.9676\n",
      "Epoch 53/60\n",
      "183/183 [==============================] - 4s 19ms/step - loss: 0.0830 - accuracy: 0.9696\n",
      "Epoch 54/60\n",
      "183/183 [==============================] - 4s 20ms/step - loss: 0.0861 - accuracy: 0.9688\n",
      "Epoch 55/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.0780 - accuracy: 0.9707\n",
      "Epoch 56/60\n",
      "183/183 [==============================] - 3s 19ms/step - loss: 0.0839 - accuracy: 0.9698\n",
      "Epoch 57/60\n",
      "183/183 [==============================] - 3s 19ms/step - loss: 0.0831 - accuracy: 0.9701\n",
      "Epoch 58/60\n",
      "183/183 [==============================] - 3s 19ms/step - loss: 0.0826 - accuracy: 0.9701\n",
      "Epoch 59/60\n",
      "183/183 [==============================] - 3s 19ms/step - loss: 0.0739 - accuracy: 0.9724\n",
      "Epoch 60/60\n",
      "183/183 [==============================] - 3s 19ms/step - loss: 0.0788 - accuracy: 0.9710\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.2702 - accuracy: 0.9401\n",
      "Model: \"sequential_32\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_96 (Conv1D)           (None, 88, 256)           2560      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_32 (MaxPooling (None, 22, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_97 (Conv1D)           (None, 18, 256)           327936    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_32 (Averag (None, 9, 256)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_98 (Conv1D)           (None, 5, 256)            327936    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_32  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_96 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_64 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_97 (Dense)             (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_65 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_98 (Dense)             (None, 6)                 3078      \n",
      "=================================================================\n",
      "Total params: 858,886\n",
      "Trainable params: 858,886\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/60\n",
      "183/183 [==============================] - 3s 19ms/step - loss: 1.1318 - accuracy: 0.5206\n",
      "Epoch 2/60\n",
      "183/183 [==============================] - 3s 19ms/step - loss: 0.7790 - accuracy: 0.6913\n",
      "Epoch 3/60\n",
      "183/183 [==============================] - 3s 19ms/step - loss: 0.5324 - accuracy: 0.8023\n",
      "Epoch 4/60\n",
      "183/183 [==============================] - 3s 19ms/step - loss: 0.4078 - accuracy: 0.8503\n",
      "Epoch 5/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183/183 [==============================] - 3s 19ms/step - loss: 0.3466 - accuracy: 0.8726\n",
      "Epoch 6/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.3293 - accuracy: 0.8808\n",
      "Epoch 7/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.2941 - accuracy: 0.8913\n",
      "Epoch 8/60\n",
      "183/183 [==============================] - 3s 19ms/step - loss: 0.2761 - accuracy: 0.9008\n",
      "Epoch 9/60\n",
      "183/183 [==============================] - 4s 20ms/step - loss: 0.2570 - accuracy: 0.9079\n",
      "Epoch 10/60\n",
      "183/183 [==============================] - 3s 19ms/step - loss: 0.2517 - accuracy: 0.9077\n",
      "Epoch 11/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.2308 - accuracy: 0.9156\n",
      "Epoch 12/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.2174 - accuracy: 0.9223\n",
      "Epoch 13/60\n",
      "183/183 [==============================] - 3s 19ms/step - loss: 0.2110 - accuracy: 0.9233\n",
      "Epoch 14/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.2008 - accuracy: 0.9272\n",
      "Epoch 15/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.1900 - accuracy: 0.9295\n",
      "Epoch 16/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.1938 - accuracy: 0.9304\n",
      "Epoch 17/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.1777 - accuracy: 0.9360\n",
      "Epoch 18/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.1720 - accuracy: 0.9371\n",
      "Epoch 19/60\n",
      "183/183 [==============================] - 3s 19ms/step - loss: 0.1938 - accuracy: 0.9306\n",
      "Epoch 20/60\n",
      "183/183 [==============================] - 3s 19ms/step - loss: 0.1754 - accuracy: 0.9352\n",
      "Epoch 21/60\n",
      "183/183 [==============================] - 3s 19ms/step - loss: 0.1682 - accuracy: 0.9380\n",
      "Epoch 22/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.1525 - accuracy: 0.9448\n",
      "Epoch 23/60\n",
      "183/183 [==============================] - 3s 19ms/step - loss: 0.1573 - accuracy: 0.9430\n",
      "Epoch 24/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.1555 - accuracy: 0.9421\n",
      "Epoch 25/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.1434 - accuracy: 0.9462\n",
      "Epoch 26/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.1347 - accuracy: 0.9498\n",
      "Epoch 27/60\n",
      "183/183 [==============================] - 3s 19ms/step - loss: 0.1323 - accuracy: 0.9506\n",
      "Epoch 28/60\n",
      "183/183 [==============================] - 3s 19ms/step - loss: 0.1286 - accuracy: 0.9524\n",
      "Epoch 29/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.1277 - accuracy: 0.9519\n",
      "Epoch 30/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.1218 - accuracy: 0.9553\n",
      "Epoch 31/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.1183 - accuracy: 0.9559\n",
      "Epoch 32/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.1152 - accuracy: 0.9571\n",
      "Epoch 33/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.1229 - accuracy: 0.9540\n",
      "Epoch 34/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.1106 - accuracy: 0.9588\n",
      "Epoch 35/60\n",
      "183/183 [==============================] - ETA: 0s - loss: 0.1061 - accuracy: 0.95 - 3s 18ms/step - loss: 0.1064 - accuracy: 0.9598\n",
      "Epoch 36/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.1117 - accuracy: 0.9590\n",
      "Epoch 37/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.1051 - accuracy: 0.9610\n",
      "Epoch 38/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.1031 - accuracy: 0.9614\n",
      "Epoch 39/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.1050 - accuracy: 0.9610\n",
      "Epoch 40/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.1003 - accuracy: 0.9630\n",
      "Epoch 41/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.1016 - accuracy: 0.9624\n",
      "Epoch 42/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.0958 - accuracy: 0.9639\n",
      "Epoch 43/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.0963 - accuracy: 0.9634\n",
      "Epoch 44/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.0969 - accuracy: 0.9646\n",
      "Epoch 45/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.0961 - accuracy: 0.9626\n",
      "Epoch 46/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.0933 - accuracy: 0.9662\n",
      "Epoch 47/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.0864 - accuracy: 0.9676\n",
      "Epoch 48/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.0856 - accuracy: 0.9684\n",
      "Epoch 49/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.0946 - accuracy: 0.9650\n",
      "Epoch 50/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.0871 - accuracy: 0.9676\n",
      "Epoch 51/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.0877 - accuracy: 0.9679\n",
      "Epoch 52/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.0821 - accuracy: 0.9694\n",
      "Epoch 53/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.0836 - accuracy: 0.9688\n",
      "Epoch 54/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.0878 - accuracy: 0.9672\n",
      "Epoch 55/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.0808 - accuracy: 0.9699\n",
      "Epoch 56/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.0780 - accuracy: 0.9704\n",
      "Epoch 57/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.0881 - accuracy: 0.9680\n",
      "Epoch 58/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.0796 - accuracy: 0.9705\n",
      "Epoch 59/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.0788 - accuracy: 0.9711\n",
      "Epoch 60/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.0810 - accuracy: 0.9703\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.3667 - accuracy: 0.9335\n",
      "Model: \"sequential_33\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_99 (Conv1D)           (None, 88, 256)           2560      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_33 (MaxPooling (None, 22, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_100 (Conv1D)          (None, 18, 256)           327936    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_33 (Averag (None, 9, 256)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_101 (Conv1D)          (None, 5, 256)            327936    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_33  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_99 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_66 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_100 (Dense)            (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_67 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_101 (Dense)            (None, 6)                 3078      \n",
      "=================================================================\n",
      "Total params: 858,886\n",
      "Trainable params: 858,886\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 1.1375 - accuracy: 0.5157\n",
      "Epoch 2/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.7730 - accuracy: 0.6943\n",
      "Epoch 3/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.5434 - accuracy: 0.8012\n",
      "Epoch 4/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.4228 - accuracy: 0.8476\n",
      "Epoch 5/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.3596 - accuracy: 0.8668\n",
      "Epoch 6/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183/183 [==============================] - 3s 18ms/step - loss: 0.3389 - accuracy: 0.8764\n",
      "Epoch 7/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.2944 - accuracy: 0.8919\n",
      "Epoch 8/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.2864 - accuracy: 0.8942\n",
      "Epoch 9/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.2598 - accuracy: 0.9035\n",
      "Epoch 10/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.2440 - accuracy: 0.9112\n",
      "Epoch 11/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.2589 - accuracy: 0.9094\n",
      "Epoch 12/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.2342 - accuracy: 0.9183\n",
      "Epoch 13/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.2210 - accuracy: 0.9175\n",
      "Epoch 14/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.2118 - accuracy: 0.9248\n",
      "Epoch 15/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.1961 - accuracy: 0.9284\n",
      "Epoch 16/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.1837 - accuracy: 0.9337\n",
      "Epoch 17/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.1880 - accuracy: 0.9317\n",
      "Epoch 18/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.1726 - accuracy: 0.9378\n",
      "Epoch 19/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.1708 - accuracy: 0.9379\n",
      "Epoch 20/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.1610 - accuracy: 0.9417\n",
      "Epoch 21/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.1602 - accuracy: 0.9407\n",
      "Epoch 22/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.1502 - accuracy: 0.9458\n",
      "Epoch 23/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.1488 - accuracy: 0.9459\n",
      "Epoch 24/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.1438 - accuracy: 0.9488\n",
      "Epoch 25/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.1358 - accuracy: 0.9508\n",
      "Epoch 26/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.1414 - accuracy: 0.9486\n",
      "Epoch 27/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.1300 - accuracy: 0.9534\n",
      "Epoch 28/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.1229 - accuracy: 0.9559\n",
      "Epoch 29/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.1219 - accuracy: 0.9563\n",
      "Epoch 30/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.1217 - accuracy: 0.9554\n",
      "Epoch 31/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.1202 - accuracy: 0.9549\n",
      "Epoch 32/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.1161 - accuracy: 0.9578\n",
      "Epoch 33/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.1083 - accuracy: 0.9596\n",
      "Epoch 34/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.1063 - accuracy: 0.9620\n",
      "Epoch 35/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.1029 - accuracy: 0.9620\n",
      "Epoch 36/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.1091 - accuracy: 0.9613\n",
      "Epoch 37/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.1077 - accuracy: 0.9607\n",
      "Epoch 38/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.0949 - accuracy: 0.9646\n",
      "Epoch 39/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.1008 - accuracy: 0.9644\n",
      "Epoch 40/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.0958 - accuracy: 0.9642\n",
      "Epoch 41/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.0949 - accuracy: 0.9655\n",
      "Epoch 42/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.0949 - accuracy: 0.9658\n",
      "Epoch 43/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.0882 - accuracy: 0.9680\n",
      "Epoch 44/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.0934 - accuracy: 0.9661\n",
      "Epoch 45/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.0905 - accuracy: 0.9667\n",
      "Epoch 46/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.1038 - accuracy: 0.9630\n",
      "Epoch 47/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.0903 - accuracy: 0.9673\n",
      "Epoch 48/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.0843 - accuracy: 0.9691\n",
      "Epoch 49/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.0863 - accuracy: 0.9691\n",
      "Epoch 50/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.0884 - accuracy: 0.9676\n",
      "Epoch 51/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.0823 - accuracy: 0.9703\n",
      "Epoch 52/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.0870 - accuracy: 0.9672\n",
      "Epoch 53/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.0818 - accuracy: 0.9708\n",
      "Epoch 54/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.0822 - accuracy: 0.9706\n",
      "Epoch 55/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.0803 - accuracy: 0.9712\n",
      "Epoch 56/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.0738 - accuracy: 0.9725\n",
      "Epoch 57/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.0743 - accuracy: 0.9739\n",
      "Epoch 58/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.0758 - accuracy: 0.9721\n",
      "Epoch 59/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.0809 - accuracy: 0.9704\n",
      "Epoch 60/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.0746 - accuracy: 0.9724\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.3087 - accuracy: 0.9378\n",
      "Model: \"sequential_34\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_102 (Conv1D)          (None, 88, 256)           2560      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_34 (MaxPooling (None, 22, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_103 (Conv1D)          (None, 18, 256)           327936    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_34 (Averag (None, 9, 256)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_104 (Conv1D)          (None, 5, 256)            327936    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_34  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_102 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_68 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_103 (Dense)            (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_69 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_104 (Dense)            (None, 6)                 3078      \n",
      "=================================================================\n",
      "Total params: 858,886\n",
      "Trainable params: 858,886\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 1.1242 - accuracy: 0.5253\n",
      "Epoch 2/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.7726 - accuracy: 0.6956\n",
      "Epoch 3/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.5296 - accuracy: 0.8068\n",
      "Epoch 4/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.4102 - accuracy: 0.8504\n",
      "Epoch 5/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.3555 - accuracy: 0.8678\n",
      "Epoch 6/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.3213 - accuracy: 0.8783\n",
      "Epoch 7/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183/183 [==============================] - 3s 18ms/step - loss: 0.2926 - accuracy: 0.8912\n",
      "Epoch 8/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.2673 - accuracy: 0.9000\n",
      "Epoch 9/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.2994 - accuracy: 0.8943\n",
      "Epoch 10/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.2446 - accuracy: 0.9104\n",
      "Epoch 11/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.2235 - accuracy: 0.9160\n",
      "Epoch 12/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.2181 - accuracy: 0.9185\n",
      "Epoch 13/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.2129 - accuracy: 0.9227\n",
      "Epoch 14/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.2016 - accuracy: 0.9258\n",
      "Epoch 15/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.2007 - accuracy: 0.9275\n",
      "Epoch 16/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.1879 - accuracy: 0.9326\n",
      "Epoch 17/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.1747 - accuracy: 0.9346\n",
      "Epoch 18/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.1713 - accuracy: 0.9362\n",
      "Epoch 19/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.1868 - accuracy: 0.9335\n",
      "Epoch 20/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.1613 - accuracy: 0.9392\n",
      "Epoch 21/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.1567 - accuracy: 0.9420\n",
      "Epoch 22/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.1547 - accuracy: 0.9426\n",
      "Epoch 23/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.1508 - accuracy: 0.9446\n",
      "Epoch 24/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.1429 - accuracy: 0.9478\n",
      "Epoch 25/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.1374 - accuracy: 0.9490\n",
      "Epoch 26/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.1572 - accuracy: 0.9453\n",
      "Epoch 27/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.1305 - accuracy: 0.9515\n",
      "Epoch 28/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.1305 - accuracy: 0.9501\n",
      "Epoch 29/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.1301 - accuracy: 0.9525\n",
      "Epoch 30/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.1186 - accuracy: 0.9557\n",
      "Epoch 31/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.1170 - accuracy: 0.9569\n",
      "Epoch 32/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.1145 - accuracy: 0.9583\n",
      "Epoch 33/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.1114 - accuracy: 0.9586\n",
      "Epoch 34/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.1109 - accuracy: 0.9592\n",
      "Epoch 35/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.1076 - accuracy: 0.9602\n",
      "Epoch 36/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.1086 - accuracy: 0.9602\n",
      "Epoch 37/60\n",
      "183/183 [==============================] - 3s 19ms/step - loss: 0.1021 - accuracy: 0.9625\n",
      "Epoch 38/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.1015 - accuracy: 0.9634\n",
      "Epoch 39/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.1001 - accuracy: 0.9629\n",
      "Epoch 40/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.1015 - accuracy: 0.9615\n",
      "Epoch 41/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.0980 - accuracy: 0.9642\n",
      "Epoch 42/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.0925 - accuracy: 0.9652\n",
      "Epoch 43/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.0933 - accuracy: 0.9658\n",
      "Epoch 44/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.0979 - accuracy: 0.9637\n",
      "Epoch 45/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.0894 - accuracy: 0.9676\n",
      "Epoch 46/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.0884 - accuracy: 0.9672\n",
      "Epoch 47/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.0891 - accuracy: 0.9671\n",
      "Epoch 48/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.0902 - accuracy: 0.9664\n",
      "Epoch 49/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.0947 - accuracy: 0.9659\n",
      "Epoch 50/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.0841 - accuracy: 0.9688\n",
      "Epoch 51/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.1010 - accuracy: 0.9633\n",
      "Epoch 52/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.1028 - accuracy: 0.9618\n",
      "Epoch 53/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.0947 - accuracy: 0.9646\n",
      "Epoch 54/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.0941 - accuracy: 0.9666\n",
      "Epoch 55/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.0826 - accuracy: 0.9699\n",
      "Epoch 56/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.0817 - accuracy: 0.9698\n",
      "Epoch 57/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.0807 - accuracy: 0.9689\n",
      "Epoch 58/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.0747 - accuracy: 0.9720\n",
      "Epoch 59/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.0740 - accuracy: 0.9731\n",
      "Epoch 60/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.0830 - accuracy: 0.9697\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 0.2973 - accuracy: 0.9361\n",
      "Model: \"sequential_35\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_105 (Conv1D)          (None, 88, 256)           2560      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_35 (MaxPooling (None, 22, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_106 (Conv1D)          (None, 18, 256)           327936    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_35 (Averag (None, 9, 256)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_107 (Conv1D)          (None, 5, 256)            327936    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_35  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_105 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_70 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_106 (Dense)            (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_71 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_107 (Dense)            (None, 6)                 3078      \n",
      "=================================================================\n",
      "Total params: 858,886\n",
      "Trainable params: 858,886\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/60\n",
      "  1/183 [..............................] - ETA: 1s - loss: 1.7862 - accuracy: 0.1641WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0079s vs `on_train_batch_end` time: 0.0130s). Check your callbacks.\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 1.1308 - accuracy: 0.5191\n",
      "Epoch 2/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.7825 - accuracy: 0.6909\n",
      "Epoch 3/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.5395 - accuracy: 0.7989\n",
      "Epoch 4/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.4252 - accuracy: 0.8442\n",
      "Epoch 5/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.3541 - accuracy: 0.8694\n",
      "Epoch 6/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183/183 [==============================] - 3s 18ms/step - loss: 0.3115 - accuracy: 0.8851\n",
      "Epoch 7/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.3089 - accuracy: 0.8880\n",
      "Epoch 8/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.2879 - accuracy: 0.8954\n",
      "Epoch 9/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.2591 - accuracy: 0.9037\n",
      "Epoch 10/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.2391 - accuracy: 0.9113\n",
      "Epoch 11/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.2285 - accuracy: 0.9168\n",
      "Epoch 12/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.2178 - accuracy: 0.9198\n",
      "Epoch 13/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.2062 - accuracy: 0.9254\n",
      "Epoch 14/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.2493 - accuracy: 0.9122\n",
      "Epoch 15/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.1969 - accuracy: 0.9294\n",
      "Epoch 16/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.1862 - accuracy: 0.9315\n",
      "Epoch 17/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.1837 - accuracy: 0.9326\n",
      "Epoch 18/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.1706 - accuracy: 0.9368\n",
      "Epoch 19/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.1673 - accuracy: 0.9379\n",
      "Epoch 20/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.1716 - accuracy: 0.9375\n",
      "Epoch 21/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.1523 - accuracy: 0.9443\n",
      "Epoch 22/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.1644 - accuracy: 0.9397\n",
      "Epoch 23/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.2134 - accuracy: 0.9292\n",
      "Epoch 24/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.1502 - accuracy: 0.9449\n",
      "Epoch 25/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.1444 - accuracy: 0.9476\n",
      "Epoch 26/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.1368 - accuracy: 0.9503\n",
      "Epoch 27/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.1336 - accuracy: 0.9513\n",
      "Epoch 28/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.1269 - accuracy: 0.9539\n",
      "Epoch 29/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.1328 - accuracy: 0.9511\n",
      "Epoch 30/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.1206 - accuracy: 0.9566\n",
      "Epoch 31/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.1197 - accuracy: 0.9566\n",
      "Epoch 32/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.1163 - accuracy: 0.9568\n",
      "Epoch 33/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.1130 - accuracy: 0.9577\n",
      "Epoch 34/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.1123 - accuracy: 0.9598\n",
      "Epoch 35/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.1084 - accuracy: 0.9595\n",
      "Epoch 36/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.1075 - accuracy: 0.9611\n",
      "Epoch 37/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.1041 - accuracy: 0.9629\n",
      "Epoch 38/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.1002 - accuracy: 0.9632\n",
      "Epoch 39/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.0987 - accuracy: 0.9638\n",
      "Epoch 40/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.0974 - accuracy: 0.9632\n",
      "Epoch 41/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.1020 - accuracy: 0.9633\n",
      "Epoch 42/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.0969 - accuracy: 0.9644\n",
      "Epoch 43/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.0926 - accuracy: 0.9661\n",
      "Epoch 44/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.0943 - accuracy: 0.9657\n",
      "Epoch 45/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.0948 - accuracy: 0.9644\n",
      "Epoch 46/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.0907 - accuracy: 0.9660\n",
      "Epoch 47/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.0932 - accuracy: 0.9665\n",
      "Epoch 48/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.0912 - accuracy: 0.9669\n",
      "Epoch 49/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.0880 - accuracy: 0.9669\n",
      "Epoch 50/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.0885 - accuracy: 0.9668\n",
      "Epoch 51/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.0862 - accuracy: 0.9684\n",
      "Epoch 52/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.0851 - accuracy: 0.9688\n",
      "Epoch 53/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.0834 - accuracy: 0.9695\n",
      "Epoch 54/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.0989 - accuracy: 0.9643\n",
      "Epoch 55/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.0832 - accuracy: 0.9691\n",
      "Epoch 56/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.0841 - accuracy: 0.9695\n",
      "Epoch 57/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.0801 - accuracy: 0.9706\n",
      "Epoch 58/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.0794 - accuracy: 0.9711\n",
      "Epoch 59/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.1032 - accuracy: 0.9624\n",
      "Epoch 60/60\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.0801 - accuracy: 0.9710\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 0.2977 - accuracy: 0.9364\n",
      "Model: \"sequential_36\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_108 (Conv1D)          (None, 88, 768)           7680      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_36 (MaxPooling (None, 22, 768)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_109 (Conv1D)          (None, 18, 768)           2949888   \n",
      "_________________________________________________________________\n",
      "average_pooling1d_36 (Averag (None, 9, 768)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_110 (Conv1D)          (None, 7, 512)            1180160   \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_36  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_108 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_72 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_109 (Dense)            (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_73 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_110 (Dense)            (None, 6)                 1542      \n",
      "=================================================================\n",
      "Total params: 4,533,254\n",
      "Trainable params: 4,533,254\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/60\n",
      "  2/183 [..............................] - ETA: 7s - loss: 1.7395 - accuracy: 0.1992WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0280s vs `on_train_batch_end` time: 0.0488s). Check your callbacks.\n",
      "183/183 [==============================] - 14s 76ms/step - loss: 1.1963 - accuracy: 0.4894\n",
      "Epoch 2/60\n",
      "183/183 [==============================] - 13s 74ms/step - loss: 0.9485 - accuracy: 0.6012\n",
      "Epoch 3/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.8203 - accuracy: 0.6698\n",
      "Epoch 4/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.7037 - accuracy: 0.7194\n",
      "Epoch 5/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183/183 [==============================] - 14s 74ms/step - loss: 0.6118 - accuracy: 0.7562\n",
      "Epoch 6/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.5710 - accuracy: 0.7710\n",
      "Epoch 7/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.5279 - accuracy: 0.7883\n",
      "Epoch 8/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.6694 - accuracy: 0.7536\n",
      "Epoch 9/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.4922 - accuracy: 0.8053\n",
      "Epoch 10/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.4512 - accuracy: 0.8211\n",
      "Epoch 11/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.4379 - accuracy: 0.8258\n",
      "Epoch 12/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 2.2267 - accuracy: 0.7352\n",
      "Epoch 13/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.7937 - accuracy: 0.6888\n",
      "Epoch 14/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.6108 - accuracy: 0.7675\n",
      "Epoch 15/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.5415 - accuracy: 0.7910\n",
      "Epoch 16/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.4973 - accuracy: 0.8097\n",
      "Epoch 17/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.4688 - accuracy: 0.8188\n",
      "Epoch 18/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.4468 - accuracy: 0.8268\n",
      "Epoch 19/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.4345 - accuracy: 0.8336\n",
      "Epoch 20/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.4201 - accuracy: 0.8372\n",
      "Epoch 21/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.4103 - accuracy: 0.8424\n",
      "Epoch 22/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.3988 - accuracy: 0.8459\n",
      "Epoch 23/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.4261 - accuracy: 0.8424\n",
      "Epoch 24/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.3774 - accuracy: 0.8561\n",
      "Epoch 25/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.3892 - accuracy: 0.8531\n",
      "Epoch 26/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.3671 - accuracy: 0.8579\n",
      "Epoch 27/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.3702 - accuracy: 0.8599\n",
      "Epoch 28/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.3548 - accuracy: 0.8627\n",
      "Epoch 29/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.3696 - accuracy: 0.8605\n",
      "Epoch 30/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.3461 - accuracy: 0.8669\n",
      "Epoch 31/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.3747 - accuracy: 0.8618\n",
      "Epoch 32/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.3388 - accuracy: 0.8694\n",
      "Epoch 33/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.3522 - accuracy: 0.8638\n",
      "Epoch 34/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.3623 - accuracy: 0.8608\n",
      "Epoch 35/60\n",
      "183/183 [==============================] - 13s 74ms/step - loss: 0.3328 - accuracy: 0.8720\n",
      "Epoch 36/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.3203 - accuracy: 0.8762\n",
      "Epoch 37/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.3199 - accuracy: 0.8759\n",
      "Epoch 38/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.3165 - accuracy: 0.8766\n",
      "Epoch 39/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.3149 - accuracy: 0.8769\n",
      "Epoch 40/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.3226 - accuracy: 0.8745\n",
      "Epoch 41/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.3010 - accuracy: 0.8820\n",
      "Epoch 42/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.4318 - accuracy: 0.8578\n",
      "Epoch 43/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.3808 - accuracy: 0.8573\n",
      "Epoch 44/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.3166 - accuracy: 0.8791\n",
      "Epoch 45/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.2998 - accuracy: 0.8809\n",
      "Epoch 46/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.2954 - accuracy: 0.8848\n",
      "Epoch 47/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.2886 - accuracy: 0.8859\n",
      "Epoch 48/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.2854 - accuracy: 0.8880\n",
      "Epoch 49/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.3655 - accuracy: 0.8668\n",
      "Epoch 50/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.2817 - accuracy: 0.8904\n",
      "Epoch 51/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.2752 - accuracy: 0.8919\n",
      "Epoch 52/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.2757 - accuracy: 0.8908\n",
      "Epoch 53/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.2724 - accuracy: 0.8922\n",
      "Epoch 54/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.3046 - accuracy: 0.8854\n",
      "Epoch 55/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.2649 - accuracy: 0.8960\n",
      "Epoch 56/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.2653 - accuracy: 0.8953\n",
      "Epoch 57/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.2640 - accuracy: 0.8977\n",
      "Epoch 58/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.2631 - accuracy: 0.8973\n",
      "Epoch 59/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.2576 - accuracy: 0.8992\n",
      "Epoch 60/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.2654 - accuracy: 0.8970\n",
      "46/46 [==============================] - 1s 25ms/step - loss: 0.8990 - accuracy: 0.7850\n",
      "Model: \"sequential_37\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_111 (Conv1D)          (None, 88, 768)           7680      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_37 (MaxPooling (None, 22, 768)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_112 (Conv1D)          (None, 18, 768)           2949888   \n",
      "_________________________________________________________________\n",
      "average_pooling1d_37 (Averag (None, 9, 768)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_113 (Conv1D)          (None, 7, 512)            1180160   \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_37  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_111 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_74 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_112 (Dense)            (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_75 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_113 (Dense)            (None, 6)                 1542      \n",
      "=================================================================\n",
      "Total params: 4,533,254\n",
      "Trainable params: 4,533,254\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/60\n",
      "  2/183 [..............................] - ETA: 11s - loss: 1.7660 - accuracy: 0.1543WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0270s vs `on_train_batch_end` time: 0.0478s). Check your callbacks.\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 1.1932 - accuracy: 0.4873\n",
      "Epoch 2/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.9562 - accuracy: 0.6020\n",
      "Epoch 3/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183/183 [==============================] - 14s 74ms/step - loss: 0.7995 - accuracy: 0.6780\n",
      "Epoch 4/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.6631 - accuracy: 0.7346\n",
      "Epoch 5/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.7424 - accuracy: 0.7153\n",
      "Epoch 6/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.5688 - accuracy: 0.7724\n",
      "Epoch 7/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.5397 - accuracy: 0.7853\n",
      "Epoch 8/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.5005 - accuracy: 0.8013\n",
      "Epoch 9/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.4793 - accuracy: 0.8093\n",
      "Epoch 10/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.4658 - accuracy: 0.8141\n",
      "Epoch 11/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 1.6707 - accuracy: 0.6320\n",
      "Epoch 12/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.6346 - accuracy: 0.7499\n",
      "Epoch 13/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.5528 - accuracy: 0.7825\n",
      "Epoch 14/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.5097 - accuracy: 0.7989\n",
      "Epoch 15/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.4689 - accuracy: 0.8163\n",
      "Epoch 16/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.4493 - accuracy: 0.8250\n",
      "Epoch 17/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.4272 - accuracy: 0.8351\n",
      "Epoch 18/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.4198 - accuracy: 0.8357\n",
      "Epoch 19/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.4090 - accuracy: 0.8412\n",
      "Epoch 20/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.3940 - accuracy: 0.8471\n",
      "Epoch 21/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.3905 - accuracy: 0.8480\n",
      "Epoch 22/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.4657 - accuracy: 0.8272\n",
      "Epoch 23/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.3751 - accuracy: 0.8544\n",
      "Epoch 24/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.3649 - accuracy: 0.8611\n",
      "Epoch 25/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.3906 - accuracy: 0.8520\n",
      "Epoch 26/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.3548 - accuracy: 0.8623\n",
      "Epoch 27/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.3533 - accuracy: 0.8605\n",
      "Epoch 28/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.3609 - accuracy: 0.8610\n",
      "Epoch 29/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.3415 - accuracy: 0.8686\n",
      "Epoch 30/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.3668 - accuracy: 0.8631\n",
      "Epoch 31/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.3418 - accuracy: 0.8673\n",
      "Epoch 32/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.3256 - accuracy: 0.8750\n",
      "Epoch 33/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.3241 - accuracy: 0.8743\n",
      "Epoch 34/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.4256 - accuracy: 0.8542\n",
      "Epoch 35/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.3679 - accuracy: 0.8598\n",
      "Epoch 36/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.3201 - accuracy: 0.8769\n",
      "Epoch 37/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.3209 - accuracy: 0.8764\n",
      "Epoch 38/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.3069 - accuracy: 0.8824\n",
      "Epoch 39/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.3161 - accuracy: 0.8803\n",
      "Epoch 40/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.3002 - accuracy: 0.8847\n",
      "Epoch 41/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.2953 - accuracy: 0.8850\n",
      "Epoch 42/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.3199 - accuracy: 0.8801\n",
      "Epoch 43/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.3195 - accuracy: 0.8818\n",
      "Epoch 44/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.2870 - accuracy: 0.8897\n",
      "Epoch 45/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.2865 - accuracy: 0.8885\n",
      "Epoch 46/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.2785 - accuracy: 0.8913\n",
      "Epoch 47/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.2847 - accuracy: 0.8912\n",
      "Epoch 48/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.2791 - accuracy: 0.8935\n",
      "Epoch 49/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.2929 - accuracy: 0.8908\n",
      "Epoch 50/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.3303 - accuracy: 0.8797\n",
      "Epoch 51/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.2660 - accuracy: 0.8974\n",
      "Epoch 52/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.2667 - accuracy: 0.8978\n",
      "Epoch 53/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.2612 - accuracy: 0.8987\n",
      "Epoch 54/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.2578 - accuracy: 0.9004\n",
      "Epoch 55/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.2684 - accuracy: 0.8990\n",
      "Epoch 56/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.2516 - accuracy: 0.9027\n",
      "Epoch 57/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.2476 - accuracy: 0.9045\n",
      "Epoch 58/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.2638 - accuracy: 0.9008\n",
      "Epoch 59/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.2493 - accuracy: 0.9039\n",
      "Epoch 60/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.2439 - accuracy: 0.9056\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 0.3175 - accuracy: 0.8887\n",
      "Model: \"sequential_38\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_114 (Conv1D)          (None, 88, 768)           7680      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_38 (MaxPooling (None, 22, 768)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_115 (Conv1D)          (None, 18, 768)           2949888   \n",
      "_________________________________________________________________\n",
      "average_pooling1d_38 (Averag (None, 9, 768)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_116 (Conv1D)          (None, 7, 512)            1180160   \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_38  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_114 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_76 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_115 (Dense)            (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_77 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_116 (Dense)            (None, 6)                 1542      \n",
      "=================================================================\n",
      "Total params: 4,533,254\n",
      "Trainable params: 4,533,254\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/60\n",
      "  2/183 [..............................] - ETA: 10s - loss: 1.7728 - accuracy: 0.1602WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0270s vs `on_train_batch_end` time: 0.0468s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183/183 [==============================] - 14s 74ms/step - loss: 1.2008 - accuracy: 0.4878\n",
      "Epoch 2/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.9713 - accuracy: 0.5972\n",
      "Epoch 3/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.7869 - accuracy: 0.6824\n",
      "Epoch 4/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.6890 - accuracy: 0.7248\n",
      "Epoch 5/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.6040 - accuracy: 0.7587\n",
      "Epoch 6/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.5674 - accuracy: 0.7717\n",
      "Epoch 7/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.5296 - accuracy: 0.7879\n",
      "Epoch 8/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.4957 - accuracy: 0.8015\n",
      "Epoch 9/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.5296 - accuracy: 0.7932\n",
      "Epoch 10/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.4434 - accuracy: 0.8226\n",
      "Epoch 11/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.4426 - accuracy: 0.8253\n",
      "Epoch 12/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.4275 - accuracy: 0.8321\n",
      "Epoch 13/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.4329 - accuracy: 0.8325\n",
      "Epoch 14/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.3965 - accuracy: 0.8439\n",
      "Epoch 15/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.3822 - accuracy: 0.8496\n",
      "Epoch 16/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.3903 - accuracy: 0.8483\n",
      "Epoch 17/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.4384 - accuracy: 0.8363\n",
      "Epoch 18/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.4512 - accuracy: 0.8301\n",
      "Epoch 19/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.3634 - accuracy: 0.8583\n",
      "Epoch 20/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.3446 - accuracy: 0.8667\n",
      "Epoch 21/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.3655 - accuracy: 0.8616\n",
      "Epoch 22/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.3382 - accuracy: 0.8679\n",
      "Epoch 23/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.3253 - accuracy: 0.8719\n",
      "Epoch 24/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.3224 - accuracy: 0.8740\n",
      "Epoch 25/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.3136 - accuracy: 0.8778\n",
      "Epoch 26/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.3396 - accuracy: 0.8681\n",
      "Epoch 27/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.3150 - accuracy: 0.8753\n",
      "Epoch 28/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.3016 - accuracy: 0.8821\n",
      "Epoch 29/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.4284 - accuracy: 0.8488\n",
      "Epoch 30/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.3071 - accuracy: 0.8809\n",
      "Epoch 31/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.2878 - accuracy: 0.8883\n",
      "Epoch 32/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.2835 - accuracy: 0.8880\n",
      "Epoch 33/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.2824 - accuracy: 0.8891\n",
      "Epoch 34/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.2945 - accuracy: 0.8829\n",
      "Epoch 35/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.2723 - accuracy: 0.8929\n",
      "Epoch 36/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.2698 - accuracy: 0.8935\n",
      "Epoch 37/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.2660 - accuracy: 0.8956\n",
      "Epoch 38/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.2640 - accuracy: 0.8959\n",
      "Epoch 39/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.2639 - accuracy: 0.8971\n",
      "Epoch 40/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.2647 - accuracy: 0.8947\n",
      "Epoch 41/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.2722 - accuracy: 0.8931\n",
      "Epoch 42/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.2497 - accuracy: 0.9034\n",
      "Epoch 43/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.2541 - accuracy: 0.8993\n",
      "Epoch 44/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.2551 - accuracy: 0.8998\n",
      "Epoch 45/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.2469 - accuracy: 0.9036\n",
      "Epoch 46/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.2388 - accuracy: 0.9057\n",
      "Epoch 47/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.2377 - accuracy: 0.9059\n",
      "Epoch 48/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 1.0222 - accuracy: 0.7658\n",
      "Epoch 49/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.3484 - accuracy: 0.8723\n",
      "Epoch 50/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.2866 - accuracy: 0.8909\n",
      "Epoch 51/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.2635 - accuracy: 0.8990\n",
      "Epoch 52/60\n",
      "183/183 [==============================] - 14s 75ms/step - loss: 0.2544 - accuracy: 0.9008\n",
      "Epoch 53/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.2410 - accuracy: 0.9059\n",
      "Epoch 54/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.2331 - accuracy: 0.9085\n",
      "Epoch 55/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.2254 - accuracy: 0.9110\n",
      "Epoch 56/60\n",
      "183/183 [==============================] - 14s 76ms/step - loss: 0.2240 - accuracy: 0.9120\n",
      "Epoch 57/60\n",
      "183/183 [==============================] - 14s 75ms/step - loss: 0.2262 - accuracy: 0.9108\n",
      "Epoch 58/60\n",
      "183/183 [==============================] - 14s 75ms/step - loss: 0.2175 - accuracy: 0.9147\n",
      "Epoch 59/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.2183 - accuracy: 0.9135\n",
      "Epoch 60/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.2153 - accuracy: 0.9148\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 0.3545 - accuracy: 0.8758\n",
      "Model: \"sequential_39\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_117 (Conv1D)          (None, 88, 768)           7680      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_39 (MaxPooling (None, 22, 768)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_118 (Conv1D)          (None, 18, 768)           2949888   \n",
      "_________________________________________________________________\n",
      "average_pooling1d_39 (Averag (None, 9, 768)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_119 (Conv1D)          (None, 7, 512)            1180160   \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_39  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_117 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_78 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_118 (Dense)            (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_79 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_119 (Dense)            (None, 6)                 1542      \n",
      "=================================================================\n",
      "Total params: 4,533,254\n",
      "Trainable params: 4,533,254\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/60\n",
      "  2/183 [..............................] - ETA: 10s - loss: 1.7785 - accuracy: 0.1562WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0249s vs `on_train_batch_end` time: 0.0459s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183/183 [==============================] - 14s 78ms/step - loss: 1.1815 - accuracy: 0.4918\n",
      "Epoch 2/60\n",
      "183/183 [==============================] - 14s 75ms/step - loss: 0.9475 - accuracy: 0.6058\n",
      "Epoch 3/60\n",
      "183/183 [==============================] - 13s 74ms/step - loss: 0.7751 - accuracy: 0.6885\n",
      "Epoch 4/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.6600 - accuracy: 0.7374\n",
      "Epoch 5/60\n",
      "183/183 [==============================] - 14s 75ms/step - loss: 0.5845 - accuracy: 0.7654\n",
      "Epoch 6/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.5507 - accuracy: 0.7810\n",
      "Epoch 7/60\n",
      "183/183 [==============================] - 13s 73ms/step - loss: 0.6797 - accuracy: 0.7461\n",
      "Epoch 8/60\n",
      "183/183 [==============================] - 13s 73ms/step - loss: 0.4966 - accuracy: 0.8042\n",
      "Epoch 9/60\n",
      "183/183 [==============================] - 13s 73ms/step - loss: 0.4779 - accuracy: 0.8128\n",
      "Epoch 10/60\n",
      "183/183 [==============================] - 13s 73ms/step - loss: 0.4796 - accuracy: 0.8142\n",
      "Epoch 11/60\n",
      "183/183 [==============================] - 13s 73ms/step - loss: 0.4457 - accuracy: 0.8266\n",
      "Epoch 12/60\n",
      "183/183 [==============================] - 13s 73ms/step - loss: 0.4304 - accuracy: 0.8330\n",
      "Epoch 13/60\n",
      "183/183 [==============================] - 13s 73ms/step - loss: 0.4114 - accuracy: 0.8399\n",
      "Epoch 14/60\n",
      "183/183 [==============================] - 13s 73ms/step - loss: 0.4094 - accuracy: 0.8409\n",
      "Epoch 15/60\n",
      "183/183 [==============================] - 13s 74ms/step - loss: 0.3849 - accuracy: 0.8492\n",
      "Epoch 16/60\n",
      "183/183 [==============================] - 13s 72ms/step - loss: 1.8884 - accuracy: 0.6300\n",
      "Epoch 17/60\n",
      "183/183 [==============================] - 13s 72ms/step - loss: 0.5860 - accuracy: 0.7731\n",
      "Epoch 18/60\n",
      "183/183 [==============================] - 13s 73ms/step - loss: 0.4751 - accuracy: 0.8184\n",
      "Epoch 19/60\n",
      "183/183 [==============================] - 13s 73ms/step - loss: 0.4310 - accuracy: 0.8370\n",
      "Epoch 20/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.4113 - accuracy: 0.8445\n",
      "Epoch 21/60\n",
      "183/183 [==============================] - 13s 73ms/step - loss: 0.3959 - accuracy: 0.8495\n",
      "Epoch 22/60\n",
      "183/183 [==============================] - 13s 73ms/step - loss: 0.3773 - accuracy: 0.8566\n",
      "Epoch 23/60\n",
      "183/183 [==============================] - 13s 73ms/step - loss: 0.3784 - accuracy: 0.8562\n",
      "Epoch 24/60\n",
      "183/183 [==============================] - 13s 72ms/step - loss: 0.3537 - accuracy: 0.8655\n",
      "Epoch 25/60\n",
      "183/183 [==============================] - 13s 72ms/step - loss: 0.3590 - accuracy: 0.8642\n",
      "Epoch 26/60\n",
      "183/183 [==============================] - 13s 73ms/step - loss: 0.3522 - accuracy: 0.8671\n",
      "Epoch 27/60\n",
      "183/183 [==============================] - 13s 72ms/step - loss: 0.3359 - accuracy: 0.8713\n",
      "Epoch 28/60\n",
      "183/183 [==============================] - 13s 73ms/step - loss: 0.3983 - accuracy: 0.8574\n",
      "Epoch 29/60\n",
      "183/183 [==============================] - 13s 72ms/step - loss: 0.3352 - accuracy: 0.8727\n",
      "Epoch 30/60\n",
      "183/183 [==============================] - 13s 72ms/step - loss: 0.3261 - accuracy: 0.8746\n",
      "Epoch 31/60\n",
      "183/183 [==============================] - 13s 73ms/step - loss: 0.3280 - accuracy: 0.8740\n",
      "Epoch 32/60\n",
      "183/183 [==============================] - 13s 73ms/step - loss: 0.3147 - accuracy: 0.8786\n",
      "Epoch 33/60\n",
      "183/183 [==============================] - 13s 73ms/step - loss: 0.3172 - accuracy: 0.8794\n",
      "Epoch 34/60\n",
      "183/183 [==============================] - 13s 72ms/step - loss: 0.3153 - accuracy: 0.8797\n",
      "Epoch 35/60\n",
      "183/183 [==============================] - 13s 73ms/step - loss: 0.3062 - accuracy: 0.8821\n",
      "Epoch 36/60\n",
      "183/183 [==============================] - 13s 73ms/step - loss: 0.3807 - accuracy: 0.8658\n",
      "Epoch 37/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.3203 - accuracy: 0.8764\n",
      "Epoch 38/60\n",
      "183/183 [==============================] - 14s 75ms/step - loss: 0.3052 - accuracy: 0.8824\n",
      "Epoch 39/60\n",
      "183/183 [==============================] - 13s 73ms/step - loss: 0.2995 - accuracy: 0.8848\n",
      "Epoch 40/60\n",
      "183/183 [==============================] - 13s 72ms/step - loss: 0.2948 - accuracy: 0.8859\n",
      "Epoch 41/60\n",
      "183/183 [==============================] - 13s 73ms/step - loss: 0.3217 - accuracy: 0.8797\n",
      "Epoch 42/60\n",
      "183/183 [==============================] - 13s 73ms/step - loss: 0.2871 - accuracy: 0.8898\n",
      "Epoch 43/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.2820 - accuracy: 0.8900\n",
      "Epoch 44/60\n",
      "183/183 [==============================] - 13s 73ms/step - loss: 0.2764 - accuracy: 0.8926\n",
      "Epoch 45/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.3603 - accuracy: 0.8725\n",
      "Epoch 46/60\n",
      "183/183 [==============================] - 13s 73ms/step - loss: 0.2919 - accuracy: 0.8897\n",
      "Epoch 47/60\n",
      "183/183 [==============================] - 13s 73ms/step - loss: 0.2926 - accuracy: 0.8864\n",
      "Epoch 48/60\n",
      "183/183 [==============================] - 13s 73ms/step - loss: 0.2726 - accuracy: 0.8964\n",
      "Epoch 49/60\n",
      "183/183 [==============================] - 13s 72ms/step - loss: 0.2740 - accuracy: 0.8963\n",
      "Epoch 50/60\n",
      "183/183 [==============================] - 13s 73ms/step - loss: 0.2608 - accuracy: 0.8993\n",
      "Epoch 51/60\n",
      "183/183 [==============================] - 13s 72ms/step - loss: 0.2586 - accuracy: 0.8992\n",
      "Epoch 52/60\n",
      "183/183 [==============================] - 13s 72ms/step - loss: 0.2609 - accuracy: 0.8991\n",
      "Epoch 53/60\n",
      "183/183 [==============================] - 13s 73ms/step - loss: 0.2755 - accuracy: 0.8957\n",
      "Epoch 54/60\n",
      "183/183 [==============================] - 13s 72ms/step - loss: 0.2531 - accuracy: 0.9028\n",
      "Epoch 55/60\n",
      "183/183 [==============================] - 13s 73ms/step - loss: 0.2516 - accuracy: 0.9017\n",
      "Epoch 56/60\n",
      "183/183 [==============================] - 13s 72ms/step - loss: 0.2512 - accuracy: 0.9019\n",
      "Epoch 57/60\n",
      "183/183 [==============================] - 13s 72ms/step - loss: 0.2439 - accuracy: 0.9054\n",
      "Epoch 58/60\n",
      "183/183 [==============================] - 13s 72ms/step - loss: 0.2434 - accuracy: 0.9058\n",
      "Epoch 59/60\n",
      "183/183 [==============================] - 13s 72ms/step - loss: 0.2541 - accuracy: 0.9026\n",
      "Epoch 60/60\n",
      "183/183 [==============================] - 13s 73ms/step - loss: 0.2389 - accuracy: 0.9074\n",
      "46/46 [==============================] - 1s 25ms/step - loss: 0.5161 - accuracy: 0.8584\n",
      "Model: \"sequential_40\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_120 (Conv1D)          (None, 88, 768)           7680      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_40 (MaxPooling (None, 22, 768)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_121 (Conv1D)          (None, 18, 768)           2949888   \n",
      "_________________________________________________________________\n",
      "average_pooling1d_40 (Averag (None, 9, 768)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_122 (Conv1D)          (None, 7, 512)            1180160   \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_40  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_120 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_80 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_121 (Dense)            (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_81 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_122 (Dense)            (None, 6)                 1542      \n",
      "=================================================================\n",
      "Total params: 4,533,254\n",
      "Trainable params: 4,533,254\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/60\n",
      "  2/183 [..............................] - ETA: 10s - loss: 1.7692 - accuracy: 0.1777WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0239s vs `on_train_batch_end` time: 0.0498s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183/183 [==============================] - 13s 73ms/step - loss: 1.1836 - accuracy: 0.4945\n",
      "Epoch 2/60\n",
      "183/183 [==============================] - 13s 73ms/step - loss: 0.9779 - accuracy: 0.5931\n",
      "Epoch 3/60\n",
      "183/183 [==============================] - 13s 72ms/step - loss: 0.7908 - accuracy: 0.6812\n",
      "Epoch 4/60\n",
      "183/183 [==============================] - 13s 72ms/step - loss: 0.7701 - accuracy: 0.6973\n",
      "Epoch 5/60\n",
      "183/183 [==============================] - 13s 72ms/step - loss: 0.6190 - accuracy: 0.7510\n",
      "Epoch 6/60\n",
      "183/183 [==============================] - 13s 73ms/step - loss: 0.5819 - accuracy: 0.7662\n",
      "Epoch 7/60\n",
      "183/183 [==============================] - 13s 73ms/step - loss: 0.5307 - accuracy: 0.7872\n",
      "Epoch 8/60\n",
      "183/183 [==============================] - 13s 73ms/step - loss: 0.5126 - accuracy: 0.7949\n",
      "Epoch 9/60\n",
      "183/183 [==============================] - 13s 74ms/step - loss: 0.5252 - accuracy: 0.7943\n",
      "Epoch 10/60\n",
      "183/183 [==============================] - 14s 75ms/step - loss: 0.4823 - accuracy: 0.8080\n",
      "Epoch 11/60\n",
      "183/183 [==============================] - 13s 72ms/step - loss: 0.4602 - accuracy: 0.8174\n",
      "Epoch 12/60\n",
      "183/183 [==============================] - 14s 74ms/step - loss: 0.4387 - accuracy: 0.8262\n",
      "Epoch 13/60\n",
      "183/183 [==============================] - 13s 72ms/step - loss: 0.4482 - accuracy: 0.8264\n",
      "Epoch 14/60\n",
      "183/183 [==============================] - 13s 72ms/step - loss: 0.4155 - accuracy: 0.8359\n",
      "Epoch 15/60\n",
      "183/183 [==============================] - 13s 72ms/step - loss: 0.4026 - accuracy: 0.8412\n",
      "Epoch 16/60\n",
      "183/183 [==============================] - 13s 73ms/step - loss: 0.3805 - accuracy: 0.8486\n",
      "Epoch 17/60\n",
      "183/183 [==============================] - 13s 73ms/step - loss: 0.3760 - accuracy: 0.8516\n",
      "Epoch 18/60\n",
      "183/183 [==============================] - 13s 73ms/step - loss: 0.5788 - accuracy: 0.7952\n",
      "Epoch 19/60\n",
      "183/183 [==============================] - 14s 75ms/step - loss: 0.3601 - accuracy: 0.8614\n",
      "Epoch 20/60\n",
      "183/183 [==============================] - 13s 73ms/step - loss: 0.3531 - accuracy: 0.8609\n",
      "Epoch 21/60\n",
      "183/183 [==============================] - 13s 73ms/step - loss: 0.3443 - accuracy: 0.8661\n",
      "Epoch 22/60\n",
      "183/183 [==============================] - 13s 73ms/step - loss: 0.3509 - accuracy: 0.8634\n",
      "Epoch 23/60\n",
      "183/183 [==============================] - 13s 72ms/step - loss: 0.3528 - accuracy: 0.8647\n",
      "Epoch 24/60\n",
      "183/183 [==============================] - 13s 73ms/step - loss: 0.3207 - accuracy: 0.8725\n",
      "Epoch 25/60\n",
      "183/183 [==============================] - 13s 73ms/step - loss: 0.3353 - accuracy: 0.8706\n",
      "Epoch 26/60\n",
      "183/183 [==============================] - 13s 72ms/step - loss: 0.6639 - accuracy: 0.8079\n",
      "Epoch 27/60\n",
      "183/183 [==============================] - 13s 72ms/step - loss: 0.3375 - accuracy: 0.8711\n",
      "Epoch 28/60\n",
      "183/183 [==============================] - 13s 72ms/step - loss: 0.3181 - accuracy: 0.8781\n",
      "Epoch 29/60\n",
      "183/183 [==============================] - 13s 73ms/step - loss: 0.3127 - accuracy: 0.8786\n",
      "Epoch 30/60\n",
      "183/183 [==============================] - 13s 72ms/step - loss: 0.3017 - accuracy: 0.8819\n",
      "Epoch 31/60\n",
      " 39/183 [=====>........................] - ETA: 10s - loss: 0.3118 - accuracy: 0.8778"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rscv = RandomizedSearchCV(model, param_distributions=params, cv=cv, n_iter=n_tune_iter)\n",
    "rscv_results = rscv.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best score is: {} using {}'.format(rscv_results.best_score_,\n",
    "rscv_results.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = rscv_results.best_estimator_\n",
    "best_param = rscv_results.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JkbhJMox8Jl9"
   },
   "source": [
    "### Test the best model based on the validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kZwGk5dR8JmS"
   },
   "outputs": [],
   "source": [
    "y_hat = best_model.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E_GNq-R_8JmZ",
    "outputId": "0fc16efe-7739-4394-f1a3-46da92e79584"
   },
   "outputs": [],
   "source": [
    "y_hat = to_categorical(y_hat)\n",
    "y_hat[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SFqRQ5XB8Jmc",
    "outputId": "a957fbed-92f8-4bdd-d24b-5df3361a8bac"
   },
   "outputs": [],
   "source": [
    "y_valid[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FTWf6Cf-8Jme",
    "outputId": "1256b170-33dc-4171-f2ff-7a3d7ddd74e3"
   },
   "outputs": [],
   "source": [
    "plt.hist(y_hat)\n",
    "_ = plt.axvline(x=0.5, color='orange')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import  accuracy_score as score\n",
    "y_pred_classes = y_hat.round()\n",
    "print(y_valid[0], y_hat[0], y_pred_classes[0])\n",
    "acc = score(y_valid, y_pred_classes) * 100\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RNljSx3v8Jmh"
   },
   "outputs": [],
   "source": [
    "pct_auc = roc_auc_score(y_valid, y_hat)*100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SO_N9lJG8Jmj",
    "outputId": "20968a52-8ca0-44d3-abf6-a1382bba5cde"
   },
   "outputs": [],
   "source": [
    "\"{:0.2f}\".format(pct_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vU3hnA298Jmo"
   },
   "outputs": [],
   "source": [
    "float_y_hat = []\n",
    "for y in y_hat:\n",
    "    float_y_hat.append(y[0:6].round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zrTf-aQl8Jmr"
   },
   "outputs": [],
   "source": [
    "ydf = pd.DataFrame(list(zip(float_y_hat, y_valid)), columns=['y_hat', 'y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zAyKh_mX8Jmu",
    "outputId": "611224b8-f980-47df-d596-9aa3a5811009"
   },
   "outputs": [],
   "source": [
    "ydf.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(rscv_results.cv_results_['params'])\n",
    "results_df['mean'] = rscv_results.cv_results_['mean_test_score']\n",
    "results_df['std'] = rscv_results.cv_results_['std_test_score']\n",
    "results_df.sort_values('mean', ascending=False, ignore_index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating best model from the best param and train it for 60 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(best_param.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_dense_2= 256\n",
    "n_dense_1= 512\n",
    "n_conv_3= 256\n",
    "n_conv_2= 768\n",
    "n_conv_1= 768\n",
    "maxpooling_pool_size= 2\n",
    "k_conv_3= 3\n",
    "k_conv_2= 5\n",
    "k_conv_1= 5\n",
    "dropout_2= 0.4\n",
    "dropout_1= 0.4\n",
    "avepooling_pool_size= 2\n",
    "activation= 'relu'\n",
    "model = Sequential()\n",
    "model.add(Conv1D(n_conv_1, k_conv_1, activation=activation, input_shape=input_shape[1:]))\n",
    "model.add(MaxPool1D(pool_size = maxpooling_pool_size))\n",
    "model.add(Conv1D(n_conv_2, k_conv_2, activation=activation))\n",
    "model.add(AveragePooling1D(pool_size = avepooling_pool_size))\n",
    "model.add(Conv1D(n_conv_3, k_conv_3, activation=activation))\n",
    "# model.add(GlobalMaxPooling1D())\n",
    "model.add(GlobalAveragePooling1D())\n",
    "model.add(Dense(n_dense_1, activation=activation))\n",
    "model.add(Dropout(dropout_1))\n",
    "model.add(Dense(n_dense_2, activation=activation))\n",
    "model.add(Dropout(dropout_2))\n",
    "model.add(Dense(n_class, activation='softmax'))\n",
    "model.summary()\n",
    "model.compile(loss='categorical_crossentropy', optimizer='nadam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "modelcheckpoint = ModelCheckpoint(filepath=output_dir+\n",
    "                                  \"/weights.{epoch:02d}.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, \n",
    "         batch_size=batch_size, epochs=epochs, verbose=1, \n",
    "         validation_data=(X_valid, y_valid), \n",
    "         callbacks=[modelcheckpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z8t0nVCw8JmP"
   },
   "outputs": [],
   "source": [
    "model.load_weights(output_dir+\"/weights.49.hdf5\") # 94.22 val accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kZwGk5dR8JmS"
   },
   "outputs": [],
   "source": [
    "y_hat = model.predict(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EPc5_h6K8JmW",
    "outputId": "cad99da9-9f89-437f-854b-a315616ed50f"
   },
   "outputs": [],
   "source": [
    "len(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E_GNq-R_8JmZ",
    "outputId": "0fc16efe-7739-4394-f1a3-46da92e79584"
   },
   "outputs": [],
   "source": [
    "y_hat[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SFqRQ5XB8Jmc",
    "outputId": "a957fbed-92f8-4bdd-d24b-5df3361a8bac"
   },
   "outputs": [],
   "source": [
    "y_valid[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FTWf6Cf-8Jme",
    "outputId": "1256b170-33dc-4171-f2ff-7a3d7ddd74e3"
   },
   "outputs": [],
   "source": [
    "plt.hist(y_hat)\n",
    "_ = plt.axvline(x=0.5, color='orange')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RNljSx3v8Jmh"
   },
   "outputs": [],
   "source": [
    "pct_auc = roc_auc_score(y_valid, y_hat)*100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SO_N9lJG8Jmj",
    "outputId": "20968a52-8ca0-44d3-abf6-a1382bba5cde"
   },
   "outputs": [],
   "source": [
    "\"{:0.2f}\".format(pct_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vU3hnA298Jmo"
   },
   "outputs": [],
   "source": [
    "float_y_hat = []\n",
    "for y in y_hat:\n",
    "    float_y_hat.append(y[0:6].round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zrTf-aQl8Jmr"
   },
   "outputs": [],
   "source": [
    "ydf = pd.DataFrame(list(zip(float_y_hat, y_valid)), columns=['y_hat', 'y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zAyKh_mX8Jmu",
    "outputId": "611224b8-f980-47df-d596-9aa3a5811009"
   },
   "outputs": [],
   "source": [
    "ydf.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "dense_sentiment_classifier.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
