{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/jonkrohn/DLTFpT/blob/master/notebooks/dense_sentiment_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ahUZuAfz8Jje"
   },
   "source": [
    "# Dense Activity Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Re0ecmVI8Jjk"
   },
   "source": [
    "In this notebook, we build a dense neural net to classify PE activity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ixsGb9tY8Jjm"
   },
   "source": [
    "#### Load dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5At1PKQp8Jjp"
   },
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, Conv1D, GlobalMaxPooling1D, MaxPool1D\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint # new! \n",
    "import os # new! \n",
    "from sklearn.metrics import roc_auc_score, roc_curve # new!\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt # new!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hg5wX2Dd8Jjz"
   },
   "source": [
    "#### Set hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lYLOM99-8Jj2"
   },
   "outputs": [],
   "source": [
    "# output directory name:\n",
    "output_dir = 'model_output/cnn2'\n",
    "input_dir =  'Z:/Research/dfuller/Walkabilly/studies/smarphone_accel/data/Ethica_Jaeger_Merged/pocket/'\n",
    "input_file_name = 'pocket-NN-data.npz'\n",
    "\n",
    "# from the data preparation section we have:\n",
    "window_size_second = 3\n",
    "frequency = 30\n",
    "lenght_of_each_seq = window_size_second * frequency\n",
    "\n",
    "# pooling layer parameters\n",
    "maxpooling_pool_size = 3\n",
    "\n",
    "\n",
    "# convolutional layer architecture:\n",
    "n_conv_1 = 512 # filters, a.k.a. kernels\n",
    "n_conv_2 = 256\n",
    "k_conv_1 = 3 # kernel length\n",
    "k_conv_2 = 3 # kernel length\n",
    "\n",
    "# dense layer architecture: \n",
    "n_dense_1 = 256\n",
    "dropout_1 = 0.25\n",
    "n_dense_2 = 128\n",
    "dropout_2 = 0.2\n",
    "\n",
    "# training:\n",
    "epochs = 30\n",
    "batch_size = 128\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DaLx4yZ48Jj9"
   },
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CD9X0yJg8Jj_"
   },
   "source": [
    "##### For this notebook we use the acceleration data gathered from the pocket location. It was prepared in the DataPrep-Deep notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6r44JKj-8JkA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acceleration_data\n",
      "metadata\n",
      "labels\n"
     ]
    }
   ],
   "source": [
    "# read the raw file and get the keys:\n",
    "raw_data = np.load(file=input_dir+input_file_name,allow_pickle=True)\n",
    "for k in raw_data.keys():\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the data\n",
    "\n",
    "accel_array = raw_data['acceleration_data']\n",
    "meta_array = raw_data['metadata']\n",
    "labels_array = raw_data['labels']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WWq3ipbu8JlG"
   },
   "source": [
    "#### Preprocess data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert the  labels to integer.\n",
    "In the raw data format of the labels is String and there are 6 classes. 'Lying', 'Sitting', 'Self Pace walk', 'Running 3 METs',\n",
    "       'Running 5 METs', 'Running 7 METs' <br>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LyReiequ8Jln"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       ...,\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change from string to integer so keras.to_categorical can consume it\n",
    "\n",
    "# could do with factorize method as well\n",
    "n_class = len(np.unique(labels_array))\n",
    "class_list, labels_array_int = np.unique(labels_array,return_inverse=True)\n",
    "labels_array_int\n",
    "\n",
    "# check if the result is consistant with the original input\n",
    "class_list[labels_array_int].reshape(len(labels_array_int), 1) == labels_array\n",
    "\n",
    "# Note: to get the reverse, i.e converting integer array to string use class_list[labels_array_int]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70392, 6)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# labels to categorical\n",
    "\n",
    "y = to_categorical(labels_array_int, num_classes=n_class)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[70392, 90, 3]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape = list(accel_array.shape)\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "GscSnCpk8Jlm"
   },
   "source": [
    "\n",
    "#### Design neural network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a conv model!\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(n_conv_1, k_conv_1, activation='relu', input_shape=input_shape[1:]))\n",
    "model.add(MaxPool1D(pool_size = maxpooling_pool_size))\n",
    "model.add(Conv1D(n_conv_2, k_conv_2, activation='relu'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(n_dense_1, activation='relu'))\n",
    "model.add(Dropout(dropout_1))\n",
    "model.add(Dense(n_dense_2, activation='relu'))\n",
    "model.add(Dropout(dropout_2))\n",
    "model.add(Dense(n_class, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3nx7eGkg8Jlr",
    "outputId": "76af5145-5c7d-45c1-f292-e9f68a0907a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_17 (Conv1D)           (None, 88, 512)           5120      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 29, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_18 (Conv1D)           (None, 27, 256)           393472    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_8 (Glob (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 6)                 774       \n",
      "=================================================================\n",
      "Total params: 498,054\n",
      "Trainable params: 498,054\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "40x3s0KY8Jlv",
    "outputId": "d3ac3e31-3c47-4b01-c2f9-ada0684b31b7"
   },
   "source": [
    "### Splitting and shuffeling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f5grc2H78Jlz",
    "outputId": "3f7eeb55-f851-4796-de4e-0c68eb9df88d"
   },
   "outputs": [],
   "source": [
    "# split and shuffle\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(\n",
    "     accel_array, y, test_size=0.1, random_state=65)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JkbhJMox8Jl9"
   },
   "source": [
    "#### Configure model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QodbQvQh8Jl_"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='nadam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zHjvYe288JmE"
   },
   "outputs": [],
   "source": [
    "modelcheckpoint = ModelCheckpoint(filepath=output_dir+\n",
    "                                  \"/weights.{epoch:02d}.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "esUwodZA8JmI"
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TEYpX7968JmL"
   },
   "source": [
    "#### Train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QaD1W7Ka8JmM",
    "outputId": "f0c30141-0962-48f6-a000-d136af50af79"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  1/495 [..............................] - ETA: 5s - loss: 0.0619 - accuracy: 0.9844WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0080s vs `on_train_batch_end` time: 0.0130s). Check your callbacks.\n",
      "492/495 [============================>.] - ETA: 0s - loss: 0.1358 - accuracy: 0.9502WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0010s vs `on_test_batch_end` time: 0.0040s). Check your callbacks.\n",
      "495/495 [==============================] - 8s 15ms/step - loss: 0.1361 - accuracy: 0.9502 - val_loss: 0.2225 - val_accuracy: 0.9371\n",
      "Epoch 2/30\n",
      "495/495 [==============================] - 7s 15ms/step - loss: 0.1287 - accuracy: 0.9529 - val_loss: 0.2069 - val_accuracy: 0.9412\n",
      "Epoch 3/30\n",
      "495/495 [==============================] - 8s 15ms/step - loss: 0.1249 - accuracy: 0.9539 - val_loss: 0.2295 - val_accuracy: 0.9406\n",
      "Epoch 4/30\n",
      "495/495 [==============================] - 8s 15ms/step - loss: 0.1271 - accuracy: 0.9535 - val_loss: 0.2265 - val_accuracy: 0.9386\n",
      "Epoch 5/30\n",
      "495/495 [==============================] - 8s 15ms/step - loss: 0.1229 - accuracy: 0.9561 - val_loss: 0.2173 - val_accuracy: 0.9430\n",
      "Epoch 6/30\n",
      "495/495 [==============================] - 8s 15ms/step - loss: 0.1205 - accuracy: 0.9555 - val_loss: 0.2325 - val_accuracy: 0.9403\n",
      "Epoch 7/30\n",
      "495/495 [==============================] - 8s 15ms/step - loss: 0.1234 - accuracy: 0.9549 - val_loss: 0.2270 - val_accuracy: 0.9440\n",
      "Epoch 8/30\n",
      "495/495 [==============================] - 8s 15ms/step - loss: 0.1186 - accuracy: 0.9563 - val_loss: 0.2240 - val_accuracy: 0.9422\n",
      "Epoch 9/30\n",
      "495/495 [==============================] - 8s 15ms/step - loss: 0.1156 - accuracy: 0.9574 - val_loss: 0.2190 - val_accuracy: 0.9412\n",
      "Epoch 10/30\n",
      "495/495 [==============================] - 8s 15ms/step - loss: 0.1197 - accuracy: 0.9560 - val_loss: 0.2253 - val_accuracy: 0.9412\n",
      "Epoch 11/30\n",
      "495/495 [==============================] - 8s 15ms/step - loss: 0.1147 - accuracy: 0.9571 - val_loss: 0.2182 - val_accuracy: 0.9419\n",
      "Epoch 12/30\n",
      "495/495 [==============================] - 8s 15ms/step - loss: 0.1083 - accuracy: 0.9605 - val_loss: 0.2163 - val_accuracy: 0.9398\n",
      "Epoch 13/30\n",
      "495/495 [==============================] - 8s 15ms/step - loss: 0.1104 - accuracy: 0.9591 - val_loss: 0.2269 - val_accuracy: 0.9482\n",
      "Epoch 14/30\n",
      "495/495 [==============================] - 8s 15ms/step - loss: 0.1082 - accuracy: 0.9600 - val_loss: 0.2275 - val_accuracy: 0.9403\n",
      "Epoch 15/30\n",
      "495/495 [==============================] - 8s 15ms/step - loss: 0.1072 - accuracy: 0.9605 - val_loss: 0.2450 - val_accuracy: 0.9445\n",
      "Epoch 16/30\n",
      "495/495 [==============================] - 8s 15ms/step - loss: 0.1070 - accuracy: 0.9600 - val_loss: 0.2280 - val_accuracy: 0.9442\n",
      "Epoch 17/30\n",
      "495/495 [==============================] - 8s 15ms/step - loss: 0.1066 - accuracy: 0.9601 - val_loss: 0.2170 - val_accuracy: 0.9479\n",
      "Epoch 18/30\n",
      "495/495 [==============================] - 8s 15ms/step - loss: 0.1023 - accuracy: 0.9625 - val_loss: 0.2670 - val_accuracy: 0.9435\n",
      "Epoch 19/30\n",
      "495/495 [==============================] - 8s 15ms/step - loss: 0.1034 - accuracy: 0.9622 - val_loss: 0.2383 - val_accuracy: 0.9396\n",
      "Epoch 20/30\n",
      "495/495 [==============================] - 8s 15ms/step - loss: 0.0989 - accuracy: 0.9630 - val_loss: 0.2432 - val_accuracy: 0.9416\n",
      "Epoch 21/30\n",
      "495/495 [==============================] - 8s 15ms/step - loss: 0.0995 - accuracy: 0.9637 - val_loss: 0.2537 - val_accuracy: 0.9476\n",
      "Epoch 22/30\n",
      "495/495 [==============================] - 8s 15ms/step - loss: 0.0985 - accuracy: 0.9642 - val_loss: 0.2538 - val_accuracy: 0.9409\n",
      "Epoch 23/30\n",
      "495/495 [==============================] - 8s 15ms/step - loss: 0.1024 - accuracy: 0.9632 - val_loss: 0.2369 - val_accuracy: 0.9466\n",
      "Epoch 24/30\n",
      "495/495 [==============================] - 8s 15ms/step - loss: 0.0968 - accuracy: 0.9642 - val_loss: 0.2424 - val_accuracy: 0.9467\n",
      "Epoch 25/30\n",
      "495/495 [==============================] - 8s 16ms/step - loss: 0.0990 - accuracy: 0.9635 - val_loss: 0.2702 - val_accuracy: 0.9428\n",
      "Epoch 26/30\n",
      "495/495 [==============================] - 8s 15ms/step - loss: 0.0959 - accuracy: 0.9638 - val_loss: 0.2706 - val_accuracy: 0.9403\n",
      "Epoch 27/30\n",
      "495/495 [==============================] - 8s 15ms/step - loss: 0.0923 - accuracy: 0.9664 - val_loss: 0.2644 - val_accuracy: 0.9401\n",
      "Epoch 28/30\n",
      "495/495 [==============================] - 8s 15ms/step - loss: 0.0920 - accuracy: 0.9655 - val_loss: 0.2530 - val_accuracy: 0.9447\n",
      "Epoch 29/30\n",
      "495/495 [==============================] - 8s 15ms/step - loss: 0.0937 - accuracy: 0.9649 - val_loss: 0.2374 - val_accuracy: 0.9439\n",
      "Epoch 30/30\n",
      "495/495 [==============================] - 8s 15ms/step - loss: 0.0988 - accuracy: 0.9650 - val_loss: 0.2639 - val_accuracy: 0.9474\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2102a438a58>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, \n",
    "         batch_size=batch_size, epochs=epochs, verbose=1, \n",
    "         validation_data=(x_valid, y_valid), \n",
    "         callbacks=[modelcheckpoint])\n",
    "\n",
    "# model.fit(x_train, y_train, \n",
    "#           batch_size=batch_size, epochs=epochs, verbose=1, \n",
    "#           validation_data=(x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7PWlH5SJ8JmP"
   },
   "source": [
    "#### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z8t0nVCw8JmP"
   },
   "outputs": [],
   "source": [
    "# model.load_weights(output_dir+\"/weights.02.hdf5\") # NOT zero-indexed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kZwGk5dR8JmS"
   },
   "outputs": [],
   "source": [
    "y_hat = model.predict(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EPc5_h6K8JmW",
    "outputId": "cad99da9-9f89-437f-854b-a315616ed50f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7040"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E_GNq-R_8JmZ",
    "outputId": "0fc16efe-7739-4394-f1a3-46da92e79584"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.0633386e-02, 3.4211429e-11, 9.9335104e-14, 3.6550644e-11,\n",
       "       3.6319195e-13, 9.4936657e-01], dtype=float32)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SFqRQ5XB8Jmc",
    "outputId": "a957fbed-92f8-4bdd-d24b-5df3361a8bac"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 1.], dtype=float32)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FTWf6Cf-8Jme",
    "outputId": "1256b170-33dc-4171-f2ff-7a3d7ddd74e3"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_hat)\n",
    "_ = plt.axvline(x=0.5, color='orange')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RNljSx3v8Jmh"
   },
   "outputs": [],
   "source": [
    "pct_auc = roc_auc_score(y_valid, y_hat)*100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SO_N9lJG8Jmj",
    "outputId": "20968a52-8ca0-44d3-abf6-a1382bba5cde"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'99.53'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"{:0.2f}\".format(pct_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vU3hnA298Jmo"
   },
   "outputs": [],
   "source": [
    "float_y_hat = []\n",
    "for y in y_hat:\n",
    "    float_y_hat.append(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zrTf-aQl8Jmr"
   },
   "outputs": [],
   "source": [
    "ydf = pd.DataFrame(list(zip(float_y_hat, y_valid)), columns=['y_hat', 'y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zAyKh_mX8Jmu",
    "outputId": "611224b8-f980-47df-d596-9aa3a5811009"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_hat</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.063339e-02</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.014386e-17</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.304533e-09</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.999671e-01</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.311461e-04</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.268511e-01</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.017311e-03</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.128616e-06</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9.535550e-01</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          y_hat                               y\n",
       "0  5.063339e-02  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0]\n",
       "1  3.014386e-17  [0.0, 0.0, 1.0, 0.0, 0.0, 0.0]\n",
       "2  1.304533e-09  [0.0, 0.0, 0.0, 0.0, 1.0, 0.0]\n",
       "3  0.000000e+00  [0.0, 0.0, 0.0, 1.0, 0.0, 0.0]\n",
       "4  9.999671e-01  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
       "5  6.311461e-04  [0.0, 0.0, 1.0, 0.0, 0.0, 0.0]\n",
       "6  1.268511e-01  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0]\n",
       "7  5.017311e-03  [0.0, 0.0, 0.0, 1.0, 0.0, 0.0]\n",
       "8  1.128616e-06  [0.0, 0.0, 0.0, 0.0, 1.0, 0.0]\n",
       "9  9.535550e-01  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ydf.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "dense_sentiment_classifier.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
