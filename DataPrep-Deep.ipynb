{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook prepares the data for NN models.\n",
    "#### Clean the start and the end of each activity session\n",
    "#### Select important columns and one hot encoding\n",
    "#### Break down to shorter time periods\n",
    "#### Encode output and shuffle the data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data frame vocabulary:\n",
    "- *df* = the raw csv dataframe\n",
    "- *df_clean* = final cleaned and processed dataframe\n",
    "- *df_level* = df for each activity level\n",
    "- *df_level_clean* = clean version of df_level\n",
    "- *df_temp* = a helper dtaframe to store temporary data for each participant and each level\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "n_ignore = 600 # ignores 20 sec with a frequency of 30 Hz\n",
    "window_size_second = 3\n",
    "frequency = 30\n",
    "lenght_of_each_seq = window_size_second * frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir =  'Z:/Research/dfuller/Walkabilly/studies/smarphone_accel/data/Ethica_Jaeger_Merged/pocket/'\n",
    "input_file_name = 'pocket_with_couns_and_vec_meg_30Hz.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(input_dir + input_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Break it down to several CSV file, Lying, Sitting, Walking, Running3, Running5, Running7\n",
    "\n",
    "Keep gender, weight and height\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "participant_list = list(df.participant_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record_time</th>\n",
       "      <th>x_axis</th>\n",
       "      <th>y_axis</th>\n",
       "      <th>z_axis</th>\n",
       "      <th>participant_id</th>\n",
       "      <th>wear_location</th>\n",
       "      <th>V.O2</th>\n",
       "      <th>VO2.kg</th>\n",
       "      <th>V.CO2</th>\n",
       "      <th>V.E</th>\n",
       "      <th>trimmed_activity</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>counts_vec_mag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-07T10:30:01Z</td>\n",
       "      <td>0.266111</td>\n",
       "      <td>-0.069464</td>\n",
       "      <td>0.966880</td>\n",
       "      <td>108</td>\n",
       "      <td>pock</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lying</td>\n",
       "      <td>164.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>30</td>\n",
       "      <td>Female</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>74.1485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-07T10:30:01.033300Z</td>\n",
       "      <td>0.266401</td>\n",
       "      <td>-0.069351</td>\n",
       "      <td>0.963832</td>\n",
       "      <td>108</td>\n",
       "      <td>pock</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lying</td>\n",
       "      <td>164.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>30</td>\n",
       "      <td>Female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>74.1485</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   record_time    x_axis    y_axis    z_axis  participant_id  \\\n",
       "0         2019-01-07T10:30:01Z  0.266111 -0.069464  0.966880             108   \n",
       "1  2019-01-07T10:30:01.033300Z  0.266401 -0.069351  0.963832             108   \n",
       "\n",
       "  wear_location  V.O2  VO2.kg  V.CO2  V.E trimmed_activity  height  weight  \\\n",
       "0          pock   NaN     NaN    NaN  NaN            Lying   164.0    68.0   \n",
       "1          pock   NaN     NaN    NaN  NaN            Lying   164.0    68.0   \n",
       "\n",
       "   age  gender     x    y     z  counts_vec_mag  \n",
       "0   30  Female  13.0  0.0  73.0         74.1485  \n",
       "1   30  Female   NaN  NaN   NaN         74.1485  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select important columns, x, y, z, height, weight, age, gender, also participant_id for cleaning. remove it later\n",
    "important_columns = ['x_axis','y_axis','z_axis','participant_id','trimmed_activity','height','weight','age','gender']\n",
    "df = df[important_columns].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dfuller\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\dfuller\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# change gender to dummy\n",
    "df.gender[df['gender']=='Female'] = 0\n",
    "df.gender[df['gender']=='Male'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_axis</th>\n",
       "      <th>y_axis</th>\n",
       "      <th>z_axis</th>\n",
       "      <th>participant_id</th>\n",
       "      <th>trimmed_activity</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.266111</td>\n",
       "      <td>-0.069464</td>\n",
       "      <td>0.966880</td>\n",
       "      <td>108</td>\n",
       "      <td>Lying</td>\n",
       "      <td>164.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.266401</td>\n",
       "      <td>-0.069351</td>\n",
       "      <td>0.963832</td>\n",
       "      <td>108</td>\n",
       "      <td>Lying</td>\n",
       "      <td>164.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.262441</td>\n",
       "      <td>-0.067394</td>\n",
       "      <td>0.943335</td>\n",
       "      <td>108</td>\n",
       "      <td>Lying</td>\n",
       "      <td>164.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     x_axis    y_axis    z_axis  participant_id trimmed_activity  height  \\\n",
       "0  0.266111 -0.069464  0.966880             108            Lying   164.0   \n",
       "1  0.266401 -0.069351  0.963832             108            Lying   164.0   \n",
       "2  0.262441 -0.067394  0.943335             108            Lying   164.0   \n",
       "\n",
       "   weight  age gender  \n",
       "0    68.0   30      0  \n",
       "1    68.0   30      0  \n",
       "2    68.0   30      0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_L = df[df['trimmed_activity'] == 'Lying']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Get rid of the first and last 20 Seconds for avoiding noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_ignore = 600 # ignores 20 sec with a frequency of 30 Hz\n",
    "\n",
    "# for partip in participant_list:\n",
    "#     df_temp = df_L[df_L['participant_id'] == partip]\n",
    "#     df_temp_nrow = df_temp.shape[0]\n",
    "#     df_temp = df_temp[n_ignore:df_temp_nrow-n_ignore]\n",
    "#     df_sub_clean = pd.concat(df_sub_clean, df_temp)\n",
    "\n",
    "# # the first row of sub is zeros    \n",
    "# df_L = df_sub_clean[1:,]\n",
    "# df_L = df_L.drop('participant_id', axis = 1)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on Lying level\n",
      "working on 108 participant\n",
      "working on 111 participant\n",
      "working on 112 participant\n",
      "working on 113 participant\n",
      "working on 114 participant\n",
      "working on 115 participant\n",
      "working on 116 participant\n",
      "working on 117 participant\n",
      "working on 118 participant\n",
      "working on 119 participant\n",
      "working on 120 participant\n",
      "working on 121 participant\n",
      "working on 122 participant\n",
      "working on 124 participant\n",
      "working on 125 participant\n",
      "working on 126 participant\n",
      "working on 123 participant\n",
      "working on 127 participant\n",
      "working on 129 participant\n",
      "working on 130 participant\n",
      "working on 131 participant\n",
      "working on 132 participant\n",
      "working on 128 participant\n",
      "working on 133 participant\n",
      "working on 136 participant\n",
      "working on 137 participant\n",
      "working on 138 participant\n",
      "working on 159 participant\n",
      "working on 142 participant\n",
      "working on 143 participant\n",
      "working on 109 participant\n",
      "working on 144 participant\n",
      "working on 145 participant\n",
      "working on 146 participant\n",
      "working on 147 participant\n",
      "working on 149 participant\n",
      "working on 152 participant\n",
      "working on 150 participant\n",
      "working on 151 participant\n",
      "working on 153 participant\n",
      "working on 139 participant\n",
      "working on 134 participant\n",
      "working on 141 participant\n",
      "working on 155 participant\n",
      "working on 140 participant\n",
      "working on 154 participant\n",
      "working on 156 participant\n",
      "working on 157 participant\n",
      "working on Sitting level\n",
      "working on 108 participant\n",
      "working on 111 participant\n",
      "working on 112 participant\n",
      "working on 113 participant\n",
      "working on 114 participant\n",
      "working on 115 participant\n",
      "working on 116 participant\n",
      "working on 117 participant\n",
      "working on 118 participant\n",
      "working on 119 participant\n",
      "working on 120 participant\n",
      "working on 121 participant\n",
      "working on 122 participant\n",
      "working on 124 participant\n",
      "working on 125 participant\n",
      "working on 126 participant\n",
      "working on 123 participant\n",
      "working on 127 participant\n",
      "working on 129 participant\n",
      "working on 130 participant\n",
      "working on 131 participant\n",
      "working on 132 participant\n",
      "working on 128 participant\n",
      "working on 133 participant\n",
      "working on 136 participant\n",
      "working on 137 participant\n",
      "working on 138 participant\n",
      "working on 159 participant\n",
      "working on 142 participant\n",
      "working on 143 participant\n",
      "working on 109 participant\n",
      "working on 144 participant\n",
      "working on 145 participant\n",
      "working on 146 participant\n",
      "working on 147 participant\n",
      "working on 149 participant\n",
      "working on 152 participant\n",
      "working on 150 participant\n",
      "working on 151 participant\n",
      "working on 153 participant\n",
      "working on 139 participant\n",
      "working on 134 participant\n",
      "working on 141 participant\n",
      "working on 155 participant\n",
      "working on 140 participant\n",
      "working on 154 participant\n",
      "working on 156 participant\n",
      "working on 157 participant\n",
      "working on Self Pace walk level\n",
      "working on 108 participant\n",
      "working on 111 participant\n",
      "working on 112 participant\n",
      "working on 113 participant\n",
      "working on 114 participant\n",
      "working on 115 participant\n",
      "working on 116 participant\n",
      "working on 117 participant\n",
      "working on 118 participant\n",
      "working on 119 participant\n",
      "working on 120 participant\n",
      "working on 121 participant\n",
      "working on 122 participant\n",
      "working on 124 participant\n",
      "working on 125 participant\n",
      "working on 126 participant\n",
      "working on 123 participant\n",
      "working on 127 participant\n",
      "working on 129 participant\n",
      "working on 130 participant\n",
      "working on 131 participant\n",
      "working on 132 participant\n",
      "working on 128 participant\n",
      "working on 133 participant\n",
      "working on 136 participant\n",
      "working on 137 participant\n",
      "working on 138 participant\n",
      "working on 159 participant\n",
      "working on 142 participant\n",
      "working on 143 participant\n",
      "working on 109 participant\n",
      "working on 144 participant\n",
      "working on 145 participant\n",
      "working on 146 participant\n",
      "working on 147 participant\n",
      "working on 149 participant\n",
      "working on 152 participant\n",
      "working on 150 participant\n",
      "working on 151 participant\n",
      "working on 153 participant\n",
      "working on 139 participant\n",
      "working on 134 participant\n",
      "working on 141 participant\n",
      "working on 155 participant\n",
      "working on 140 participant\n",
      "working on 154 participant\n",
      "working on 156 participant\n",
      "working on 157 participant\n",
      "working on Running 3 METs level\n",
      "working on 108 participant\n",
      "working on 111 participant\n",
      "working on 112 participant\n",
      "working on 113 participant\n",
      "working on 114 participant\n",
      "working on 115 participant\n",
      "working on 116 participant\n",
      "working on 117 participant\n",
      "working on 118 participant\n",
      "working on 119 participant\n",
      "working on 120 participant\n",
      "working on 121 participant\n",
      "working on 122 participant\n",
      "working on 124 participant\n",
      "working on 125 participant\n",
      "working on 126 participant\n",
      "working on 123 participant\n",
      "working on 127 participant\n",
      "working on 129 participant\n",
      "working on 130 participant\n",
      "working on 131 participant\n",
      "working on 132 participant\n",
      "working on 128 participant\n",
      "working on 133 participant\n",
      "working on 136 participant\n",
      "working on 137 participant\n",
      "working on 138 participant\n",
      "working on 159 participant\n",
      "working on 142 participant\n",
      "working on 143 participant\n",
      "working on 109 participant\n",
      "working on 144 participant\n",
      "working on 145 participant\n",
      "working on 146 participant\n",
      "working on 147 participant\n",
      "working on 149 participant\n",
      "working on 152 participant\n",
      "working on 150 participant\n",
      "working on 151 participant\n",
      "working on 153 participant\n",
      "working on 139 participant\n",
      "working on 134 participant\n",
      "working on 141 participant\n",
      "working on 155 participant\n",
      "working on 140 participant\n",
      "working on 154 participant\n",
      "working on 156 participant\n",
      "working on 157 participant\n",
      "working on Running 5 METs level\n",
      "working on 108 participant\n",
      "working on 111 participant\n",
      "working on 112 participant\n",
      "working on 113 participant\n",
      "working on 114 participant\n",
      "working on 115 participant\n",
      "working on 116 participant\n",
      "working on 117 participant\n",
      "working on 118 participant\n",
      "working on 119 participant\n",
      "working on 120 participant\n",
      "working on 121 participant\n",
      "working on 122 participant\n",
      "working on 124 participant\n",
      "working on 125 participant\n",
      "working on 126 participant\n",
      "working on 123 participant\n",
      "working on 127 participant\n",
      "working on 129 participant\n",
      "working on 130 participant\n",
      "working on 131 participant\n",
      "working on 132 participant\n",
      "working on 128 participant\n",
      "working on 133 participant\n",
      "working on 136 participant\n",
      "working on 137 participant\n",
      "working on 138 participant\n",
      "working on 159 participant\n",
      "working on 142 participant\n",
      "working on 143 participant\n",
      "working on 109 participant\n",
      "working on 144 participant\n",
      "working on 145 participant\n",
      "working on 146 participant\n",
      "working on 147 participant\n",
      "working on 149 participant\n",
      "working on 152 participant\n",
      "working on 150 participant\n",
      "working on 151 participant\n",
      "working on 153 participant\n",
      "working on 139 participant\n",
      "working on 134 participant\n",
      "working on 141 participant\n",
      "working on 155 participant\n",
      "working on 140 participant\n",
      "working on 154 participant\n",
      "working on 156 participant\n",
      "working on 157 participant\n",
      "working on Running 7 METs level\n",
      "working on 108 participant\n",
      "working on 111 participant\n",
      "working on 112 participant\n",
      "working on 113 participant\n",
      "working on 114 participant\n",
      "working on 115 participant\n",
      "working on 116 participant\n",
      "working on 117 participant\n",
      "working on 118 participant\n",
      "working on 119 participant\n",
      "working on 120 participant\n",
      "working on 121 participant\n",
      "working on 122 participant\n",
      "working on 124 participant\n",
      "working on 125 participant\n",
      "working on 126 participant\n",
      "working on 123 participant\n",
      "working on 127 participant\n",
      "working on 129 participant\n",
      "working on 130 participant\n",
      "working on 131 participant\n",
      "working on 132 participant\n",
      "working on 128 participant\n",
      "working on 133 participant\n",
      "working on 136 participant\n",
      "working on 137 participant\n",
      "working on 138 participant\n",
      "working on 159 participant\n",
      "working on 142 participant\n",
      "working on 143 participant\n",
      "working on 109 participant\n",
      "working on 144 participant\n",
      "working on 145 participant\n",
      "working on 146 participant\n",
      "working on 147 participant\n",
      "working on 149 participant\n",
      "working on 152 participant\n",
      "working on 150 participant\n",
      "working on 151 participant\n",
      "working on 153 participant\n",
      "working on 139 participant\n",
      "working on 134 participant\n",
      "working on 141 participant\n",
      "working on 155 participant\n",
      "working on 140 participant\n",
      "working on 154 participant\n",
      "working on 156 participant\n",
      "working on 157 participant\n"
     ]
    }
   ],
   "source": [
    "# repeat for all PE levels \n",
    "\n",
    "# get levels to loop thru\n",
    "PE_levels = df.trimmed_activity.unique()\n",
    "\n",
    "# ceate empty df\n",
    "df_clean = pd.DataFrame(columns = important_columns)\n",
    "\n",
    "for level in PE_levels:\n",
    "    print(\"working on {} level\".format(level))\n",
    "    df_level = df[df['trimmed_activity'] == level]\n",
    "    df_level_clean = pd.DataFrame(columns = important_columns)\n",
    "\n",
    "\n",
    "    for partip in participant_list:\n",
    "        df_temp = df_level[df_level['participant_id'] == partip]\n",
    "        df_temp_nrow = df_temp.shape[0]\n",
    "        # ignore the noisy data in the beginning and the end\n",
    "        df_temp = df_temp.iloc[n_ignore:df_temp_nrow-n_ignore,]\n",
    "        \n",
    "        # make it devisable by sequence length\n",
    "        number_of_sequences = df_temp.shape[0] // lenght_of_each_seq\n",
    "        n_row= number_of_sequences * lenght_of_each_seq\n",
    "        df_temp = df_temp.iloc[:n_row,]\n",
    "    \n",
    "        df_level_clean = pd.concat([df_level_clean, df_temp])\n",
    "        print(\"working on {} participant\".format(partip))\n",
    "\n",
    "\n",
    "    df_clean = pd.concat([df_clean, df_level_clean])\n",
    "\n",
    "  \n",
    "# df_clean = df_clean.drop('participant_id', axis = 1)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We need to create something like an 1-D image. so we can feed it to CNN.\n",
    "For image processing, an image has three channels, and two dimenssion. So for a 264*264 pixel image,the shape is:\n",
    "264, 264, 3\n",
    "\n",
    "In our case, if we use a window of 3 second we have 90 reading(30 Hz), similar to pixel number in images. And we have 3 dimenssion,z,y, andz so the input shape is (90,3)\n",
    "\n",
    "Now if we have n input (n sequesnces or n images), the inout shape is (n,90,3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data generator\n",
    "\n",
    "### Create sequence of acceleration data\n",
    "\n",
    "For each axis we do:\n",
    "\n",
    "\n",
    "Get the axis and put in a numpy array\n",
    "\n",
    "reshape it to (n,1) where n is the total length of acceleration data for a specific activity and person\n",
    "\n",
    "stack all the axis horizontally. e.i. bind columns\n",
    "\n",
    "reshape to (number_of_sequences, lenght_of_each_seq, number_of_axis i.e. 3) \n",
    "\n",
    "Note that n =number_of_sequences * lenght_of_each_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create meta data and labels\n",
    "\n",
    "\n",
    "How to create meta data:\n",
    "- follow the pre cell, but don't need to stack anything. We will process age, gender, labesl, etc separetely.\n",
    "- the dim is **number_of_sequences, lenght_of_each_seq,**\n",
    "- use numpy max and get the max (or min) and reduce the matrix to an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_axis</th>\n",
       "      <th>y_axis</th>\n",
       "      <th>z_axis</th>\n",
       "      <th>participant_id</th>\n",
       "      <th>trimmed_activity</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>0.270312</td>\n",
       "      <td>-0.066408</td>\n",
       "      <td>0.961516</td>\n",
       "      <td>108</td>\n",
       "      <td>Lying</td>\n",
       "      <td>164.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601</th>\n",
       "      <td>0.269653</td>\n",
       "      <td>-0.066482</td>\n",
       "      <td>0.959821</td>\n",
       "      <td>108</td>\n",
       "      <td>Lying</td>\n",
       "      <td>164.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602</th>\n",
       "      <td>0.263954</td>\n",
       "      <td>-0.065834</td>\n",
       "      <td>0.942104</td>\n",
       "      <td>108</td>\n",
       "      <td>Lying</td>\n",
       "      <td>164.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>0.262995</td>\n",
       "      <td>-0.066327</td>\n",
       "      <td>0.941666</td>\n",
       "      <td>108</td>\n",
       "      <td>Lying</td>\n",
       "      <td>164.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>0.264132</td>\n",
       "      <td>-0.066887</td>\n",
       "      <td>0.947164</td>\n",
       "      <td>108</td>\n",
       "      <td>Lying</td>\n",
       "      <td>164.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       x_axis    y_axis    z_axis participant_id trimmed_activity  height  \\\n",
       "600  0.270312 -0.066408  0.961516            108            Lying   164.0   \n",
       "601  0.269653 -0.066482  0.959821            108            Lying   164.0   \n",
       "602  0.263954 -0.065834  0.942104            108            Lying   164.0   \n",
       "603  0.262995 -0.066327  0.941666            108            Lying   164.0   \n",
       "604  0.264132 -0.066887  0.947164            108            Lying   164.0   \n",
       "\n",
       "     weight age gender  \n",
       "600    68.0  30      0  \n",
       "601    68.0  30      0  \n",
       "602    68.0  30      0  \n",
       "603    68.0  30      0  \n",
       "604    68.0  30      0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Acceleration sequense data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We will have  70392  sequences to available.\n",
      "(6335280, 1)\n",
      "(6335280, 2)\n",
      "(6335280, 3)\n",
      "(70392, 90, 3)\n"
     ]
    }
   ],
   "source": [
    "# sequence generator\n",
    "# output size (number_of_sequences, lenght_of_each_seq, number_of_axis i.e. 3)\n",
    "\n",
    "n_row = df_clean.shape[0]\n",
    "number_of_sequences = int(n_row / lenght_of_each_seq)\n",
    "print(\"We will have \", number_of_sequences ,\" sequences to available.\")\n",
    "accel_array = np.empty((n_row,0))\n",
    "\n",
    "\n",
    "# repeat for all axes\n",
    "axes_list = ['x_axis','y_axis','z_axis']\n",
    "for axis in axes_list:\n",
    "\n",
    "    # filter based on axis\n",
    "    working_array = df_clean[axis]\n",
    "\n",
    "    working_array = np.array(working_array).reshape(n_row,1)\n",
    "    accel_array = np.hstack((accel_array, working_array))\n",
    "    \n",
    "    print(accel_array.shape)\n",
    "n_axis = len(axes_list)\n",
    "accel_array = accel_array.reshape((number_of_sequences, lenght_of_each_seq, 3)) \n",
    "print(accel_array.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing reshaping = Worked\n",
    "x = np.arange(8).reshape(8,1)\n",
    "# print(x)\n",
    "y = np.arange(8,16).reshape(8,1)\n",
    "z = np.arange(16,24).reshape(8,1)\n",
    "a = np.hstack((x,y,z))\n",
    "a = a.reshape((2,4,3))\n",
    "a[0,:,:].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Meta data generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We will have  70392  sequences to available.\n",
      "(70392, 1)      (70392, 90, 1)\n",
      "(70392, 1)      (70392, 90, 1)\n",
      "(70392, 1)      (70392, 90, 1)\n",
      "(70392, 1)      (70392, 90, 1)\n",
      "(70392, 4)\n"
     ]
    }
   ],
   "source": [
    "# has the same logic as accelereation sequence generator\n",
    "# for each column output size (number_of_sequences,  1)\n",
    "# for all of them, the out put in meta_array  size ((number_of_sequences, len(mata_column_list)))\n",
    "\n",
    "\n",
    "\n",
    "n_row = df_clean.shape[0]\n",
    "number_of_sequences = int(n_row / lenght_of_each_seq)\n",
    "print(\"We will have \", number_of_sequences ,\" sequences to available.\")\n",
    "# repeat for all meta data columns \n",
    "meta_column_list = ['height','weight','age','gender']\n",
    "\n",
    "\n",
    "compressed_array = np.empty((number_of_sequences,1))\n",
    "meta_array = np.empty((number_of_sequences, 0))\n",
    "\n",
    "for meta in meta_column_list:\n",
    "\n",
    "    # filter based on meta data column\n",
    "    working_array = df_clean[meta]\n",
    "\n",
    "    working_array = np.array(working_array).reshape(number_of_sequences, lenght_of_each_seq, 1)\n",
    "    for i in range(number_of_sequences):\n",
    "        compressed_array[i] = working_array[i,].max()\n",
    "    \n",
    "    meta_array = np.hstack((meta_array, compressed_array))\n",
    "    print(compressed_array.shape, \"    \" , working_array.shape)\n",
    "print(meta_array.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We will have  70392  sequences to available.\n",
      "(70392, 90, 1)\n",
      "(70392, 1)\n",
      "[['Lying']\n",
      " ['Lying']\n",
      " ['Lying']\n",
      " ...\n",
      " ['Running 7 METs']\n",
      " ['Running 7 METs']\n",
      " ['Running 7 METs']]\n"
     ]
    }
   ],
   "source": [
    "# repeat for  trimmed activity which is the labels\n",
    "# has the same logic as accelereation sequence generator\n",
    "# for labels output size (number_of_sequences,  1)\n",
    "\n",
    "n_row = df_clean.shape[0]\n",
    "number_of_sequences = int(n_row / lenght_of_each_seq)\n",
    "print(\"We will have \", number_of_sequences ,\" sequences to available.\")\n",
    "label_column_list = ['trimmed_activity']\n",
    "\n",
    "\n",
    "label_array = np.empty((number_of_sequences,1), dtype=list)\n",
    "\n",
    "# as we only have one outcome ( label) we don;t need another array to store all of them\n",
    "# We could do it without the for loop as well\n",
    "for label in label_column_list:\n",
    "    # filter based on the column\n",
    "    working_array = df_clean[label]\n",
    "    working_array = np.array(working_array).reshape(number_of_sequences, lenght_of_each_seq, 1)\n",
    "    print(working_array.shape)\n",
    "    for i in range(number_of_sequences):\n",
    "        label_array[i] = working_array[i,0] \n",
    "print(label_array.shape)\n",
    "print(label_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check to see if the data is intact\n",
    "\n",
    "We ignored n_ignore data from the beginning of each activity. Therefore the first processed data in n_ignore th +1 data in the raw data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we start for  600  when indexing from the raw dataframe\n",
      "[ 0.26965277 -0.06648238  0.95982104]\n",
      "[164.  68.  30.   0.]\n",
      "['Lying']\n",
      "       x_axis    y_axis    z_axis  participant_id trimmed_activity  height  \\\n",
      "600  0.270312 -0.066408  0.961516             108            Lying   164.0   \n",
      "601  0.269653 -0.066482  0.959821             108            Lying   164.0   \n",
      "602  0.263954 -0.065834  0.942104             108            Lying   164.0   \n",
      "\n",
      "     weight  age gender  \n",
      "600    68.0   30      0  \n",
      "601    68.0   30      0  \n",
      "602    68.0   30      0  \n"
     ]
    }
   ],
   "source": [
    "print(\"we start for \",n_ignore,\" when indexing from the raw dataframe\")\n",
    "print(accel_array[0,1])\n",
    "print(meta_array[0])\n",
    "print(label_array[0])\n",
    "print(df.iloc[n_ignore:n_ignore+3,])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the results as numpy objects\n",
    "location = 'pocket'\n",
    "output_file_name = input_dir +location + '-deep-data'\n",
    "np.savez_compressed(output_file_name,\n",
    "                    acceleration_data=accel_array,\n",
    "                    metadata=meta_array,\n",
    "                    labels=label_array\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['Lying', 'Running 3 METs', 'Running 5 METs', 'Running 7 METs',\n",
       "        'Self Pace walk', 'Sitting'], dtype=object)]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "# encoder = OneHotEncoder()\n",
    "# encoder.fit(label_array)\n",
    "# encoder.categories_\n",
    "\n",
    "# label_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test to make sure the data is currect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save everything, probably in 2 different files\n",
    "# numpy.save(\"mydata.npy\",a)\n",
    "# b = numpy.load(\"mydata.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load from another notebook and it's ready fro CNN, RNN , etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Igonre the following cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def breakDown(working_df, window_size=3):\n",
    "    # truncate df rows to add the helper column\n",
    "    n_row = working_df.shape[0] // window_size * window_size\n",
    "    working_df= working_df.iloc[0:n_row]\n",
    "    # help grouping\n",
    "    helper_col_df = pd.DataFrame(data = list(range(0,window_size,1)) * (n_row//window_size), columns=['counter'])\n",
    "    working_df = working_df.reset_index()\n",
    "    working_df = pd.concat((working_df,helper_col_df), axis=1)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15, 1)\n",
      "(15, 9)\n",
      "     index    x_axis    y_axis    z_axis  participant_id trimmed_activity  \\\n",
      "0  6669936  0.423716  0.109737 -0.028063             157   Running 7 METs   \n",
      "1  6669937  0.676451 -0.316380 -0.249883             157   Running 7 METs   \n",
      "2  6669938  0.251704 -0.119815  0.003971             157   Running 7 METs   \n",
      "3  6669939  0.455297 -0.550348  0.078684             157   Running 7 METs   \n",
      "4  6669940 -0.173043  0.076750  0.257825             157   Running 7 METs   \n",
      "5  6669941 -0.441424  0.122000  0.213023             157   Running 7 METs   \n",
      "6  6669942 -0.479676  2.545022 -0.615723             157   Running 7 METs   \n",
      "\n",
      "   height  weight  age gender  counter  \n",
      "0   159.0    55.0   29      0        0  \n",
      "1   159.0    55.0   29      0        1  \n",
      "2   159.0    55.0   29      0        2  \n",
      "3   159.0    55.0   29      0        0  \n",
      "4   159.0    55.0   29      0        1  \n",
      "5   159.0    55.0   29      0        2  \n",
      "6   159.0    55.0   29      0        0  \n"
     ]
    }
   ],
   "source": [
    "window_size = 3\n",
    "working_df = df_temp.iloc[0:16,].copy() # replace with the reall data inside the loops\n",
    "\n",
    "# truncate df rows to add the helper column\n",
    "n_row = working_df.shape[0] // window_size * window_size\n",
    "working_df= working_df.iloc[0:n_row]\n",
    "# help grouping\n",
    "helper_col_df = pd.DataFrame(data = list(range(0,window_size,1)) * (n_row//window_size), columns=['counter'])\n",
    "print(helper_col_df.shape)\n",
    "print(working_df.shape)\n",
    "working_df = working_df.reset_index()\n",
    "working_df = pd.concat((working_df,helper_col_df), axis=1)\n",
    "print(working_df.head(7))\n",
    " # here we need to groupby the counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5,)"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# working_df = working_df.drop(columns='counter') \n",
    "working_df.head()\n",
    "result = working_df.groupby(by='counter').apply((lambda x: melting(x)))\n",
    "result = result.to_numpy()\n",
    "result[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "def melting(df):\n",
    "    x_axis_df = df.melt(value_vars='x_axis')\n",
    "    return x_axis_df.value.to_numpy().transpose()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 15)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_axis_df = working_df.melt(value_vars='x_axis')\n",
    "y_axis_df = working_df.melt(value_vars='y_axis')\n",
    "z_axis_df = working_df.melt(value_vars='z_axis')\n",
    "# working_df.head(2)\n",
    "df_temp.head(2)\n",
    "working_df.head(2)\n",
    "x_axis_np = x_axis_df.value.to_numpy()\n",
    "y_axis_np = y_axis_df.value.to_numpy()\n",
    "z_axis_np = z_axis_df.value.to_numpy()\n",
    "total_np = np.array([x_axis_np, y_axis_np, z_axis_np])\n",
    "total_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# break into 150(use a variable) readings chunks by adding a helper column\n",
    "# spread based on the helper column\n",
    "# bind all the files of different levels\n",
    "# export as the final output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>counter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    counter\n",
       "0         0\n",
       "1         1\n",
       "2         2\n",
       "3         0\n",
       "4         1\n",
       "5         2\n",
       "6         0\n",
       "7         1\n",
       "8         2\n",
       "9         0\n",
       "10        1\n",
       "11        2\n",
       "12        0\n",
       "13        1\n",
       "14        2"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "helper_col_df = pd.DataFrame(data = list(range(0,window_size,1)) * (n_row//window_size), columns=['counter'])\n",
    "helper_col_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# before training\n",
    "# suffle\n",
    "# Seperate to x and y (y is the levels)\n",
    "# one hot encode y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Given date string not likely a datetime.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-89-7c9766b4a610>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mperiod_range\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\period.py\u001b[0m in \u001b[0;36mperiod_range\u001b[1;34m(start, end, periods, freq, name)\u001b[0m\n\u001b[0;32m    962\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    963\u001b[0m     data, freq = PeriodArray._generate_range(start, end, periods, freq,\n\u001b[1;32m--> 964\u001b[1;33m                                              fields={})\n\u001b[0m\u001b[0;32m    965\u001b[0m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPeriodArray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfreq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfreq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    966\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mPeriodIndex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\period.py\u001b[0m in \u001b[0;36m_generate_range\u001b[1;34m(cls, start, end, periods, freq, fields)\u001b[0m\n\u001b[0;32m    231\u001b[0m                 raise ValueError('Can either instantiate from fields '\n\u001b[0;32m    232\u001b[0m                                  'or endpoints, but not both')\n\u001b[1;32m--> 233\u001b[1;33m             \u001b[0msubarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfreq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_ordinal_range\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mperiods\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfreq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    234\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mfield_count\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    235\u001b[0m             \u001b[0msubarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfreq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_range_from_fields\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfreq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfields\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\period.py\u001b[0m in \u001b[0;36m_get_ordinal_range\u001b[1;34m(start, end, periods, freq, mult)\u001b[0m\n\u001b[0;32m    870\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    871\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mstart\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 872\u001b[1;33m         \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPeriod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfreq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    873\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    874\u001b[0m         \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPeriod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfreq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/tslibs/period.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslibs.period.Period.__new__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/tslibs/parsing.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslibs.parsing.parse_time_string\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/tslibs/parsing.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslibs.parsing.parse_datetime_string_with_reso\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Given date string not likely a datetime."
     ]
    }
   ],
   "source": [
    "pd.period_range(1,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IntervalIndex([(0, 1], (1, 2], (2, 3], (3, 4]],\n",
       "              closed='right',\n",
       "              dtype='interval[int64]')"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.interval_range(start=0, periods=4, freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(1,15,1)) * 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
